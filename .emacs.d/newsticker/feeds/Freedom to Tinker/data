;; -*- coding: utf-8 -*-
(("Freedom to Tinker" "Research and expert commentary on digital technologies in public life" "https://freedom-to-tinker.com" (21317 36648 536651 117000) feed 0 nil nil ((title nil "Freedom to Tinker") (atom:link ((href . "https://freedom-to-tinker.com/feed/") (rel . "self") (type . "application/rss+xml"))) (link nil "https://freedom-to-tinker.com") (description nil "Research and expert commentary on digital technologies in public life") (lastBuildDate nil "Wed, 09 Apr 2014 16:17:28 +0000") (language nil "en-US") (sy:updatePeriod nil "hourly") (sy:updateFrequency nil "1") (generator nil "http://wordpress.org/?v=3.5") (item nil (title nil "How to protect yourself from Heartbleed") (link nil "https://freedom-to-tinker.com/blog/felten/how-to-protect-yourself-from-heartbleed/") (comments nil "https://freedom-to-tinker.com/blog/felten/how-to-protect-yourself-from-heartbleed/#comments") (pubDate nil "Wed, 09 Apr 2014 14:57:41 +0000") (dc:creator nil "Ed Felten") (guid ((isPermaLink . "false")) "https://freedom-to-tinker.com/?p=9774") (description nil "The Heartbleed vulnerability is one of the worst Internet security problems we have seen. I&#8217;ll be writing more about what we can learn from Heartbleed and the response to it. For now, here is a quick checklist of what you can do to protect yourself. If you are a regular user: Most of the sites [...]") (content:encoded nil "<p>The Heartbleed vulnerability is one of the worst Internet security problems we have seen.  I&#8217;ll be writing more about what we can learn from Heartbleed and the response to it.  </p><p>For now, here is a quick checklist of what you can do to protect yourself.</p><p><strong>If you are a regular user:</strong></p><p>Most of the sites you use were probably vulnerable.  Your password might have been leaked from any one of them.  Unless you&#8217;re sure that a site was <em>never</em> vulnerable, you should change your password on that site.  (It&#8217;s not enough that a site is invulnerable <em>now</em>, because your password could have leaked before the site was fixed.)</p><p>Yes, it&#8217;s a pain to change your passwords, but you were really meaning to change them at some point anyway, weren&#8217;t you?  Now is a good time.  (It&#8217;s also a good time to turn on two-factor authentication, on sites that offer it.)</p><p>But, before you change your password on a site, you need to make sure that that site has closed any remaining vulnerability.  Look for an unequivocal statement from the site that (1) they are no longer vulnerable and (2) they have changed the private encryption key they use to protect HTTPS traffic.   Once you&#8217;re sure that they have done those two things, then you should go ahead and change your password on the site.  If they haven&#8217;t done those two things, then it&#8217;s best to wait until they do.  Make yourself a note to come back and check in a few days.  </p><p>The bad news is that some of your private information might have leaked from a vulnerable site.  It will be very difficult to tell whether this happened, even for the site itself, and nearly impossible to undo a leak if it did happen. </p><p><strong>If you run a website that supports HTTPS, and you run your own server:</strong></p><ul><li>Go to http://filippo.io/Heartbleed/ and enter the name of your site, to test whether your site is vulnerable.   If you&#8217;re not vulnerable, you&#8217;re done.  If you are vulnerable, carry out the following steps.</li><li>Upgrade your server software to a non-vulnerable version.  I can&#8217;t give you general advice on how to do this because it depends on which software you are running.  Once you have done the upgrade, go back to http://filippo.io/Heartbleed/ and verify that you are no longer vulnerable.</li><li>After upgrading your software, generate a new SSL/TLS key and get a certificate for the new key.  Start using the new key and certificate.  (This is necessary because an attacker could have gotten your old key.)</li><li>Revoke the certificate you were previously using.  (This is necessary because an attacker who got your old key could be using your old key and certificate to impersonate your site.)</li><li>Have your users change the passwords that they use to log in to your site. (This is necessary because users&#8217; existing passwords could have been leaked. You need to get your house in order by carrying out the previous steps, before users can safely change passwords.)</li></ul><p><strong>If you run a website that supports HTTPS, and you use a web hosting service:</strong><br />
In this case, the hosting service runs the web server that powers your site.</p><ul><li>Find out from the hosting service whether its server was ever vulnerable to Heartbleed attacks.  If you&#8217;re confident that it was never vulnerable, then you&#8217;re good.  Otherwise, carry out the following steps.</li><li>Wait until the hosting service has upgraded its software to a non-vulnerable version.  Once they have done the upgrade, you should be able to go to http://filippo.io/Heartbleed/ and enter the address of your site, and be told that it is not vulnerable.   If this isn&#8217;t true yet, ask the hosting service to fix the problem, then wait a while and repeat.</li><li>Once the hosting service has upgraded its software and the test site shows you as not vulnerable, generate a new SSL/TLS key and get a certificate for the new key.  Start using the new key and certificate.  (This is necessary because an attacker could have gotten your old key.)</li><li>Revoke the certificate you were previously using.  (This is necessary because an attacker who got your old key could be using your old key and certificate to impersonate your site.)</li><li>If your site assigns passwords to users, have your users change the passwords that they use to log in to your site. (This is necessary because users&#8217; existing passwords could have been leaked. You need to get your house in order by carrying out the previous steps, before users can safely change passwords.)</li></ul>
") (wfw:commentRss nil "https://freedom-to-tinker.com/blog/felten/how-to-protect-yourself-from-heartbleed/feed/") (slash:comments nil "6")) (item nil (title nil "Cookies that give you away: The surveillance implications of web tracking") (link nil "https://freedom-to-tinker.com/blog/dreisman/cookies-that-give-you-away-the-surveillance-implications-of-web-tracking/") (comments nil "https://freedom-to-tinker.com/blog/dreisman/cookies-that-give-you-away-the-surveillance-implications-of-web-tracking/#comments") (pubDate nil "Fri, 04 Apr 2014 10:30:25 +0000") (dc:creator nil "Dillon Reisman") (category nil "cookies") (category nil "NSA") (category nil "surveillance") (guid ((isPermaLink . "false")) "https://freedom-to-tinker.com/?p=9732") (description nil "[Today we have another announcement of an exciting new research paper. Undergraduate Dillon Reisman, for his senior thesis, applied our web measurement platform to study some timely questions. -Arvind Narayanan] Over the past three months we’ve learnt that NSA uses third-party tracking cookies for surveillance (1, 2). These cookies, provided by a third-party advertising or analytics network [...]") (content:encoded nil "<p><i>[Today we have another announcement of an exciting new research paper. Undergraduate Dillon Reisman, for his senior thesis, applied our <a href=\"https://freedom-to-tinker.com/blog/randomwalker/web-measurement-for-fairness-and-transparency/\" target=\"_blank\">web measurement platform</a> to study some timely questions. -Arvind Narayanan]</i></p><p>Over the past three months we’ve learnt that NSA uses third-party tracking cookies for surveillance (<a href=\"http://www.washingtonpost.com/blogs/the-switch/wp/2013/12/10/nsa-uses-google-cookies-to-pinpoint-targets-for-hacking/\">1</a>, <a href=\"https://firstlook.org/theintercept/article/2014/03/12/nsa-plans-infect-millions-computers-malware/\">2</a>). These cookies, provided by a third-party advertising or analytics network (e.g. doubleclick.com, scorecardresearch.com), are ubiquitous on the web, and tag users’ browsers with unique pseudonymous IDs. In <a href=\"http://randomwalker.info/publications/cookie-surveillance.pdf\">a new paper</a>, we study just how big a privacy problem this is. We quantify what an observer can learn about a user&#8217;s web traffic by purely passively eavesdropping on the network, and arrive at surprising answers.</p><p>At first sight it doesn’t seem possible that eavesdropping alone can reveal much. First the eavesdropper on the Internet backbone sees millions of HTTP requests and responses. How can he associate the third-party HTTP request containing a user’s cookie with request to the first-party web page that the browser visited, which doesn’t contain the cookie? Second, how can visits to different first parties be linked to each other? And finally, even if all the web traffic for a single user can be linked together, how can the adversary go from a set pseudonymous cookies to the user’s real-world identity?</p><p><img class=\"aligncenter\" alt=\" \" src=\"https://lh6.googleusercontent.com/r00CfwTjy7KfYRzeh9NORNAMye90G3UTRYJXDWTJTl3599IyUEthHs7FZFEb8S6JPE9mQw4qYCxChixyjQxWxXQ-leyJ8SgJXZ95DPwjuyOQ04UEM0nC0ZUKOXQXXg\" width=\"579px;\" height=\"448px;\" /></p><p>The diagram illustrates how the eavesdropper can use multiple third-party cookies to link traffic. When a user visits ‘www.exampleA.com,’ the response contains the embedded tracker X, with an ID cookie ‘xxx’. The visits to exampleA and to X are tied together by IP address, which typically doesn’t change within a single page visit [1]. Another page visited by the same user might embed tracker Y bearing the pseudonymous cookie ‘yyy’. If the two page visits were made from different IP addresses, an eavesdropper seeing these cookies can’t tell that the same browser made both visits. But if a third page, however, embeds both trackers X and Y, then the eavesdropper will know that IDs ‘xxx’ and ‘yyy’ belong to the same user. This method applied iteratively has the potential of tying together a lot of the traffic of a single user.</p><p dir=\"ltr\">Once we had this idea, we wanted to test if it would actually work in practice. Everything depends on just how densely third-party trackers are actually embedded on sites. We conducted automated web crawls of 65 simulated users’ web browsing over three months, and found that unique cookies are so prevalent that the eavesdropper can reliably link 90% of a user’s web page visits to the same pseudonymous ID. (We omitted pages that embed no ID cookies at all, but those are a minority.)</p><p dir=\"ltr\">We also found that the cookie linking method is extremely robust and succeeds under a variety of conditions (Section 4.1). We considered how variations in cookie expiration dates, the size of the user’s history (i.e., the number of pages visited), and the types of pages visited affect the eavesdropper’s changes, and found the impact to be minimal. Perhaps most significantly, however, we found that this surveillance method can still link about 50% of a user’s history to the same pseudonymous ID even with just 25% of the current density of trackers on the web. This means that even if 75% of sites or trackers adopt mitigation strategies (such as deploying HTTPS), the eavesdropper still learns a lot.</p><p dir=\"ltr\"><img class=\"aligncenter\" alt=\" \" src=\"https://lh6.googleusercontent.com/w89sqWi4ZKGwI_50PZFfo09BbWfrTVSr-PiAqDKwdVBWhx1WaxYfUmnRWnyULdRf4QAnoFFoDe2a4851uymJijwZwellnr6ktrgqNePLLRNMsXZok2blDVbhn1esbQ\" width=\"405px;\" height=\"199px;\" /></p><p dir=\"ltr\">Finally, we studied how an eavesdropper might learn the real-world identity behind a cluster of web pages associated with a pseudonymous ID. It turns out that this is surprisingly easy &#8212; many sites display real-world attributes such as real name, username, or email on unencrypted pages to logged in users, which means that the eavesdropper gets to see these identifiers. We conducted a survey of such leakage on popular sites, and found that over half of popular sites with account creation leak some form of real-world identity (Section 4.2).</p><p dir=\"ltr\">While it’s no surprise that web traffic contains sensitive information about individuals, what we’ve shown is just how complete a profile can be extracted even if the user’s traffic is mixed with millions of other users. Further, an eavesdropper can connect these profiles to real-world identities without needing the co-operation of any websites. While HTTPS deployment by trackers can help, the only practical solution at the current time seems to be for users to install anti-tracking and anonymity tools.</p><p>&nbsp;</p><p dir=\"ltr\">[1] An exception is if the user routes traffic through Tor. Different requests can take different paths and the exit node IPs will be different. Thus, use of Tor with application-layer anonymization (e.g., Tor browser bundle) defeats our attack.</p><p dir=\"ltr\"><em>[Edit: minor edit for clarity.]</em></p>
") (wfw:commentRss nil "https://freedom-to-tinker.com/blog/dreisman/cookies-that-give-you-away-the-surveillance-implications-of-web-tracking/feed/") (slash:comments nil "9")) (item nil (title nil "Historic E.U. Net Neutrality Win Shows Maturing Digital Rights Advocacy") (link nil "https://freedom-to-tinker.com/blog/axel/historic-e-u-net-neutrality-win-shows-maturing-digital-rights-advocacy/") (comments nil "https://freedom-to-tinker.com/blog/axel/historic-e-u-net-neutrality-win-shows-maturing-digital-rights-advocacy/#comments") (pubDate nil "Thu, 03 Apr 2014 19:23:06 +0000") (dc:creator nil "Axel Arnbak") (guid ((isPermaLink . "false")) "https://freedom-to-tinker.com/?p=9750") (description nil "After a 5-year long campaign by European and U.S. digital rights NGOs, today the European Parliament turned a dubious Commission proposal on its head to safeguard the principle of net neutrality. It&#8217;s a historic win, and all over the news. It also shows how digital rights advocacy is maturing. The legislative proposal and its amendments [...]") (content:encoded nil "<p>After a 5-year long campaign by European and U.S. digital rights NGOs, today the European Parliament turned a dubious Commission proposal on its head to safeguard the principle of net neutrality. It&#8217;s a historic win, and <a href=\"http://www.nytimes.com/2014/04/04/business/international/eu-lawmakers-approve-tough-net-neutrality-rules.html?_r=0\" target=\"_blank\">all</a><a href=\"http://www.nytimes.com/2014/03/31/business/international/european-lawmakers-prepare-to-vote-on-net-neutrality.html\" target=\"_blank\">over</a><a href=\"http://blogs.wsj.com/digits/2014/04/02/who-says-european-net-neutrality-politics-is-boring/\" target=\"_blank\">the</a><a href=\"www.bbc.com/news/technology-26865869\" target=\"_blank\">news</a>. It also shows how digital rights advocacy is maturing. <img title=\"More...\" alt=\" \" src=\"https://www.axelarnbak.nl/wp-includes/js/tinymce/plugins/wordpress/img/trans.gif\" /></p><p>The <a href=\"http://www.europarl.europa.eu/sides/getDoc.do?pubRef=-//EP//TEXT+REPORT+A7-2014-0190+0+DOC+XML+V0//EN\" target=\"_blank\">legislative proposal and its amendments</a> contain a clear definition of net neutrality and quite solid provisions. With the final text, as always, the devil will be in the details. For one, the enforcement provisions could have been stronger. Perhaps some national governments, such as <a href=\"https://www.axelarnbak.nl/2014/03/13/translation-dutch-net-freedom-laws-2011-net-neutrality-no-commercial-wiretapping-no-3-strikes/\" target=\"_blank\">The Netherlands where net neutrality has already been enshrined in law for some years now</a>, will lobby for more discretion to enforce the rules on the national level.</p><p>Of course, it ain&#8217;t over till the fat lady sings: the E.U. Council (the relevant ministers of national governments) will debate the Parliament legislative text on 5/6 June 2014. Will it respect a democratic vote, or be influenced by the Telecoms lobby? History learns that industry lobbies are almost certain to leverage more power towards the E.U. Council, than citizens have with regard to their respective governments. Europe is often used as a proxy for politics that can&#8217;t be realized on a national level. Moreover, the May 2014 Parliament election comes before those negotiations in June, potentially changing the political dynamics: the current majority for net neutrality could change. So the jury is still out.</p><p>But what&#8217;s truly fascinating about the net neutrality vote, and perfect case study material, is how digital rights advocacy in Europe is maturing. A <a href=\"http://savetheinternet.eu/\" target=\"_blank\">slick campaign</a> was set up that got more people to call/fax/e-mail their representatives than back in the day with the historic no-vote on ACTA. That&#8217;s a second crucial point: ACTA was a no-vote, but here digital rights and consumer advocates were able to suggest meaningful legislative reform amidst intense political struggle. Expert amendments were suggested, a dubious proposal by the (Dutch) E.U. Commissioner &#8212; primarily interested in quick wins on roaming tariffs &#8212; delegitimized and the immensely powerful telecoms lobby were faced head-on. Quite nasty tactics by hostile E.U. Parliamentarians and lobbies were cleverly tackled. Unsurprisingly, and completely missing the point, even the <a href=\"http://pastebin.com/ezMCuF5s\" target=\"_blank\">child abuse card was played the night before the final vote</a>. Until the last minute, digital rights groups &#8212; in a highly dispersed Europe and with the help of U.S. NGOs &#8212; have shown that they can play ball as one front, when it really matters.</p><p>We see this more often these days, and it should give rise to some opportunism on E.U. policymaking. Apart from ACTA and net neutrality, data protection, mandatory website blocking and data retention also come to mind. Digital rights advocacy has matured in the last five years. Sure, the web has turned public and private online life into a surveillance society &#8212; so why be optimistic? Because at the same time, it appears that the obscure Brussels lobbying arena feels the surveillance of the public more and more.  Of course, we&#8217;re nowhere near a transparent political process, but these are interesting times.</p><p>For now, it&#8217;s a historic win for digital rights in Europe, that may spur spill-over effects to the U.S. and other countries as well. Time to enjoy a beer and some sleep for those that did the heavy lifting, including MEPs Amelia Andersdottir, Catherine Trautmann, Marietje Schaake and Petra Kammerevert and organizations such as <a href=\"https://www.edri.org\" target=\"_blank\">European Digital Rights</a>, <a href=\"http://www.laquadrature.net/en\" target=\"_blank\">La Quadrature du Net</a> and <a href=\"https://www.bitsoffreedom.nl\" target=\"_blank\">Bits of Freedom.</a> Remember those names, you&#8217;ll be hearing them again in a not so distant fascinating future.</p>
") (wfw:commentRss nil "https://freedom-to-tinker.com/blog/axel/historic-e-u-net-neutrality-win-shows-maturing-digital-rights-advocacy/feed/") (slash:comments nil "0")) (item nil (title nil "Secure protocols for accountable warrant execution") (link nil "https://freedom-to-tinker.com/blog/felten/secure-protocols-for-accountable-warrant-execution/") (comments nil "https://freedom-to-tinker.com/blog/felten/secure-protocols-for-accountable-warrant-execution/#comments") (pubDate nil "Wed, 02 Apr 2014 11:22:03 +0000") (dc:creator nil "Ed Felten") (guid ((isPermaLink . "false")) "https://freedom-to-tinker.com/?p=9708") (description nil "Last week the press reported that the White House will seek to redesign the NSA’s mass phone call data program, so that data will be held by the phone companies and accessed by the NSA, subject to a new warrant requirement. The Foreign Intelligence Surveillance Court will issue the warrants. Today Josh Kroll and I, [...]") (content:encoded nil "<p>Last week the press <a href=\"http://www.nytimes.com/2014/03/25/us/obama-to-seek-nsa-curb-on-call-data.html\"> reported</a> that the White House will seek to redesign the NSA’s mass phone call data program, so that data will be held by the phone companies and accessed by the NSA, subject to a new warrant requirement.  The Foreign Intelligence Surveillance Court will issue the warrants.</p><p>Today Josh Kroll and I, with colleagues at Stanford University, released a <a href=\"http://www.cs.princeton.edu/~felten/warrant-paper.pdf\">draft paper</a> on how to use cryptography to implement warrants to data in a secure, private, and accountable way.  </p><p>Our solution is a set of multi-party cryptographic protocols involving three primary parties: a data source who has data records, an investigator who wants access to data held by the data source, and a court (or other authorizer) who issues an order or warrant to authorize access to a record.  For example, a phone company might be the data source, the NSA might be the investigator, and the Foreign Intelligence Surveillance Court might be the court that issues an order.  Alternatively, an email provider might be the data source, an FBI agent might be the investigator, and a senior FBI official might act as the &#8220;court&#8221; that issues a National Security Letter.  Although we use words like &#8220;court&#8221;, &#8220;order&#8221;, and &#8220;investigator&#8221;, the protocol has wider application to situations where Party A is authorizing Party B to access data held by Party C, with legally defined requirements for access.</p><p>The protocol uses cryptography to guarantee several security, privacy, and accountability properties:</p><ul><li>When the court issues an order, it publishes a sealed version of the order. If challenged later, the court can unseal the order and reveal which record it covered.</li><li>Until the order is unsealed, only the court and the investigator can see which record the order covers.  If and when the order is unsealed, everyone can see which record it covered.</li><li>The investigator does not learn the contents of any record, unless there is a valid order for that record and the court has published a valid sealed version of that order.</li></ul><p>A counterintuitive aspect of our protocols is that an order can be executed, thereby giving the investigator access to the record covered by the order, without the data source necessarily learning (at the time) which record the investigator accessed.</p><p>These properties can be viewed as a set of checks on the power of the parties, to prevent any dishonest party from getting access to information without leaving a suitable trail.  When the trail itself is supposed to be secret, the protocol aims for accountability&#8212;for example, the court can issue an unjustified order but the court must commit to the order so that the violation will be uncovered if the court’s actions are challenged later.</p><p>Our paper gives more precise definitions of the desired properties, how the protocols work, and why the protocols achieve the desired properties.  We build on the work of previous researchers, as cited in our paper, and we present several versions of the protocol, with different security properties.</p><p>Our approach is feasible, even for very large data sets.  Our paper describes our work on implementing one of our more advanced protocols, and we show by experiment that the protocol is reasonably fast even for data sets of national scope.   We have released the <a href=\"http://www.cs.princeton.edu/~felten/warrant-benchmark.tar.gz\">code</a> we used to do these performance measurements.</p><p>We are releasing this paper now because there are important debates going on about how to organize lawful access to data by intelligence agencies.  We want to make the point that technology allows these processes to be both more secure and more accountable.  </p><p>We urge policymakers to consider how cryptography can make warrant regimes more secure for all parties, and more accountable.  Expert agencies within government, such as NIST, might provide input on these issues, in consultation with experts inside and outside of government.</p>
") (wfw:commentRss nil "https://freedom-to-tinker.com/blog/felten/secure-protocols-for-accountable-warrant-execution/feed/") (slash:comments nil "3")) (item nil (title nil "New research: Better wallet security for Bitcoin") (link nil "https://freedom-to-tinker.com/blog/stevenag/new-research-better-wallet-security-for-bitcoin/") (comments nil "https://freedom-to-tinker.com/blog/stevenag/new-research-better-wallet-security-for-bitcoin/#comments") (pubDate nil "Fri, 28 Mar 2014 16:26:01 +0000") (dc:creator nil "Steven Goldfeder") (guid ((isPermaLink . "false")) "https://freedom-to-tinker.com/?p=9718") (description nil "[UPDATE (April 3, 2014): We've found an error in our paper. In the threshold signature scheme that we used, there are restrictions on the threshold value. In particular if the key is shared over a degree t polynomial, then 2t+1 players (not t+1) are required to to construct a signature. We thought that this could [...]") (content:encoded nil "<p><strong>[UPDATE (April 3, 2014): We've found an error in our paper. In the threshold signature scheme that we used, there are restrictions on the threshold value. In particular if the key is shared over a degree t polynomial, then 2t+1 players (not t+1) are required to to construct a signature. We thought that this could be reduced to t+1, but our technique was flawed. We are exploring various modifications, and we will post further details when we have an update.]</strong></p><p dir=\"ltr\">The Bitcoin ecosystem has been plagued by thefts and losses that have affected both businesses and individuals. The security of a Bitcoin wallet rests entirely on the security of its associated private keys which can digitally sign transactions to irreversibly spend the coins in the wallet. In a <a href=\"http://www.cs.princeton.edu/~stevenag/bitcoin_threshold_signatures.pdf\">new paper</a>, we show how to use the cryptographic technique of <em>threshold signatures</em> to increase the security of both corporate and individual wallets.</p><p>Perhaps Bitcoin’s toughest security challenge is protecting Internet-connected wallets from insider threats. Such <em><a href=\"https://en.bitcoin.it/wiki/Hot_wallet\">hot wallets</a></em>cannot be kept in highly secure, offline cold storage. One good way for businesses to mitigate this vulnerability is to have hot wallets jointly controlled by multiple parties. This way, no party can independently steal corporate funds. In our paper, we show how to achieve <em>joint control</em> of wallets using threshold signatures.</p><p>The problem of implementing joint control is more important and more difficult for a Bitcoin wallet than it is for a traditional bank account. Whereas regular bank transactions have recovery mechanisms if fraud is detected, Bitcoin transactions are irreversible and their pseudonymity makes it difficult to identify thieves and attempt to recover stolen funds. Moreover, while large bank transactions typically require human action to complete, Bitcoin transactions&#8211;no matter how large&#8211;require only a cryptographic signature to authorize.</p><p>The threshold signature approach to joint control works like this: the private key controlling the wallet is split between devices belonging to <em>n</em> different participants such that any <em>m</em> of them can jointly produce a digital signature, while a group of less than <em>m</em> participants cannot. Crucially, in the process of producing a signature, <em>the key is never reconstructed</em>. As long as an attacker has compromised fewer than <em>m</em> devices, the key remains secure.</p><p>Our method for achieving joint control has significant benefits over Bitcoin’s “<a href=\"https://gist.github.com/gavinandresen/4039433\">multi-signature</a>” transactions. With multi-signatures, each party’s signature is published to the block chain, whereas threshold signatures allow participants to privately create a single signature which is indistinguishable from ordinary Bitcoin signatures. You can think of our solution as “stealth multi-signatures.” This improves anonymity and confidentiality while keeping transactions a constant size, reducing fees and providing flexibility to scale to an arbitrary number of parties.</p><p>We implemented a threshold signature protocol and have used it to demonstrate  joint control over a Bitcoin wallet. We produced <a href=\"https://blockchain.info/tx/55451090debe729120d4a2e6b49bd3d5cabb881e753ccda0f5ea499a3438de9b\">this transaction</a> using a 9-of-12 threshold signature. If you click on the link to see the transaction details, you won’t see anything special; it looks like any regular transaction. That’s exactly the point!</p><p>Joint control is one of several security measures that can be built using threshold signatures. In our paper, we show that threshold signatures can be used as a primitive to build schemes for <em>secure bookkeeping</em> and <em>secure delegation</em>. One application that we’re particularly excited about is using threshold signatures to achieve <em>two-factor security</em> for personal wallets. In a follow-up post, we will elaborate on this application and discuss our ongoing efforts to build a two-factor secure wallet.</p><p>The main lesson from our work is that a spectrum of traditional internal financial controls can be translated to the Bitcoin world by novel application of cryptography. We hope that the security measures we’ve proposed will become standard in Bitcoin usage, and we are looking forward to working with developers and others who want to adopt our solutions.</p><p>We’d like to thank Greg Maxwell and Andrew Miller for providing useful feedback.</p>
") (wfw:commentRss nil "https://freedom-to-tinker.com/blog/stevenag/new-research-better-wallet-security-for-bitcoin/feed/") (slash:comments nil "7")) (item nil (title nil "Reflecting on Sunshine Week") (link nil "https://freedom-to-tinker.com/blog/jtignor/reflecting-on-sunshine-week/") (comments nil "https://freedom-to-tinker.com/blog/jtignor/reflecting-on-sunshine-week/#comments") (pubDate nil "Wed, 26 Mar 2014 13:15:32 +0000") (dc:creator nil "Jeffrey Tignor") (category nil "Government transparency") (guid ((isPermaLink . "false")) "https://freedom-to-tinker.com/?p=9710") (description nil "Last Wednesday evening, I attended the D.C. Open Government Summit: Street View, which took place at the National Press Club in conjunction with Sunshine Week. The Summit was sponsored by the D.C. Open Government Coalition, a non-profit that “seeks to enhance the public’s access to government information and ensure the transparency of government operations of [...]") (content:encoded nil "<p>Last Wednesday evening, I attended the D.C. Open Government Summit: Street View, which took place at the National Press Club in conjunction with Sunshine Week. The Summit was sponsored by the D.C. Open Government Coalition, a non-profit that “seeks to enhance the public’s access to government information and ensure the transparency of government operations of the District of Columbia.” The Summit successfully focused on two main ideas – using government information to innovate and using government information to inform. I left the Summit encouraged by the enthusiasm for innovation and transparency in the attendees and among some District of Columbia government leaders, but also discouraged because there was a consensus that Washington, DC is still far behind cities such as New York, Kansas City, and Boston in using technology for innovation in government and there is not a vision or financial commitment from the Mayor’s office to facilitate government-wide progress.</p><p>In her keynote address, Traci Hughes, the Director of the District of Columbia Office of Open Government, commented that her office only has two employees and almost no budget beyond that for salaries. She has, therefore, been looking to certain District government agencies and non-profit partners outside of government to support her vision for a more open government. Ms. Hughes commented, for example, that the Council of the District of Columbia’s General Counsel has been a great partner, as has been the Office of the State Superintendent of Education, which has been a leader in making information about education available to parents. Ms. Hughes recognized Code for DC, the all-volunteer local chapter of Code for America, for producing “ANC Finder,” an application that provides residents, based on their address, with information about their Advisory Neighborhood Commission – DC’s hyper-local level of government where each Commissioner represents approximately 2,000 people.</p><p>Ms. Hughes, however, has a broader vision for open access to the District of Columbia’s data and records. Ms. Hughes stated that the Council of the District of Columbia and the Mayor need to pass legislation to drive the open government process. In addition, the city must do more to bridge the gaps between people with varying levels of Internet access. I interpreted this statement as her way of saying that many more city services should be accessible through mobile devices. Indeed, a 2013 Pew study indicates that 10% of urban residents have a smartphone, but no home broadband connection.</p><p>Making government services available through mobile devices was one of the themes of the evening. The representatives from Code for DC stressed the importance of moving government processes to mobile platforms. The process of applying for public housing, for example, often involves filling out a different paper form for each potential housing option for which a person is applying. While the non-profit Bread for the City is currently helping people with the paper forms, Code for DC volunteers are working toward a technology-based solution. In addition, people are lobbying to make filing a Freedom of Information Act request and contesting a property tax assessment possible through mobile devices. I had a great side conversation with a Code for DC volunteer who has mapped the DC restaurants that have been cited recently for health code violations. His next step is developing a mobile app. Given the ubiquity of the violations, I was glad I had already eaten.</p><p>Beyond mobile, one of the most impressive recent innovations by the DC government is Advisory Neighborhood Commission 3F live streaming its monthly meetings. Advisory Neighborhood Commission meetings are not typically broadcast on public access television, therefore live streaming makes meetings available, for example, to people with kids who can’t get out in the evening and senior citizens or people with disabilities who cannot get to the meeting location. Live streaming uses only $75 of the Advisory Neighborhood Commission’s budget per meeting and people can ask questions directly beneath the feed or by reaching out to the Advisory Neighborhood Commission’s Chairman via Twitter. Another Advisory Neighborhood Commission records its meetings and posts them on YouTube subsequently. While these are great solutions for constituents who are tech savvy and have fast home broadband connections, to reach the widest possible audience, Advisory Neighborhood Commissions still must continue to use both on-line and off-line engagement methods.</p><p>While increasing participation is very important, so is facilitating accountability. A local activist and Washington Post reporter both discussed the importance of responses to FOIA requests in conducting research, particularly on under-the-radar issues that are nonetheless affecting city residents’ lives. FOIAs have been a critical tool in preventing legal on-line gambling in DC and exposing corruption in the Office of the Chief Financial Officer regarding commercial property assessments.</p><p>Based on the Summit, here are my three recommendations: (1) The DC Office of Open Government needs to have a more productive and collaborative relationship with the Mayor’s Office. The Mayor’s office needs to promote a culture that makes sharing information with both the public and across the city government a priority; (2) Cities that are integrating technology into governance effectively, such as New York, Boston, and Philadelphia, have someone leading those efforts from the Mayor’s office. Washington, DC needs leadership at that level; and (3) To eliminate the inconsistencies across city agencies, the DC government needs to establish written, uniform policies for responding to FOIAs and providing data sets that are easy to manipulate by members of the public and post these policies where the public can review them. The seeds of an open, efficient government exist, but will only grow with strong and committed leadership.</p>
") (wfw:commentRss nil "https://freedom-to-tinker.com/blog/jtignor/reflecting-on-sunshine-week/feed/") (slash:comments nil "3")) (item nil (title nil "Algorithms can be more accountable than people") (link nil "https://freedom-to-tinker.com/blog/felten/algorithms-can-be-more-accountable-than-people/") (comments nil "https://freedom-to-tinker.com/blog/felten/algorithms-can-be-more-accountable-than-people/#comments") (pubDate nil "Wed, 19 Mar 2014 12:06:40 +0000") (dc:creator nil "Ed Felten") (guid ((isPermaLink . "false")) "https://freedom-to-tinker.com/?p=9696") (description nil "At an academic meeting recently, I was surprised to hear some social scientists accept as obviously correct the claim that involving &#8220;algorithms&#8221; in decision-making, instead of sticking with good old-fashioned human decision-making, necessarily reduces accountability and increases the risk of bias. I tend to believe the opposite, that making processes algorithmic improves our ability to [...]") (content:encoded nil "<p>At an academic meeting recently, I was surprised to hear some social scientists accept as obviously correct the claim that involving &#8220;algorithms&#8221; in decision-making, instead of sticking with good old-fashioned human decision-making, necessarily reduces accountability and increases the risk of bias.  I tend to believe the opposite, that making processes algorithmic improves our ability to understand why they give the results they do.  Let me explain why.</p><p>Consider a process to decide who receives some award or benefit; and suppose we want to make sure the process is not biased against some disadvantaged group, which I&#8217;ll call Group G.  If a person just makes the decision, we can ask them whether they were fair to members of Group G.  Or we can ask them why decided the way they did.  Either way, they can simply lie about their true motivation and process, to construct a story that is consistent with non-discrimination; or they might honestly believe their decision was fair even though it reflected unconscious bias. At the risk of massive understatement: history teaches that this kind of bias in human decision-making is difficult to prevent.</p><p>An algorithm, by contrast, cannot hide from everyone the details of how it reached its decision.  If you want to know that an algorithm didn&#8217;t use information about a person&#8217;s Group G status, you can verify that the Group G status wasn&#8217;t provided to the algorithm.  Or, if you prefer, you can re-run the algorithm with the Group G status field changed, to see if the result would have been different.  Or you can collect statistics on whether certain parts of the algorithm have a disparate impact on Group G members as compared to the rest of the population.</p><p>This is not to say that everything about algorithms is easy.  There are plenty of hard problems in understanding algorithms, both in theory and in practice.  My point is merely that if you want to understand how a decision was made, or you want to build in protections to make sure the decision process has certain desirable properties, you&#8217;re better off working with an algorithm than with a human decision, because the algorithm can tell you how it got from inputs to outputs.</p><p>When people complain that algorithms aren&#8217;t transparent, the real problem is usually that someone is keeping the algorithm or its input data secret.  What makes the process non-transparent is that the result is emitted without explanation&#8212;which is a non-transparent approach no matter what is behind the curtain, a person or a machine.</p><p>Of course, a company might be justified legally in keeping their algorithm secret from you; and it might be good business for them to do so.  Regardless, it&#8217;s important to recognize that non-transparency is a choice they are making and not a consequence of the fact that they&#8217;re using computation.</p><p>If accountability is important to us&#8212;and I think it should be&#8212;then we should be developing ways to reconcile transparency with partial secrecy, so that a company or government agency can keep some aspects of their process secret when that is justified, while making other aspects transparent.  Transparency needn&#8217;t be an all-or-nothing choice.</p>
") (wfw:commentRss nil "https://freedom-to-tinker.com/blog/felten/algorithms-can-be-more-accountable-than-people/feed/") (slash:comments nil "9")) (item nil (title nil "Why Dorian Nakamoto Probably Isn’t Satoshi") (link nil "https://freedom-to-tinker.com/blog/felten/why-dorian-nakamoto-probably-isnt-satoshi/") (comments nil "https://freedom-to-tinker.com/blog/felten/why-dorian-nakamoto-probably-isnt-satoshi/#comments") (pubDate nil "Tue, 11 Mar 2014 13:23:30 +0000") (dc:creator nil "Ed Felten") (category nil "bitcoin") (category nil "Satoshi") (guid ((isPermaLink . "false")) "https://freedom-to-tinker.com/?p=9691") (description nil "When Newsweek published its cover story last week claiming to have identified the creator of Bitcoin, I tweeted that I was reserving judgment on their claim, pending more evidence. At this point it looks like they don&#8217;t have more evidence to show us&#8212;and that Newsweek is probably wrong. Bitcoin&#8217;s founder called himself &#8220;Satoshi Nakamoto&#8221; and [...]") (content:encoded nil "<p>When Newsweek published its <a href=\"http://mag.newsweek.com/2014/03/14/bitcoin-satoshi-nakamoto.html\">cover story</a> last week claiming to have identified the creator of Bitcoin, I tweeted that I was reserving judgment on their claim, pending more evidence.  At this point it looks like they don&#8217;t have more evidence to show us&#8212;and that Newsweek is probably wrong.</p><p>Bitcoin&#8217;s founder called himself &#8220;Satoshi Nakamoto&#8221; and is commonly called simply &#8220;Satoshi.&#8221;  Most people believe the founder chose this pseudonym to hide his/her/their identity.  Newsweek claims instead that a California engineer named Dorian Prentice Satoshi Nakamoto is Satoshi.  Dorian&#8217;s birth name was Satoshi Nakamoto but he legally changed his name to Dorian in 1973.  (For clarity, I&#8217;ll call him &#8220;Dorian&#8221;, and I&#8217;ll use &#8220;Satoshi&#8221; to refer to the Bitcoin founder, so that the question at hand is whether Dorian and Satoshi are the same person.)</p><p>Felix Salmon, who has some of the best commentary on the Dorian/Satoshi matter, <a href=\"http://blogs.reuters.com/felix-salmon/2014/03/10/satoshi-why-newsweek-isnt-convincing/\">points out</a> that Newsweek&#8217;s claim is almost universally disbelieved in the technical community. Part of the reason is the perception that Newsweek&#8217;s evidence is thin, and people in the tech community aren&#8217;t inclined to defer to the institutional reputation of Newsweek.</p><p>Another reason is that the Newsweek piece is craftily written to give the impression that the evidence is stronger than it is. This starts from the first two words of the piece, which refer to Dorian as &#8220;Satoshi Nakamoto&#8221;.  Only later is it made clear that that is not actually the man&#8217;s name, and hasn&#8217;t been his name at any point in the relevant period. Newsweek even says that his &#8220;name really is Satoshi Nakamoto&#8221;&#8212;which is not true. Newsweek wants us to believe that Dorian decided to sign the Bitcoin paper with his birth name rather than the name he had been using for 35 years.  There&#8217;s no explanation as to why he would have used his birth name on the Bitcoin paper.</p><p>The followup comments from Newsweek&#8217;s team don&#8217;t give much confidence either.  For example, Salmon quotes Newsweek editor Jim Impoco as saying &#8220;we eliminated every other possible person.&#8221;  That can&#8217;t possibly be true, or even close to true.  And it&#8217;s not the only time Newsweek people have fallen back on an argument that they couldn&#8217;t rule out Dorian, which is far short of saying that they have positive evidence that Dorian is Satoshi.</p><p>To me, one of the weakest points in Newsweek&#8217;s argument is their assertion that Dorian had the skills and background to create Bitcoin.  All they really have as evidence is that Dorian trained as a physicist, worked as an engineer, and is reputed to be very intelligent.  But none of that indicates that Dorian understood cryptography or distributed algorithms well enough to devise Bitcoin and write the <a href=\"https://bitcoin.org/bitcoin.pdf\">original Bitcoin paper</a>.  </p><p>The real Satoshi was obviously conversant with crypto&#8212;the Bitcoin design shows it, and the fluency of the crypto discussion in the paper tells us that Satoshi was well acquainted with the jargon and literature of the field.  Newsweek doesn&#8217;t offer any evidence that Dorian knew crypto.</p><p>Imagine you&#8217;re trying to track down the author of a novel written in fluent Hungarian.  Somebody points to a possible author who is a talented writer and speaks several languages.  One of the first questions you&#8217;ll ask is whether this candidate author knows Hungarian&#8212;especially when there are several known Hungarian speakers who are already suspected as possible authors.</p><p>Newsweek&#8217;s failure to ask such obvious questions&#8212;or their decision to plunge ahead despite not getting useful answers&#8212;is at the core of technologists&#8217; skepticism about the story.  If they didn&#8217;t think to ask whether Dorian knew crypto, then they were probably in over their heads technically which throws other aspects of their analysis into doubt.  If they did ask, didn&#8217;t find answers they liked, and wrote the piece anyway without mentioning the missing evidence, then they are confirming the impression that their decision to publish was driven more by a desire for page-views than by the strength of the story.</p><p>It&#8217;s not too late for Newsweek, or somebody else, to show up with evidence tying Dorian to Satoshi.  But unless that evidence does turn up, I will continue to believe that Dorian Nakamoto is not the creator of Bitcoin.</p>
") (wfw:commentRss nil "https://freedom-to-tinker.com/blog/felten/why-dorian-nakamoto-probably-isnt-satoshi/feed/") (slash:comments nil "4")) (item nil (title nil "FOIA: When the Exemptions Swallow the Rule") (link nil "https://freedom-to-tinker.com/blog/abridy/foia-when-the-exemptions-swallow-the-rule/") (comments nil "https://freedom-to-tinker.com/blog/abridy/foia-when-the-exemptions-swallow-the-rule/#comments") (pubDate nil "Wed, 05 Mar 2014 21:42:36 +0000") (dc:creator nil "Annemarie Bridy") (category nil "Exemption 4") (category nil "Exemption 5") (category nil "FOIA") (category nil "intellectual property") (category nil "IPEC") (category nil "SOPA") (guid ((isPermaLink . "false")) "https://freedom-to-tinker.com/?p=9678") (description nil "I&#8217;ve been researching and writing over the last few years on privately ordered—what the government calls “non-regulatory”—approaches to online IP enforcement. The gist of this approach is that members of trade groups representing different types of online intermediaries (broadband providers, payment processors, ad networks, online pharmacies) agree in private contracts or less formal “voluntary best [...]") (content:encoded nil "<p>I&#8217;ve been researching and writing over the last few years on privately ordered—what the government calls “non-regulatory”—approaches to online IP enforcement. The gist of this approach is that members of trade groups representing different types of online intermediaries (broadband providers, payment processors, ad networks, online pharmacies) agree in private contracts or less formal “voluntary best practices” documents to sanction or cut services to alleged IP infringers. I put quotes around “non-regulatory” not only because that’s the government’s word, but because the descriptor masks the fact that the government, at the behest of corporate rights owners, leans heavily on targeted intermediaries to negotiate and accept these agreements, all the while holding the threat of regulation over their heads. It has proven to be a very effective strategy. Many of the website blocking provisions in SOPA, which so memorably went down in flames of public outrage, have subsequently been implemented through these agreements, which belong to a broad category of regulatory practices that governance scholars call soft law.</p><p>Soft law arrangements between corporate rights owners and online intermediaries raise lots of concerns about due process and First Amendment rights, because such arrangements generally don’t provide for any neutral adjudication of accusations of infringement. (The “six strikes” protocol for deterring unlawful P2P file-sharing, about which you can read more <a title=\"&quot;Six Strikes&quot; Measured Against Five Norms\" href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2145059\" target=\"_blank\">here</a>, is a notable exception.) Moreover, there is no occasion for judicial scrutiny of the constitutional issues arising from these private arrangements, because there is no state action to trigger review. The arrangements have the effect of public law, insofar as they impact millions of members of the public, but without accountability to the public.</p><p>The way most of these arrangements work is as follows: A corporate rights owner makes an accusation of infringement or counterfeiting to a participating online intermediary. The complaint triggers some form of investigation internal to the intermediary.  Following the investigation, a sanction is imposed if the accused website operator cannot prove his or her innocence to the intermediary’s satisfaction. The sanction can be as severe as termination of service by the participating intermediary. Unlike in a civil court case, where the burden of proof is on the complainant, the burden under these protocols is on the accused to prove that she is not an infringer.</p><p>My current work in this area focuses on a code of voluntary best practices adopted by payment processors like Visa, MasterCard, and PayPal. The document is referenced multiple times in the Office of the Intellectual Property Enforcement Coordinator&#8217;s <a title=\"IPEC 2013 JSP\" href=\"http://www.whitehouse.gov/sites/default/files/omb/IPEC/2013-us-ipec-joint-strategic-plan.pdf\" target=\"_blank\">2013 Joint Strategic Plan</a>. In connection with my research, I asked a librarian with whom I work to submit a FOIA request to IPEC. I was curious to know the nature and extent of IPEC’s role as a midwife for these private enforcement arrangements. The request submitted was for “any documents pertaining to the development or drafting of a code of voluntary best practices for payment processors or intermediaries with respect to online transactions.”</p><p>IPEC recently <a title=\"IPEC Denial\" href=\"https://drive.google.com/file/d/0BzAtTUkwGWhbdHppUlhNbFpiZFE/edit?usp=sharing\" target=\"_blank\">responded</a> to the request. It said that it had located 60 relevant documents, including the four-page best practices document. It refused, however, to produce any of the responsive documents, citing Exemptions 4 and 5 of FOIA. <a title=\"FOIA Exemption 4 - DOJ Guide\" href=\"http://www.justice.gov/oip/exemption4.htm\" target=\"_blank\">Exemption 4</a> is basically for trade secrets entrusted to the government by third parties. <a title=\"FOIA Exemption 5 - DOJ Guide\" href=\"http://www.justice.gov/oip/exemption5.htm\" target=\"_blank\">Exemption 5</a> covers documents relating to the “deliberative process” of an agency engaged in rule-making. Given IPEC’s own claim that the voluntary best practices approach is non-regulatory, it seems highly questionable for IPEC to have invoked the deliberative process privilege. This is particularly true in light of President Obama&#8217;s directive to agency heads that a presumption of disclosure should apply to all decisions involving FOIA.</p><p>I was ultimately able to get the four-page best practices document from the International Anti-Counterfeiting Coalition (IACC), which operates as the point of intake for complaints by corporate rights owners. Given that the document is a collection of industry-embraced “best practices” that applies to every website operator that accepts third-party payments, it should be openly available. And IPEC&#8217;s role in its development should be a matter of public record.</p>
") (wfw:commentRss nil "https://freedom-to-tinker.com/blog/abridy/foia-when-the-exemptions-swallow-the-rule/feed/") (slash:comments nil "0")) (item nil (title nil "9 Problems of Government Hacking: Why IT-Systems Deserve Constitutional Protection") (link nil "https://freedom-to-tinker.com/blog/axel/9-problems-of-governments-hacking-why-it-systems-deserve-constitutional-protection/") (comments nil "https://freedom-to-tinker.com/blog/axel/9-problems-of-governments-hacking-why-it-systems-deserve-constitutional-protection/#comments") (pubDate nil "Thu, 20 Feb 2014 13:54:08 +0000") (dc:creator nil "Axel Arnbak") (guid ((isPermaLink . "false")) "https://freedom-to-tinker.com/?p=9656") (description nil "Governments around the world are increasingly hacking into IT-systems. But for every apparent benefit, government hacking creates deeper problems. Time to unpack 9 of them, and to discuss one unique perspective: in response to a proposed hacking law in 2008, the German Constitutional Court created a new human right protecting the &#8216;confidentiality and integrity of [...]") (content:encoded nil "<p>Governments around the world are increasingly hacking into IT-systems. But for every apparent benefit, government hacking creates deeper problems. Time to unpack 9 of them, and to discuss one unique perspective: in response to a proposed hacking law in 2008, the German Constitutional Court created a new human right protecting the &#8216;confidentiality and integrity of IT-systems&#8217;. The rest of the world should follow suit, and outlaw government hacking until its deep problems are addressed. </p><p>The <a href=\"http://www.wired.com/threatlevel/2013/12/nsa-hacking-catalogue/\">NSA</a> has been hacking for a while now, but the FBI, state and even local authorities also seem to be hacking at will without public accountability. Yale ISP and Chris Soghoian put together a great conference on <a href=\"http://www.yaleisp.org/event/law-enforcement-and-hacking\">Law Enforcement Hacking</a> to start the discussion (video online soon). Probably because of its <a href=\"http://www.axelarnbak.nl/2014/01/29/echr-fast-tracks-court-case-on-prism-and-tempora-and-very-angry-birds/\">constitutional DNA</a>, some law enforcement agencies in Europe have felt obliged to provide some details to the public. So in my short talk [<a href=\"http://www.axelarnbak.nl/wp-content/uploads/2014/02/Arnbak-Yale-ISP-Law-Enforcement-Hacking-Hydra-180214.pdf\">slides</a> pdf] I could discuss the 2010 <a href=\"http://www.bredolab.nl/\">Bredolab</a> botnet case, as well as the 2008 German Constitutional Court ‘Bundestrojaner’ ruling (<a href=\"http://www.bverfg.de/en/press/bvg08-022en.html\">English summary</a>, excellent <a href=\"http://www2.law.ed.ac.uk/ahrc/script-ed/vol6-1/abel.asp\">case note</a>).</p><p>In the landmark ‘Federal Trojan’ case, the German court established a constitutional right the ‘confidentiality and integrity of IT-systems’ (recognize the c.i.a.-triad?). It held that IT-systems are a qualitatively unique space with regard to surveillance, and that government hacking is a stepping stone into further violations. IT-systems contain our most intimate and sensitive data – ‘the core of personality’ that is inviolate under art. 1 of its Constitution. As devices are increasingly networked, a successful hack also gives insight into the lives of people you interact with. Furthermore, devices might become a one stop-shop for law enforcement as we concentrate and even structure our lives on our devices or in the cloud. The Court also reflected on the internet of things: if your future fridge has ‘general purpose’ functionality such as storage, it may fall within the new constitutional right in Germany. The Court left a possibility open for future hacking laws, but only if such laws meet the strictest legal criteria the Court set to date. Much stricter than placing a wiretap, or searching a house.</p><p>Its rulings have had global impact before. In 1983, the German election census case created a new constitutional right to ‘informational self-determination’, providing a solid constitutional basis in Europe for data protection and the concept of consent. Interestingly, the European Court of Human Rights case-law is slowly but surely moving forward: <i><a href=\"http://hudoc.echr.coe.int/sites/eng/pages/search.aspx?i=001-87510\">I v. Finland</a></i> (2008, para. 37-39) establishes positive obligations to ensure data security through specific legislation, and the <i><a href=\"http://hudoc.echr.coe.int/sites/eng/pages/search.aspx?i=001-117133\">Bernh Larsen v. Norway</a></i> case (2013, para. 106) rules that ‘all data on a server’ deserves protection, not ‘only’ personal data. The <a href=\"https://freedom-to-tinker.com/blog/axel/echr-fast-tracks-court-case-on-prism-and-tempora-and-very-angry-birds/\" target=\"_blank\">fast-tracked and pending post-Snowden case</a> may push it further.</p><p>Constitutional protection provides the normative baseline to evaluate government surveillance law. And to condemn actual practices. The Chaos Computer Club discovered a few years after the ‘Bundestrojaner’ (love that term) ruling that German authorities continued to spread malware anyway. It got hold of a Bundestrojan and reverse-engineered it (<a href=\"http://ccc.de/en/updates/2011/staatstrojaner\">recommended read</a>). With the Dutch bredolab case and the comments made by the panel at the conference, a fascinating problem set emerges:</p><ol><li><b>Judicial oversight</b>: judges face a hard or impossible task assessing the admissibility of government hacking warrant. The hacking tools and payload of government malware are either lied about (as in Germany), sealed in court documentation, or obscured in newspeak: ‘network investigation tool’ or any other of over 20 synonyms.</li><li><b>Insecure malware</b>: the reverse engineered German malware was of so deplorable state, that it in facr facilitated man in the middle attacks on suspect and even law enforcement IT-systems. The commends to the trojan were unencrypted. All serious problems in themselves, also creating evidence issues in trial. A suspect may be able to claim someone else has placed code or data on its device.</li><li><b>Bad incentives</b>: governments get an incentive to weaken information security. Bits of Freedom launched a campaign on the <a href=\"https://www.bof.nl/2013/10/25/experts-call-upon-the-vendors-of-antivirus-software-for-transparency/\">role of antivirus companies</a>, which many co-signed, asking whether they will let badly crafted government malware through. FinFisher and <a href=\"https://en.wikipedia.org/wiki/FinFisher\">FinSpy</a> are existing, deeply troubling commercial hacking toolkit governments can get installed at ISPs. And at the conference we discussed OS software updates as an attack vector for governments. Will Microsoft, Apple or Google be forced to comply with government requests to provide backdoored updates to specific targets?</li><li><b><a href=\"http://www.reuters.com/article/2013/08/05/us-dea-sod-idUSBRE97409R20130805\">Parallel Construction</a>:</b> a <a href=\"http://www.washingtonpost.com/blogs/the-switch/wp/2013/08/05/the-nsa-is-giving-your-phone-records-to-the-dea-and-the-dea-is-covering-it-up/\">major issue</a>. This occurs when, say, the NSA hacks into a target, tips a law enforcement agency, which re-creates the same evidence from a different source. At a CITP reading group, we discussed whether this had actually happened in the Silkroad/DPR case.</li><li><b>Jurisdiction</b>: when can a law enforcement agency act? What determines a sovereign territory? ‘Citizenship’, ‘ip-address block’, or can governments hack across borders? Dutch authorities used the Bredolab botnet to hack into and remotely install a unverifiable .executable at thousands of infected machines across the internet.</li><li><b>Constitutional scope: </b>if I VPN my connection to Amsterdam, even though I’m physically based in the U.S., do I lose my reasonable expectation to 4th amendment protection that I would have if the government would raid my U.S. apartment?</li><li><b>Geopolitics</b>: what about the geopolitical Pandora’s box? if you happen to hack into a foreign government system, what about reciprocity, or retaliation?</li><li><b>No reliable data</b>: We don’t have reliable data about the size of the problem. Not aggregate, not in individual cases. Threats are systematically inflated, the size of the Bredolab botnet easily by an <a href=\"http://www.internetgovernance.org/2010/11/01/dutch-police-inflates-bredolab-botnet-success-by-factor-of-ten-and-then-some/\">order of magnitude</a>.</li><li><b>Necessity</b>: is government malware, or hacking even necessary? Many well-respected technologists <a href=\"http://www.theguardian.com/commentisfree/2014/jan/06/nsa-tailored-access-operations-privacy\">frame</a> the debate as “either mass surveillance, or targeted hacking”. While I agree that mass surveillance and weakening of infrastructure is even more problematic, I think that frame is incorrect in this golden age of surveillance. Less problematic alternatives will exist: the recent takedown of Utopia, a TOR hidden service widely regarded as a Silk Road heir, employed intrusive but well-established <a href=\"http://www.om.nl/@162281/undercover-onderzoek/\">undercover techniques</a>.</li></ol><p>The list doesn’t end here. The cynic and realist would say, “it’s happening anyway so why bother?” The simple answer is: government hacking is different than a wiretap, so needs a specific policy response. Until aforementioned problems are addressed and legal safeguards are in place, judges should push back and government hacking should be considered what it currently is: illegal.</p>
") (wfw:commentRss nil "https://freedom-to-tinker.com/blog/axel/9-problems-of-governments-hacking-why-it-systems-deserve-constitutional-protection/feed/") (slash:comments nil "7")))) ("How to protect yourself from Heartbleed" "<p>The Heartbleed vulnerability is one of the worst Internet security problems we have seen.  I’ll be writing more about what we can learn from Heartbleed and the response to it.  </p><p>For now, here is a quick checklist of what you can do to protect yourself.</p><p><strong>If you are a regular user:</strong></p><p>Most of the sites you use were probably vulnerable.  Your password might have been leaked from any one of them.  Unless you’re sure that a site was <em>never</em> vulnerable, you should change your password on that site.  (It’s not enough that a site is invulnerable <em>now</em>, because your password could have leaked before the site was fixed.)</p><p>Yes, it’s a pain to change your passwords, but you were really meaning to change them at some point anyway, weren’t you?  Now is a good time.  (It’s also a good time to turn on two-factor authentication, on sites that offer it.)</p><p>But, before you change your password on a site, you need to make sure that that site has closed any remaining vulnerability.  Look for an unequivocal statement from the site that (1) they are no longer vulnerable and (2) they have changed the private encryption key they use to protect HTTPS traffic.   Once you’re sure that they have done those two things, then you should go ahead and change your password on the site.  If they haven’t done those two things, then it’s best to wait until they do.  Make yourself a note to come back and check in a few days.  </p><p>The bad news is that some of your private information might have leaked from a vulnerable site.  It will be very difficult to tell whether this happened, even for the site itself, and nearly impossible to undo a leak if it did happen. </p><p><strong>If you run a website that supports HTTPS, and you run your own server:</strong></p><ul><li>Go to http://filippo.io/Heartbleed/ and enter the name of your site, to test whether your site is vulnerable.   If you’re not vulnerable, you’re done.  If you are vulnerable, carry out the following steps.</li><li>Upgrade your server software to a non-vulnerable version.  I can’t give you general advice on how to do this because it depends on which software you are running.  Once you have done the upgrade, go back to http://filippo.io/Heartbleed/ and verify that you are no longer vulnerable.</li><li>After upgrading your software, generate a new SSL/TLS key and get a certificate for the new key.  Start using the new key and certificate.  (This is necessary because an attacker could have gotten your old key.)</li><li>Revoke the certificate you were previously using.  (This is necessary because an attacker who got your old key could be using your old key and certificate to impersonate your site.)</li><li>Have your users change the passwords that they use to log in to your site. (This is necessary because users’ existing passwords could have been leaked. You need to get your house in order by carrying out the previous steps, before users can safely change passwords.)</li></ul><p><strong>If you run a website that supports HTTPS, and you use a web hosting service:</strong><br />
In this case, the hosting service runs the web server that powers your site.</p><ul><li>Find out from the hosting service whether its server was ever vulnerable to Heartbleed attacks.  If you’re confident that it was never vulnerable, then you’re good.  Otherwise, carry out the following steps.</li><li>Wait until the hosting service has upgraded its software to a non-vulnerable version.  Once they have done the upgrade, you should be able to go to http://filippo.io/Heartbleed/ and enter the address of your site, and be told that it is not vulnerable.   If this isn’t true yet, ask the hosting service to fix the problem, then wait a while and repeat.</li><li>Once the hosting service has upgraded its software and the test site shows you as not vulnerable, generate a new SSL/TLS key and get a certificate for the new key.  Start using the new key and certificate.  (This is necessary because an attacker could have gotten your old key.)</li><li>Revoke the certificate you were previously using.  (This is necessary because an attacker who got your old key could be using your old key and certificate to impersonate your site.)</li><li>If your site assigns passwords to users, have your users change the passwords that they use to log in to your site. (This is necessary because users’ existing passwords could have been leaked. You need to get your house in order by carrying out the previous steps, before users can safely change passwords.)</li></ul>" "https://freedom-to-tinker.com/blog/felten/how-to-protect-yourself-from-heartbleed/" (21317 24549) new 1 nil nil ((title nil "How to protect yourself from Heartbleed") (link nil "https://freedom-to-tinker.com/blog/felten/how-to-protect-yourself-from-heartbleed/") (comments nil "https://freedom-to-tinker.com/blog/felten/how-to-protect-yourself-from-heartbleed/#comments") (pubDate nil "Wed, 09 Apr 2014 14:57:41 +0000") (dc:creator nil "Ed Felten") (guid ((isPermaLink . "false")) "https://freedom-to-tinker.com/?p=9774") (description nil "The Heartbleed vulnerability is one of the worst Internet security problems we have seen. I&#8217;ll be writing more about what we can learn from Heartbleed and the response to it. For now, here is a quick checklist of what you can do to protect yourself. If you are a regular user: Most of the sites [...]") (content:encoded nil "<p>The Heartbleed vulnerability is one of the worst Internet security problems we have seen.  I&#8217;ll be writing more about what we can learn from Heartbleed and the response to it.  </p><p>For now, here is a quick checklist of what you can do to protect yourself.</p><p><strong>If you are a regular user:</strong></p><p>Most of the sites you use were probably vulnerable.  Your password might have been leaked from any one of them.  Unless you&#8217;re sure that a site was <em>never</em> vulnerable, you should change your password on that site.  (It&#8217;s not enough that a site is invulnerable <em>now</em>, because your password could have leaked before the site was fixed.)</p><p>Yes, it&#8217;s a pain to change your passwords, but you were really meaning to change them at some point anyway, weren&#8217;t you?  Now is a good time.  (It&#8217;s also a good time to turn on two-factor authentication, on sites that offer it.)</p><p>But, before you change your password on a site, you need to make sure that that site has closed any remaining vulnerability.  Look for an unequivocal statement from the site that (1) they are no longer vulnerable and (2) they have changed the private encryption key they use to protect HTTPS traffic.   Once you&#8217;re sure that they have done those two things, then you should go ahead and change your password on the site.  If they haven&#8217;t done those two things, then it&#8217;s best to wait until they do.  Make yourself a note to come back and check in a few days.  </p><p>The bad news is that some of your private information might have leaked from a vulnerable site.  It will be very difficult to tell whether this happened, even for the site itself, and nearly impossible to undo a leak if it did happen. </p><p><strong>If you run a website that supports HTTPS, and you run your own server:</strong></p><ul><li>Go to http://filippo.io/Heartbleed/ and enter the name of your site, to test whether your site is vulnerable.   If you&#8217;re not vulnerable, you&#8217;re done.  If you are vulnerable, carry out the following steps.</li><li>Upgrade your server software to a non-vulnerable version.  I can&#8217;t give you general advice on how to do this because it depends on which software you are running.  Once you have done the upgrade, go back to http://filippo.io/Heartbleed/ and verify that you are no longer vulnerable.</li><li>After upgrading your software, generate a new SSL/TLS key and get a certificate for the new key.  Start using the new key and certificate.  (This is necessary because an attacker could have gotten your old key.)</li><li>Revoke the certificate you were previously using.  (This is necessary because an attacker who got your old key could be using your old key and certificate to impersonate your site.)</li><li>Have your users change the passwords that they use to log in to your site. (This is necessary because users&#8217; existing passwords could have been leaked. You need to get your house in order by carrying out the previous steps, before users can safely change passwords.)</li></ul><p><strong>If you run a website that supports HTTPS, and you use a web hosting service:</strong><br />
In this case, the hosting service runs the web server that powers your site.</p><ul><li>Find out from the hosting service whether its server was ever vulnerable to Heartbleed attacks.  If you&#8217;re confident that it was never vulnerable, then you&#8217;re good.  Otherwise, carry out the following steps.</li><li>Wait until the hosting service has upgraded its software to a non-vulnerable version.  Once they have done the upgrade, you should be able to go to http://filippo.io/Heartbleed/ and enter the address of your site, and be told that it is not vulnerable.   If this isn&#8217;t true yet, ask the hosting service to fix the problem, then wait a while and repeat.</li><li>Once the hosting service has upgraded its software and the test site shows you as not vulnerable, generate a new SSL/TLS key and get a certificate for the new key.  Start using the new key and certificate.  (This is necessary because an attacker could have gotten your old key.)</li><li>Revoke the certificate you were previously using.  (This is necessary because an attacker who got your old key could be using your old key and certificate to impersonate your site.)</li><li>If your site assigns passwords to users, have your users change the passwords that they use to log in to your site. (This is necessary because users&#8217; existing passwords could have been leaked. You need to get your house in order by carrying out the previous steps, before users can safely change passwords.)</li></ul>
") (wfw:commentRss nil "https://freedom-to-tinker.com/blog/felten/how-to-protect-yourself-from-heartbleed/feed/") (slash:comments nil "6"))) ("Cookies that give you away: The surveillance implications of web tracking" "<p><i>[Today we have another announcement of an exciting new research paper. Undergraduate Dillon Reisman, for his senior thesis, applied our <a href=\"https://freedom-to-tinker.com/blog/randomwalker/web-measurement-for-fairness-and-transparency/\" target=\"_blank\">web measurement platform</a> to study some timely questions. -Arvind Narayanan]</i></p><p>Over the past three months we’ve learnt that NSA uses third-party tracking cookies for surveillance (<a href=\"http://www.washingtonpost.com/blogs/the-switch/wp/2013/12/10/nsa-uses-google-cookies-to-pinpoint-targets-for-hacking/\">1</a>, <a href=\"https://firstlook.org/theintercept/article/2014/03/12/nsa-plans-infect-millions-computers-malware/\">2</a>). These cookies, provided by a third-party advertising or analytics network (e.g. doubleclick.com, scorecardresearch.com), are ubiquitous on the web, and tag users’ browsers with unique pseudonymous IDs. In <a href=\"http://randomwalker.info/publications/cookie-surveillance.pdf\">a new paper</a>, we study just how big a privacy problem this is. We quantify what an observer can learn about a user’s web traffic by purely passively eavesdropping on the network, and arrive at surprising answers.</p><p>At first sight it doesn’t seem possible that eavesdropping alone can reveal much. First the eavesdropper on the Internet backbone sees millions of HTTP requests and responses. How can he associate the third-party HTTP request containing a user’s cookie with request to the first-party web page that the browser visited, which doesn’t contain the cookie? Second, how can visits to different first parties be linked to each other? And finally, even if all the web traffic for a single user can be linked together, how can the adversary go from a set pseudonymous cookies to the user’s real-world identity?</p><p><img class=\"aligncenter\" alt=\" \" src=\"https://lh6.googleusercontent.com/r00CfwTjy7KfYRzeh9NORNAMye90G3UTRYJXDWTJTl3599IyUEthHs7FZFEb8S6JPE9mQw4qYCxChixyjQxWxXQ-leyJ8SgJXZ95DPwjuyOQ04UEM0nC0ZUKOXQXXg\" width=\"579px;\" height=\"448px;\" /></p><p>The diagram illustrates how the eavesdropper can use multiple third-party cookies to link traffic. When a user visits ‘www.exampleA.com,’ the response contains the embedded tracker X, with an ID cookie ‘xxx’. The visits to exampleA and to X are tied together by IP address, which typically doesn’t change within a single page visit [1]. Another page visited by the same user might embed tracker Y bearing the pseudonymous cookie ‘yyy’. If the two page visits were made from different IP addresses, an eavesdropper seeing these cookies can’t tell that the same browser made both visits. But if a third page, however, embeds both trackers X and Y, then the eavesdropper will know that IDs ‘xxx’ and ‘yyy’ belong to the same user. This method applied iteratively has the potential of tying together a lot of the traffic of a single user.</p><p dir=\"ltr\">Once we had this idea, we wanted to test if it would actually work in practice. Everything depends on just how densely third-party trackers are actually embedded on sites. We conducted automated web crawls of 65 simulated users’ web browsing over three months, and found that unique cookies are so prevalent that the eavesdropper can reliably link 90% of a user’s web page visits to the same pseudonymous ID. (We omitted pages that embed no ID cookies at all, but those are a minority.)</p><p dir=\"ltr\">We also found that the cookie linking method is extremely robust and succeeds under a variety of conditions (Section 4.1). We considered how variations in cookie expiration dates, the size of the user’s history (i.e., the number of pages visited), and the types of pages visited affect the eavesdropper’s changes, and found the impact to be minimal. Perhaps most significantly, however, we found that this surveillance method can still link about 50% of a user’s history to the same pseudonymous ID even with just 25% of the current density of trackers on the web. This means that even if 75% of sites or trackers adopt mitigation strategies (such as deploying HTTPS), the eavesdropper still learns a lot.</p><p dir=\"ltr\"><img class=\"aligncenter\" alt=\" \" src=\"https://lh6.googleusercontent.com/w89sqWi4ZKGwI_50PZFfo09BbWfrTVSr-PiAqDKwdVBWhx1WaxYfUmnRWnyULdRf4QAnoFFoDe2a4851uymJijwZwellnr6ktrgqNePLLRNMsXZok2blDVbhn1esbQ\" width=\"405px;\" height=\"199px;\" /></p><p dir=\"ltr\">Finally, we studied how an eavesdropper might learn the real-world identity behind a cluster of web pages associated with a pseudonymous ID. It turns out that this is surprisingly easy — many sites display real-world attributes such as real name, username, or email on unencrypted pages to logged in users, which means that the eavesdropper gets to see these identifiers. We conducted a survey of such leakage on popular sites, and found that over half of popular sites with account creation leak some form of real-world identity (Section 4.2).</p><p dir=\"ltr\">While it’s no surprise that web traffic contains sensitive information about individuals, what we’ve shown is just how complete a profile can be extracted even if the user’s traffic is mixed with millions of other users. Further, an eavesdropper can connect these profiles to real-world identities without needing the co-operation of any websites. While HTTPS deployment by trackers can help, the only practical solution at the current time seems to be for users to install anti-tracking and anonymity tools.</p><p>&nbsp;</p><p dir=\"ltr\">[1] An exception is if the user routes traffic through Tor. Different requests can take different paths and the exit node IPs will be different. Thus, use of Tor with application-layer anonymization (e.g., Tor browser bundle) defeats our attack.</p><p dir=\"ltr\"><em>[Edit: minor edit for clarity.]</em></p>" "https://freedom-to-tinker.com/blog/dreisman/cookies-that-give-you-away-the-surveillance-implications-of-web-tracking/" (21310 35265) new 2 nil nil ((title nil "Cookies that give you away: The surveillance implications of web tracking") (link nil "https://freedom-to-tinker.com/blog/dreisman/cookies-that-give-you-away-the-surveillance-implications-of-web-tracking/") (comments nil "https://freedom-to-tinker.com/blog/dreisman/cookies-that-give-you-away-the-surveillance-implications-of-web-tracking/#comments") (pubDate nil "Fri, 04 Apr 2014 10:30:25 +0000") (dc:creator nil "Dillon Reisman") (category nil "cookies") (category nil "NSA") (category nil "surveillance") (guid ((isPermaLink . "false")) "https://freedom-to-tinker.com/?p=9732") (description nil "[Today we have another announcement of an exciting new research paper. Undergraduate Dillon Reisman, for his senior thesis, applied our web measurement platform to study some timely questions. -Arvind Narayanan] Over the past three months we’ve learnt that NSA uses third-party tracking cookies for surveillance (1, 2). These cookies, provided by a third-party advertising or analytics network [...]") (content:encoded nil "<p><i>[Today we have another announcement of an exciting new research paper. Undergraduate Dillon Reisman, for his senior thesis, applied our <a href=\"https://freedom-to-tinker.com/blog/randomwalker/web-measurement-for-fairness-and-transparency/\" target=\"_blank\">web measurement platform</a> to study some timely questions. -Arvind Narayanan]</i></p><p>Over the past three months we’ve learnt that NSA uses third-party tracking cookies for surveillance (<a href=\"http://www.washingtonpost.com/blogs/the-switch/wp/2013/12/10/nsa-uses-google-cookies-to-pinpoint-targets-for-hacking/\">1</a>, <a href=\"https://firstlook.org/theintercept/article/2014/03/12/nsa-plans-infect-millions-computers-malware/\">2</a>). These cookies, provided by a third-party advertising or analytics network (e.g. doubleclick.com, scorecardresearch.com), are ubiquitous on the web, and tag users’ browsers with unique pseudonymous IDs. In <a href=\"http://randomwalker.info/publications/cookie-surveillance.pdf\">a new paper</a>, we study just how big a privacy problem this is. We quantify what an observer can learn about a user&#8217;s web traffic by purely passively eavesdropping on the network, and arrive at surprising answers.</p><p>At first sight it doesn’t seem possible that eavesdropping alone can reveal much. First the eavesdropper on the Internet backbone sees millions of HTTP requests and responses. How can he associate the third-party HTTP request containing a user’s cookie with request to the first-party web page that the browser visited, which doesn’t contain the cookie? Second, how can visits to different first parties be linked to each other? And finally, even if all the web traffic for a single user can be linked together, how can the adversary go from a set pseudonymous cookies to the user’s real-world identity?</p><p><img class=\"aligncenter\" alt=\" \" src=\"https://lh6.googleusercontent.com/r00CfwTjy7KfYRzeh9NORNAMye90G3UTRYJXDWTJTl3599IyUEthHs7FZFEb8S6JPE9mQw4qYCxChixyjQxWxXQ-leyJ8SgJXZ95DPwjuyOQ04UEM0nC0ZUKOXQXXg\" width=\"579px;\" height=\"448px;\" /></p><p>The diagram illustrates how the eavesdropper can use multiple third-party cookies to link traffic. When a user visits ‘www.exampleA.com,’ the response contains the embedded tracker X, with an ID cookie ‘xxx’. The visits to exampleA and to X are tied together by IP address, which typically doesn’t change within a single page visit [1]. Another page visited by the same user might embed tracker Y bearing the pseudonymous cookie ‘yyy’. If the two page visits were made from different IP addresses, an eavesdropper seeing these cookies can’t tell that the same browser made both visits. But if a third page, however, embeds both trackers X and Y, then the eavesdropper will know that IDs ‘xxx’ and ‘yyy’ belong to the same user. This method applied iteratively has the potential of tying together a lot of the traffic of a single user.</p><p dir=\"ltr\">Once we had this idea, we wanted to test if it would actually work in practice. Everything depends on just how densely third-party trackers are actually embedded on sites. We conducted automated web crawls of 65 simulated users’ web browsing over three months, and found that unique cookies are so prevalent that the eavesdropper can reliably link 90% of a user’s web page visits to the same pseudonymous ID. (We omitted pages that embed no ID cookies at all, but those are a minority.)</p><p dir=\"ltr\">We also found that the cookie linking method is extremely robust and succeeds under a variety of conditions (Section 4.1). We considered how variations in cookie expiration dates, the size of the user’s history (i.e., the number of pages visited), and the types of pages visited affect the eavesdropper’s changes, and found the impact to be minimal. Perhaps most significantly, however, we found that this surveillance method can still link about 50% of a user’s history to the same pseudonymous ID even with just 25% of the current density of trackers on the web. This means that even if 75% of sites or trackers adopt mitigation strategies (such as deploying HTTPS), the eavesdropper still learns a lot.</p><p dir=\"ltr\"><img class=\"aligncenter\" alt=\" \" src=\"https://lh6.googleusercontent.com/w89sqWi4ZKGwI_50PZFfo09BbWfrTVSr-PiAqDKwdVBWhx1WaxYfUmnRWnyULdRf4QAnoFFoDe2a4851uymJijwZwellnr6ktrgqNePLLRNMsXZok2blDVbhn1esbQ\" width=\"405px;\" height=\"199px;\" /></p><p dir=\"ltr\">Finally, we studied how an eavesdropper might learn the real-world identity behind a cluster of web pages associated with a pseudonymous ID. It turns out that this is surprisingly easy &#8212; many sites display real-world attributes such as real name, username, or email on unencrypted pages to logged in users, which means that the eavesdropper gets to see these identifiers. We conducted a survey of such leakage on popular sites, and found that over half of popular sites with account creation leak some form of real-world identity (Section 4.2).</p><p dir=\"ltr\">While it’s no surprise that web traffic contains sensitive information about individuals, what we’ve shown is just how complete a profile can be extracted even if the user’s traffic is mixed with millions of other users. Further, an eavesdropper can connect these profiles to real-world identities without needing the co-operation of any websites. While HTTPS deployment by trackers can help, the only practical solution at the current time seems to be for users to install anti-tracking and anonymity tools.</p><p>&nbsp;</p><p dir=\"ltr\">[1] An exception is if the user routes traffic through Tor. Different requests can take different paths and the exit node IPs will be different. Thus, use of Tor with application-layer anonymization (e.g., Tor browser bundle) defeats our attack.</p><p dir=\"ltr\"><em>[Edit: minor edit for clarity.]</em></p>
") (wfw:commentRss nil "https://freedom-to-tinker.com/blog/dreisman/cookies-that-give-you-away-the-surveillance-implications-of-web-tracking/feed/") (slash:comments nil "9"))) ("Historic E.U. Net Neutrality Win Shows Maturing Digital Rights Advocacy" "<p>After a 5-year long campaign by European and U.S. digital rights NGOs, today the European Parliament turned a dubious Commission proposal on its head to safeguard the principle of net neutrality. It’s a historic win, and <a href=\"http://www.nytimes.com/2014/04/04/business/international/eu-lawmakers-approve-tough-net-neutrality-rules.html?_r=0\" target=\"_blank\">all</a><a href=\"http://www.nytimes.com/2014/03/31/business/international/european-lawmakers-prepare-to-vote-on-net-neutrality.html\" target=\"_blank\">over</a><a href=\"http://blogs.wsj.com/digits/2014/04/02/who-says-european-net-neutrality-politics-is-boring/\" target=\"_blank\">the</a><a href=\"www.bbc.com/news/technology-26865869\" target=\"_blank\">news</a>. It also shows how digital rights advocacy is maturing. <img title=\"More...\" alt=\" \" src=\"https://www.axelarnbak.nl/wp-includes/js/tinymce/plugins/wordpress/img/trans.gif\" /></p><p>The <a href=\"http://www.europarl.europa.eu/sides/getDoc.do?pubRef=-//EP//TEXT+REPORT+A7-2014-0190+0+DOC+XML+V0//EN\" target=\"_blank\">legislative proposal and its amendments</a> contain a clear definition of net neutrality and quite solid provisions. With the final text, as always, the devil will be in the details. For one, the enforcement provisions could have been stronger. Perhaps some national governments, such as <a href=\"https://www.axelarnbak.nl/2014/03/13/translation-dutch-net-freedom-laws-2011-net-neutrality-no-commercial-wiretapping-no-3-strikes/\" target=\"_blank\">The Netherlands where net neutrality has already been enshrined in law for some years now</a>, will lobby for more discretion to enforce the rules on the national level.</p><p>Of course, it ain’t over till the fat lady sings: the E.U. Council (the relevant ministers of national governments) will debate the Parliament legislative text on 5/6 June 2014. Will it respect a democratic vote, or be influenced by the Telecoms lobby? History learns that industry lobbies are almost certain to leverage more power towards the E.U. Council, than citizens have with regard to their respective governments. Europe is often used as a proxy for politics that can’t be realized on a national level. Moreover, the May 2014 Parliament election comes before those negotiations in June, potentially changing the political dynamics: the current majority for net neutrality could change. So the jury is still out.</p><p>But what’s truly fascinating about the net neutrality vote, and perfect case study material, is how digital rights advocacy in Europe is maturing. A <a href=\"http://savetheinternet.eu/\" target=\"_blank\">slick campaign</a> was set up that got more people to call/fax/e-mail their representatives than back in the day with the historic no-vote on ACTA. That’s a second crucial point: ACTA was a no-vote, but here digital rights and consumer advocates were able to suggest meaningful legislative reform amidst intense political struggle. Expert amendments were suggested, a dubious proposal by the (Dutch) E.U. Commissioner — primarily interested in quick wins on roaming tariffs — delegitimized and the immensely powerful telecoms lobby were faced head-on. Quite nasty tactics by hostile E.U. Parliamentarians and lobbies were cleverly tackled. Unsurprisingly, and completely missing the point, even the <a href=\"http://pastebin.com/ezMCuF5s\" target=\"_blank\">child abuse card was played the night before the final vote</a>. Until the last minute, digital rights groups — in a highly dispersed Europe and with the help of U.S. NGOs — have shown that they can play ball as one front, when it really matters.</p><p>We see this more often these days, and it should give rise to some opportunism on E.U. policymaking. Apart from ACTA and net neutrality, data protection, mandatory website blocking and data retention also come to mind. Digital rights advocacy has matured in the last five years. Sure, the web has turned public and private online life into a surveillance society — so why be optimistic? Because at the same time, it appears that the obscure Brussels lobbying arena feels the surveillance of the public more and more.  Of course, we’re nowhere near a transparent political process, but these are interesting times.</p><p>For now, it’s a historic win for digital rights in Europe, that may spur spill-over effects to the U.S. and other countries as well. Time to enjoy a beer and some sleep for those that did the heavy lifting, including MEPs Amelia Andersdottir, Catherine Trautmann, Marietje Schaake and Petra Kammerevert and organizations such as <a href=\"https://www.edri.org\" target=\"_blank\">European Digital Rights</a>, <a href=\"http://www.laquadrature.net/en\" target=\"_blank\">La Quadrature du Net</a> and <a href=\"https://www.bitsoffreedom.nl\" target=\"_blank\">Bits of Freedom.</a> Remember those names, you’ll be hearing them again in a not so distant fascinating future.</p>" "https://freedom-to-tinker.com/blog/axel/historic-e-u-net-neutrality-win-shows-maturing-digital-rights-advocacy/" (21309 46362) new 3 nil nil ((title nil "Historic E.U. Net Neutrality Win Shows Maturing Digital Rights Advocacy") (link nil "https://freedom-to-tinker.com/blog/axel/historic-e-u-net-neutrality-win-shows-maturing-digital-rights-advocacy/") (comments nil "https://freedom-to-tinker.com/blog/axel/historic-e-u-net-neutrality-win-shows-maturing-digital-rights-advocacy/#comments") (pubDate nil "Thu, 03 Apr 2014 19:23:06 +0000") (dc:creator nil "Axel Arnbak") (guid ((isPermaLink . "false")) "https://freedom-to-tinker.com/?p=9750") (description nil "After a 5-year long campaign by European and U.S. digital rights NGOs, today the European Parliament turned a dubious Commission proposal on its head to safeguard the principle of net neutrality. It&#8217;s a historic win, and all over the news. It also shows how digital rights advocacy is maturing. The legislative proposal and its amendments [...]") (content:encoded nil "<p>After a 5-year long campaign by European and U.S. digital rights NGOs, today the European Parliament turned a dubious Commission proposal on its head to safeguard the principle of net neutrality. It&#8217;s a historic win, and <a href=\"http://www.nytimes.com/2014/04/04/business/international/eu-lawmakers-approve-tough-net-neutrality-rules.html?_r=0\" target=\"_blank\">all</a><a href=\"http://www.nytimes.com/2014/03/31/business/international/european-lawmakers-prepare-to-vote-on-net-neutrality.html\" target=\"_blank\">over</a><a href=\"http://blogs.wsj.com/digits/2014/04/02/who-says-european-net-neutrality-politics-is-boring/\" target=\"_blank\">the</a><a href=\"www.bbc.com/news/technology-26865869\" target=\"_blank\">news</a>. It also shows how digital rights advocacy is maturing. <img title=\"More...\" alt=\" \" src=\"https://www.axelarnbak.nl/wp-includes/js/tinymce/plugins/wordpress/img/trans.gif\" /></p><p>The <a href=\"http://www.europarl.europa.eu/sides/getDoc.do?pubRef=-//EP//TEXT+REPORT+A7-2014-0190+0+DOC+XML+V0//EN\" target=\"_blank\">legislative proposal and its amendments</a> contain a clear definition of net neutrality and quite solid provisions. With the final text, as always, the devil will be in the details. For one, the enforcement provisions could have been stronger. Perhaps some national governments, such as <a href=\"https://www.axelarnbak.nl/2014/03/13/translation-dutch-net-freedom-laws-2011-net-neutrality-no-commercial-wiretapping-no-3-strikes/\" target=\"_blank\">The Netherlands where net neutrality has already been enshrined in law for some years now</a>, will lobby for more discretion to enforce the rules on the national level.</p><p>Of course, it ain&#8217;t over till the fat lady sings: the E.U. Council (the relevant ministers of national governments) will debate the Parliament legislative text on 5/6 June 2014. Will it respect a democratic vote, or be influenced by the Telecoms lobby? History learns that industry lobbies are almost certain to leverage more power towards the E.U. Council, than citizens have with regard to their respective governments. Europe is often used as a proxy for politics that can&#8217;t be realized on a national level. Moreover, the May 2014 Parliament election comes before those negotiations in June, potentially changing the political dynamics: the current majority for net neutrality could change. So the jury is still out.</p><p>But what&#8217;s truly fascinating about the net neutrality vote, and perfect case study material, is how digital rights advocacy in Europe is maturing. A <a href=\"http://savetheinternet.eu/\" target=\"_blank\">slick campaign</a> was set up that got more people to call/fax/e-mail their representatives than back in the day with the historic no-vote on ACTA. That&#8217;s a second crucial point: ACTA was a no-vote, but here digital rights and consumer advocates were able to suggest meaningful legislative reform amidst intense political struggle. Expert amendments were suggested, a dubious proposal by the (Dutch) E.U. Commissioner &#8212; primarily interested in quick wins on roaming tariffs &#8212; delegitimized and the immensely powerful telecoms lobby were faced head-on. Quite nasty tactics by hostile E.U. Parliamentarians and lobbies were cleverly tackled. Unsurprisingly, and completely missing the point, even the <a href=\"http://pastebin.com/ezMCuF5s\" target=\"_blank\">child abuse card was played the night before the final vote</a>. Until the last minute, digital rights groups &#8212; in a highly dispersed Europe and with the help of U.S. NGOs &#8212; have shown that they can play ball as one front, when it really matters.</p><p>We see this more often these days, and it should give rise to some opportunism on E.U. policymaking. Apart from ACTA and net neutrality, data protection, mandatory website blocking and data retention also come to mind. Digital rights advocacy has matured in the last five years. Sure, the web has turned public and private online life into a surveillance society &#8212; so why be optimistic? Because at the same time, it appears that the obscure Brussels lobbying arena feels the surveillance of the public more and more.  Of course, we&#8217;re nowhere near a transparent political process, but these are interesting times.</p><p>For now, it&#8217;s a historic win for digital rights in Europe, that may spur spill-over effects to the U.S. and other countries as well. Time to enjoy a beer and some sleep for those that did the heavy lifting, including MEPs Amelia Andersdottir, Catherine Trautmann, Marietje Schaake and Petra Kammerevert and organizations such as <a href=\"https://www.edri.org\" target=\"_blank\">European Digital Rights</a>, <a href=\"http://www.laquadrature.net/en\" target=\"_blank\">La Quadrature du Net</a> and <a href=\"https://www.bitsoffreedom.nl\" target=\"_blank\">Bits of Freedom.</a> Remember those names, you&#8217;ll be hearing them again in a not so distant fascinating future.</p>
") (wfw:commentRss nil "https://freedom-to-tinker.com/blog/axel/historic-e-u-net-neutrality-win-shows-maturing-digital-rights-advocacy/feed/") (slash:comments nil "0"))) ("Secure protocols for accountable warrant execution" "<p>Last week the press <a href=\"http://www.nytimes.com/2014/03/25/us/obama-to-seek-nsa-curb-on-call-data.html\"> reported</a> that the White House will seek to redesign the NSA’s mass phone call data program, so that data will be held by the phone companies and accessed by the NSA, subject to a new warrant requirement.  The Foreign Intelligence Surveillance Court will issue the warrants.</p><p>Today Josh Kroll and I, with colleagues at Stanford University, released a <a href=\"http://www.cs.princeton.edu/~felten/warrant-paper.pdf\">draft paper</a> on how to use cryptography to implement warrants to data in a secure, private, and accountable way.  </p><p>Our solution is a set of multi-party cryptographic protocols involving three primary parties: a data source who has data records, an investigator who wants access to data held by the data source, and a court (or other authorizer) who issues an order or warrant to authorize access to a record.  For example, a phone company might be the data source, the NSA might be the investigator, and the Foreign Intelligence Surveillance Court might be the court that issues an order.  Alternatively, an email provider might be the data source, an FBI agent might be the investigator, and a senior FBI official might act as the “court” that issues a National Security Letter.  Although we use words like “court”, “order”, and “investigator”, the protocol has wider application to situations where Party A is authorizing Party B to access data held by Party C, with legally defined requirements for access.</p><p>The protocol uses cryptography to guarantee several security, privacy, and accountability properties:</p><ul><li>When the court issues an order, it publishes a sealed version of the order. If challenged later, the court can unseal the order and reveal which record it covered.</li><li>Until the order is unsealed, only the court and the investigator can see which record the order covers.  If and when the order is unsealed, everyone can see which record it covered.</li><li>The investigator does not learn the contents of any record, unless there is a valid order for that record and the court has published a valid sealed version of that order.</li></ul><p>A counterintuitive aspect of our protocols is that an order can be executed, thereby giving the investigator access to the record covered by the order, without the data source necessarily learning (at the time) which record the investigator accessed.</p><p>These properties can be viewed as a set of checks on the power of the parties, to prevent any dishonest party from getting access to information without leaving a suitable trail.  When the trail itself is supposed to be secret, the protocol aims for accountability—for example, the court can issue an unjustified order but the court must commit to the order so that the violation will be uncovered if the court’s actions are challenged later.</p><p>Our paper gives more precise definitions of the desired properties, how the protocols work, and why the protocols achieve the desired properties.  We build on the work of previous researchers, as cited in our paper, and we present several versions of the protocol, with different security properties.</p><p>Our approach is feasible, even for very large data sets.  Our paper describes our work on implementing one of our more advanced protocols, and we show by experiment that the protocol is reasonably fast even for data sets of national scope.   We have released the <a href=\"http://www.cs.princeton.edu/~felten/warrant-benchmark.tar.gz\">code</a> we used to do these performance measurements.</p><p>We are releasing this paper now because there are important debates going on about how to organize lawful access to data by intelligence agencies.  We want to make the point that technology allows these processes to be both more secure and more accountable.  </p><p>We urge policymakers to consider how cryptography can make warrant regimes more secure for all parties, and more accountable.  Expert agencies within government, such as NIST, might provide input on these issues, in consultation with experts inside and outside of government.</p>" "https://freedom-to-tinker.com/blog/felten/secure-protocols-for-accountable-warrant-execution/" (21307 62171) new 4 nil nil ((title nil "Secure protocols for accountable warrant execution") (link nil "https://freedom-to-tinker.com/blog/felten/secure-protocols-for-accountable-warrant-execution/") (comments nil "https://freedom-to-tinker.com/blog/felten/secure-protocols-for-accountable-warrant-execution/#comments") (pubDate nil "Wed, 02 Apr 2014 11:22:03 +0000") (dc:creator nil "Ed Felten") (guid ((isPermaLink . "false")) "https://freedom-to-tinker.com/?p=9708") (description nil "Last week the press reported that the White House will seek to redesign the NSA’s mass phone call data program, so that data will be held by the phone companies and accessed by the NSA, subject to a new warrant requirement. The Foreign Intelligence Surveillance Court will issue the warrants. Today Josh Kroll and I, [...]") (content:encoded nil "<p>Last week the press <a href=\"http://www.nytimes.com/2014/03/25/us/obama-to-seek-nsa-curb-on-call-data.html\"> reported</a> that the White House will seek to redesign the NSA’s mass phone call data program, so that data will be held by the phone companies and accessed by the NSA, subject to a new warrant requirement.  The Foreign Intelligence Surveillance Court will issue the warrants.</p><p>Today Josh Kroll and I, with colleagues at Stanford University, released a <a href=\"http://www.cs.princeton.edu/~felten/warrant-paper.pdf\">draft paper</a> on how to use cryptography to implement warrants to data in a secure, private, and accountable way.  </p><p>Our solution is a set of multi-party cryptographic protocols involving three primary parties: a data source who has data records, an investigator who wants access to data held by the data source, and a court (or other authorizer) who issues an order or warrant to authorize access to a record.  For example, a phone company might be the data source, the NSA might be the investigator, and the Foreign Intelligence Surveillance Court might be the court that issues an order.  Alternatively, an email provider might be the data source, an FBI agent might be the investigator, and a senior FBI official might act as the &#8220;court&#8221; that issues a National Security Letter.  Although we use words like &#8220;court&#8221;, &#8220;order&#8221;, and &#8220;investigator&#8221;, the protocol has wider application to situations where Party A is authorizing Party B to access data held by Party C, with legally defined requirements for access.</p><p>The protocol uses cryptography to guarantee several security, privacy, and accountability properties:</p><ul><li>When the court issues an order, it publishes a sealed version of the order. If challenged later, the court can unseal the order and reveal which record it covered.</li><li>Until the order is unsealed, only the court and the investigator can see which record the order covers.  If and when the order is unsealed, everyone can see which record it covered.</li><li>The investigator does not learn the contents of any record, unless there is a valid order for that record and the court has published a valid sealed version of that order.</li></ul><p>A counterintuitive aspect of our protocols is that an order can be executed, thereby giving the investigator access to the record covered by the order, without the data source necessarily learning (at the time) which record the investigator accessed.</p><p>These properties can be viewed as a set of checks on the power of the parties, to prevent any dishonest party from getting access to information without leaving a suitable trail.  When the trail itself is supposed to be secret, the protocol aims for accountability&#8212;for example, the court can issue an unjustified order but the court must commit to the order so that the violation will be uncovered if the court’s actions are challenged later.</p><p>Our paper gives more precise definitions of the desired properties, how the protocols work, and why the protocols achieve the desired properties.  We build on the work of previous researchers, as cited in our paper, and we present several versions of the protocol, with different security properties.</p><p>Our approach is feasible, even for very large data sets.  Our paper describes our work on implementing one of our more advanced protocols, and we show by experiment that the protocol is reasonably fast even for data sets of national scope.   We have released the <a href=\"http://www.cs.princeton.edu/~felten/warrant-benchmark.tar.gz\">code</a> we used to do these performance measurements.</p><p>We are releasing this paper now because there are important debates going on about how to organize lawful access to data by intelligence agencies.  We want to make the point that technology allows these processes to be both more secure and more accountable.  </p><p>We urge policymakers to consider how cryptography can make warrant regimes more secure for all parties, and more accountable.  Expert agencies within government, such as NIST, might provide input on these issues, in consultation with experts inside and outside of government.</p>
") (wfw:commentRss nil "https://freedom-to-tinker.com/blog/felten/secure-protocols-for-accountable-warrant-execution/feed/") (slash:comments nil "3"))) ("New research: Better wallet security for Bitcoin" "<p><strong>[UPDATE (April 3, 2014): We've found an error in our paper. In the threshold signature scheme that we used, there are restrictions on the threshold value. In particular if the key is shared over a degree t polynomial, then 2t+1 players (not t+1) are required to to construct a signature. We thought that this could be reduced to t+1, but our technique was flawed. We are exploring various modifications, and we will post further details when we have an update.]</strong></p><p dir=\"ltr\">The Bitcoin ecosystem has been plagued by thefts and losses that have affected both businesses and individuals. The security of a Bitcoin wallet rests entirely on the security of its associated private keys which can digitally sign transactions to irreversibly spend the coins in the wallet. In a <a href=\"http://www.cs.princeton.edu/~stevenag/bitcoin_threshold_signatures.pdf\">new paper</a>, we show how to use the cryptographic technique of <em>threshold signatures</em> to increase the security of both corporate and individual wallets.</p><p>Perhaps Bitcoin’s toughest security challenge is protecting Internet-connected wallets from insider threats. Such <em><a href=\"https://en.bitcoin.it/wiki/Hot_wallet\">hot wallets</a></em>cannot be kept in highly secure, offline cold storage. One good way for businesses to mitigate this vulnerability is to have hot wallets jointly controlled by multiple parties. This way, no party can independently steal corporate funds. In our paper, we show how to achieve <em>joint control</em> of wallets using threshold signatures.</p><p>The problem of implementing joint control is more important and more difficult for a Bitcoin wallet than it is for a traditional bank account. Whereas regular bank transactions have recovery mechanisms if fraud is detected, Bitcoin transactions are irreversible and their pseudonymity makes it difficult to identify thieves and attempt to recover stolen funds. Moreover, while large bank transactions typically require human action to complete, Bitcoin transactions–no matter how large–require only a cryptographic signature to authorize.</p><p>The threshold signature approach to joint control works like this: the private key controlling the wallet is split between devices belonging to <em>n</em> different participants such that any <em>m</em> of them can jointly produce a digital signature, while a group of less than <em>m</em> participants cannot. Crucially, in the process of producing a signature, <em>the key is never reconstructed</em>. As long as an attacker has compromised fewer than <em>m</em> devices, the key remains secure.</p><p>Our method for achieving joint control has significant benefits over Bitcoin’s “<a href=\"https://gist.github.com/gavinandresen/4039433\">multi-signature</a>” transactions. With multi-signatures, each party’s signature is published to the block chain, whereas threshold signatures allow participants to privately create a single signature which is indistinguishable from ordinary Bitcoin signatures. You can think of our solution as “stealth multi-signatures.” This improves anonymity and confidentiality while keeping transactions a constant size, reducing fees and providing flexibility to scale to an arbitrary number of parties.</p><p>We implemented a threshold signature protocol and have used it to demonstrate  joint control over a Bitcoin wallet. We produced <a href=\"https://blockchain.info/tx/55451090debe729120d4a2e6b49bd3d5cabb881e753ccda0f5ea499a3438de9b\">this transaction</a> using a 9-of-12 threshold signature. If you click on the link to see the transaction details, you won’t see anything special; it looks like any regular transaction. That’s exactly the point!</p><p>Joint control is one of several security measures that can be built using threshold signatures. In our paper, we show that threshold signatures can be used as a primitive to build schemes for <em>secure bookkeeping</em> and <em>secure delegation</em>. One application that we’re particularly excited about is using threshold signatures to achieve <em>two-factor security</em> for personal wallets. In a follow-up post, we will elaborate on this application and discuss our ongoing efforts to build a two-factor secure wallet.</p><p>The main lesson from our work is that a spectrum of traditional internal financial controls can be translated to the Bitcoin world by novel application of cryptography. We hope that the security measures we’ve proposed will become standard in Bitcoin usage, and we are looking forward to working with developers and others who want to adopt our solutions.</p><p>We’d like to thank Greg Maxwell and Andrew Miller for providing useful feedback.</p>" "https://freedom-to-tinker.com/blog/stevenag/new-research-better-wallet-security-for-bitcoin/" (21301 41625) new 5 nil nil ((title nil "New research: Better wallet security for Bitcoin") (link nil "https://freedom-to-tinker.com/blog/stevenag/new-research-better-wallet-security-for-bitcoin/") (comments nil "https://freedom-to-tinker.com/blog/stevenag/new-research-better-wallet-security-for-bitcoin/#comments") (pubDate nil "Fri, 28 Mar 2014 16:26:01 +0000") (dc:creator nil "Steven Goldfeder") (guid ((isPermaLink . "false")) "https://freedom-to-tinker.com/?p=9718") (description nil "[UPDATE (April 3, 2014): We've found an error in our paper. In the threshold signature scheme that we used, there are restrictions on the threshold value. In particular if the key is shared over a degree t polynomial, then 2t+1 players (not t+1) are required to to construct a signature. We thought that this could [...]") (content:encoded nil "<p><strong>[UPDATE (April 3, 2014): We've found an error in our paper. In the threshold signature scheme that we used, there are restrictions on the threshold value. In particular if the key is shared over a degree t polynomial, then 2t+1 players (not t+1) are required to to construct a signature. We thought that this could be reduced to t+1, but our technique was flawed. We are exploring various modifications, and we will post further details when we have an update.]</strong></p><p dir=\"ltr\">The Bitcoin ecosystem has been plagued by thefts and losses that have affected both businesses and individuals. The security of a Bitcoin wallet rests entirely on the security of its associated private keys which can digitally sign transactions to irreversibly spend the coins in the wallet. In a <a href=\"http://www.cs.princeton.edu/~stevenag/bitcoin_threshold_signatures.pdf\">new paper</a>, we show how to use the cryptographic technique of <em>threshold signatures</em> to increase the security of both corporate and individual wallets.</p><p>Perhaps Bitcoin’s toughest security challenge is protecting Internet-connected wallets from insider threats. Such <em><a href=\"https://en.bitcoin.it/wiki/Hot_wallet\">hot wallets</a></em>cannot be kept in highly secure, offline cold storage. One good way for businesses to mitigate this vulnerability is to have hot wallets jointly controlled by multiple parties. This way, no party can independently steal corporate funds. In our paper, we show how to achieve <em>joint control</em> of wallets using threshold signatures.</p><p>The problem of implementing joint control is more important and more difficult for a Bitcoin wallet than it is for a traditional bank account. Whereas regular bank transactions have recovery mechanisms if fraud is detected, Bitcoin transactions are irreversible and their pseudonymity makes it difficult to identify thieves and attempt to recover stolen funds. Moreover, while large bank transactions typically require human action to complete, Bitcoin transactions&#8211;no matter how large&#8211;require only a cryptographic signature to authorize.</p><p>The threshold signature approach to joint control works like this: the private key controlling the wallet is split between devices belonging to <em>n</em> different participants such that any <em>m</em> of them can jointly produce a digital signature, while a group of less than <em>m</em> participants cannot. Crucially, in the process of producing a signature, <em>the key is never reconstructed</em>. As long as an attacker has compromised fewer than <em>m</em> devices, the key remains secure.</p><p>Our method for achieving joint control has significant benefits over Bitcoin’s “<a href=\"https://gist.github.com/gavinandresen/4039433\">multi-signature</a>” transactions. With multi-signatures, each party’s signature is published to the block chain, whereas threshold signatures allow participants to privately create a single signature which is indistinguishable from ordinary Bitcoin signatures. You can think of our solution as “stealth multi-signatures.” This improves anonymity and confidentiality while keeping transactions a constant size, reducing fees and providing flexibility to scale to an arbitrary number of parties.</p><p>We implemented a threshold signature protocol and have used it to demonstrate  joint control over a Bitcoin wallet. We produced <a href=\"https://blockchain.info/tx/55451090debe729120d4a2e6b49bd3d5cabb881e753ccda0f5ea499a3438de9b\">this transaction</a> using a 9-of-12 threshold signature. If you click on the link to see the transaction details, you won’t see anything special; it looks like any regular transaction. That’s exactly the point!</p><p>Joint control is one of several security measures that can be built using threshold signatures. In our paper, we show that threshold signatures can be used as a primitive to build schemes for <em>secure bookkeeping</em> and <em>secure delegation</em>. One application that we’re particularly excited about is using threshold signatures to achieve <em>two-factor security</em> for personal wallets. In a follow-up post, we will elaborate on this application and discuss our ongoing efforts to build a two-factor secure wallet.</p><p>The main lesson from our work is that a spectrum of traditional internal financial controls can be translated to the Bitcoin world by novel application of cryptography. We hope that the security measures we’ve proposed will become standard in Bitcoin usage, and we are looking forward to working with developers and others who want to adopt our solutions.</p><p>We’d like to thank Greg Maxwell and Andrew Miller for providing useful feedback.</p>
") (wfw:commentRss nil "https://freedom-to-tinker.com/blog/stevenag/new-research-better-wallet-security-for-bitcoin/feed/") (slash:comments nil "7"))) ("Reflecting on Sunshine Week" "<p>Last Wednesday evening, I attended the D.C. Open Government Summit: Street View, which took place at the National Press Club in conjunction with Sunshine Week. The Summit was sponsored by the D.C. Open Government Coalition, a non-profit that “seeks to enhance the public’s access to government information and ensure the transparency of government operations of the District of Columbia.” The Summit successfully focused on two main ideas – using government information to innovate and using government information to inform. I left the Summit encouraged by the enthusiasm for innovation and transparency in the attendees and among some District of Columbia government leaders, but also discouraged because there was a consensus that Washington, DC is still far behind cities such as New York, Kansas City, and Boston in using technology for innovation in government and there is not a vision or financial commitment from the Mayor’s office to facilitate government-wide progress.</p><p>In her keynote address, Traci Hughes, the Director of the District of Columbia Office of Open Government, commented that her office only has two employees and almost no budget beyond that for salaries. She has, therefore, been looking to certain District government agencies and non-profit partners outside of government to support her vision for a more open government. Ms. Hughes commented, for example, that the Council of the District of Columbia’s General Counsel has been a great partner, as has been the Office of the State Superintendent of Education, which has been a leader in making information about education available to parents. Ms. Hughes recognized Code for DC, the all-volunteer local chapter of Code for America, for producing “ANC Finder,” an application that provides residents, based on their address, with information about their Advisory Neighborhood Commission – DC’s hyper-local level of government where each Commissioner represents approximately 2,000 people.</p><p>Ms. Hughes, however, has a broader vision for open access to the District of Columbia’s data and records. Ms. Hughes stated that the Council of the District of Columbia and the Mayor need to pass legislation to drive the open government process. In addition, the city must do more to bridge the gaps between people with varying levels of Internet access. I interpreted this statement as her way of saying that many more city services should be accessible through mobile devices. Indeed, a 2013 Pew study indicates that 10% of urban residents have a smartphone, but no home broadband connection.</p><p>Making government services available through mobile devices was one of the themes of the evening. The representatives from Code for DC stressed the importance of moving government processes to mobile platforms. The process of applying for public housing, for example, often involves filling out a different paper form for each potential housing option for which a person is applying. While the non-profit Bread for the City is currently helping people with the paper forms, Code for DC volunteers are working toward a technology-based solution. In addition, people are lobbying to make filing a Freedom of Information Act request and contesting a property tax assessment possible through mobile devices. I had a great side conversation with a Code for DC volunteer who has mapped the DC restaurants that have been cited recently for health code violations. His next step is developing a mobile app. Given the ubiquity of the violations, I was glad I had already eaten.</p><p>Beyond mobile, one of the most impressive recent innovations by the DC government is Advisory Neighborhood Commission 3F live streaming its monthly meetings. Advisory Neighborhood Commission meetings are not typically broadcast on public access television, therefore live streaming makes meetings available, for example, to people with kids who can’t get out in the evening and senior citizens or people with disabilities who cannot get to the meeting location. Live streaming uses only $75 of the Advisory Neighborhood Commission’s budget per meeting and people can ask questions directly beneath the feed or by reaching out to the Advisory Neighborhood Commission’s Chairman via Twitter. Another Advisory Neighborhood Commission records its meetings and posts them on YouTube subsequently. While these are great solutions for constituents who are tech savvy and have fast home broadband connections, to reach the widest possible audience, Advisory Neighborhood Commissions still must continue to use both on-line and off-line engagement methods.</p><p>While increasing participation is very important, so is facilitating accountability. A local activist and Washington Post reporter both discussed the importance of responses to FOIA requests in conducting research, particularly on under-the-radar issues that are nonetheless affecting city residents’ lives. FOIAs have been a critical tool in preventing legal on-line gambling in DC and exposing corruption in the Office of the Chief Financial Officer regarding commercial property assessments.</p><p>Based on the Summit, here are my three recommendations: (1) The DC Office of Open Government needs to have a more productive and collaborative relationship with the Mayor’s Office. The Mayor’s office needs to promote a culture that makes sharing information with both the public and across the city government a priority; (2) Cities that are integrating technology into governance effectively, such as New York, Boston, and Philadelphia, have someone leading those efforts from the Mayor’s office. Washington, DC needs leadership at that level; and (3) To eliminate the inconsistencies across city agencies, the DC government needs to establish written, uniform policies for responding to FOIAs and providing data sets that are easy to manipulate by members of the public and post these policies where the public can review them. The seeds of an open, efficient government exist, but will only grow with strong and committed leadership.</p>" "https://freedom-to-tinker.com/blog/jtignor/reflecting-on-sunshine-week/" (21298 54004) new 6 nil nil ((title nil "Reflecting on Sunshine Week") (link nil "https://freedom-to-tinker.com/blog/jtignor/reflecting-on-sunshine-week/") (comments nil "https://freedom-to-tinker.com/blog/jtignor/reflecting-on-sunshine-week/#comments") (pubDate nil "Wed, 26 Mar 2014 13:15:32 +0000") (dc:creator nil "Jeffrey Tignor") (category nil "Government transparency") (guid ((isPermaLink . "false")) "https://freedom-to-tinker.com/?p=9710") (description nil "Last Wednesday evening, I attended the D.C. Open Government Summit: Street View, which took place at the National Press Club in conjunction with Sunshine Week. The Summit was sponsored by the D.C. Open Government Coalition, a non-profit that “seeks to enhance the public’s access to government information and ensure the transparency of government operations of [...]") (content:encoded nil "<p>Last Wednesday evening, I attended the D.C. Open Government Summit: Street View, which took place at the National Press Club in conjunction with Sunshine Week. The Summit was sponsored by the D.C. Open Government Coalition, a non-profit that “seeks to enhance the public’s access to government information and ensure the transparency of government operations of the District of Columbia.” The Summit successfully focused on two main ideas – using government information to innovate and using government information to inform. I left the Summit encouraged by the enthusiasm for innovation and transparency in the attendees and among some District of Columbia government leaders, but also discouraged because there was a consensus that Washington, DC is still far behind cities such as New York, Kansas City, and Boston in using technology for innovation in government and there is not a vision or financial commitment from the Mayor’s office to facilitate government-wide progress.</p><p>In her keynote address, Traci Hughes, the Director of the District of Columbia Office of Open Government, commented that her office only has two employees and almost no budget beyond that for salaries. She has, therefore, been looking to certain District government agencies and non-profit partners outside of government to support her vision for a more open government. Ms. Hughes commented, for example, that the Council of the District of Columbia’s General Counsel has been a great partner, as has been the Office of the State Superintendent of Education, which has been a leader in making information about education available to parents. Ms. Hughes recognized Code for DC, the all-volunteer local chapter of Code for America, for producing “ANC Finder,” an application that provides residents, based on their address, with information about their Advisory Neighborhood Commission – DC’s hyper-local level of government where each Commissioner represents approximately 2,000 people.</p><p>Ms. Hughes, however, has a broader vision for open access to the District of Columbia’s data and records. Ms. Hughes stated that the Council of the District of Columbia and the Mayor need to pass legislation to drive the open government process. In addition, the city must do more to bridge the gaps between people with varying levels of Internet access. I interpreted this statement as her way of saying that many more city services should be accessible through mobile devices. Indeed, a 2013 Pew study indicates that 10% of urban residents have a smartphone, but no home broadband connection.</p><p>Making government services available through mobile devices was one of the themes of the evening. The representatives from Code for DC stressed the importance of moving government processes to mobile platforms. The process of applying for public housing, for example, often involves filling out a different paper form for each potential housing option for which a person is applying. While the non-profit Bread for the City is currently helping people with the paper forms, Code for DC volunteers are working toward a technology-based solution. In addition, people are lobbying to make filing a Freedom of Information Act request and contesting a property tax assessment possible through mobile devices. I had a great side conversation with a Code for DC volunteer who has mapped the DC restaurants that have been cited recently for health code violations. His next step is developing a mobile app. Given the ubiquity of the violations, I was glad I had already eaten.</p><p>Beyond mobile, one of the most impressive recent innovations by the DC government is Advisory Neighborhood Commission 3F live streaming its monthly meetings. Advisory Neighborhood Commission meetings are not typically broadcast on public access television, therefore live streaming makes meetings available, for example, to people with kids who can’t get out in the evening and senior citizens or people with disabilities who cannot get to the meeting location. Live streaming uses only $75 of the Advisory Neighborhood Commission’s budget per meeting and people can ask questions directly beneath the feed or by reaching out to the Advisory Neighborhood Commission’s Chairman via Twitter. Another Advisory Neighborhood Commission records its meetings and posts them on YouTube subsequently. While these are great solutions for constituents who are tech savvy and have fast home broadband connections, to reach the widest possible audience, Advisory Neighborhood Commissions still must continue to use both on-line and off-line engagement methods.</p><p>While increasing participation is very important, so is facilitating accountability. A local activist and Washington Post reporter both discussed the importance of responses to FOIA requests in conducting research, particularly on under-the-radar issues that are nonetheless affecting city residents’ lives. FOIAs have been a critical tool in preventing legal on-line gambling in DC and exposing corruption in the Office of the Chief Financial Officer regarding commercial property assessments.</p><p>Based on the Summit, here are my three recommendations: (1) The DC Office of Open Government needs to have a more productive and collaborative relationship with the Mayor’s Office. The Mayor’s office needs to promote a culture that makes sharing information with both the public and across the city government a priority; (2) Cities that are integrating technology into governance effectively, such as New York, Boston, and Philadelphia, have someone leading those efforts from the Mayor’s office. Washington, DC needs leadership at that level; and (3) To eliminate the inconsistencies across city agencies, the DC government needs to establish written, uniform policies for responding to FOIAs and providing data sets that are easy to manipulate by members of the public and post these policies where the public can review them. The seeds of an open, efficient government exist, but will only grow with strong and committed leadership.</p>
") (wfw:commentRss nil "https://freedom-to-tinker.com/blog/jtignor/reflecting-on-sunshine-week/feed/") (slash:comments nil "3"))) ("Algorithms can be more accountable than people" "<p>At an academic meeting recently, I was surprised to hear some social scientists accept as obviously correct the claim that involving “algorithms” in decision-making, instead of sticking with good old-fashioned human decision-making, necessarily reduces accountability and increases the risk of bias.  I tend to believe the opposite, that making processes algorithmic improves our ability to understand why they give the results they do.  Let me explain why.</p><p>Consider a process to decide who receives some award or benefit; and suppose we want to make sure the process is not biased against some disadvantaged group, which I’ll call Group G.  If a person just makes the decision, we can ask them whether they were fair to members of Group G.  Or we can ask them why decided the way they did.  Either way, they can simply lie about their true motivation and process, to construct a story that is consistent with non-discrimination; or they might honestly believe their decision was fair even though it reflected unconscious bias. At the risk of massive understatement: history teaches that this kind of bias in human decision-making is difficult to prevent.</p><p>An algorithm, by contrast, cannot hide from everyone the details of how it reached its decision.  If you want to know that an algorithm didn’t use information about a person’s Group G status, you can verify that the Group G status wasn’t provided to the algorithm.  Or, if you prefer, you can re-run the algorithm with the Group G status field changed, to see if the result would have been different.  Or you can collect statistics on whether certain parts of the algorithm have a disparate impact on Group G members as compared to the rest of the population.</p><p>This is not to say that everything about algorithms is easy.  There are plenty of hard problems in understanding algorithms, both in theory and in practice.  My point is merely that if you want to understand how a decision was made, or you want to build in protections to make sure the decision process has certain desirable properties, you’re better off working with an algorithm than with a human decision, because the algorithm can tell you how it got from inputs to outputs.</p><p>When people complain that algorithms aren’t transparent, the real problem is usually that someone is keeping the algorithm or its input data secret.  What makes the process non-transparent is that the result is emitted without explanation—which is a non-transparent approach no matter what is behind the curtain, a person or a machine.</p><p>Of course, a company might be justified legally in keeping their algorithm secret from you; and it might be good business for them to do so.  Regardless, it’s important to recognize that non-transparency is a choice they are making and not a consequence of the fact that they’re using computation.</p><p>If accountability is important to us—and I think it should be—then we should be developing ways to reconcile transparency with partial secrecy, so that a company or government agency can keep some aspects of their process secret when that is justified, while making other aspects transparent.  Transparency needn’t be an all-or-nothing choice.</p>" "https://freedom-to-tinker.com/blog/felten/algorithms-can-be-more-accountable-than-people/" (21289 34896) new 7 nil nil ((title nil "Algorithms can be more accountable than people") (link nil "https://freedom-to-tinker.com/blog/felten/algorithms-can-be-more-accountable-than-people/") (comments nil "https://freedom-to-tinker.com/blog/felten/algorithms-can-be-more-accountable-than-people/#comments") (pubDate nil "Wed, 19 Mar 2014 12:06:40 +0000") (dc:creator nil "Ed Felten") (guid ((isPermaLink . "false")) "https://freedom-to-tinker.com/?p=9696") (description nil "At an academic meeting recently, I was surprised to hear some social scientists accept as obviously correct the claim that involving &#8220;algorithms&#8221; in decision-making, instead of sticking with good old-fashioned human decision-making, necessarily reduces accountability and increases the risk of bias. I tend to believe the opposite, that making processes algorithmic improves our ability to [...]") (content:encoded nil "<p>At an academic meeting recently, I was surprised to hear some social scientists accept as obviously correct the claim that involving &#8220;algorithms&#8221; in decision-making, instead of sticking with good old-fashioned human decision-making, necessarily reduces accountability and increases the risk of bias.  I tend to believe the opposite, that making processes algorithmic improves our ability to understand why they give the results they do.  Let me explain why.</p><p>Consider a process to decide who receives some award or benefit; and suppose we want to make sure the process is not biased against some disadvantaged group, which I&#8217;ll call Group G.  If a person just makes the decision, we can ask them whether they were fair to members of Group G.  Or we can ask them why decided the way they did.  Either way, they can simply lie about their true motivation and process, to construct a story that is consistent with non-discrimination; or they might honestly believe their decision was fair even though it reflected unconscious bias. At the risk of massive understatement: history teaches that this kind of bias in human decision-making is difficult to prevent.</p><p>An algorithm, by contrast, cannot hide from everyone the details of how it reached its decision.  If you want to know that an algorithm didn&#8217;t use information about a person&#8217;s Group G status, you can verify that the Group G status wasn&#8217;t provided to the algorithm.  Or, if you prefer, you can re-run the algorithm with the Group G status field changed, to see if the result would have been different.  Or you can collect statistics on whether certain parts of the algorithm have a disparate impact on Group G members as compared to the rest of the population.</p><p>This is not to say that everything about algorithms is easy.  There are plenty of hard problems in understanding algorithms, both in theory and in practice.  My point is merely that if you want to understand how a decision was made, or you want to build in protections to make sure the decision process has certain desirable properties, you&#8217;re better off working with an algorithm than with a human decision, because the algorithm can tell you how it got from inputs to outputs.</p><p>When people complain that algorithms aren&#8217;t transparent, the real problem is usually that someone is keeping the algorithm or its input data secret.  What makes the process non-transparent is that the result is emitted without explanation&#8212;which is a non-transparent approach no matter what is behind the curtain, a person or a machine.</p><p>Of course, a company might be justified legally in keeping their algorithm secret from you; and it might be good business for them to do so.  Regardless, it&#8217;s important to recognize that non-transparency is a choice they are making and not a consequence of the fact that they&#8217;re using computation.</p><p>If accountability is important to us&#8212;and I think it should be&#8212;then we should be developing ways to reconcile transparency with partial secrecy, so that a company or government agency can keep some aspects of their process secret when that is justified, while making other aspects transparent.  Transparency needn&#8217;t be an all-or-nothing choice.</p>
") (wfw:commentRss nil "https://freedom-to-tinker.com/blog/felten/algorithms-can-be-more-accountable-than-people/feed/") (slash:comments nil "9"))) ("Why Dorian Nakamoto Probably Isn’t Satoshi" "<p>When Newsweek published its <a href=\"http://mag.newsweek.com/2014/03/14/bitcoin-satoshi-nakamoto.html\">cover story</a> last week claiming to have identified the creator of Bitcoin, I tweeted that I was reserving judgment on their claim, pending more evidence.  At this point it looks like they don’t have more evidence to show us—and that Newsweek is probably wrong.</p><p>Bitcoin’s founder called himself “Satoshi Nakamoto” and is commonly called simply “Satoshi.”  Most people believe the founder chose this pseudonym to hide his/her/their identity.  Newsweek claims instead that a California engineer named Dorian Prentice Satoshi Nakamoto is Satoshi.  Dorian’s birth name was Satoshi Nakamoto but he legally changed his name to Dorian in 1973.  (For clarity, I’ll call him “Dorian”, and I’ll use “Satoshi” to refer to the Bitcoin founder, so that the question at hand is whether Dorian and Satoshi are the same person.)</p><p>Felix Salmon, who has some of the best commentary on the Dorian/Satoshi matter, <a href=\"http://blogs.reuters.com/felix-salmon/2014/03/10/satoshi-why-newsweek-isnt-convincing/\">points out</a> that Newsweek’s claim is almost universally disbelieved in the technical community. Part of the reason is the perception that Newsweek’s evidence is thin, and people in the tech community aren’t inclined to defer to the institutional reputation of Newsweek.</p><p>Another reason is that the Newsweek piece is craftily written to give the impression that the evidence is stronger than it is. This starts from the first two words of the piece, which refer to Dorian as “Satoshi Nakamoto”.  Only later is it made clear that that is not actually the man’s name, and hasn’t been his name at any point in the relevant period. Newsweek even says that his “name really is Satoshi Nakamoto”—which is not true. Newsweek wants us to believe that Dorian decided to sign the Bitcoin paper with his birth name rather than the name he had been using for 35 years.  There’s no explanation as to why he would have used his birth name on the Bitcoin paper.</p><p>The followup comments from Newsweek’s team don’t give much confidence either.  For example, Salmon quotes Newsweek editor Jim Impoco as saying “we eliminated every other possible person.”  That can’t possibly be true, or even close to true.  And it’s not the only time Newsweek people have fallen back on an argument that they couldn’t rule out Dorian, which is far short of saying that they have positive evidence that Dorian is Satoshi.</p><p>To me, one of the weakest points in Newsweek’s argument is their assertion that Dorian had the skills and background to create Bitcoin.  All they really have as evidence is that Dorian trained as a physicist, worked as an engineer, and is reputed to be very intelligent.  But none of that indicates that Dorian understood cryptography or distributed algorithms well enough to devise Bitcoin and write the <a href=\"https://bitcoin.org/bitcoin.pdf\">original Bitcoin paper</a>.  </p><p>The real Satoshi was obviously conversant with crypto—the Bitcoin design shows it, and the fluency of the crypto discussion in the paper tells us that Satoshi was well acquainted with the jargon and literature of the field.  Newsweek doesn’t offer any evidence that Dorian knew crypto.</p><p>Imagine you’re trying to track down the author of a novel written in fluent Hungarian.  Somebody points to a possible author who is a talented writer and speaks several languages.  One of the first questions you’ll ask is whether this candidate author knows Hungarian—especially when there are several known Hungarian speakers who are already suspected as possible authors.</p><p>Newsweek’s failure to ask such obvious questions—or their decision to plunge ahead despite not getting useful answers—is at the core of technologists’ skepticism about the story.  If they didn’t think to ask whether Dorian knew crypto, then they were probably in over their heads technically which throws other aspects of their analysis into doubt.  If they did ask, didn’t find answers they liked, and wrote the piece anyway without mentioning the missing evidence, then they are confirming the impression that their decision to publish was driven more by a desire for page-views than by the strength of the story.</p><p>It’s not too late for Newsweek, or somebody else, to show up with evidence tying Dorian to Satoshi.  But unless that evidence does turn up, I will continue to believe that Dorian Nakamoto is not the creator of Bitcoin.</p>" "https://freedom-to-tinker.com/blog/felten/why-dorian-nakamoto-probably-isnt-satoshi/" (21279 3666) new 8 nil nil ((title nil "Why Dorian Nakamoto Probably Isn’t Satoshi") (link nil "https://freedom-to-tinker.com/blog/felten/why-dorian-nakamoto-probably-isnt-satoshi/") (comments nil "https://freedom-to-tinker.com/blog/felten/why-dorian-nakamoto-probably-isnt-satoshi/#comments") (pubDate nil "Tue, 11 Mar 2014 13:23:30 +0000") (dc:creator nil "Ed Felten") (category nil "bitcoin") (category nil "Satoshi") (guid ((isPermaLink . "false")) "https://freedom-to-tinker.com/?p=9691") (description nil "When Newsweek published its cover story last week claiming to have identified the creator of Bitcoin, I tweeted that I was reserving judgment on their claim, pending more evidence. At this point it looks like they don&#8217;t have more evidence to show us&#8212;and that Newsweek is probably wrong. Bitcoin&#8217;s founder called himself &#8220;Satoshi Nakamoto&#8221; and [...]") (content:encoded nil "<p>When Newsweek published its <a href=\"http://mag.newsweek.com/2014/03/14/bitcoin-satoshi-nakamoto.html\">cover story</a> last week claiming to have identified the creator of Bitcoin, I tweeted that I was reserving judgment on their claim, pending more evidence.  At this point it looks like they don&#8217;t have more evidence to show us&#8212;and that Newsweek is probably wrong.</p><p>Bitcoin&#8217;s founder called himself &#8220;Satoshi Nakamoto&#8221; and is commonly called simply &#8220;Satoshi.&#8221;  Most people believe the founder chose this pseudonym to hide his/her/their identity.  Newsweek claims instead that a California engineer named Dorian Prentice Satoshi Nakamoto is Satoshi.  Dorian&#8217;s birth name was Satoshi Nakamoto but he legally changed his name to Dorian in 1973.  (For clarity, I&#8217;ll call him &#8220;Dorian&#8221;, and I&#8217;ll use &#8220;Satoshi&#8221; to refer to the Bitcoin founder, so that the question at hand is whether Dorian and Satoshi are the same person.)</p><p>Felix Salmon, who has some of the best commentary on the Dorian/Satoshi matter, <a href=\"http://blogs.reuters.com/felix-salmon/2014/03/10/satoshi-why-newsweek-isnt-convincing/\">points out</a> that Newsweek&#8217;s claim is almost universally disbelieved in the technical community. Part of the reason is the perception that Newsweek&#8217;s evidence is thin, and people in the tech community aren&#8217;t inclined to defer to the institutional reputation of Newsweek.</p><p>Another reason is that the Newsweek piece is craftily written to give the impression that the evidence is stronger than it is. This starts from the first two words of the piece, which refer to Dorian as &#8220;Satoshi Nakamoto&#8221;.  Only later is it made clear that that is not actually the man&#8217;s name, and hasn&#8217;t been his name at any point in the relevant period. Newsweek even says that his &#8220;name really is Satoshi Nakamoto&#8221;&#8212;which is not true. Newsweek wants us to believe that Dorian decided to sign the Bitcoin paper with his birth name rather than the name he had been using for 35 years.  There&#8217;s no explanation as to why he would have used his birth name on the Bitcoin paper.</p><p>The followup comments from Newsweek&#8217;s team don&#8217;t give much confidence either.  For example, Salmon quotes Newsweek editor Jim Impoco as saying &#8220;we eliminated every other possible person.&#8221;  That can&#8217;t possibly be true, or even close to true.  And it&#8217;s not the only time Newsweek people have fallen back on an argument that they couldn&#8217;t rule out Dorian, which is far short of saying that they have positive evidence that Dorian is Satoshi.</p><p>To me, one of the weakest points in Newsweek&#8217;s argument is their assertion that Dorian had the skills and background to create Bitcoin.  All they really have as evidence is that Dorian trained as a physicist, worked as an engineer, and is reputed to be very intelligent.  But none of that indicates that Dorian understood cryptography or distributed algorithms well enough to devise Bitcoin and write the <a href=\"https://bitcoin.org/bitcoin.pdf\">original Bitcoin paper</a>.  </p><p>The real Satoshi was obviously conversant with crypto&#8212;the Bitcoin design shows it, and the fluency of the crypto discussion in the paper tells us that Satoshi was well acquainted with the jargon and literature of the field.  Newsweek doesn&#8217;t offer any evidence that Dorian knew crypto.</p><p>Imagine you&#8217;re trying to track down the author of a novel written in fluent Hungarian.  Somebody points to a possible author who is a talented writer and speaks several languages.  One of the first questions you&#8217;ll ask is whether this candidate author knows Hungarian&#8212;especially when there are several known Hungarian speakers who are already suspected as possible authors.</p><p>Newsweek&#8217;s failure to ask such obvious questions&#8212;or their decision to plunge ahead despite not getting useful answers&#8212;is at the core of technologists&#8217; skepticism about the story.  If they didn&#8217;t think to ask whether Dorian knew crypto, then they were probably in over their heads technically which throws other aspects of their analysis into doubt.  If they did ask, didn&#8217;t find answers they liked, and wrote the piece anyway without mentioning the missing evidence, then they are confirming the impression that their decision to publish was driven more by a desire for page-views than by the strength of the story.</p><p>It&#8217;s not too late for Newsweek, or somebody else, to show up with evidence tying Dorian to Satoshi.  But unless that evidence does turn up, I will continue to believe that Dorian Nakamoto is not the creator of Bitcoin.</p>
") (wfw:commentRss nil "https://freedom-to-tinker.com/blog/felten/why-dorian-nakamoto-probably-isnt-satoshi/feed/") (slash:comments nil "4"))) ("FOIA: When the Exemptions Swallow the Rule" "<p>I’ve been researching and writing over the last few years on privately ordered—what the government calls “non-regulatory”—approaches to online IP enforcement. The gist of this approach is that members of trade groups representing different types of online intermediaries (broadband providers, payment processors, ad networks, online pharmacies) agree in private contracts or less formal “voluntary best practices” documents to sanction or cut services to alleged IP infringers. I put quotes around “non-regulatory” not only because that’s the government’s word, but because the descriptor masks the fact that the government, at the behest of corporate rights owners, leans heavily on targeted intermediaries to negotiate and accept these agreements, all the while holding the threat of regulation over their heads. It has proven to be a very effective strategy. Many of the website blocking provisions in SOPA, which so memorably went down in flames of public outrage, have subsequently been implemented through these agreements, which belong to a broad category of regulatory practices that governance scholars call soft law.</p><p>Soft law arrangements between corporate rights owners and online intermediaries raise lots of concerns about due process and First Amendment rights, because such arrangements generally don’t provide for any neutral adjudication of accusations of infringement. (The “six strikes” protocol for deterring unlawful P2P file-sharing, about which you can read more <a title=\"&quot;Six Strikes&quot; Measured Against Five Norms\" href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2145059\" target=\"_blank\">here</a>, is a notable exception.) Moreover, there is no occasion for judicial scrutiny of the constitutional issues arising from these private arrangements, because there is no state action to trigger review. The arrangements have the effect of public law, insofar as they impact millions of members of the public, but without accountability to the public.</p><p>The way most of these arrangements work is as follows: A corporate rights owner makes an accusation of infringement or counterfeiting to a participating online intermediary. The complaint triggers some form of investigation internal to the intermediary.  Following the investigation, a sanction is imposed if the accused website operator cannot prove his or her innocence to the intermediary’s satisfaction. The sanction can be as severe as termination of service by the participating intermediary. Unlike in a civil court case, where the burden of proof is on the complainant, the burden under these protocols is on the accused to prove that she is not an infringer.</p><p>My current work in this area focuses on a code of voluntary best practices adopted by payment processors like Visa, MasterCard, and PayPal. The document is referenced multiple times in the Office of the Intellectual Property Enforcement Coordinator’s <a title=\"IPEC 2013 JSP\" href=\"http://www.whitehouse.gov/sites/default/files/omb/IPEC/2013-us-ipec-joint-strategic-plan.pdf\" target=\"_blank\">2013 Joint Strategic Plan</a>. In connection with my research, I asked a librarian with whom I work to submit a FOIA request to IPEC. I was curious to know the nature and extent of IPEC’s role as a midwife for these private enforcement arrangements. The request submitted was for “any documents pertaining to the development or drafting of a code of voluntary best practices for payment processors or intermediaries with respect to online transactions.”</p><p>IPEC recently <a title=\"IPEC Denial\" href=\"https://drive.google.com/file/d/0BzAtTUkwGWhbdHppUlhNbFpiZFE/edit?usp=sharing\" target=\"_blank\">responded</a> to the request. It said that it had located 60 relevant documents, including the four-page best practices document. It refused, however, to produce any of the responsive documents, citing Exemptions 4 and 5 of FOIA. <a title=\"FOIA Exemption 4 - DOJ Guide\" href=\"http://www.justice.gov/oip/exemption4.htm\" target=\"_blank\">Exemption 4</a> is basically for trade secrets entrusted to the government by third parties. <a title=\"FOIA Exemption 5 - DOJ Guide\" href=\"http://www.justice.gov/oip/exemption5.htm\" target=\"_blank\">Exemption 5</a> covers documents relating to the “deliberative process” of an agency engaged in rule-making. Given IPEC’s own claim that the voluntary best practices approach is non-regulatory, it seems highly questionable for IPEC to have invoked the deliberative process privilege. This is particularly true in light of President Obama’s directive to agency heads that a presumption of disclosure should apply to all decisions involving FOIA.</p><p>I was ultimately able to get the four-page best practices document from the International Anti-Counterfeiting Coalition (IACC), which operates as the point of intake for complaints by corporate rights owners. Given that the document is a collection of industry-embraced “best practices” that applies to every website operator that accepts third-party payments, it should be openly available. And IPEC’s role in its development should be a matter of public record.</p>" "https://freedom-to-tinker.com/blog/abridy/foia-when-the-exemptions-swallow-the-rule/" (21271 39500) new 9 nil nil ((title nil "FOIA: When the Exemptions Swallow the Rule") (link nil "https://freedom-to-tinker.com/blog/abridy/foia-when-the-exemptions-swallow-the-rule/") (comments nil "https://freedom-to-tinker.com/blog/abridy/foia-when-the-exemptions-swallow-the-rule/#comments") (pubDate nil "Wed, 05 Mar 2014 21:42:36 +0000") (dc:creator nil "Annemarie Bridy") (category nil "Exemption 4") (category nil "Exemption 5") (category nil "FOIA") (category nil "intellectual property") (category nil "IPEC") (category nil "SOPA") (guid ((isPermaLink . "false")) "https://freedom-to-tinker.com/?p=9678") (description nil "I&#8217;ve been researching and writing over the last few years on privately ordered—what the government calls “non-regulatory”—approaches to online IP enforcement. The gist of this approach is that members of trade groups representing different types of online intermediaries (broadband providers, payment processors, ad networks, online pharmacies) agree in private contracts or less formal “voluntary best [...]") (content:encoded nil "<p>I&#8217;ve been researching and writing over the last few years on privately ordered—what the government calls “non-regulatory”—approaches to online IP enforcement. The gist of this approach is that members of trade groups representing different types of online intermediaries (broadband providers, payment processors, ad networks, online pharmacies) agree in private contracts or less formal “voluntary best practices” documents to sanction or cut services to alleged IP infringers. I put quotes around “non-regulatory” not only because that’s the government’s word, but because the descriptor masks the fact that the government, at the behest of corporate rights owners, leans heavily on targeted intermediaries to negotiate and accept these agreements, all the while holding the threat of regulation over their heads. It has proven to be a very effective strategy. Many of the website blocking provisions in SOPA, which so memorably went down in flames of public outrage, have subsequently been implemented through these agreements, which belong to a broad category of regulatory practices that governance scholars call soft law.</p><p>Soft law arrangements between corporate rights owners and online intermediaries raise lots of concerns about due process and First Amendment rights, because such arrangements generally don’t provide for any neutral adjudication of accusations of infringement. (The “six strikes” protocol for deterring unlawful P2P file-sharing, about which you can read more <a title=\"&quot;Six Strikes&quot; Measured Against Five Norms\" href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2145059\" target=\"_blank\">here</a>, is a notable exception.) Moreover, there is no occasion for judicial scrutiny of the constitutional issues arising from these private arrangements, because there is no state action to trigger review. The arrangements have the effect of public law, insofar as they impact millions of members of the public, but without accountability to the public.</p><p>The way most of these arrangements work is as follows: A corporate rights owner makes an accusation of infringement or counterfeiting to a participating online intermediary. The complaint triggers some form of investigation internal to the intermediary.  Following the investigation, a sanction is imposed if the accused website operator cannot prove his or her innocence to the intermediary’s satisfaction. The sanction can be as severe as termination of service by the participating intermediary. Unlike in a civil court case, where the burden of proof is on the complainant, the burden under these protocols is on the accused to prove that she is not an infringer.</p><p>My current work in this area focuses on a code of voluntary best practices adopted by payment processors like Visa, MasterCard, and PayPal. The document is referenced multiple times in the Office of the Intellectual Property Enforcement Coordinator&#8217;s <a title=\"IPEC 2013 JSP\" href=\"http://www.whitehouse.gov/sites/default/files/omb/IPEC/2013-us-ipec-joint-strategic-plan.pdf\" target=\"_blank\">2013 Joint Strategic Plan</a>. In connection with my research, I asked a librarian with whom I work to submit a FOIA request to IPEC. I was curious to know the nature and extent of IPEC’s role as a midwife for these private enforcement arrangements. The request submitted was for “any documents pertaining to the development or drafting of a code of voluntary best practices for payment processors or intermediaries with respect to online transactions.”</p><p>IPEC recently <a title=\"IPEC Denial\" href=\"https://drive.google.com/file/d/0BzAtTUkwGWhbdHppUlhNbFpiZFE/edit?usp=sharing\" target=\"_blank\">responded</a> to the request. It said that it had located 60 relevant documents, including the four-page best practices document. It refused, however, to produce any of the responsive documents, citing Exemptions 4 and 5 of FOIA. <a title=\"FOIA Exemption 4 - DOJ Guide\" href=\"http://www.justice.gov/oip/exemption4.htm\" target=\"_blank\">Exemption 4</a> is basically for trade secrets entrusted to the government by third parties. <a title=\"FOIA Exemption 5 - DOJ Guide\" href=\"http://www.justice.gov/oip/exemption5.htm\" target=\"_blank\">Exemption 5</a> covers documents relating to the “deliberative process” of an agency engaged in rule-making. Given IPEC’s own claim that the voluntary best practices approach is non-regulatory, it seems highly questionable for IPEC to have invoked the deliberative process privilege. This is particularly true in light of President Obama&#8217;s directive to agency heads that a presumption of disclosure should apply to all decisions involving FOIA.</p><p>I was ultimately able to get the four-page best practices document from the International Anti-Counterfeiting Coalition (IACC), which operates as the point of intake for complaints by corporate rights owners. Given that the document is a collection of industry-embraced “best practices” that applies to every website operator that accepts third-party payments, it should be openly available. And IPEC&#8217;s role in its development should be a matter of public record.</p>
") (wfw:commentRss nil "https://freedom-to-tinker.com/blog/abridy/foia-when-the-exemptions-swallow-the-rule/feed/") (slash:comments nil "0"))) ("9 Problems of Government Hacking: Why IT-Systems Deserve Constitutional Protection" "<p>Governments around the world are increasingly hacking into IT-systems. But for every apparent benefit, government hacking creates deeper problems. Time to unpack 9 of them, and to discuss one unique perspective: in response to a proposed hacking law in 2008, the German Constitutional Court created a new human right protecting the ‘confidentiality and integrity of IT-systems’. The rest of the world should follow suit, and outlaw government hacking until its deep problems are addressed. </p><p>The <a href=\"http://www.wired.com/threatlevel/2013/12/nsa-hacking-catalogue/\">NSA</a> has been hacking for a while now, but the FBI, state and even local authorities also seem to be hacking at will without public accountability. Yale ISP and Chris Soghoian put together a great conference on <a href=\"http://www.yaleisp.org/event/law-enforcement-and-hacking\">Law Enforcement Hacking</a> to start the discussion (video online soon). Probably because of its <a href=\"http://www.axelarnbak.nl/2014/01/29/echr-fast-tracks-court-case-on-prism-and-tempora-and-very-angry-birds/\">constitutional DNA</a>, some law enforcement agencies in Europe have felt obliged to provide some details to the public. So in my short talk [<a href=\"http://www.axelarnbak.nl/wp-content/uploads/2014/02/Arnbak-Yale-ISP-Law-Enforcement-Hacking-Hydra-180214.pdf\">slides</a> pdf] I could discuss the 2010 <a href=\"http://www.bredolab.nl/\">Bredolab</a> botnet case, as well as the 2008 German Constitutional Court ‘Bundestrojaner’ ruling (<a href=\"http://www.bverfg.de/en/press/bvg08-022en.html\">English summary</a>, excellent <a href=\"http://www2.law.ed.ac.uk/ahrc/script-ed/vol6-1/abel.asp\">case note</a>).</p><p>In the landmark ‘Federal Trojan’ case, the German court established a constitutional right the ‘confidentiality and integrity of IT-systems’ (recognize the c.i.a.-triad?). It held that IT-systems are a qualitatively unique space with regard to surveillance, and that government hacking is a stepping stone into further violations. IT-systems contain our most intimate and sensitive data – ‘the core of personality’ that is inviolate under art. 1 of its Constitution. As devices are increasingly networked, a successful hack also gives insight into the lives of people you interact with. Furthermore, devices might become a one stop-shop for law enforcement as we concentrate and even structure our lives on our devices or in the cloud. The Court also reflected on the internet of things: if your future fridge has ‘general purpose’ functionality such as storage, it may fall within the new constitutional right in Germany. The Court left a possibility open for future hacking laws, but only if such laws meet the strictest legal criteria the Court set to date. Much stricter than placing a wiretap, or searching a house.</p><p>Its rulings have had global impact before. In 1983, the German election census case created a new constitutional right to ‘informational self-determination’, providing a solid constitutional basis in Europe for data protection and the concept of consent. Interestingly, the European Court of Human Rights case-law is slowly but surely moving forward: <i><a href=\"http://hudoc.echr.coe.int/sites/eng/pages/search.aspx?i=001-87510\">I v. Finland</a></i> (2008, para. 37-39) establishes positive obligations to ensure data security through specific legislation, and the <i><a href=\"http://hudoc.echr.coe.int/sites/eng/pages/search.aspx?i=001-117133\">Bernh Larsen v. Norway</a></i> case (2013, para. 106) rules that ‘all data on a server’ deserves protection, not ‘only’ personal data. The <a href=\"https://freedom-to-tinker.com/blog/axel/echr-fast-tracks-court-case-on-prism-and-tempora-and-very-angry-birds/\" target=\"_blank\">fast-tracked and pending post-Snowden case</a> may push it further.</p><p>Constitutional protection provides the normative baseline to evaluate government surveillance law. And to condemn actual practices. The Chaos Computer Club discovered a few years after the ‘Bundestrojaner’ (love that term) ruling that German authorities continued to spread malware anyway. It got hold of a Bundestrojan and reverse-engineered it (<a href=\"http://ccc.de/en/updates/2011/staatstrojaner\">recommended read</a>). With the Dutch bredolab case and the comments made by the panel at the conference, a fascinating problem set emerges:</p><ol><li><b>Judicial oversight</b>: judges face a hard or impossible task assessing the admissibility of government hacking warrant. The hacking tools and payload of government malware are either lied about (as in Germany), sealed in court documentation, or obscured in newspeak: ‘network investigation tool’ or any other of over 20 synonyms.</li><li><b>Insecure malware</b>: the reverse engineered German malware was of so deplorable state, that it in facr facilitated man in the middle attacks on suspect and even law enforcement IT-systems. The commends to the trojan were unencrypted. All serious problems in themselves, also creating evidence issues in trial. A suspect may be able to claim someone else has placed code or data on its device.</li><li><b>Bad incentives</b>: governments get an incentive to weaken information security. Bits of Freedom launched a campaign on the <a href=\"https://www.bof.nl/2013/10/25/experts-call-upon-the-vendors-of-antivirus-software-for-transparency/\">role of antivirus companies</a>, which many co-signed, asking whether they will let badly crafted government malware through. FinFisher and <a href=\"https://en.wikipedia.org/wiki/FinFisher\">FinSpy</a> are existing, deeply troubling commercial hacking toolkit governments can get installed at ISPs. And at the conference we discussed OS software updates as an attack vector for governments. Will Microsoft, Apple or Google be forced to comply with government requests to provide backdoored updates to specific targets?</li><li><b><a href=\"http://www.reuters.com/article/2013/08/05/us-dea-sod-idUSBRE97409R20130805\">Parallel Construction</a>:</b> a <a href=\"http://www.washingtonpost.com/blogs/the-switch/wp/2013/08/05/the-nsa-is-giving-your-phone-records-to-the-dea-and-the-dea-is-covering-it-up/\">major issue</a>. This occurs when, say, the NSA hacks into a target, tips a law enforcement agency, which re-creates the same evidence from a different source. At a CITP reading group, we discussed whether this had actually happened in the Silkroad/DPR case.</li><li><b>Jurisdiction</b>: when can a law enforcement agency act? What determines a sovereign territory? ‘Citizenship’, ‘ip-address block’, or can governments hack across borders? Dutch authorities used the Bredolab botnet to hack into and remotely install a unverifiable .executable at thousands of infected machines across the internet.</li><li><b>Constitutional scope: </b>if I VPN my connection to Amsterdam, even though I’m physically based in the U.S., do I lose my reasonable expectation to 4th amendment protection that I would have if the government would raid my U.S. apartment?</li><li><b>Geopolitics</b>: what about the geopolitical Pandora’s box? if you happen to hack into a foreign government system, what about reciprocity, or retaliation?</li><li><b>No reliable data</b>: We don’t have reliable data about the size of the problem. Not aggregate, not in individual cases. Threats are systematically inflated, the size of the Bredolab botnet easily by an <a href=\"http://www.internetgovernance.org/2010/11/01/dutch-police-inflates-bredolab-botnet-success-by-factor-of-ten-and-then-some/\">order of magnitude</a>.</li><li><b>Necessity</b>: is government malware, or hacking even necessary? Many well-respected technologists <a href=\"http://www.theguardian.com/commentisfree/2014/jan/06/nsa-tailored-access-operations-privacy\">frame</a> the debate as “either mass surveillance, or targeted hacking”. While I agree that mass surveillance and weakening of infrastructure is even more problematic, I think that frame is incorrect in this golden age of surveillance. Less problematic alternatives will exist: the recent takedown of Utopia, a TOR hidden service widely regarded as a Silk Road heir, employed intrusive but well-established <a href=\"http://www.om.nl/@162281/undercover-onderzoek/\">undercover techniques</a>.</li></ol><p>The list doesn’t end here. The cynic and realist would say, “it’s happening anyway so why bother?” The simple answer is: government hacking is different than a wiretap, so needs a specific policy response. Until aforementioned problems are addressed and legal safeguards are in place, judges should push back and government hacking should be considered what it currently is: illegal.</p>" "https://freedom-to-tinker.com/blog/axel/9-problems-of-governments-hacking-why-it-systems-deserve-constitutional-protection/" (21254 2304) new 10 nil nil ((title nil "9 Problems of Government Hacking: Why IT-Systems Deserve Constitutional Protection") (link nil "https://freedom-to-tinker.com/blog/axel/9-problems-of-governments-hacking-why-it-systems-deserve-constitutional-protection/") (comments nil "https://freedom-to-tinker.com/blog/axel/9-problems-of-governments-hacking-why-it-systems-deserve-constitutional-protection/#comments") (pubDate nil "Thu, 20 Feb 2014 13:54:08 +0000") (dc:creator nil "Axel Arnbak") (guid ((isPermaLink . "false")) "https://freedom-to-tinker.com/?p=9656") (description nil "Governments around the world are increasingly hacking into IT-systems. But for every apparent benefit, government hacking creates deeper problems. Time to unpack 9 of them, and to discuss one unique perspective: in response to a proposed hacking law in 2008, the German Constitutional Court created a new human right protecting the &#8216;confidentiality and integrity of [...]") (content:encoded nil "<p>Governments around the world are increasingly hacking into IT-systems. But for every apparent benefit, government hacking creates deeper problems. Time to unpack 9 of them, and to discuss one unique perspective: in response to a proposed hacking law in 2008, the German Constitutional Court created a new human right protecting the &#8216;confidentiality and integrity of IT-systems&#8217;. The rest of the world should follow suit, and outlaw government hacking until its deep problems are addressed. </p><p>The <a href=\"http://www.wired.com/threatlevel/2013/12/nsa-hacking-catalogue/\">NSA</a> has been hacking for a while now, but the FBI, state and even local authorities also seem to be hacking at will without public accountability. Yale ISP and Chris Soghoian put together a great conference on <a href=\"http://www.yaleisp.org/event/law-enforcement-and-hacking\">Law Enforcement Hacking</a> to start the discussion (video online soon). Probably because of its <a href=\"http://www.axelarnbak.nl/2014/01/29/echr-fast-tracks-court-case-on-prism-and-tempora-and-very-angry-birds/\">constitutional DNA</a>, some law enforcement agencies in Europe have felt obliged to provide some details to the public. So in my short talk [<a href=\"http://www.axelarnbak.nl/wp-content/uploads/2014/02/Arnbak-Yale-ISP-Law-Enforcement-Hacking-Hydra-180214.pdf\">slides</a> pdf] I could discuss the 2010 <a href=\"http://www.bredolab.nl/\">Bredolab</a> botnet case, as well as the 2008 German Constitutional Court ‘Bundestrojaner’ ruling (<a href=\"http://www.bverfg.de/en/press/bvg08-022en.html\">English summary</a>, excellent <a href=\"http://www2.law.ed.ac.uk/ahrc/script-ed/vol6-1/abel.asp\">case note</a>).</p><p>In the landmark ‘Federal Trojan’ case, the German court established a constitutional right the ‘confidentiality and integrity of IT-systems’ (recognize the c.i.a.-triad?). It held that IT-systems are a qualitatively unique space with regard to surveillance, and that government hacking is a stepping stone into further violations. IT-systems contain our most intimate and sensitive data – ‘the core of personality’ that is inviolate under art. 1 of its Constitution. As devices are increasingly networked, a successful hack also gives insight into the lives of people you interact with. Furthermore, devices might become a one stop-shop for law enforcement as we concentrate and even structure our lives on our devices or in the cloud. The Court also reflected on the internet of things: if your future fridge has ‘general purpose’ functionality such as storage, it may fall within the new constitutional right in Germany. The Court left a possibility open for future hacking laws, but only if such laws meet the strictest legal criteria the Court set to date. Much stricter than placing a wiretap, or searching a house.</p><p>Its rulings have had global impact before. In 1983, the German election census case created a new constitutional right to ‘informational self-determination’, providing a solid constitutional basis in Europe for data protection and the concept of consent. Interestingly, the European Court of Human Rights case-law is slowly but surely moving forward: <i><a href=\"http://hudoc.echr.coe.int/sites/eng/pages/search.aspx?i=001-87510\">I v. Finland</a></i> (2008, para. 37-39) establishes positive obligations to ensure data security through specific legislation, and the <i><a href=\"http://hudoc.echr.coe.int/sites/eng/pages/search.aspx?i=001-117133\">Bernh Larsen v. Norway</a></i> case (2013, para. 106) rules that ‘all data on a server’ deserves protection, not ‘only’ personal data. The <a href=\"https://freedom-to-tinker.com/blog/axel/echr-fast-tracks-court-case-on-prism-and-tempora-and-very-angry-birds/\" target=\"_blank\">fast-tracked and pending post-Snowden case</a> may push it further.</p><p>Constitutional protection provides the normative baseline to evaluate government surveillance law. And to condemn actual practices. The Chaos Computer Club discovered a few years after the ‘Bundestrojaner’ (love that term) ruling that German authorities continued to spread malware anyway. It got hold of a Bundestrojan and reverse-engineered it (<a href=\"http://ccc.de/en/updates/2011/staatstrojaner\">recommended read</a>). With the Dutch bredolab case and the comments made by the panel at the conference, a fascinating problem set emerges:</p><ol><li><b>Judicial oversight</b>: judges face a hard or impossible task assessing the admissibility of government hacking warrant. The hacking tools and payload of government malware are either lied about (as in Germany), sealed in court documentation, or obscured in newspeak: ‘network investigation tool’ or any other of over 20 synonyms.</li><li><b>Insecure malware</b>: the reverse engineered German malware was of so deplorable state, that it in facr facilitated man in the middle attacks on suspect and even law enforcement IT-systems. The commends to the trojan were unencrypted. All serious problems in themselves, also creating evidence issues in trial. A suspect may be able to claim someone else has placed code or data on its device.</li><li><b>Bad incentives</b>: governments get an incentive to weaken information security. Bits of Freedom launched a campaign on the <a href=\"https://www.bof.nl/2013/10/25/experts-call-upon-the-vendors-of-antivirus-software-for-transparency/\">role of antivirus companies</a>, which many co-signed, asking whether they will let badly crafted government malware through. FinFisher and <a href=\"https://en.wikipedia.org/wiki/FinFisher\">FinSpy</a> are existing, deeply troubling commercial hacking toolkit governments can get installed at ISPs. And at the conference we discussed OS software updates as an attack vector for governments. Will Microsoft, Apple or Google be forced to comply with government requests to provide backdoored updates to specific targets?</li><li><b><a href=\"http://www.reuters.com/article/2013/08/05/us-dea-sod-idUSBRE97409R20130805\">Parallel Construction</a>:</b> a <a href=\"http://www.washingtonpost.com/blogs/the-switch/wp/2013/08/05/the-nsa-is-giving-your-phone-records-to-the-dea-and-the-dea-is-covering-it-up/\">major issue</a>. This occurs when, say, the NSA hacks into a target, tips a law enforcement agency, which re-creates the same evidence from a different source. At a CITP reading group, we discussed whether this had actually happened in the Silkroad/DPR case.</li><li><b>Jurisdiction</b>: when can a law enforcement agency act? What determines a sovereign territory? ‘Citizenship’, ‘ip-address block’, or can governments hack across borders? Dutch authorities used the Bredolab botnet to hack into and remotely install a unverifiable .executable at thousands of infected machines across the internet.</li><li><b>Constitutional scope: </b>if I VPN my connection to Amsterdam, even though I’m physically based in the U.S., do I lose my reasonable expectation to 4th amendment protection that I would have if the government would raid my U.S. apartment?</li><li><b>Geopolitics</b>: what about the geopolitical Pandora’s box? if you happen to hack into a foreign government system, what about reciprocity, or retaliation?</li><li><b>No reliable data</b>: We don’t have reliable data about the size of the problem. Not aggregate, not in individual cases. Threats are systematically inflated, the size of the Bredolab botnet easily by an <a href=\"http://www.internetgovernance.org/2010/11/01/dutch-police-inflates-bredolab-botnet-success-by-factor-of-ten-and-then-some/\">order of magnitude</a>.</li><li><b>Necessity</b>: is government malware, or hacking even necessary? Many well-respected technologists <a href=\"http://www.theguardian.com/commentisfree/2014/jan/06/nsa-tailored-access-operations-privacy\">frame</a> the debate as “either mass surveillance, or targeted hacking”. While I agree that mass surveillance and weakening of infrastructure is even more problematic, I think that frame is incorrect in this golden age of surveillance. Less problematic alternatives will exist: the recent takedown of Utopia, a TOR hidden service widely regarded as a Silk Road heir, employed intrusive but well-established <a href=\"http://www.om.nl/@162281/undercover-onderzoek/\">undercover techniques</a>.</li></ol><p>The list doesn’t end here. The cynic and realist would say, “it’s happening anyway so why bother?” The simple answer is: government hacking is different than a wiretap, so needs a specific policy response. Until aforementioned problems are addressed and legal safeguards are in place, judges should push back and government hacking should be considered what it currently is: illegal.</p>
") (wfw:commentRss nil "https://freedom-to-tinker.com/blog/axel/9-problems-of-governments-hacking-why-it-systems-deserve-constitutional-protection/feed/") (slash:comments nil "7"))))