;; -*- coding: utf-8 -*-
(("Freedom to Tinker" "Research and expert commentary on digital technologies in public life" "https://freedom-to-tinker.com" (21325 61144 730158 669000) feed 0 nil nil ((title nil "Freedom to Tinker") (atom:link ((href . "https://freedom-to-tinker.com/feed/") (rel . "self") (type . "application/rss+xml"))) (link nil "https://freedom-to-tinker.com") (description nil "Research and expert commentary on digital technologies in public life") (lastBuildDate nil "Wed, 09 Apr 2014 16:17:28 +0000") (language nil "en-US") (sy:updatePeriod nil "hourly") (sy:updateFrequency nil "1") (generator nil "http://wordpress.org/?v=3.5") (item nil (title nil "How to protect yourself from Heartbleed") (link nil "https://freedom-to-tinker.com/blog/felten/how-to-protect-yourself-from-heartbleed/") (comments nil "https://freedom-to-tinker.com/blog/felten/how-to-protect-yourself-from-heartbleed/#comments") (pubDate nil "Wed, 09 Apr 2014 14:57:41 +0000") (dc:creator nil "Ed Felten") (guid ((isPermaLink . "false")) "https://freedom-to-tinker.com/?p=9774") (description nil "The Heartbleed vulnerability is one of the worst Internet security problems we have seen. I&#8217;ll be writing more about what we can learn from Heartbleed and the response to it. For now, here is a quick checklist of what you can do to protect yourself. If you are a regular user: Most of the sites [...]") (content:encoded nil "<p>The Heartbleed vulnerability is one of the worst Internet security problems we have seen.  I&#8217;ll be writing more about what we can learn from Heartbleed and the response to it.  </p><p>For now, here is a quick checklist of what you can do to protect yourself.</p><p><strong>If you are a regular user:</strong></p><p>Most of the sites you use were probably vulnerable.  Your password might have been leaked from any one of them.  Unless you&#8217;re sure that a site was <em>never</em> vulnerable, you should change your password on that site.  (It&#8217;s not enough that a site is invulnerable <em>now</em>, because your password could have leaked before the site was fixed.)</p><p>Yes, it&#8217;s a pain to change your passwords, but you were really meaning to change them at some point anyway, weren&#8217;t you?  Now is a good time.  (It&#8217;s also a good time to turn on two-factor authentication, on sites that offer it.)</p><p>But, before you change your password on a site, you need to make sure that that site has closed any remaining vulnerability.  Look for an unequivocal statement from the site that (1) they are no longer vulnerable and (2) they have changed the private encryption key they use to protect HTTPS traffic.   Once you&#8217;re sure that they have done those two things, then you should go ahead and change your password on the site.  If they haven&#8217;t done those two things, then it&#8217;s best to wait until they do.  Make yourself a note to come back and check in a few days.  </p><p>The bad news is that some of your private information might have leaked from a vulnerable site.  It will be very difficult to tell whether this happened, even for the site itself, and nearly impossible to undo a leak if it did happen. </p><p><strong>If you run a website that supports HTTPS, and you run your own server:</strong></p><ul><li>Go to http://filippo.io/Heartbleed/ and enter the name of your site, to test whether your site is vulnerable.   If you&#8217;re not vulnerable, you&#8217;re done.  If you are vulnerable, carry out the following steps.</li><li>Upgrade your server software to a non-vulnerable version.  I can&#8217;t give you general advice on how to do this because it depends on which software you are running.  Once you have done the upgrade, go back to http://filippo.io/Heartbleed/ and verify that you are no longer vulnerable.</li><li>After upgrading your software, generate a new SSL/TLS key and get a certificate for the new key.  Start using the new key and certificate.  (This is necessary because an attacker could have gotten your old key.)</li><li>Revoke the certificate you were previously using.  (This is necessary because an attacker who got your old key could be using your old key and certificate to impersonate your site.)</li><li>Have your users change the passwords that they use to log in to your site. (This is necessary because users&#8217; existing passwords could have been leaked. You need to get your house in order by carrying out the previous steps, before users can safely change passwords.)</li></ul><p><strong>If you run a website that supports HTTPS, and you use a web hosting service:</strong><br />
In this case, the hosting service runs the web server that powers your site.</p><ul><li>Find out from the hosting service whether its server was ever vulnerable to Heartbleed attacks.  If you&#8217;re confident that it was never vulnerable, then you&#8217;re good.  Otherwise, carry out the following steps.</li><li>Wait until the hosting service has upgraded its software to a non-vulnerable version.  Once they have done the upgrade, you should be able to go to http://filippo.io/Heartbleed/ and enter the address of your site, and be told that it is not vulnerable.   If this isn&#8217;t true yet, ask the hosting service to fix the problem, then wait a while and repeat.</li><li>Once the hosting service has upgraded its software and the test site shows you as not vulnerable, generate a new SSL/TLS key and get a certificate for the new key.  Start using the new key and certificate.  (This is necessary because an attacker could have gotten your old key.)</li><li>Revoke the certificate you were previously using.  (This is necessary because an attacker who got your old key could be using your old key and certificate to impersonate your site.)</li><li>If your site assigns passwords to users, have your users change the passwords that they use to log in to your site. (This is necessary because users&#8217; existing passwords could have been leaked. You need to get your house in order by carrying out the previous steps, before users can safely change passwords.)</li></ul>
") (wfw:commentRss nil "https://freedom-to-tinker.com/blog/felten/how-to-protect-yourself-from-heartbleed/feed/") (slash:comments nil "6")) (item nil (title nil "Cookies that give you away: The surveillance implications of web tracking") (link nil "https://freedom-to-tinker.com/blog/dreisman/cookies-that-give-you-away-the-surveillance-implications-of-web-tracking/") (comments nil "https://freedom-to-tinker.com/blog/dreisman/cookies-that-give-you-away-the-surveillance-implications-of-web-tracking/#comments") (pubDate nil "Fri, 04 Apr 2014 10:30:25 +0000") (dc:creator nil "Dillon Reisman") (category nil "cookies") (category nil "NSA") (category nil "surveillance") (guid ((isPermaLink . "false")) "https://freedom-to-tinker.com/?p=9732") (description nil "[Today we have another announcement of an exciting new research paper. Undergraduate Dillon Reisman, for his senior thesis, applied our web measurement platform to study some timely questions. -Arvind Narayanan] Over the past three months we’ve learnt that NSA uses third-party tracking cookies for surveillance (1, 2). These cookies, provided by a third-party advertising or analytics network [...]") (content:encoded nil "<p><i>[Today we have another announcement of an exciting new research paper. Undergraduate Dillon Reisman, for his senior thesis, applied our <a href=\"https://freedom-to-tinker.com/blog/randomwalker/web-measurement-for-fairness-and-transparency/\" target=\"_blank\">web measurement platform</a> to study some timely questions. -Arvind Narayanan]</i></p><p>Over the past three months we’ve learnt that NSA uses third-party tracking cookies for surveillance (<a href=\"http://www.washingtonpost.com/blogs/the-switch/wp/2013/12/10/nsa-uses-google-cookies-to-pinpoint-targets-for-hacking/\">1</a>, <a href=\"https://firstlook.org/theintercept/article/2014/03/12/nsa-plans-infect-millions-computers-malware/\">2</a>). These cookies, provided by a third-party advertising or analytics network (e.g. doubleclick.com, scorecardresearch.com), are ubiquitous on the web, and tag users’ browsers with unique pseudonymous IDs. In <a href=\"http://randomwalker.info/publications/cookie-surveillance.pdf\">a new paper</a>, we study just how big a privacy problem this is. We quantify what an observer can learn about a user&#8217;s web traffic by purely passively eavesdropping on the network, and arrive at surprising answers.</p><p>At first sight it doesn’t seem possible that eavesdropping alone can reveal much. First the eavesdropper on the Internet backbone sees millions of HTTP requests and responses. How can he associate the third-party HTTP request containing a user’s cookie with request to the first-party web page that the browser visited, which doesn’t contain the cookie? Second, how can visits to different first parties be linked to each other? And finally, even if all the web traffic for a single user can be linked together, how can the adversary go from a set pseudonymous cookies to the user’s real-world identity?</p><p><img class=\"aligncenter\" alt=\" \" src=\"https://lh6.googleusercontent.com/r00CfwTjy7KfYRzeh9NORNAMye90G3UTRYJXDWTJTl3599IyUEthHs7FZFEb8S6JPE9mQw4qYCxChixyjQxWxXQ-leyJ8SgJXZ95DPwjuyOQ04UEM0nC0ZUKOXQXXg\" width=\"579px;\" height=\"448px;\" /></p><p>The diagram illustrates how the eavesdropper can use multiple third-party cookies to link traffic. When a user visits ‘www.exampleA.com,’ the response contains the embedded tracker X, with an ID cookie ‘xxx’. The visits to exampleA and to X are tied together by IP address, which typically doesn’t change within a single page visit [1]. Another page visited by the same user might embed tracker Y bearing the pseudonymous cookie ‘yyy’. If the two page visits were made from different IP addresses, an eavesdropper seeing these cookies can’t tell that the same browser made both visits. But if a third page, however, embeds both trackers X and Y, then the eavesdropper will know that IDs ‘xxx’ and ‘yyy’ belong to the same user. This method applied iteratively has the potential of tying together a lot of the traffic of a single user.</p><p dir=\"ltr\">Once we had this idea, we wanted to test if it would actually work in practice. Everything depends on just how densely third-party trackers are actually embedded on sites. We conducted automated web crawls of 65 simulated users’ web browsing over three months, and found that unique cookies are so prevalent that the eavesdropper can reliably link 90% of a user’s web page visits to the same pseudonymous ID. (We omitted pages that embed no ID cookies at all, but those are a minority.)</p><p dir=\"ltr\">We also found that the cookie linking method is extremely robust and succeeds under a variety of conditions (Section 4.1). We considered how variations in cookie expiration dates, the size of the user’s history (i.e., the number of pages visited), and the types of pages visited affect the eavesdropper’s changes, and found the impact to be minimal. Perhaps most significantly, however, we found that this surveillance method can still link about 50% of a user’s history to the same pseudonymous ID even with just 25% of the current density of trackers on the web. This means that even if 75% of sites or trackers adopt mitigation strategies (such as deploying HTTPS), the eavesdropper still learns a lot.</p><p dir=\"ltr\"><img class=\"aligncenter\" alt=\" \" src=\"https://lh6.googleusercontent.com/w89sqWi4ZKGwI_50PZFfo09BbWfrTVSr-PiAqDKwdVBWhx1WaxYfUmnRWnyULdRf4QAnoFFoDe2a4851uymJijwZwellnr6ktrgqNePLLRNMsXZok2blDVbhn1esbQ\" width=\"405px;\" height=\"199px;\" /></p><p dir=\"ltr\">Finally, we studied how an eavesdropper might learn the real-world identity behind a cluster of web pages associated with a pseudonymous ID. It turns out that this is surprisingly easy &#8212; many sites display real-world attributes such as real name, username, or email on unencrypted pages to logged in users, which means that the eavesdropper gets to see these identifiers. We conducted a survey of such leakage on popular sites, and found that over half of popular sites with account creation leak some form of real-world identity (Section 4.2).</p><p dir=\"ltr\">While it’s no surprise that web traffic contains sensitive information about individuals, what we’ve shown is just how complete a profile can be extracted even if the user’s traffic is mixed with millions of other users. Further, an eavesdropper can connect these profiles to real-world identities without needing the co-operation of any websites. While HTTPS deployment by trackers can help, the only practical solution at the current time seems to be for users to install anti-tracking and anonymity tools.</p><p>&nbsp;</p><p dir=\"ltr\">[1] An exception is if the user routes traffic through Tor. Different requests can take different paths and the exit node IPs will be different. Thus, use of Tor with application-layer anonymization (e.g., Tor browser bundle) defeats our attack.</p><p dir=\"ltr\"><em>[Edit: minor edit for clarity.]</em></p>
") (wfw:commentRss nil "https://freedom-to-tinker.com/blog/dreisman/cookies-that-give-you-away-the-surveillance-implications-of-web-tracking/feed/") (slash:comments nil "9")) (item nil (title nil "Historic E.U. Net Neutrality Win Shows Maturing Digital Rights Advocacy") (link nil "https://freedom-to-tinker.com/blog/axel/historic-e-u-net-neutrality-win-shows-maturing-digital-rights-advocacy/") (comments nil "https://freedom-to-tinker.com/blog/axel/historic-e-u-net-neutrality-win-shows-maturing-digital-rights-advocacy/#comments") (pubDate nil "Thu, 03 Apr 2014 19:23:06 +0000") (dc:creator nil "Axel Arnbak") (guid ((isPermaLink . "false")) "https://freedom-to-tinker.com/?p=9750") (description nil "After a 5-year long campaign by European and U.S. digital rights NGOs, today the European Parliament turned a dubious Commission proposal on its head to safeguard the principle of net neutrality. It&#8217;s a historic win, and all over the news. It also shows how digital rights advocacy is maturing. The legislative proposal and its amendments [...]") (content:encoded nil "<p>After a 5-year long campaign by European and U.S. digital rights NGOs, today the European Parliament turned a dubious Commission proposal on its head to safeguard the principle of net neutrality. It&#8217;s a historic win, and <a href=\"http://www.nytimes.com/2014/04/04/business/international/eu-lawmakers-approve-tough-net-neutrality-rules.html?_r=0\" target=\"_blank\">all</a><a href=\"http://www.nytimes.com/2014/03/31/business/international/european-lawmakers-prepare-to-vote-on-net-neutrality.html\" target=\"_blank\">over</a><a href=\"http://blogs.wsj.com/digits/2014/04/02/who-says-european-net-neutrality-politics-is-boring/\" target=\"_blank\">the</a><a href=\"www.bbc.com/news/technology-26865869\" target=\"_blank\">news</a>. It also shows how digital rights advocacy is maturing. <img title=\"More...\" alt=\" \" src=\"https://www.axelarnbak.nl/wp-includes/js/tinymce/plugins/wordpress/img/trans.gif\" /></p><p>The <a href=\"http://www.europarl.europa.eu/sides/getDoc.do?pubRef=-//EP//TEXT+REPORT+A7-2014-0190+0+DOC+XML+V0//EN\" target=\"_blank\">legislative proposal and its amendments</a> contain a clear definition of net neutrality and quite solid provisions. With the final text, as always, the devil will be in the details. For one, the enforcement provisions could have been stronger. Perhaps some national governments, such as <a href=\"https://www.axelarnbak.nl/2014/03/13/translation-dutch-net-freedom-laws-2011-net-neutrality-no-commercial-wiretapping-no-3-strikes/\" target=\"_blank\">The Netherlands where net neutrality has already been enshrined in law for some years now</a>, will lobby for more discretion to enforce the rules on the national level.</p><p>Of course, it ain&#8217;t over till the fat lady sings: the E.U. Council (the relevant ministers of national governments) will debate the Parliament legislative text on 5/6 June 2014. Will it respect a democratic vote, or be influenced by the Telecoms lobby? History learns that industry lobbies are almost certain to leverage more power towards the E.U. Council, than citizens have with regard to their respective governments. Europe is often used as a proxy for politics that can&#8217;t be realized on a national level. Moreover, the May 2014 Parliament election comes before those negotiations in June, potentially changing the political dynamics: the current majority for net neutrality could change. So the jury is still out.</p><p>But what&#8217;s truly fascinating about the net neutrality vote, and perfect case study material, is how digital rights advocacy in Europe is maturing. A <a href=\"http://savetheinternet.eu/\" target=\"_blank\">slick campaign</a> was set up that got more people to call/fax/e-mail their representatives than back in the day with the historic no-vote on ACTA. That&#8217;s a second crucial point: ACTA was a no-vote, but here digital rights and consumer advocates were able to suggest meaningful legislative reform amidst intense political struggle. Expert amendments were suggested, a dubious proposal by the (Dutch) E.U. Commissioner &#8212; primarily interested in quick wins on roaming tariffs &#8212; delegitimized and the immensely powerful telecoms lobby were faced head-on. Quite nasty tactics by hostile E.U. Parliamentarians and lobbies were cleverly tackled. Unsurprisingly, and completely missing the point, even the <a href=\"http://pastebin.com/ezMCuF5s\" target=\"_blank\">child abuse card was played the night before the final vote</a>. Until the last minute, digital rights groups &#8212; in a highly dispersed Europe and with the help of U.S. NGOs &#8212; have shown that they can play ball as one front, when it really matters.</p><p>We see this more often these days, and it should give rise to some opportunism on E.U. policymaking. Apart from ACTA and net neutrality, data protection, mandatory website blocking and data retention also come to mind. Digital rights advocacy has matured in the last five years. Sure, the web has turned public and private online life into a surveillance society &#8212; so why be optimistic? Because at the same time, it appears that the obscure Brussels lobbying arena feels the surveillance of the public more and more.  Of course, we&#8217;re nowhere near a transparent political process, but these are interesting times.</p><p>For now, it&#8217;s a historic win for digital rights in Europe, that may spur spill-over effects to the U.S. and other countries as well. Time to enjoy a beer and some sleep for those that did the heavy lifting, including MEPs Amelia Andersdottir, Catherine Trautmann, Marietje Schaake and Petra Kammerevert and organizations such as <a href=\"https://www.edri.org\" target=\"_blank\">European Digital Rights</a>, <a href=\"http://www.laquadrature.net/en\" target=\"_blank\">La Quadrature du Net</a> and <a href=\"https://www.bitsoffreedom.nl\" target=\"_blank\">Bits of Freedom.</a> Remember those names, you&#8217;ll be hearing them again in a not so distant fascinating future.</p>
") (wfw:commentRss nil "https://freedom-to-tinker.com/blog/axel/historic-e-u-net-neutrality-win-shows-maturing-digital-rights-advocacy/feed/") (slash:comments nil "0")) (item nil (title nil "Secure protocols for accountable warrant execution") (link nil "https://freedom-to-tinker.com/blog/felten/secure-protocols-for-accountable-warrant-execution/") (comments nil "https://freedom-to-tinker.com/blog/felten/secure-protocols-for-accountable-warrant-execution/#comments") (pubDate nil "Wed, 02 Apr 2014 11:22:03 +0000") (dc:creator nil "Ed Felten") (guid ((isPermaLink . "false")) "https://freedom-to-tinker.com/?p=9708") (description nil "Last week the press reported that the White House will seek to redesign the NSA’s mass phone call data program, so that data will be held by the phone companies and accessed by the NSA, subject to a new warrant requirement. The Foreign Intelligence Surveillance Court will issue the warrants. Today Josh Kroll and I, [...]") (content:encoded nil "<p>Last week the press <a href=\"http://www.nytimes.com/2014/03/25/us/obama-to-seek-nsa-curb-on-call-data.html\"> reported</a> that the White House will seek to redesign the NSA’s mass phone call data program, so that data will be held by the phone companies and accessed by the NSA, subject to a new warrant requirement.  The Foreign Intelligence Surveillance Court will issue the warrants.</p><p>Today Josh Kroll and I, with colleagues at Stanford University, released a <a href=\"http://www.cs.princeton.edu/~felten/warrant-paper.pdf\">draft paper</a> on how to use cryptography to implement warrants to data in a secure, private, and accountable way.  </p><p>Our solution is a set of multi-party cryptographic protocols involving three primary parties: a data source who has data records, an investigator who wants access to data held by the data source, and a court (or other authorizer) who issues an order or warrant to authorize access to a record.  For example, a phone company might be the data source, the NSA might be the investigator, and the Foreign Intelligence Surveillance Court might be the court that issues an order.  Alternatively, an email provider might be the data source, an FBI agent might be the investigator, and a senior FBI official might act as the &#8220;court&#8221; that issues a National Security Letter.  Although we use words like &#8220;court&#8221;, &#8220;order&#8221;, and &#8220;investigator&#8221;, the protocol has wider application to situations where Party A is authorizing Party B to access data held by Party C, with legally defined requirements for access.</p><p>The protocol uses cryptography to guarantee several security, privacy, and accountability properties:</p><ul><li>When the court issues an order, it publishes a sealed version of the order. If challenged later, the court can unseal the order and reveal which record it covered.</li><li>Until the order is unsealed, only the court and the investigator can see which record the order covers.  If and when the order is unsealed, everyone can see which record it covered.</li><li>The investigator does not learn the contents of any record, unless there is a valid order for that record and the court has published a valid sealed version of that order.</li></ul><p>A counterintuitive aspect of our protocols is that an order can be executed, thereby giving the investigator access to the record covered by the order, without the data source necessarily learning (at the time) which record the investigator accessed.</p><p>These properties can be viewed as a set of checks on the power of the parties, to prevent any dishonest party from getting access to information without leaving a suitable trail.  When the trail itself is supposed to be secret, the protocol aims for accountability&#8212;for example, the court can issue an unjustified order but the court must commit to the order so that the violation will be uncovered if the court’s actions are challenged later.</p><p>Our paper gives more precise definitions of the desired properties, how the protocols work, and why the protocols achieve the desired properties.  We build on the work of previous researchers, as cited in our paper, and we present several versions of the protocol, with different security properties.</p><p>Our approach is feasible, even for very large data sets.  Our paper describes our work on implementing one of our more advanced protocols, and we show by experiment that the protocol is reasonably fast even for data sets of national scope.   We have released the <a href=\"http://www.cs.princeton.edu/~felten/warrant-benchmark.tar.gz\">code</a> we used to do these performance measurements.</p><p>We are releasing this paper now because there are important debates going on about how to organize lawful access to data by intelligence agencies.  We want to make the point that technology allows these processes to be both more secure and more accountable.  </p><p>We urge policymakers to consider how cryptography can make warrant regimes more secure for all parties, and more accountable.  Expert agencies within government, such as NIST, might provide input on these issues, in consultation with experts inside and outside of government.</p>
") (wfw:commentRss nil "https://freedom-to-tinker.com/blog/felten/secure-protocols-for-accountable-warrant-execution/feed/") (slash:comments nil "3")) (item nil (title nil "New research: Better wallet security for Bitcoin") (link nil "https://freedom-to-tinker.com/blog/stevenag/new-research-better-wallet-security-for-bitcoin/") (comments nil "https://freedom-to-tinker.com/blog/stevenag/new-research-better-wallet-security-for-bitcoin/#comments") (pubDate nil "Fri, 28 Mar 2014 16:26:01 +0000") (dc:creator nil "Steven Goldfeder") (guid ((isPermaLink . "false")) "https://freedom-to-tinker.com/?p=9718") (description nil "[UPDATE (April 3, 2014): We've found an error in our paper. In the threshold signature scheme that we used, there are restrictions on the threshold value. In particular if the key is shared over a degree t polynomial, then 2t+1 players (not t+1) are required to to construct a signature. We thought that this could [...]") (content:encoded nil "<p><strong>[UPDATE (April 3, 2014): We've found an error in our paper. In the threshold signature scheme that we used, there are restrictions on the threshold value. In particular if the key is shared over a degree t polynomial, then 2t+1 players (not t+1) are required to to construct a signature. We thought that this could be reduced to t+1, but our technique was flawed. We are exploring various modifications, and we will post further details when we have an update.]</strong></p><p dir=\"ltr\">The Bitcoin ecosystem has been plagued by thefts and losses that have affected both businesses and individuals. The security of a Bitcoin wallet rests entirely on the security of its associated private keys which can digitally sign transactions to irreversibly spend the coins in the wallet. In a <a href=\"http://www.cs.princeton.edu/~stevenag/bitcoin_threshold_signatures.pdf\">new paper</a>, we show how to use the cryptographic technique of <em>threshold signatures</em> to increase the security of both corporate and individual wallets.</p><p>Perhaps Bitcoin’s toughest security challenge is protecting Internet-connected wallets from insider threats. Such <em><a href=\"https://en.bitcoin.it/wiki/Hot_wallet\">hot wallets</a></em>cannot be kept in highly secure, offline cold storage. One good way for businesses to mitigate this vulnerability is to have hot wallets jointly controlled by multiple parties. This way, no party can independently steal corporate funds. In our paper, we show how to achieve <em>joint control</em> of wallets using threshold signatures.</p><p>The problem of implementing joint control is more important and more difficult for a Bitcoin wallet than it is for a traditional bank account. Whereas regular bank transactions have recovery mechanisms if fraud is detected, Bitcoin transactions are irreversible and their pseudonymity makes it difficult to identify thieves and attempt to recover stolen funds. Moreover, while large bank transactions typically require human action to complete, Bitcoin transactions&#8211;no matter how large&#8211;require only a cryptographic signature to authorize.</p><p>The threshold signature approach to joint control works like this: the private key controlling the wallet is split between devices belonging to <em>n</em> different participants such that any <em>m</em> of them can jointly produce a digital signature, while a group of less than <em>m</em> participants cannot. Crucially, in the process of producing a signature, <em>the key is never reconstructed</em>. As long as an attacker has compromised fewer than <em>m</em> devices, the key remains secure.</p><p>Our method for achieving joint control has significant benefits over Bitcoin’s “<a href=\"https://gist.github.com/gavinandresen/4039433\">multi-signature</a>” transactions. With multi-signatures, each party’s signature is published to the block chain, whereas threshold signatures allow participants to privately create a single signature which is indistinguishable from ordinary Bitcoin signatures. You can think of our solution as “stealth multi-signatures.” This improves anonymity and confidentiality while keeping transactions a constant size, reducing fees and providing flexibility to scale to an arbitrary number of parties.</p><p>We implemented a threshold signature protocol and have used it to demonstrate  joint control over a Bitcoin wallet. We produced <a href=\"https://blockchain.info/tx/55451090debe729120d4a2e6b49bd3d5cabb881e753ccda0f5ea499a3438de9b\">this transaction</a> using a 9-of-12 threshold signature. If you click on the link to see the transaction details, you won’t see anything special; it looks like any regular transaction. That’s exactly the point!</p><p>Joint control is one of several security measures that can be built using threshold signatures. In our paper, we show that threshold signatures can be used as a primitive to build schemes for <em>secure bookkeeping</em> and <em>secure delegation</em>. One application that we’re particularly excited about is using threshold signatures to achieve <em>two-factor security</em> for personal wallets. In a follow-up post, we will elaborate on this application and discuss our ongoing efforts to build a two-factor secure wallet.</p><p>The main lesson from our work is that a spectrum of traditional internal financial controls can be translated to the Bitcoin world by novel application of cryptography. We hope that the security measures we’ve proposed will become standard in Bitcoin usage, and we are looking forward to working with developers and others who want to adopt our solutions.</p><p>We’d like to thank Greg Maxwell and Andrew Miller for providing useful feedback.</p>
") (wfw:commentRss nil "https://freedom-to-tinker.com/blog/stevenag/new-research-better-wallet-security-for-bitcoin/feed/") (slash:comments nil "7")) (item nil (title nil "Reflecting on Sunshine Week") (link nil "https://freedom-to-tinker.com/blog/jtignor/reflecting-on-sunshine-week/") (comments nil "https://freedom-to-tinker.com/blog/jtignor/reflecting-on-sunshine-week/#comments") (pubDate nil "Wed, 26 Mar 2014 13:15:32 +0000") (dc:creator nil "Jeffrey Tignor") (category nil "Government transparency") (guid ((isPermaLink . "false")) "https://freedom-to-tinker.com/?p=9710") (description nil "Last Wednesday evening, I attended the D.C. Open Government Summit: Street View, which took place at the National Press Club in conjunction with Sunshine Week. The Summit was sponsored by the D.C. Open Government Coalition, a non-profit that “seeks to enhance the public’s access to government information and ensure the transparency of government operations of [...]") (content:encoded nil "<p>Last Wednesday evening, I attended the D.C. Open Government Summit: Street View, which took place at the National Press Club in conjunction with Sunshine Week. The Summit was sponsored by the D.C. Open Government Coalition, a non-profit that “seeks to enhance the public’s access to government information and ensure the transparency of government operations of the District of Columbia.” The Summit successfully focused on two main ideas – using government information to innovate and using government information to inform. I left the Summit encouraged by the enthusiasm for innovation and transparency in the attendees and among some District of Columbia government leaders, but also discouraged because there was a consensus that Washington, DC is still far behind cities such as New York, Kansas City, and Boston in using technology for innovation in government and there is not a vision or financial commitment from the Mayor’s office to facilitate government-wide progress.</p><p>In her keynote address, Traci Hughes, the Director of the District of Columbia Office of Open Government, commented that her office only has two employees and almost no budget beyond that for salaries. She has, therefore, been looking to certain District government agencies and non-profit partners outside of government to support her vision for a more open government. Ms. Hughes commented, for example, that the Council of the District of Columbia’s General Counsel has been a great partner, as has been the Office of the State Superintendent of Education, which has been a leader in making information about education available to parents. Ms. Hughes recognized Code for DC, the all-volunteer local chapter of Code for America, for producing “ANC Finder,” an application that provides residents, based on their address, with information about their Advisory Neighborhood Commission – DC’s hyper-local level of government where each Commissioner represents approximately 2,000 people.</p><p>Ms. Hughes, however, has a broader vision for open access to the District of Columbia’s data and records. Ms. Hughes stated that the Council of the District of Columbia and the Mayor need to pass legislation to drive the open government process. In addition, the city must do more to bridge the gaps between people with varying levels of Internet access. I interpreted this statement as her way of saying that many more city services should be accessible through mobile devices. Indeed, a 2013 Pew study indicates that 10% of urban residents have a smartphone, but no home broadband connection.</p><p>Making government services available through mobile devices was one of the themes of the evening. The representatives from Code for DC stressed the importance of moving government processes to mobile platforms. The process of applying for public housing, for example, often involves filling out a different paper form for each potential housing option for which a person is applying. While the non-profit Bread for the City is currently helping people with the paper forms, Code for DC volunteers are working toward a technology-based solution. In addition, people are lobbying to make filing a Freedom of Information Act request and contesting a property tax assessment possible through mobile devices. I had a great side conversation with a Code for DC volunteer who has mapped the DC restaurants that have been cited recently for health code violations. His next step is developing a mobile app. Given the ubiquity of the violations, I was glad I had already eaten.</p><p>Beyond mobile, one of the most impressive recent innovations by the DC government is Advisory Neighborhood Commission 3F live streaming its monthly meetings. Advisory Neighborhood Commission meetings are not typically broadcast on public access television, therefore live streaming makes meetings available, for example, to people with kids who can’t get out in the evening and senior citizens or people with disabilities who cannot get to the meeting location. Live streaming uses only $75 of the Advisory Neighborhood Commission’s budget per meeting and people can ask questions directly beneath the feed or by reaching out to the Advisory Neighborhood Commission’s Chairman via Twitter. Another Advisory Neighborhood Commission records its meetings and posts them on YouTube subsequently. While these are great solutions for constituents who are tech savvy and have fast home broadband connections, to reach the widest possible audience, Advisory Neighborhood Commissions still must continue to use both on-line and off-line engagement methods.</p><p>While increasing participation is very important, so is facilitating accountability. A local activist and Washington Post reporter both discussed the importance of responses to FOIA requests in conducting research, particularly on under-the-radar issues that are nonetheless affecting city residents’ lives. FOIAs have been a critical tool in preventing legal on-line gambling in DC and exposing corruption in the Office of the Chief Financial Officer regarding commercial property assessments.</p><p>Based on the Summit, here are my three recommendations: (1) The DC Office of Open Government needs to have a more productive and collaborative relationship with the Mayor’s Office. The Mayor’s office needs to promote a culture that makes sharing information with both the public and across the city government a priority; (2) Cities that are integrating technology into governance effectively, such as New York, Boston, and Philadelphia, have someone leading those efforts from the Mayor’s office. Washington, DC needs leadership at that level; and (3) To eliminate the inconsistencies across city agencies, the DC government needs to establish written, uniform policies for responding to FOIAs and providing data sets that are easy to manipulate by members of the public and post these policies where the public can review them. The seeds of an open, efficient government exist, but will only grow with strong and committed leadership.</p>
") (wfw:commentRss nil "https://freedom-to-tinker.com/blog/jtignor/reflecting-on-sunshine-week/feed/") (slash:comments nil "3")) (item nil (title nil "Algorithms can be more accountable than people") (link nil "https://freedom-to-tinker.com/blog/felten/algorithms-can-be-more-accountable-than-people/") (comments nil "https://freedom-to-tinker.com/blog/felten/algorithms-can-be-more-accountable-than-people/#comments") (pubDate nil "Wed, 19 Mar 2014 12:06:40 +0000") (dc:creator nil "Ed Felten") (guid ((isPermaLink . "false")) "https://freedom-to-tinker.com/?p=9696") (description nil "At an academic meeting recently, I was surprised to hear some social scientists accept as obviously correct the claim that involving &#8220;algorithms&#8221; in decision-making, instead of sticking with good old-fashioned human decision-making, necessarily reduces accountability and increases the risk of bias. I tend to believe the opposite, that making processes algorithmic improves our ability to [...]") (content:encoded nil "<p>At an academic meeting recently, I was surprised to hear some social scientists accept as obviously correct the claim that involving &#8220;algorithms&#8221; in decision-making, instead of sticking with good old-fashioned human decision-making, necessarily reduces accountability and increases the risk of bias.  I tend to believe the opposite, that making processes algorithmic improves our ability to understand why they give the results they do.  Let me explain why.</p><p>Consider a process to decide who receives some award or benefit; and suppose we want to make sure the process is not biased against some disadvantaged group, which I&#8217;ll call Group G.  If a person just makes the decision, we can ask them whether they were fair to members of Group G.  Or we can ask them why decided the way they did.  Either way, they can simply lie about their true motivation and process, to construct a story that is consistent with non-discrimination; or they might honestly believe their decision was fair even though it reflected unconscious bias. At the risk of massive understatement: history teaches that this kind of bias in human decision-making is difficult to prevent.</p><p>An algorithm, by contrast, cannot hide from everyone the details of how it reached its decision.  If you want to know that an algorithm didn&#8217;t use information about a person&#8217;s Group G status, you can verify that the Group G status wasn&#8217;t provided to the algorithm.  Or, if you prefer, you can re-run the algorithm with the Group G status field changed, to see if the result would have been different.  Or you can collect statistics on whether certain parts of the algorithm have a disparate impact on Group G members as compared to the rest of the population.</p><p>This is not to say that everything about algorithms is easy.  There are plenty of hard problems in understanding algorithms, both in theory and in practice.  My point is merely that if you want to understand how a decision was made, or you want to build in protections to make sure the decision process has certain desirable properties, you&#8217;re better off working with an algorithm than with a human decision, because the algorithm can tell you how it got from inputs to outputs.</p><p>When people complain that algorithms aren&#8217;t transparent, the real problem is usually that someone is keeping the algorithm or its input data secret.  What makes the process non-transparent is that the result is emitted without explanation&#8212;which is a non-transparent approach no matter what is behind the curtain, a person or a machine.</p><p>Of course, a company might be justified legally in keeping their algorithm secret from you; and it might be good business for them to do so.  Regardless, it&#8217;s important to recognize that non-transparency is a choice they are making and not a consequence of the fact that they&#8217;re using computation.</p><p>If accountability is important to us&#8212;and I think it should be&#8212;then we should be developing ways to reconcile transparency with partial secrecy, so that a company or government agency can keep some aspects of their process secret when that is justified, while making other aspects transparent.  Transparency needn&#8217;t be an all-or-nothing choice.</p>
") (wfw:commentRss nil "https://freedom-to-tinker.com/blog/felten/algorithms-can-be-more-accountable-than-people/feed/") (slash:comments nil "9")) (item nil (title nil "Why Dorian Nakamoto Probably Isn’t Satoshi") (link nil "https://freedom-to-tinker.com/blog/felten/why-dorian-nakamoto-probably-isnt-satoshi/") (comments nil "https://freedom-to-tinker.com/blog/felten/why-dorian-nakamoto-probably-isnt-satoshi/#comments") (pubDate nil "Tue, 11 Mar 2014 13:23:30 +0000") (dc:creator nil "Ed Felten") (category nil "bitcoin") (category nil "Satoshi") (guid ((isPermaLink . "false")) "https://freedom-to-tinker.com/?p=9691") (description nil "When Newsweek published its cover story last week claiming to have identified the creator of Bitcoin, I tweeted that I was reserving judgment on their claim, pending more evidence. At this point it looks like they don&#8217;t have more evidence to show us&#8212;and that Newsweek is probably wrong. Bitcoin&#8217;s founder called himself &#8220;Satoshi Nakamoto&#8221; and [...]") (content:encoded nil "<p>When Newsweek published its <a href=\"http://mag.newsweek.com/2014/03/14/bitcoin-satoshi-nakamoto.html\">cover story</a> last week claiming to have identified the creator of Bitcoin, I tweeted that I was reserving judgment on their claim, pending more evidence.  At this point it looks like they don&#8217;t have more evidence to show us&#8212;and that Newsweek is probably wrong.</p><p>Bitcoin&#8217;s founder called himself &#8220;Satoshi Nakamoto&#8221; and is commonly called simply &#8220;Satoshi.&#8221;  Most people believe the founder chose this pseudonym to hide his/her/their identity.  Newsweek claims instead that a California engineer named Dorian Prentice Satoshi Nakamoto is Satoshi.  Dorian&#8217;s birth name was Satoshi Nakamoto but he legally changed his name to Dorian in 1973.  (For clarity, I&#8217;ll call him &#8220;Dorian&#8221;, and I&#8217;ll use &#8220;Satoshi&#8221; to refer to the Bitcoin founder, so that the question at hand is whether Dorian and Satoshi are the same person.)</p><p>Felix Salmon, who has some of the best commentary on the Dorian/Satoshi matter, <a href=\"http://blogs.reuters.com/felix-salmon/2014/03/10/satoshi-why-newsweek-isnt-convincing/\">points out</a> that Newsweek&#8217;s claim is almost universally disbelieved in the technical community. Part of the reason is the perception that Newsweek&#8217;s evidence is thin, and people in the tech community aren&#8217;t inclined to defer to the institutional reputation of Newsweek.</p><p>Another reason is that the Newsweek piece is craftily written to give the impression that the evidence is stronger than it is. This starts from the first two words of the piece, which refer to Dorian as &#8220;Satoshi Nakamoto&#8221;.  Only later is it made clear that that is not actually the man&#8217;s name, and hasn&#8217;t been his name at any point in the relevant period. Newsweek even says that his &#8220;name really is Satoshi Nakamoto&#8221;&#8212;which is not true. Newsweek wants us to believe that Dorian decided to sign the Bitcoin paper with his birth name rather than the name he had been using for 35 years.  There&#8217;s no explanation as to why he would have used his birth name on the Bitcoin paper.</p><p>The followup comments from Newsweek&#8217;s team don&#8217;t give much confidence either.  For example, Salmon quotes Newsweek editor Jim Impoco as saying &#8220;we eliminated every other possible person.&#8221;  That can&#8217;t possibly be true, or even close to true.  And it&#8217;s not the only time Newsweek people have fallen back on an argument that they couldn&#8217;t rule out Dorian, which is far short of saying that they have positive evidence that Dorian is Satoshi.</p><p>To me, one of the weakest points in Newsweek&#8217;s argument is their assertion that Dorian had the skills and background to create Bitcoin.  All they really have as evidence is that Dorian trained as a physicist, worked as an engineer, and is reputed to be very intelligent.  But none of that indicates that Dorian understood cryptography or distributed algorithms well enough to devise Bitcoin and write the <a href=\"https://bitcoin.org/bitcoin.pdf\">original Bitcoin paper</a>.  </p><p>The real Satoshi was obviously conversant with crypto&#8212;the Bitcoin design shows it, and the fluency of the crypto discussion in the paper tells us that Satoshi was well acquainted with the jargon and literature of the field.  Newsweek doesn&#8217;t offer any evidence that Dorian knew crypto.</p><p>Imagine you&#8217;re trying to track down the author of a novel written in fluent Hungarian.  Somebody points to a possible author who is a talented writer and speaks several languages.  One of the first questions you&#8217;ll ask is whether this candidate author knows Hungarian&#8212;especially when there are several known Hungarian speakers who are already suspected as possible authors.</p><p>Newsweek&#8217;s failure to ask such obvious questions&#8212;or their decision to plunge ahead despite not getting useful answers&#8212;is at the core of technologists&#8217; skepticism about the story.  If they didn&#8217;t think to ask whether Dorian knew crypto, then they were probably in over their heads technically which throws other aspects of their analysis into doubt.  If they did ask, didn&#8217;t find answers they liked, and wrote the piece anyway without mentioning the missing evidence, then they are confirming the impression that their decision to publish was driven more by a desire for page-views than by the strength of the story.</p><p>It&#8217;s not too late for Newsweek, or somebody else, to show up with evidence tying Dorian to Satoshi.  But unless that evidence does turn up, I will continue to believe that Dorian Nakamoto is not the creator of Bitcoin.</p>
") (wfw:commentRss nil "https://freedom-to-tinker.com/blog/felten/why-dorian-nakamoto-probably-isnt-satoshi/feed/") (slash:comments nil "4")) (item nil (title nil "FOIA: When the Exemptions Swallow the Rule") (link nil "https://freedom-to-tinker.com/blog/abridy/foia-when-the-exemptions-swallow-the-rule/") (comments nil "https://freedom-to-tinker.com/blog/abridy/foia-when-the-exemptions-swallow-the-rule/#comments") (pubDate nil "Wed, 05 Mar 2014 21:42:36 +0000") (dc:creator nil "Annemarie Bridy") (category nil "Exemption 4") (category nil "Exemption 5") (category nil "FOIA") (category nil "intellectual property") (category nil "IPEC") (category nil "SOPA") (guid ((isPermaLink . "false")) "https://freedom-to-tinker.com/?p=9678") (description nil "I&#8217;ve been researching and writing over the last few years on privately ordered—what the government calls “non-regulatory”—approaches to online IP enforcement. The gist of this approach is that members of trade groups representing different types of online intermediaries (broadband providers, payment processors, ad networks, online pharmacies) agree in private contracts or less formal “voluntary best [...]") (content:encoded nil "<p>I&#8217;ve been researching and writing over the last few years on privately ordered—what the government calls “non-regulatory”—approaches to online IP enforcement. The gist of this approach is that members of trade groups representing different types of online intermediaries (broadband providers, payment processors, ad networks, online pharmacies) agree in private contracts or less formal “voluntary best practices” documents to sanction or cut services to alleged IP infringers. I put quotes around “non-regulatory” not only because that’s the government’s word, but because the descriptor masks the fact that the government, at the behest of corporate rights owners, leans heavily on targeted intermediaries to negotiate and accept these agreements, all the while holding the threat of regulation over their heads. It has proven to be a very effective strategy. Many of the website blocking provisions in SOPA, which so memorably went down in flames of public outrage, have subsequently been implemented through these agreements, which belong to a broad category of regulatory practices that governance scholars call soft law.</p><p>Soft law arrangements between corporate rights owners and online intermediaries raise lots of concerns about due process and First Amendment rights, because such arrangements generally don’t provide for any neutral adjudication of accusations of infringement. (The “six strikes” protocol for deterring unlawful P2P file-sharing, about which you can read more <a title=\"&quot;Six Strikes&quot; Measured Against Five Norms\" href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2145059\" target=\"_blank\">here</a>, is a notable exception.) Moreover, there is no occasion for judicial scrutiny of the constitutional issues arising from these private arrangements, because there is no state action to trigger review. The arrangements have the effect of public law, insofar as they impact millions of members of the public, but without accountability to the public.</p><p>The way most of these arrangements work is as follows: A corporate rights owner makes an accusation of infringement or counterfeiting to a participating online intermediary. The complaint triggers some form of investigation internal to the intermediary.  Following the investigation, a sanction is imposed if the accused website operator cannot prove his or her innocence to the intermediary’s satisfaction. The sanction can be as severe as termination of service by the participating intermediary. Unlike in a civil court case, where the burden of proof is on the complainant, the burden under these protocols is on the accused to prove that she is not an infringer.</p><p>My current work in this area focuses on a code of voluntary best practices adopted by payment processors like Visa, MasterCard, and PayPal. The document is referenced multiple times in the Office of the Intellectual Property Enforcement Coordinator&#8217;s <a title=\"IPEC 2013 JSP\" href=\"http://www.whitehouse.gov/sites/default/files/omb/IPEC/2013-us-ipec-joint-strategic-plan.pdf\" target=\"_blank\">2013 Joint Strategic Plan</a>. In connection with my research, I asked a librarian with whom I work to submit a FOIA request to IPEC. I was curious to know the nature and extent of IPEC’s role as a midwife for these private enforcement arrangements. The request submitted was for “any documents pertaining to the development or drafting of a code of voluntary best practices for payment processors or intermediaries with respect to online transactions.”</p><p>IPEC recently <a title=\"IPEC Denial\" href=\"https://drive.google.com/file/d/0BzAtTUkwGWhbdHppUlhNbFpiZFE/edit?usp=sharing\" target=\"_blank\">responded</a> to the request. It said that it had located 60 relevant documents, including the four-page best practices document. It refused, however, to produce any of the responsive documents, citing Exemptions 4 and 5 of FOIA. <a title=\"FOIA Exemption 4 - DOJ Guide\" href=\"http://www.justice.gov/oip/exemption4.htm\" target=\"_blank\">Exemption 4</a> is basically for trade secrets entrusted to the government by third parties. <a title=\"FOIA Exemption 5 - DOJ Guide\" href=\"http://www.justice.gov/oip/exemption5.htm\" target=\"_blank\">Exemption 5</a> covers documents relating to the “deliberative process” of an agency engaged in rule-making. Given IPEC’s own claim that the voluntary best practices approach is non-regulatory, it seems highly questionable for IPEC to have invoked the deliberative process privilege. This is particularly true in light of President Obama&#8217;s directive to agency heads that a presumption of disclosure should apply to all decisions involving FOIA.</p><p>I was ultimately able to get the four-page best practices document from the International Anti-Counterfeiting Coalition (IACC), which operates as the point of intake for complaints by corporate rights owners. Given that the document is a collection of industry-embraced “best practices” that applies to every website operator that accepts third-party payments, it should be openly available. And IPEC&#8217;s role in its development should be a matter of public record.</p>
") (wfw:commentRss nil "https://freedom-to-tinker.com/blog/abridy/foia-when-the-exemptions-swallow-the-rule/feed/") (slash:comments nil "0")) (item nil (title nil "9 Problems of Government Hacking: Why IT-Systems Deserve Constitutional Protection") (link nil "https://freedom-to-tinker.com/blog/axel/9-problems-of-governments-hacking-why-it-systems-deserve-constitutional-protection/") (comments nil "https://freedom-to-tinker.com/blog/axel/9-problems-of-governments-hacking-why-it-systems-deserve-constitutional-protection/#comments") (pubDate nil "Thu, 20 Feb 2014 13:54:08 +0000") (dc:creator nil "Axel Arnbak") (guid ((isPermaLink . "false")) "https://freedom-to-tinker.com/?p=9656") (description nil "Governments around the world are increasingly hacking into IT-systems. But for every apparent benefit, government hacking creates deeper problems. Time to unpack 9 of them, and to discuss one unique perspective: in response to a proposed hacking law in 2008, the German Constitutional Court created a new human right protecting the &#8216;confidentiality and integrity of [...]") (content:encoded nil "<p>Governments around the world are increasingly hacking into IT-systems. But for every apparent benefit, government hacking creates deeper problems. Time to unpack 9 of them, and to discuss one unique perspective: in response to a proposed hacking law in 2008, the German Constitutional Court created a new human right protecting the &#8216;confidentiality and integrity of IT-systems&#8217;. The rest of the world should follow suit, and outlaw government hacking until its deep problems are addressed. </p><p>The <a href=\"http://www.wired.com/threatlevel/2013/12/nsa-hacking-catalogue/\">NSA</a> has been hacking for a while now, but the FBI, state and even local authorities also seem to be hacking at will without public accountability. Yale ISP and Chris Soghoian put together a great conference on <a href=\"http://www.yaleisp.org/event/law-enforcement-and-hacking\">Law Enforcement Hacking</a> to start the discussion (video online soon). Probably because of its <a href=\"http://www.axelarnbak.nl/2014/01/29/echr-fast-tracks-court-case-on-prism-and-tempora-and-very-angry-birds/\">constitutional DNA</a>, some law enforcement agencies in Europe have felt obliged to provide some details to the public. So in my short talk [<a href=\"http://www.axelarnbak.nl/wp-content/uploads/2014/02/Arnbak-Yale-ISP-Law-Enforcement-Hacking-Hydra-180214.pdf\">slides</a> pdf] I could discuss the 2010 <a href=\"http://www.bredolab.nl/\">Bredolab</a> botnet case, as well as the 2008 German Constitutional Court ‘Bundestrojaner’ ruling (<a href=\"http://www.bverfg.de/en/press/bvg08-022en.html\">English summary</a>, excellent <a href=\"http://www2.law.ed.ac.uk/ahrc/script-ed/vol6-1/abel.asp\">case note</a>).</p><p>In the landmark ‘Federal Trojan’ case, the German court established a constitutional right the ‘confidentiality and integrity of IT-systems’ (recognize the c.i.a.-triad?). It held that IT-systems are a qualitatively unique space with regard to surveillance, and that government hacking is a stepping stone into further violations. IT-systems contain our most intimate and sensitive data – ‘the core of personality’ that is inviolate under art. 1 of its Constitution. As devices are increasingly networked, a successful hack also gives insight into the lives of people you interact with. Furthermore, devices might become a one stop-shop for law enforcement as we concentrate and even structure our lives on our devices or in the cloud. The Court also reflected on the internet of things: if your future fridge has ‘general purpose’ functionality such as storage, it may fall within the new constitutional right in Germany. The Court left a possibility open for future hacking laws, but only if such laws meet the strictest legal criteria the Court set to date. Much stricter than placing a wiretap, or searching a house.</p><p>Its rulings have had global impact before. In 1983, the German election census case created a new constitutional right to ‘informational self-determination’, providing a solid constitutional basis in Europe for data protection and the concept of consent. Interestingly, the European Court of Human Rights case-law is slowly but surely moving forward: <i><a href=\"http://hudoc.echr.coe.int/sites/eng/pages/search.aspx?i=001-87510\">I v. Finland</a></i> (2008, para. 37-39) establishes positive obligations to ensure data security through specific legislation, and the <i><a href=\"http://hudoc.echr.coe.int/sites/eng/pages/search.aspx?i=001-117133\">Bernh Larsen v. Norway</a></i> case (2013, para. 106) rules that ‘all data on a server’ deserves protection, not ‘only’ personal data. The <a href=\"https://freedom-to-tinker.com/blog/axel/echr-fast-tracks-court-case-on-prism-and-tempora-and-very-angry-birds/\" target=\"_blank\">fast-tracked and pending post-Snowden case</a> may push it further.</p><p>Constitutional protection provides the normative baseline to evaluate government surveillance law. And to condemn actual practices. The Chaos Computer Club discovered a few years after the ‘Bundestrojaner’ (love that term) ruling that German authorities continued to spread malware anyway. It got hold of a Bundestrojan and reverse-engineered it (<a href=\"http://ccc.de/en/updates/2011/staatstrojaner\">recommended read</a>). With the Dutch bredolab case and the comments made by the panel at the conference, a fascinating problem set emerges:</p><ol><li><b>Judicial oversight</b>: judges face a hard or impossible task assessing the admissibility of government hacking warrant. The hacking tools and payload of government malware are either lied about (as in Germany), sealed in court documentation, or obscured in newspeak: ‘network investigation tool’ or any other of over 20 synonyms.</li><li><b>Insecure malware</b>: the reverse engineered German malware was of so deplorable state, that it in facr facilitated man in the middle attacks on suspect and even law enforcement IT-systems. The commends to the trojan were unencrypted. All serious problems in themselves, also creating evidence issues in trial. A suspect may be able to claim someone else has placed code or data on its device.</li><li><b>Bad incentives</b>: governments get an incentive to weaken information security. Bits of Freedom launched a campaign on the <a href=\"https://www.bof.nl/2013/10/25/experts-call-upon-the-vendors-of-antivirus-software-for-transparency/\">role of antivirus companies</a>, which many co-signed, asking whether they will let badly crafted government malware through. FinFisher and <a href=\"https://en.wikipedia.org/wiki/FinFisher\">FinSpy</a> are existing, deeply troubling commercial hacking toolkit governments can get installed at ISPs. And at the conference we discussed OS software updates as an attack vector for governments. Will Microsoft, Apple or Google be forced to comply with government requests to provide backdoored updates to specific targets?</li><li><b><a href=\"http://www.reuters.com/article/2013/08/05/us-dea-sod-idUSBRE97409R20130805\">Parallel Construction</a>:</b> a <a href=\"http://www.washingtonpost.com/blogs/the-switch/wp/2013/08/05/the-nsa-is-giving-your-phone-records-to-the-dea-and-the-dea-is-covering-it-up/\">major issue</a>. This occurs when, say, the NSA hacks into a target, tips a law enforcement agency, which re-creates the same evidence from a different source. At a CITP reading group, we discussed whether this had actually happened in the Silkroad/DPR case.</li><li><b>Jurisdiction</b>: when can a law enforcement agency act? What determines a sovereign territory? ‘Citizenship’, ‘ip-address block’, or can governments hack across borders? Dutch authorities used the Bredolab botnet to hack into and remotely install a unverifiable .executable at thousands of infected machines across the internet.</li><li><b>Constitutional scope: </b>if I VPN my connection to Amsterdam, even though I’m physically based in the U.S., do I lose my reasonable expectation to 4th amendment protection that I would have if the government would raid my U.S. apartment?</li><li><b>Geopolitics</b>: what about the geopolitical Pandora’s box? if you happen to hack into a foreign government system, what about reciprocity, or retaliation?</li><li><b>No reliable data</b>: We don’t have reliable data about the size of the problem. Not aggregate, not in individual cases. Threats are systematically inflated, the size of the Bredolab botnet easily by an <a href=\"http://www.internetgovernance.org/2010/11/01/dutch-police-inflates-bredolab-botnet-success-by-factor-of-ten-and-then-some/\">order of magnitude</a>.</li><li><b>Necessity</b>: is government malware, or hacking even necessary? Many well-respected technologists <a href=\"http://www.theguardian.com/commentisfree/2014/jan/06/nsa-tailored-access-operations-privacy\">frame</a> the debate as “either mass surveillance, or targeted hacking”. While I agree that mass surveillance and weakening of infrastructure is even more problematic, I think that frame is incorrect in this golden age of surveillance. Less problematic alternatives will exist: the recent takedown of Utopia, a TOR hidden service widely regarded as a Silk Road heir, employed intrusive but well-established <a href=\"http://www.om.nl/@162281/undercover-onderzoek/\">undercover techniques</a>.</li></ol><p>The list doesn’t end here. The cynic and realist would say, “it’s happening anyway so why bother?” The simple answer is: government hacking is different than a wiretap, so needs a specific policy response. Until aforementioned problems are addressed and legal safeguards are in place, judges should push back and government hacking should be considered what it currently is: illegal.</p>
") (wfw:commentRss nil "https://freedom-to-tinker.com/blog/axel/9-problems-of-governments-hacking-why-it-systems-deserve-constitutional-protection/feed/") (slash:comments nil "7")))) ("How to protect yourself from Heartbleed" "<p>The Heartbleed vulnerability is one of the worst Internet security problems we have seen.  I’ll be writing more about what we can learn from Heartbleed and the response to it.  </p><p>For now, here is a quick checklist of what you can do to protect yourself.</p><p><strong>If you are a regular user:</strong></p><p>Most of the sites you use were probably vulnerable.  Your password might have been leaked from any one of them.  Unless you’re sure that a site was <em>never</em> vulnerable, you should change your password on that site.  (It’s not enough that a site is invulnerable <em>now</em>, because your password could have leaked before the site was fixed.)</p><p>Yes, it’s a pain to change your passwords, but you were really meaning to change them at some point anyway, weren’t you?  Now is a good time.  (It’s also a good time to turn on two-factor authentication, on sites that offer it.)</p><p>But, before you change your password on a site, you need to make sure that that site has closed any remaining vulnerability.  Look for an unequivocal statement from the site that (1) they are no longer vulnerable and (2) they have changed the private encryption key they use to protect HTTPS traffic.   Once you’re sure that they have done those two things, then you should go ahead and change your password on the site.  If they haven’t done those two things, then it’s best to wait until they do.  Make yourself a note to come back and check in a few days.  </p><p>The bad news is that some of your private information might have leaked from a vulnerable site.  It will be very difficult to tell whether this happened, even for the site itself, and nearly impossible to undo a leak if it did happen. </p><p><strong>If you run a website that supports HTTPS, and you run your own server:</strong></p><ul><li>Go to http://filippo.io/Heartbleed/ and enter the name of your site, to test whether your site is vulnerable.   If you’re not vulnerable, you’re done.  If you are vulnerable, carry out the following steps.</li><li>Upgrade your server software to a non-vulnerable version.  I can’t give you general advice on how to do this because it depends on which software you are running.  Once you have done the upgrade, go back to http://filippo.io/Heartbleed/ and verify that you are no longer vulnerable.</li><li>After upgrading your software, generate a new SSL/TLS key and get a certificate for the new key.  Start using the new key and certificate.  (This is necessary because an attacker could have gotten your old key.)</li><li>Revoke the certificate you were previously using.  (This is necessary because an attacker who got your old key could be using your old key and certificate to impersonate your site.)</li><li>Have your users change the passwords that they use to log in to your site. (This is necessary because users’ existing passwords could have been leaked. You need to get your house in order by carrying out the previous steps, before users can safely change passwords.)</li></ul><p><strong>If you run a website that supports HTTPS, and you use a web hosting service:</strong><br />
In this case, the hosting service runs the web server that powers your site.</p><ul><li>Find out from the hosting service whether its server was ever vulnerable to Heartbleed attacks.  If you’re confident that it was never vulnerable, then you’re good.  Otherwise, carry out the following steps.</li><li>Wait until the hosting service has upgraded its software to a non-vulnerable version.  Once they have done the upgrade, you should be able to go to http://filippo.io/Heartbleed/ and enter the address of your site, and be told that it is not vulnerable.   If this isn’t true yet, ask the hosting service to fix the problem, then wait a while and repeat.</li><li>Once the hosting service has upgraded its software and the test site shows you as not vulnerable, generate a new SSL/TLS key and get a certificate for the new key.  Start using the new key and certificate.  (This is necessary because an attacker could have gotten your old key.)</li><li>Revoke the certificate you were previously using.  (This is necessary because an attacker who got your old key could be using your old key and certificate to impersonate your site.)</li><li>If your site assigns passwords to users, have your users change the passwords that they use to log in to your site. (This is necessary because users’ existing passwords could have been leaked. You need to get your house in order by carrying out the previous steps, before users can safely change passwords.)</li></ul>" "https://freedom-to-tinker.com/blog/felten/how-to-protect-yourself-from-heartbleed/" (21317 24549) old 4 nil nil ((title nil "How to protect yourself from Heartbleed") (link nil "https://freedom-to-tinker.com/blog/felten/how-to-protect-yourself-from-heartbleed/") (comments nil "https://freedom-to-tinker.com/blog/felten/how-to-protect-yourself-from-heartbleed/#comments") (pubDate nil "Wed, 09 Apr 2014 14:57:41 +0000") (dc:creator nil "Ed Felten") (guid ((isPermaLink . "false")) "https://freedom-to-tinker.com/?p=9774") (description nil "The Heartbleed vulnerability is one of the worst Internet security problems we have seen. I&#8217;ll be writing more about what we can learn from Heartbleed and the response to it. For now, here is a quick checklist of what you can do to protect yourself. If you are a regular user: Most of the sites [...]") (content:encoded nil "<p>The Heartbleed vulnerability is one of the worst Internet security problems we have seen.  I&#8217;ll be writing more about what we can learn from Heartbleed and the response to it.  </p><p>For now, here is a quick checklist of what you can do to protect yourself.</p><p><strong>If you are a regular user:</strong></p><p>Most of the sites you use were probably vulnerable.  Your password might have been leaked from any one of them.  Unless you&#8217;re sure that a site was <em>never</em> vulnerable, you should change your password on that site.  (It&#8217;s not enough that a site is invulnerable <em>now</em>, because your password could have leaked before the site was fixed.)</p><p>Yes, it&#8217;s a pain to change your passwords, but you were really meaning to change them at some point anyway, weren&#8217;t you?  Now is a good time.  (It&#8217;s also a good time to turn on two-factor authentication, on sites that offer it.)</p><p>But, before you change your password on a site, you need to make sure that that site has closed any remaining vulnerability.  Look for an unequivocal statement from the site that (1) they are no longer vulnerable and (2) they have changed the private encryption key they use to protect HTTPS traffic.   Once you&#8217;re sure that they have done those two things, then you should go ahead and change your password on the site.  If they haven&#8217;t done those two things, then it&#8217;s best to wait until they do.  Make yourself a note to come back and check in a few days.  </p><p>The bad news is that some of your private information might have leaked from a vulnerable site.  It will be very difficult to tell whether this happened, even for the site itself, and nearly impossible to undo a leak if it did happen. </p><p><strong>If you run a website that supports HTTPS, and you run your own server:</strong></p><ul><li>Go to http://filippo.io/Heartbleed/ and enter the name of your site, to test whether your site is vulnerable.   If you&#8217;re not vulnerable, you&#8217;re done.  If you are vulnerable, carry out the following steps.</li><li>Upgrade your server software to a non-vulnerable version.  I can&#8217;t give you general advice on how to do this because it depends on which software you are running.  Once you have done the upgrade, go back to http://filippo.io/Heartbleed/ and verify that you are no longer vulnerable.</li><li>After upgrading your software, generate a new SSL/TLS key and get a certificate for the new key.  Start using the new key and certificate.  (This is necessary because an attacker could have gotten your old key.)</li><li>Revoke the certificate you were previously using.  (This is necessary because an attacker who got your old key could be using your old key and certificate to impersonate your site.)</li><li>Have your users change the passwords that they use to log in to your site. (This is necessary because users&#8217; existing passwords could have been leaked. You need to get your house in order by carrying out the previous steps, before users can safely change passwords.)</li></ul><p><strong>If you run a website that supports HTTPS, and you use a web hosting service:</strong><br />
In this case, the hosting service runs the web server that powers your site.</p><ul><li>Find out from the hosting service whether its server was ever vulnerable to Heartbleed attacks.  If you&#8217;re confident that it was never vulnerable, then you&#8217;re good.  Otherwise, carry out the following steps.</li><li>Wait until the hosting service has upgraded its software to a non-vulnerable version.  Once they have done the upgrade, you should be able to go to http://filippo.io/Heartbleed/ and enter the address of your site, and be told that it is not vulnerable.   If this isn&#8217;t true yet, ask the hosting service to fix the problem, then wait a while and repeat.</li><li>Once the hosting service has upgraded its software and the test site shows you as not vulnerable, generate a new SSL/TLS key and get a certificate for the new key.  Start using the new key and certificate.  (This is necessary because an attacker could have gotten your old key.)</li><li>Revoke the certificate you were previously using.  (This is necessary because an attacker who got your old key could be using your old key and certificate to impersonate your site.)</li><li>If your site assigns passwords to users, have your users change the passwords that they use to log in to your site. (This is necessary because users&#8217; existing passwords could have been leaked. You need to get your house in order by carrying out the previous steps, before users can safely change passwords.)</li></ul>
") (wfw:commentRss nil "https://freedom-to-tinker.com/blog/felten/how-to-protect-yourself-from-heartbleed/feed/") (slash:comments nil "6"))) ("Cookies that give you away: The surveillance implications of web tracking" "<p><i>[Today we have another announcement of an exciting new research paper. Undergraduate Dillon Reisman, for his senior thesis, applied our <a href=\"https://freedom-to-tinker.com/blog/randomwalker/web-measurement-for-fairness-and-transparency/\" target=\"_blank\">web measurement platform</a> to study some timely questions. -Arvind Narayanan]</i></p><p>Over the past three months we’ve learnt that NSA uses third-party tracking cookies for surveillance (<a href=\"http://www.washingtonpost.com/blogs/the-switch/wp/2013/12/10/nsa-uses-google-cookies-to-pinpoint-targets-for-hacking/\">1</a>, <a href=\"https://firstlook.org/theintercept/article/2014/03/12/nsa-plans-infect-millions-computers-malware/\">2</a>). These cookies, provided by a third-party advertising or analytics network (e.g. doubleclick.com, scorecardresearch.com), are ubiquitous on the web, and tag users’ browsers with unique pseudonymous IDs. In <a href=\"http://randomwalker.info/publications/cookie-surveillance.pdf\">a new paper</a>, we study just how big a privacy problem this is. We quantify what an observer can learn about a user’s web traffic by purely passively eavesdropping on the network, and arrive at surprising answers.</p><p>At first sight it doesn’t seem possible that eavesdropping alone can reveal much. First the eavesdropper on the Internet backbone sees millions of HTTP requests and responses. How can he associate the third-party HTTP request containing a user’s cookie with request to the first-party web page that the browser visited, which doesn’t contain the cookie? Second, how can visits to different first parties be linked to each other? And finally, even if all the web traffic for a single user can be linked together, how can the adversary go from a set pseudonymous cookies to the user’s real-world identity?</p><p><img class=\"aligncenter\" alt=\" \" src=\"https://lh6.googleusercontent.com/r00CfwTjy7KfYRzeh9NORNAMye90G3UTRYJXDWTJTl3599IyUEthHs7FZFEb8S6JPE9mQw4qYCxChixyjQxWxXQ-leyJ8SgJXZ95DPwjuyOQ04UEM0nC0ZUKOXQXXg\" width=\"579px;\" height=\"448px;\" /></p><p>The diagram illustrates how the eavesdropper can use multiple third-party cookies to link traffic. When a user visits ‘www.exampleA.com,’ the response contains the embedded tracker X, with an ID cookie ‘xxx’. The visits to exampleA and to X are tied together by IP address, which typically doesn’t change within a single page visit [1]. Another page visited by the same user might embed tracker Y bearing the pseudonymous cookie ‘yyy’. If the two page visits were made from different IP addresses, an eavesdropper seeing these cookies can’t tell that the same browser made both visits. But if a third page, however, embeds both trackers X and Y, then the eavesdropper will know that IDs ‘xxx’ and ‘yyy’ belong to the same user. This method applied iteratively has the potential of tying together a lot of the traffic of a single user.</p><p dir=\"ltr\">Once we had this idea, we wanted to test if it would actually work in practice. Everything depends on just how densely third-party trackers are actually embedded on sites. We conducted automated web crawls of 65 simulated users’ web browsing over three months, and found that unique cookies are so prevalent that the eavesdropper can reliably link 90% of a user’s web page visits to the same pseudonymous ID. (We omitted pages that embed no ID cookies at all, but those are a minority.)</p><p dir=\"ltr\">We also found that the cookie linking method is extremely robust and succeeds under a variety of conditions (Section 4.1). We considered how variations in cookie expiration dates, the size of the user’s history (i.e., the number of pages visited), and the types of pages visited affect the eavesdropper’s changes, and found the impact to be minimal. Perhaps most significantly, however, we found that this surveillance method can still link about 50% of a user’s history to the same pseudonymous ID even with just 25% of the current density of trackers on the web. This means that even if 75% of sites or trackers adopt mitigation strategies (such as deploying HTTPS), the eavesdropper still learns a lot.</p><p dir=\"ltr\"><img class=\"aligncenter\" alt=\" \" src=\"https://lh6.googleusercontent.com/w89sqWi4ZKGwI_50PZFfo09BbWfrTVSr-PiAqDKwdVBWhx1WaxYfUmnRWnyULdRf4QAnoFFoDe2a4851uymJijwZwellnr6ktrgqNePLLRNMsXZok2blDVbhn1esbQ\" width=\"405px;\" height=\"199px;\" /></p><p dir=\"ltr\">Finally, we studied how an eavesdropper might learn the real-world identity behind a cluster of web pages associated with a pseudonymous ID. It turns out that this is surprisingly easy — many sites display real-world attributes such as real name, username, or email on unencrypted pages to logged in users, which means that the eavesdropper gets to see these identifiers. We conducted a survey of such leakage on popular sites, and found that over half of popular sites with account creation leak some form of real-world identity (Section 4.2).</p><p dir=\"ltr\">While it’s no surprise that web traffic contains sensitive information about individuals, what we’ve shown is just how complete a profile can be extracted even if the user’s traffic is mixed with millions of other users. Further, an eavesdropper can connect these profiles to real-world identities without needing the co-operation of any websites. While HTTPS deployment by trackers can help, the only practical solution at the current time seems to be for users to install anti-tracking and anonymity tools.</p><p>&nbsp;</p><p dir=\"ltr\">[1] An exception is if the user routes traffic through Tor. Different requests can take different paths and the exit node IPs will be different. Thus, use of Tor with application-layer anonymization (e.g., Tor browser bundle) defeats our attack.</p><p dir=\"ltr\"><em>[Edit: minor edit for clarity.]</em></p>" "https://freedom-to-tinker.com/blog/dreisman/cookies-that-give-you-away-the-surveillance-implications-of-web-tracking/" (21310 35265) old 5 nil nil ((title nil "Cookies that give you away: The surveillance implications of web tracking") (link nil "https://freedom-to-tinker.com/blog/dreisman/cookies-that-give-you-away-the-surveillance-implications-of-web-tracking/") (comments nil "https://freedom-to-tinker.com/blog/dreisman/cookies-that-give-you-away-the-surveillance-implications-of-web-tracking/#comments") (pubDate nil "Fri, 04 Apr 2014 10:30:25 +0000") (dc:creator nil "Dillon Reisman") (category nil "cookies") (category nil "NSA") (category nil "surveillance") (guid ((isPermaLink . "false")) "https://freedom-to-tinker.com/?p=9732") (description nil "[Today we have another announcement of an exciting new research paper. Undergraduate Dillon Reisman, for his senior thesis, applied our web measurement platform to study some timely questions. -Arvind Narayanan] Over the past three months we’ve learnt that NSA uses third-party tracking cookies for surveillance (1, 2). These cookies, provided by a third-party advertising or analytics network [...]") (content:encoded nil "<p><i>[Today we have another announcement of an exciting new research paper. Undergraduate Dillon Reisman, for his senior thesis, applied our <a href=\"https://freedom-to-tinker.com/blog/randomwalker/web-measurement-for-fairness-and-transparency/\" target=\"_blank\">web measurement platform</a> to study some timely questions. -Arvind Narayanan]</i></p><p>Over the past three months we’ve learnt that NSA uses third-party tracking cookies for surveillance (<a href=\"http://www.washingtonpost.com/blogs/the-switch/wp/2013/12/10/nsa-uses-google-cookies-to-pinpoint-targets-for-hacking/\">1</a>, <a href=\"https://firstlook.org/theintercept/article/2014/03/12/nsa-plans-infect-millions-computers-malware/\">2</a>). These cookies, provided by a third-party advertising or analytics network (e.g. doubleclick.com, scorecardresearch.com), are ubiquitous on the web, and tag users’ browsers with unique pseudonymous IDs. In <a href=\"http://randomwalker.info/publications/cookie-surveillance.pdf\">a new paper</a>, we study just how big a privacy problem this is. We quantify what an observer can learn about a user&#8217;s web traffic by purely passively eavesdropping on the network, and arrive at surprising answers.</p><p>At first sight it doesn’t seem possible that eavesdropping alone can reveal much. First the eavesdropper on the Internet backbone sees millions of HTTP requests and responses. How can he associate the third-party HTTP request containing a user’s cookie with request to the first-party web page that the browser visited, which doesn’t contain the cookie? Second, how can visits to different first parties be linked to each other? And finally, even if all the web traffic for a single user can be linked together, how can the adversary go from a set pseudonymous cookies to the user’s real-world identity?</p><p><img class=\"aligncenter\" alt=\" \" src=\"https://lh6.googleusercontent.com/r00CfwTjy7KfYRzeh9NORNAMye90G3UTRYJXDWTJTl3599IyUEthHs7FZFEb8S6JPE9mQw4qYCxChixyjQxWxXQ-leyJ8SgJXZ95DPwjuyOQ04UEM0nC0ZUKOXQXXg\" width=\"579px;\" height=\"448px;\" /></p><p>The diagram illustrates how the eavesdropper can use multiple third-party cookies to link traffic. When a user visits ‘www.exampleA.com,’ the response contains the embedded tracker X, with an ID cookie ‘xxx’. The visits to exampleA and to X are tied together by IP address, which typically doesn’t change within a single page visit [1]. Another page visited by the same user might embed tracker Y bearing the pseudonymous cookie ‘yyy’. If the two page visits were made from different IP addresses, an eavesdropper seeing these cookies can’t tell that the same browser made both visits. But if a third page, however, embeds both trackers X and Y, then the eavesdropper will know that IDs ‘xxx’ and ‘yyy’ belong to the same user. This method applied iteratively has the potential of tying together a lot of the traffic of a single user.</p><p dir=\"ltr\">Once we had this idea, we wanted to test if it would actually work in practice. Everything depends on just how densely third-party trackers are actually embedded on sites. We conducted automated web crawls of 65 simulated users’ web browsing over three months, and found that unique cookies are so prevalent that the eavesdropper can reliably link 90% of a user’s web page visits to the same pseudonymous ID. (We omitted pages that embed no ID cookies at all, but those are a minority.)</p><p dir=\"ltr\">We also found that the cookie linking method is extremely robust and succeeds under a variety of conditions (Section 4.1). We considered how variations in cookie expiration dates, the size of the user’s history (i.e., the number of pages visited), and the types of pages visited affect the eavesdropper’s changes, and found the impact to be minimal. Perhaps most significantly, however, we found that this surveillance method can still link about 50% of a user’s history to the same pseudonymous ID even with just 25% of the current density of trackers on the web. This means that even if 75% of sites or trackers adopt mitigation strategies (such as deploying HTTPS), the eavesdropper still learns a lot.</p><p dir=\"ltr\"><img class=\"aligncenter\" alt=\" \" src=\"https://lh6.googleusercontent.com/w89sqWi4ZKGwI_50PZFfo09BbWfrTVSr-PiAqDKwdVBWhx1WaxYfUmnRWnyULdRf4QAnoFFoDe2a4851uymJijwZwellnr6ktrgqNePLLRNMsXZok2blDVbhn1esbQ\" width=\"405px;\" height=\"199px;\" /></p><p dir=\"ltr\">Finally, we studied how an eavesdropper might learn the real-world identity behind a cluster of web pages associated with a pseudonymous ID. It turns out that this is surprisingly easy &#8212; many sites display real-world attributes such as real name, username, or email on unencrypted pages to logged in users, which means that the eavesdropper gets to see these identifiers. We conducted a survey of such leakage on popular sites, and found that over half of popular sites with account creation leak some form of real-world identity (Section 4.2).</p><p dir=\"ltr\">While it’s no surprise that web traffic contains sensitive information about individuals, what we’ve shown is just how complete a profile can be extracted even if the user’s traffic is mixed with millions of other users. Further, an eavesdropper can connect these profiles to real-world identities without needing the co-operation of any websites. While HTTPS deployment by trackers can help, the only practical solution at the current time seems to be for users to install anti-tracking and anonymity tools.</p><p>&nbsp;</p><p dir=\"ltr\">[1] An exception is if the user routes traffic through Tor. Different requests can take different paths and the exit node IPs will be different. Thus, use of Tor with application-layer anonymization (e.g., Tor browser bundle) defeats our attack.</p><p dir=\"ltr\"><em>[Edit: minor edit for clarity.]</em></p>
") (wfw:commentRss nil "https://freedom-to-tinker.com/blog/dreisman/cookies-that-give-you-away-the-surveillance-implications-of-web-tracking/feed/") (slash:comments nil "9"))) ("Historic E.U. Net Neutrality Win Shows Maturing Digital Rights Advocacy" "<p>After a 5-year long campaign by European and U.S. digital rights NGOs, today the European Parliament turned a dubious Commission proposal on its head to safeguard the principle of net neutrality. It’s a historic win, and <a href=\"http://www.nytimes.com/2014/04/04/business/international/eu-lawmakers-approve-tough-net-neutrality-rules.html?_r=0\" target=\"_blank\">all</a><a href=\"http://www.nytimes.com/2014/03/31/business/international/european-lawmakers-prepare-to-vote-on-net-neutrality.html\" target=\"_blank\">over</a><a href=\"http://blogs.wsj.com/digits/2014/04/02/who-says-european-net-neutrality-politics-is-boring/\" target=\"_blank\">the</a><a href=\"www.bbc.com/news/technology-26865869\" target=\"_blank\">news</a>. It also shows how digital rights advocacy is maturing. <img title=\"More...\" alt=\" \" src=\"https://www.axelarnbak.nl/wp-includes/js/tinymce/plugins/wordpress/img/trans.gif\" /></p><p>The <a href=\"http://www.europarl.europa.eu/sides/getDoc.do?pubRef=-//EP//TEXT+REPORT+A7-2014-0190+0+DOC+XML+V0//EN\" target=\"_blank\">legislative proposal and its amendments</a> contain a clear definition of net neutrality and quite solid provisions. With the final text, as always, the devil will be in the details. For one, the enforcement provisions could have been stronger. Perhaps some national governments, such as <a href=\"https://www.axelarnbak.nl/2014/03/13/translation-dutch-net-freedom-laws-2011-net-neutrality-no-commercial-wiretapping-no-3-strikes/\" target=\"_blank\">The Netherlands where net neutrality has already been enshrined in law for some years now</a>, will lobby for more discretion to enforce the rules on the national level.</p><p>Of course, it ain’t over till the fat lady sings: the E.U. Council (the relevant ministers of national governments) will debate the Parliament legislative text on 5/6 June 2014. Will it respect a democratic vote, or be influenced by the Telecoms lobby? History learns that industry lobbies are almost certain to leverage more power towards the E.U. Council, than citizens have with regard to their respective governments. Europe is often used as a proxy for politics that can’t be realized on a national level. Moreover, the May 2014 Parliament election comes before those negotiations in June, potentially changing the political dynamics: the current majority for net neutrality could change. So the jury is still out.</p><p>But what’s truly fascinating about the net neutrality vote, and perfect case study material, is how digital rights advocacy in Europe is maturing. A <a href=\"http://savetheinternet.eu/\" target=\"_blank\">slick campaign</a> was set up that got more people to call/fax/e-mail their representatives than back in the day with the historic no-vote on ACTA. That’s a second crucial point: ACTA was a no-vote, but here digital rights and consumer advocates were able to suggest meaningful legislative reform amidst intense political struggle. Expert amendments were suggested, a dubious proposal by the (Dutch) E.U. Commissioner — primarily interested in quick wins on roaming tariffs — delegitimized and the immensely powerful telecoms lobby were faced head-on. Quite nasty tactics by hostile E.U. Parliamentarians and lobbies were cleverly tackled. Unsurprisingly, and completely missing the point, even the <a href=\"http://pastebin.com/ezMCuF5s\" target=\"_blank\">child abuse card was played the night before the final vote</a>. Until the last minute, digital rights groups — in a highly dispersed Europe and with the help of U.S. NGOs — have shown that they can play ball as one front, when it really matters.</p><p>We see this more often these days, and it should give rise to some opportunism on E.U. policymaking. Apart from ACTA and net neutrality, data protection, mandatory website blocking and data retention also come to mind. Digital rights advocacy has matured in the last five years. Sure, the web has turned public and private online life into a surveillance society — so why be optimistic? Because at the same time, it appears that the obscure Brussels lobbying arena feels the surveillance of the public more and more.  Of course, we’re nowhere near a transparent political process, but these are interesting times.</p><p>For now, it’s a historic win for digital rights in Europe, that may spur spill-over effects to the U.S. and other countries as well. Time to enjoy a beer and some sleep for those that did the heavy lifting, including MEPs Amelia Andersdottir, Catherine Trautmann, Marietje Schaake and Petra Kammerevert and organizations such as <a href=\"https://www.edri.org\" target=\"_blank\">European Digital Rights</a>, <a href=\"http://www.laquadrature.net/en\" target=\"_blank\">La Quadrature du Net</a> and <a href=\"https://www.bitsoffreedom.nl\" target=\"_blank\">Bits of Freedom.</a> Remember those names, you’ll be hearing them again in a not so distant fascinating future.</p>" "https://freedom-to-tinker.com/blog/axel/historic-e-u-net-neutrality-win-shows-maturing-digital-rights-advocacy/" (21309 46362) old 6 nil nil ((title nil "Historic E.U. Net Neutrality Win Shows Maturing Digital Rights Advocacy") (link nil "https://freedom-to-tinker.com/blog/axel/historic-e-u-net-neutrality-win-shows-maturing-digital-rights-advocacy/") (comments nil "https://freedom-to-tinker.com/blog/axel/historic-e-u-net-neutrality-win-shows-maturing-digital-rights-advocacy/#comments") (pubDate nil "Thu, 03 Apr 2014 19:23:06 +0000") (dc:creator nil "Axel Arnbak") (guid ((isPermaLink . "false")) "https://freedom-to-tinker.com/?p=9750") (description nil "After a 5-year long campaign by European and U.S. digital rights NGOs, today the European Parliament turned a dubious Commission proposal on its head to safeguard the principle of net neutrality. It&#8217;s a historic win, and all over the news. It also shows how digital rights advocacy is maturing. The legislative proposal and its amendments [...]") (content:encoded nil "<p>After a 5-year long campaign by European and U.S. digital rights NGOs, today the European Parliament turned a dubious Commission proposal on its head to safeguard the principle of net neutrality. It&#8217;s a historic win, and <a href=\"http://www.nytimes.com/2014/04/04/business/international/eu-lawmakers-approve-tough-net-neutrality-rules.html?_r=0\" target=\"_blank\">all</a><a href=\"http://www.nytimes.com/2014/03/31/business/international/european-lawmakers-prepare-to-vote-on-net-neutrality.html\" target=\"_blank\">over</a><a href=\"http://blogs.wsj.com/digits/2014/04/02/who-says-european-net-neutrality-politics-is-boring/\" target=\"_blank\">the</a><a href=\"www.bbc.com/news/technology-26865869\" target=\"_blank\">news</a>. It also shows how digital rights advocacy is maturing. <img title=\"More...\" alt=\" \" src=\"https://www.axelarnbak.nl/wp-includes/js/tinymce/plugins/wordpress/img/trans.gif\" /></p><p>The <a href=\"http://www.europarl.europa.eu/sides/getDoc.do?pubRef=-//EP//TEXT+REPORT+A7-2014-0190+0+DOC+XML+V0//EN\" target=\"_blank\">legislative proposal and its amendments</a> contain a clear definition of net neutrality and quite solid provisions. With the final text, as always, the devil will be in the details. For one, the enforcement provisions could have been stronger. Perhaps some national governments, such as <a href=\"https://www.axelarnbak.nl/2014/03/13/translation-dutch-net-freedom-laws-2011-net-neutrality-no-commercial-wiretapping-no-3-strikes/\" target=\"_blank\">The Netherlands where net neutrality has already been enshrined in law for some years now</a>, will lobby for more discretion to enforce the rules on the national level.</p><p>Of course, it ain&#8217;t over till the fat lady sings: the E.U. Council (the relevant ministers of national governments) will debate the Parliament legislative text on 5/6 June 2014. Will it respect a democratic vote, or be influenced by the Telecoms lobby? History learns that industry lobbies are almost certain to leverage more power towards the E.U. Council, than citizens have with regard to their respective governments. Europe is often used as a proxy for politics that can&#8217;t be realized on a national level. Moreover, the May 2014 Parliament election comes before those negotiations in June, potentially changing the political dynamics: the current majority for net neutrality could change. So the jury is still out.</p><p>But what&#8217;s truly fascinating about the net neutrality vote, and perfect case study material, is how digital rights advocacy in Europe is maturing. A <a href=\"http://savetheinternet.eu/\" target=\"_blank\">slick campaign</a> was set up that got more people to call/fax/e-mail their representatives than back in the day with the historic no-vote on ACTA. That&#8217;s a second crucial point: ACTA was a no-vote, but here digital rights and consumer advocates were able to suggest meaningful legislative reform amidst intense political struggle. Expert amendments were suggested, a dubious proposal by the (Dutch) E.U. Commissioner &#8212; primarily interested in quick wins on roaming tariffs &#8212; delegitimized and the immensely powerful telecoms lobby were faced head-on. Quite nasty tactics by hostile E.U. Parliamentarians and lobbies were cleverly tackled. Unsurprisingly, and completely missing the point, even the <a href=\"http://pastebin.com/ezMCuF5s\" target=\"_blank\">child abuse card was played the night before the final vote</a>. Until the last minute, digital rights groups &#8212; in a highly dispersed Europe and with the help of U.S. NGOs &#8212; have shown that they can play ball as one front, when it really matters.</p><p>We see this more often these days, and it should give rise to some opportunism on E.U. policymaking. Apart from ACTA and net neutrality, data protection, mandatory website blocking and data retention also come to mind. Digital rights advocacy has matured in the last five years. Sure, the web has turned public and private online life into a surveillance society &#8212; so why be optimistic? Because at the same time, it appears that the obscure Brussels lobbying arena feels the surveillance of the public more and more.  Of course, we&#8217;re nowhere near a transparent political process, but these are interesting times.</p><p>For now, it&#8217;s a historic win for digital rights in Europe, that may spur spill-over effects to the U.S. and other countries as well. Time to enjoy a beer and some sleep for those that did the heavy lifting, including MEPs Amelia Andersdottir, Catherine Trautmann, Marietje Schaake and Petra Kammerevert and organizations such as <a href=\"https://www.edri.org\" target=\"_blank\">European Digital Rights</a>, <a href=\"http://www.laquadrature.net/en\" target=\"_blank\">La Quadrature du Net</a> and <a href=\"https://www.bitsoffreedom.nl\" target=\"_blank\">Bits of Freedom.</a> Remember those names, you&#8217;ll be hearing them again in a not so distant fascinating future.</p>
") (wfw:commentRss nil "https://freedom-to-tinker.com/blog/axel/historic-e-u-net-neutrality-win-shows-maturing-digital-rights-advocacy/feed/") (slash:comments nil "0"))) ("Secure protocols for accountable warrant execution" "<p>Last week the press <a href=\"http://www.nytimes.com/2014/03/25/us/obama-to-seek-nsa-curb-on-call-data.html\"> reported</a> that the White House will seek to redesign the NSA’s mass phone call data program, so that data will be held by the phone companies and accessed by the NSA, subject to a new warrant requirement.  The Foreign Intelligence Surveillance Court will issue the warrants.</p><p>Today Josh Kroll and I, with colleagues at Stanford University, released a <a href=\"http://www.cs.princeton.edu/~felten/warrant-paper.pdf\">draft paper</a> on how to use cryptography to implement warrants to data in a secure, private, and accountable way.  </p><p>Our solution is a set of multi-party cryptographic protocols involving three primary parties: a data source who has data records, an investigator who wants access to data held by the data source, and a court (or other authorizer) who issues an order or warrant to authorize access to a record.  For example, a phone company might be the data source, the NSA might be the investigator, and the Foreign Intelligence Surveillance Court might be the court that issues an order.  Alternatively, an email provider might be the data source, an FBI agent might be the investigator, and a senior FBI official might act as the “court” that issues a National Security Letter.  Although we use words like “court”, “order”, and “investigator”, the protocol has wider application to situations where Party A is authorizing Party B to access data held by Party C, with legally defined requirements for access.</p><p>The protocol uses cryptography to guarantee several security, privacy, and accountability properties:</p><ul><li>When the court issues an order, it publishes a sealed version of the order. If challenged later, the court can unseal the order and reveal which record it covered.</li><li>Until the order is unsealed, only the court and the investigator can see which record the order covers.  If and when the order is unsealed, everyone can see which record it covered.</li><li>The investigator does not learn the contents of any record, unless there is a valid order for that record and the court has published a valid sealed version of that order.</li></ul><p>A counterintuitive aspect of our protocols is that an order can be executed, thereby giving the investigator access to the record covered by the order, without the data source necessarily learning (at the time) which record the investigator accessed.</p><p>These properties can be viewed as a set of checks on the power of the parties, to prevent any dishonest party from getting access to information without leaving a suitable trail.  When the trail itself is supposed to be secret, the protocol aims for accountability—for example, the court can issue an unjustified order but the court must commit to the order so that the violation will be uncovered if the court’s actions are challenged later.</p><p>Our paper gives more precise definitions of the desired properties, how the protocols work, and why the protocols achieve the desired properties.  We build on the work of previous researchers, as cited in our paper, and we present several versions of the protocol, with different security properties.</p><p>Our approach is feasible, even for very large data sets.  Our paper describes our work on implementing one of our more advanced protocols, and we show by experiment that the protocol is reasonably fast even for data sets of national scope.   We have released the <a href=\"http://www.cs.princeton.edu/~felten/warrant-benchmark.tar.gz\">code</a> we used to do these performance measurements.</p><p>We are releasing this paper now because there are important debates going on about how to organize lawful access to data by intelligence agencies.  We want to make the point that technology allows these processes to be both more secure and more accountable.  </p><p>We urge policymakers to consider how cryptography can make warrant regimes more secure for all parties, and more accountable.  Expert agencies within government, such as NIST, might provide input on these issues, in consultation with experts inside and outside of government.</p>" "https://freedom-to-tinker.com/blog/felten/secure-protocols-for-accountable-warrant-execution/" (21307 62171) old 7 nil nil ((title nil "Secure protocols for accountable warrant execution") (link nil "https://freedom-to-tinker.com/blog/felten/secure-protocols-for-accountable-warrant-execution/") (comments nil "https://freedom-to-tinker.com/blog/felten/secure-protocols-for-accountable-warrant-execution/#comments") (pubDate nil "Wed, 02 Apr 2014 11:22:03 +0000") (dc:creator nil "Ed Felten") (guid ((isPermaLink . "false")) "https://freedom-to-tinker.com/?p=9708") (description nil "Last week the press reported that the White House will seek to redesign the NSA’s mass phone call data program, so that data will be held by the phone companies and accessed by the NSA, subject to a new warrant requirement. The Foreign Intelligence Surveillance Court will issue the warrants. Today Josh Kroll and I, [...]") (content:encoded nil "<p>Last week the press <a href=\"http://www.nytimes.com/2014/03/25/us/obama-to-seek-nsa-curb-on-call-data.html\"> reported</a> that the White House will seek to redesign the NSA’s mass phone call data program, so that data will be held by the phone companies and accessed by the NSA, subject to a new warrant requirement.  The Foreign Intelligence Surveillance Court will issue the warrants.</p><p>Today Josh Kroll and I, with colleagues at Stanford University, released a <a href=\"http://www.cs.princeton.edu/~felten/warrant-paper.pdf\">draft paper</a> on how to use cryptography to implement warrants to data in a secure, private, and accountable way.  </p><p>Our solution is a set of multi-party cryptographic protocols involving three primary parties: a data source who has data records, an investigator who wants access to data held by the data source, and a court (or other authorizer) who issues an order or warrant to authorize access to a record.  For example, a phone company might be the data source, the NSA might be the investigator, and the Foreign Intelligence Surveillance Court might be the court that issues an order.  Alternatively, an email provider might be the data source, an FBI agent might be the investigator, and a senior FBI official might act as the &#8220;court&#8221; that issues a National Security Letter.  Although we use words like &#8220;court&#8221;, &#8220;order&#8221;, and &#8220;investigator&#8221;, the protocol has wider application to situations where Party A is authorizing Party B to access data held by Party C, with legally defined requirements for access.</p><p>The protocol uses cryptography to guarantee several security, privacy, and accountability properties:</p><ul><li>When the court issues an order, it publishes a sealed version of the order. If challenged later, the court can unseal the order and reveal which record it covered.</li><li>Until the order is unsealed, only the court and the investigator can see which record the order covers.  If and when the order is unsealed, everyone can see which record it covered.</li><li>The investigator does not learn the contents of any record, unless there is a valid order for that record and the court has published a valid sealed version of that order.</li></ul><p>A counterintuitive aspect of our protocols is that an order can be executed, thereby giving the investigator access to the record covered by the order, without the data source necessarily learning (at the time) which record the investigator accessed.</p><p>These properties can be viewed as a set of checks on the power of the parties, to prevent any dishonest party from getting access to information without leaving a suitable trail.  When the trail itself is supposed to be secret, the protocol aims for accountability&#8212;for example, the court can issue an unjustified order but the court must commit to the order so that the violation will be uncovered if the court’s actions are challenged later.</p><p>Our paper gives more precise definitions of the desired properties, how the protocols work, and why the protocols achieve the desired properties.  We build on the work of previous researchers, as cited in our paper, and we present several versions of the protocol, with different security properties.</p><p>Our approach is feasible, even for very large data sets.  Our paper describes our work on implementing one of our more advanced protocols, and we show by experiment that the protocol is reasonably fast even for data sets of national scope.   We have released the <a href=\"http://www.cs.princeton.edu/~felten/warrant-benchmark.tar.gz\">code</a> we used to do these performance measurements.</p><p>We are releasing this paper now because there are important debates going on about how to organize lawful access to data by intelligence agencies.  We want to make the point that technology allows these processes to be both more secure and more accountable.  </p><p>We urge policymakers to consider how cryptography can make warrant regimes more secure for all parties, and more accountable.  Expert agencies within government, such as NIST, might provide input on these issues, in consultation with experts inside and outside of government.</p>
") (wfw:commentRss nil "https://freedom-to-tinker.com/blog/felten/secure-protocols-for-accountable-warrant-execution/feed/") (slash:comments nil "3"))) ("New research: Better wallet security for Bitcoin" "<p><strong>[UPDATE (April 3, 2014): We've found an error in our paper. In the threshold signature scheme that we used, there are restrictions on the threshold value. In particular if the key is shared over a degree t polynomial, then 2t+1 players (not t+1) are required to to construct a signature. We thought that this could be reduced to t+1, but our technique was flawed. We are exploring various modifications, and we will post further details when we have an update.]</strong></p><p dir=\"ltr\">The Bitcoin ecosystem has been plagued by thefts and losses that have affected both businesses and individuals. The security of a Bitcoin wallet rests entirely on the security of its associated private keys which can digitally sign transactions to irreversibly spend the coins in the wallet. In a <a href=\"http://www.cs.princeton.edu/~stevenag/bitcoin_threshold_signatures.pdf\">new paper</a>, we show how to use the cryptographic technique of <em>threshold signatures</em> to increase the security of both corporate and individual wallets.</p><p>Perhaps Bitcoin’s toughest security challenge is protecting Internet-connected wallets from insider threats. Such <em><a href=\"https://en.bitcoin.it/wiki/Hot_wallet\">hot wallets</a></em>cannot be kept in highly secure, offline cold storage. One good way for businesses to mitigate this vulnerability is to have hot wallets jointly controlled by multiple parties. This way, no party can independently steal corporate funds. In our paper, we show how to achieve <em>joint control</em> of wallets using threshold signatures.</p><p>The problem of implementing joint control is more important and more difficult for a Bitcoin wallet than it is for a traditional bank account. Whereas regular bank transactions have recovery mechanisms if fraud is detected, Bitcoin transactions are irreversible and their pseudonymity makes it difficult to identify thieves and attempt to recover stolen funds. Moreover, while large bank transactions typically require human action to complete, Bitcoin transactions–no matter how large–require only a cryptographic signature to authorize.</p><p>The threshold signature approach to joint control works like this: the private key controlling the wallet is split between devices belonging to <em>n</em> different participants such that any <em>m</em> of them can jointly produce a digital signature, while a group of less than <em>m</em> participants cannot. Crucially, in the process of producing a signature, <em>the key is never reconstructed</em>. As long as an attacker has compromised fewer than <em>m</em> devices, the key remains secure.</p><p>Our method for achieving joint control has significant benefits over Bitcoin’s “<a href=\"https://gist.github.com/gavinandresen/4039433\">multi-signature</a>” transactions. With multi-signatures, each party’s signature is published to the block chain, whereas threshold signatures allow participants to privately create a single signature which is indistinguishable from ordinary Bitcoin signatures. You can think of our solution as “stealth multi-signatures.” This improves anonymity and confidentiality while keeping transactions a constant size, reducing fees and providing flexibility to scale to an arbitrary number of parties.</p><p>We implemented a threshold signature protocol and have used it to demonstrate  joint control over a Bitcoin wallet. We produced <a href=\"https://blockchain.info/tx/55451090debe729120d4a2e6b49bd3d5cabb881e753ccda0f5ea499a3438de9b\">this transaction</a> using a 9-of-12 threshold signature. If you click on the link to see the transaction details, you won’t see anything special; it looks like any regular transaction. That’s exactly the point!</p><p>Joint control is one of several security measures that can be built using threshold signatures. In our paper, we show that threshold signatures can be used as a primitive to build schemes for <em>secure bookkeeping</em> and <em>secure delegation</em>. One application that we’re particularly excited about is using threshold signatures to achieve <em>two-factor security</em> for personal wallets. In a follow-up post, we will elaborate on this application and discuss our ongoing efforts to build a two-factor secure wallet.</p><p>The main lesson from our work is that a spectrum of traditional internal financial controls can be translated to the Bitcoin world by novel application of cryptography. We hope that the security measures we’ve proposed will become standard in Bitcoin usage, and we are looking forward to working with developers and others who want to adopt our solutions.</p><p>We’d like to thank Greg Maxwell and Andrew Miller for providing useful feedback.</p>" "https://freedom-to-tinker.com/blog/stevenag/new-research-better-wallet-security-for-bitcoin/" (21301 41625) old 8 nil nil ((title nil "New research: Better wallet security for Bitcoin") (link nil "https://freedom-to-tinker.com/blog/stevenag/new-research-better-wallet-security-for-bitcoin/") (comments nil "https://freedom-to-tinker.com/blog/stevenag/new-research-better-wallet-security-for-bitcoin/#comments") (pubDate nil "Fri, 28 Mar 2014 16:26:01 +0000") (dc:creator nil "Steven Goldfeder") (guid ((isPermaLink . "false")) "https://freedom-to-tinker.com/?p=9718") (description nil "[UPDATE (April 3, 2014): We've found an error in our paper. In the threshold signature scheme that we used, there are restrictions on the threshold value. In particular if the key is shared over a degree t polynomial, then 2t+1 players (not t+1) are required to to construct a signature. We thought that this could [...]") (content:encoded nil "<p><strong>[UPDATE (April 3, 2014): We've found an error in our paper. In the threshold signature scheme that we used, there are restrictions on the threshold value. In particular if the key is shared over a degree t polynomial, then 2t+1 players (not t+1) are required to to construct a signature. We thought that this could be reduced to t+1, but our technique was flawed. We are exploring various modifications, and we will post further details when we have an update.]</strong></p><p dir=\"ltr\">The Bitcoin ecosystem has been plagued by thefts and losses that have affected both businesses and individuals. The security of a Bitcoin wallet rests entirely on the security of its associated private keys which can digitally sign transactions to irreversibly spend the coins in the wallet. In a <a href=\"http://www.cs.princeton.edu/~stevenag/bitcoin_threshold_signatures.pdf\">new paper</a>, we show how to use the cryptographic technique of <em>threshold signatures</em> to increase the security of both corporate and individual wallets.</p><p>Perhaps Bitcoin’s toughest security challenge is protecting Internet-connected wallets from insider threats. Such <em><a href=\"https://en.bitcoin.it/wiki/Hot_wallet\">hot wallets</a></em>cannot be kept in highly secure, offline cold storage. One good way for businesses to mitigate this vulnerability is to have hot wallets jointly controlled by multiple parties. This way, no party can independently steal corporate funds. In our paper, we show how to achieve <em>joint control</em> of wallets using threshold signatures.</p><p>The problem of implementing joint control is more important and more difficult for a Bitcoin wallet than it is for a traditional bank account. Whereas regular bank transactions have recovery mechanisms if fraud is detected, Bitcoin transactions are irreversible and their pseudonymity makes it difficult to identify thieves and attempt to recover stolen funds. Moreover, while large bank transactions typically require human action to complete, Bitcoin transactions&#8211;no matter how large&#8211;require only a cryptographic signature to authorize.</p><p>The threshold signature approach to joint control works like this: the private key controlling the wallet is split between devices belonging to <em>n</em> different participants such that any <em>m</em> of them can jointly produce a digital signature, while a group of less than <em>m</em> participants cannot. Crucially, in the process of producing a signature, <em>the key is never reconstructed</em>. As long as an attacker has compromised fewer than <em>m</em> devices, the key remains secure.</p><p>Our method for achieving joint control has significant benefits over Bitcoin’s “<a href=\"https://gist.github.com/gavinandresen/4039433\">multi-signature</a>” transactions. With multi-signatures, each party’s signature is published to the block chain, whereas threshold signatures allow participants to privately create a single signature which is indistinguishable from ordinary Bitcoin signatures. You can think of our solution as “stealth multi-signatures.” This improves anonymity and confidentiality while keeping transactions a constant size, reducing fees and providing flexibility to scale to an arbitrary number of parties.</p><p>We implemented a threshold signature protocol and have used it to demonstrate  joint control over a Bitcoin wallet. We produced <a href=\"https://blockchain.info/tx/55451090debe729120d4a2e6b49bd3d5cabb881e753ccda0f5ea499a3438de9b\">this transaction</a> using a 9-of-12 threshold signature. If you click on the link to see the transaction details, you won’t see anything special; it looks like any regular transaction. That’s exactly the point!</p><p>Joint control is one of several security measures that can be built using threshold signatures. In our paper, we show that threshold signatures can be used as a primitive to build schemes for <em>secure bookkeeping</em> and <em>secure delegation</em>. One application that we’re particularly excited about is using threshold signatures to achieve <em>two-factor security</em> for personal wallets. In a follow-up post, we will elaborate on this application and discuss our ongoing efforts to build a two-factor secure wallet.</p><p>The main lesson from our work is that a spectrum of traditional internal financial controls can be translated to the Bitcoin world by novel application of cryptography. We hope that the security measures we’ve proposed will become standard in Bitcoin usage, and we are looking forward to working with developers and others who want to adopt our solutions.</p><p>We’d like to thank Greg Maxwell and Andrew Miller for providing useful feedback.</p>
") (wfw:commentRss nil "https://freedom-to-tinker.com/blog/stevenag/new-research-better-wallet-security-for-bitcoin/feed/") (slash:comments nil "7"))) ("Reflecting on Sunshine Week" "<p>Last Wednesday evening, I attended the D.C. Open Government Summit: Street View, which took place at the National Press Club in conjunction with Sunshine Week. The Summit was sponsored by the D.C. Open Government Coalition, a non-profit that “seeks to enhance the public’s access to government information and ensure the transparency of government operations of the District of Columbia.” The Summit successfully focused on two main ideas – using government information to innovate and using government information to inform. I left the Summit encouraged by the enthusiasm for innovation and transparency in the attendees and among some District of Columbia government leaders, but also discouraged because there was a consensus that Washington, DC is still far behind cities such as New York, Kansas City, and Boston in using technology for innovation in government and there is not a vision or financial commitment from the Mayor’s office to facilitate government-wide progress.</p><p>In her keynote address, Traci Hughes, the Director of the District of Columbia Office of Open Government, commented that her office only has two employees and almost no budget beyond that for salaries. She has, therefore, been looking to certain District government agencies and non-profit partners outside of government to support her vision for a more open government. Ms. Hughes commented, for example, that the Council of the District of Columbia’s General Counsel has been a great partner, as has been the Office of the State Superintendent of Education, which has been a leader in making information about education available to parents. Ms. Hughes recognized Code for DC, the all-volunteer local chapter of Code for America, for producing “ANC Finder,” an application that provides residents, based on their address, with information about their Advisory Neighborhood Commission – DC’s hyper-local level of government where each Commissioner represents approximately 2,000 people.</p><p>Ms. Hughes, however, has a broader vision for open access to the District of Columbia’s data and records. Ms. Hughes stated that the Council of the District of Columbia and the Mayor need to pass legislation to drive the open government process. In addition, the city must do more to bridge the gaps between people with varying levels of Internet access. I interpreted this statement as her way of saying that many more city services should be accessible through mobile devices. Indeed, a 2013 Pew study indicates that 10% of urban residents have a smartphone, but no home broadband connection.</p><p>Making government services available through mobile devices was one of the themes of the evening. The representatives from Code for DC stressed the importance of moving government processes to mobile platforms. The process of applying for public housing, for example, often involves filling out a different paper form for each potential housing option for which a person is applying. While the non-profit Bread for the City is currently helping people with the paper forms, Code for DC volunteers are working toward a technology-based solution. In addition, people are lobbying to make filing a Freedom of Information Act request and contesting a property tax assessment possible through mobile devices. I had a great side conversation with a Code for DC volunteer who has mapped the DC restaurants that have been cited recently for health code violations. His next step is developing a mobile app. Given the ubiquity of the violations, I was glad I had already eaten.</p><p>Beyond mobile, one of the most impressive recent innovations by the DC government is Advisory Neighborhood Commission 3F live streaming its monthly meetings. Advisory Neighborhood Commission meetings are not typically broadcast on public access television, therefore live streaming makes meetings available, for example, to people with kids who can’t get out in the evening and senior citizens or people with disabilities who cannot get to the meeting location. Live streaming uses only $75 of the Advisory Neighborhood Commission’s budget per meeting and people can ask questions directly beneath the feed or by reaching out to the Advisory Neighborhood Commission’s Chairman via Twitter. Another Advisory Neighborhood Commission records its meetings and posts them on YouTube subsequently. While these are great solutions for constituents who are tech savvy and have fast home broadband connections, to reach the widest possible audience, Advisory Neighborhood Commissions still must continue to use both on-line and off-line engagement methods.</p><p>While increasing participation is very important, so is facilitating accountability. A local activist and Washington Post reporter both discussed the importance of responses to FOIA requests in conducting research, particularly on under-the-radar issues that are nonetheless affecting city residents’ lives. FOIAs have been a critical tool in preventing legal on-line gambling in DC and exposing corruption in the Office of the Chief Financial Officer regarding commercial property assessments.</p><p>Based on the Summit, here are my three recommendations: (1) The DC Office of Open Government needs to have a more productive and collaborative relationship with the Mayor’s Office. The Mayor’s office needs to promote a culture that makes sharing information with both the public and across the city government a priority; (2) Cities that are integrating technology into governance effectively, such as New York, Boston, and Philadelphia, have someone leading those efforts from the Mayor’s office. Washington, DC needs leadership at that level; and (3) To eliminate the inconsistencies across city agencies, the DC government needs to establish written, uniform policies for responding to FOIAs and providing data sets that are easy to manipulate by members of the public and post these policies where the public can review them. The seeds of an open, efficient government exist, but will only grow with strong and committed leadership.</p>" "https://freedom-to-tinker.com/blog/jtignor/reflecting-on-sunshine-week/" (21298 54004) old 9 nil nil ((title nil "Reflecting on Sunshine Week") (link nil "https://freedom-to-tinker.com/blog/jtignor/reflecting-on-sunshine-week/") (comments nil "https://freedom-to-tinker.com/blog/jtignor/reflecting-on-sunshine-week/#comments") (pubDate nil "Wed, 26 Mar 2014 13:15:32 +0000") (dc:creator nil "Jeffrey Tignor") (category nil "Government transparency") (guid ((isPermaLink . "false")) "https://freedom-to-tinker.com/?p=9710") (description nil "Last Wednesday evening, I attended the D.C. Open Government Summit: Street View, which took place at the National Press Club in conjunction with Sunshine Week. The Summit was sponsored by the D.C. Open Government Coalition, a non-profit that “seeks to enhance the public’s access to government information and ensure the transparency of government operations of [...]") (content:encoded nil "<p>Last Wednesday evening, I attended the D.C. Open Government Summit: Street View, which took place at the National Press Club in conjunction with Sunshine Week. The Summit was sponsored by the D.C. Open Government Coalition, a non-profit that “seeks to enhance the public’s access to government information and ensure the transparency of government operations of the District of Columbia.” The Summit successfully focused on two main ideas – using government information to innovate and using government information to inform. I left the Summit encouraged by the enthusiasm for innovation and transparency in the attendees and among some District of Columbia government leaders, but also discouraged because there was a consensus that Washington, DC is still far behind cities such as New York, Kansas City, and Boston in using technology for innovation in government and there is not a vision or financial commitment from the Mayor’s office to facilitate government-wide progress.</p><p>In her keynote address, Traci Hughes, the Director of the District of Columbia Office of Open Government, commented that her office only has two employees and almost no budget beyond that for salaries. She has, therefore, been looking to certain District government agencies and non-profit partners outside of government to support her vision for a more open government. Ms. Hughes commented, for example, that the Council of the District of Columbia’s General Counsel has been a great partner, as has been the Office of the State Superintendent of Education, which has been a leader in making information about education available to parents. Ms. Hughes recognized Code for DC, the all-volunteer local chapter of Code for America, for producing “ANC Finder,” an application that provides residents, based on their address, with information about their Advisory Neighborhood Commission – DC’s hyper-local level of government where each Commissioner represents approximately 2,000 people.</p><p>Ms. Hughes, however, has a broader vision for open access to the District of Columbia’s data and records. Ms. Hughes stated that the Council of the District of Columbia and the Mayor need to pass legislation to drive the open government process. In addition, the city must do more to bridge the gaps between people with varying levels of Internet access. I interpreted this statement as her way of saying that many more city services should be accessible through mobile devices. Indeed, a 2013 Pew study indicates that 10% of urban residents have a smartphone, but no home broadband connection.</p><p>Making government services available through mobile devices was one of the themes of the evening. The representatives from Code for DC stressed the importance of moving government processes to mobile platforms. The process of applying for public housing, for example, often involves filling out a different paper form for each potential housing option for which a person is applying. While the non-profit Bread for the City is currently helping people with the paper forms, Code for DC volunteers are working toward a technology-based solution. In addition, people are lobbying to make filing a Freedom of Information Act request and contesting a property tax assessment possible through mobile devices. I had a great side conversation with a Code for DC volunteer who has mapped the DC restaurants that have been cited recently for health code violations. His next step is developing a mobile app. Given the ubiquity of the violations, I was glad I had already eaten.</p><p>Beyond mobile, one of the most impressive recent innovations by the DC government is Advisory Neighborhood Commission 3F live streaming its monthly meetings. Advisory Neighborhood Commission meetings are not typically broadcast on public access television, therefore live streaming makes meetings available, for example, to people with kids who can’t get out in the evening and senior citizens or people with disabilities who cannot get to the meeting location. Live streaming uses only $75 of the Advisory Neighborhood Commission’s budget per meeting and people can ask questions directly beneath the feed or by reaching out to the Advisory Neighborhood Commission’s Chairman via Twitter. Another Advisory Neighborhood Commission records its meetings and posts them on YouTube subsequently. While these are great solutions for constituents who are tech savvy and have fast home broadband connections, to reach the widest possible audience, Advisory Neighborhood Commissions still must continue to use both on-line and off-line engagement methods.</p><p>While increasing participation is very important, so is facilitating accountability. A local activist and Washington Post reporter both discussed the importance of responses to FOIA requests in conducting research, particularly on under-the-radar issues that are nonetheless affecting city residents’ lives. FOIAs have been a critical tool in preventing legal on-line gambling in DC and exposing corruption in the Office of the Chief Financial Officer regarding commercial property assessments.</p><p>Based on the Summit, here are my three recommendations: (1) The DC Office of Open Government needs to have a more productive and collaborative relationship with the Mayor’s Office. The Mayor’s office needs to promote a culture that makes sharing information with both the public and across the city government a priority; (2) Cities that are integrating technology into governance effectively, such as New York, Boston, and Philadelphia, have someone leading those efforts from the Mayor’s office. Washington, DC needs leadership at that level; and (3) To eliminate the inconsistencies across city agencies, the DC government needs to establish written, uniform policies for responding to FOIAs and providing data sets that are easy to manipulate by members of the public and post these policies where the public can review them. The seeds of an open, efficient government exist, but will only grow with strong and committed leadership.</p>
") (wfw:commentRss nil "https://freedom-to-tinker.com/blog/jtignor/reflecting-on-sunshine-week/feed/") (slash:comments nil "3"))) ("Algorithms can be more accountable than people" "<p>At an academic meeting recently, I was surprised to hear some social scientists accept as obviously correct the claim that involving “algorithms” in decision-making, instead of sticking with good old-fashioned human decision-making, necessarily reduces accountability and increases the risk of bias.  I tend to believe the opposite, that making processes algorithmic improves our ability to understand why they give the results they do.  Let me explain why.</p><p>Consider a process to decide who receives some award or benefit; and suppose we want to make sure the process is not biased against some disadvantaged group, which I’ll call Group G.  If a person just makes the decision, we can ask them whether they were fair to members of Group G.  Or we can ask them why decided the way they did.  Either way, they can simply lie about their true motivation and process, to construct a story that is consistent with non-discrimination; or they might honestly believe their decision was fair even though it reflected unconscious bias. At the risk of massive understatement: history teaches that this kind of bias in human decision-making is difficult to prevent.</p><p>An algorithm, by contrast, cannot hide from everyone the details of how it reached its decision.  If you want to know that an algorithm didn’t use information about a person’s Group G status, you can verify that the Group G status wasn’t provided to the algorithm.  Or, if you prefer, you can re-run the algorithm with the Group G status field changed, to see if the result would have been different.  Or you can collect statistics on whether certain parts of the algorithm have a disparate impact on Group G members as compared to the rest of the population.</p><p>This is not to say that everything about algorithms is easy.  There are plenty of hard problems in understanding algorithms, both in theory and in practice.  My point is merely that if you want to understand how a decision was made, or you want to build in protections to make sure the decision process has certain desirable properties, you’re better off working with an algorithm than with a human decision, because the algorithm can tell you how it got from inputs to outputs.</p><p>When people complain that algorithms aren’t transparent, the real problem is usually that someone is keeping the algorithm or its input data secret.  What makes the process non-transparent is that the result is emitted without explanation—which is a non-transparent approach no matter what is behind the curtain, a person or a machine.</p><p>Of course, a company might be justified legally in keeping their algorithm secret from you; and it might be good business for them to do so.  Regardless, it’s important to recognize that non-transparency is a choice they are making and not a consequence of the fact that they’re using computation.</p><p>If accountability is important to us—and I think it should be—then we should be developing ways to reconcile transparency with partial secrecy, so that a company or government agency can keep some aspects of their process secret when that is justified, while making other aspects transparent.  Transparency needn’t be an all-or-nothing choice.</p>" "https://freedom-to-tinker.com/blog/felten/algorithms-can-be-more-accountable-than-people/" (21289 34896) old 10 nil nil ((title nil "Algorithms can be more accountable than people") (link nil "https://freedom-to-tinker.com/blog/felten/algorithms-can-be-more-accountable-than-people/") (comments nil "https://freedom-to-tinker.com/blog/felten/algorithms-can-be-more-accountable-than-people/#comments") (pubDate nil "Wed, 19 Mar 2014 12:06:40 +0000") (dc:creator nil "Ed Felten") (guid ((isPermaLink . "false")) "https://freedom-to-tinker.com/?p=9696") (description nil "At an academic meeting recently, I was surprised to hear some social scientists accept as obviously correct the claim that involving &#8220;algorithms&#8221; in decision-making, instead of sticking with good old-fashioned human decision-making, necessarily reduces accountability and increases the risk of bias. I tend to believe the opposite, that making processes algorithmic improves our ability to [...]") (content:encoded nil "<p>At an academic meeting recently, I was surprised to hear some social scientists accept as obviously correct the claim that involving &#8220;algorithms&#8221; in decision-making, instead of sticking with good old-fashioned human decision-making, necessarily reduces accountability and increases the risk of bias.  I tend to believe the opposite, that making processes algorithmic improves our ability to understand why they give the results they do.  Let me explain why.</p><p>Consider a process to decide who receives some award or benefit; and suppose we want to make sure the process is not biased against some disadvantaged group, which I&#8217;ll call Group G.  If a person just makes the decision, we can ask them whether they were fair to members of Group G.  Or we can ask them why decided the way they did.  Either way, they can simply lie about their true motivation and process, to construct a story that is consistent with non-discrimination; or they might honestly believe their decision was fair even though it reflected unconscious bias. At the risk of massive understatement: history teaches that this kind of bias in human decision-making is difficult to prevent.</p><p>An algorithm, by contrast, cannot hide from everyone the details of how it reached its decision.  If you want to know that an algorithm didn&#8217;t use information about a person&#8217;s Group G status, you can verify that the Group G status wasn&#8217;t provided to the algorithm.  Or, if you prefer, you can re-run the algorithm with the Group G status field changed, to see if the result would have been different.  Or you can collect statistics on whether certain parts of the algorithm have a disparate impact on Group G members as compared to the rest of the population.</p><p>This is not to say that everything about algorithms is easy.  There are plenty of hard problems in understanding algorithms, both in theory and in practice.  My point is merely that if you want to understand how a decision was made, or you want to build in protections to make sure the decision process has certain desirable properties, you&#8217;re better off working with an algorithm than with a human decision, because the algorithm can tell you how it got from inputs to outputs.</p><p>When people complain that algorithms aren&#8217;t transparent, the real problem is usually that someone is keeping the algorithm or its input data secret.  What makes the process non-transparent is that the result is emitted without explanation&#8212;which is a non-transparent approach no matter what is behind the curtain, a person or a machine.</p><p>Of course, a company might be justified legally in keeping their algorithm secret from you; and it might be good business for them to do so.  Regardless, it&#8217;s important to recognize that non-transparency is a choice they are making and not a consequence of the fact that they&#8217;re using computation.</p><p>If accountability is important to us&#8212;and I think it should be&#8212;then we should be developing ways to reconcile transparency with partial secrecy, so that a company or government agency can keep some aspects of their process secret when that is justified, while making other aspects transparent.  Transparency needn&#8217;t be an all-or-nothing choice.</p>
") (wfw:commentRss nil "https://freedom-to-tinker.com/blog/felten/algorithms-can-be-more-accountable-than-people/feed/") (slash:comments nil "9"))) ("Heartsick about Heartbleed" "<p>Ed Felten <a href=\"https://freedom-to-tinker.com/blog/felten/how-to-protect-yourself-from-heartbleed/\">provides good advice</a> on this blog about what to do in the wake of Heartbleed, and I’ve read some good technical discussions of the technical problem (see <a href=\"http://blog.existentialize.com/diagnosis-of-the-openssl-heartbleed-bug.html\">this</a> for a particularly understandable explanation).</p><p>In this brief posting, I want to look at a different angle – what’s the scope of the vulnerability? I’m going to be (moderately) optimistic and suggest that within a week, major sites of all shapes and sizes (banks, e-shopping, government) will have installed the patches to their web servers and generated new keys/certificates, so it’s safe to visit them to change your password (if it’s an important account), and move on with your life. [That's being optimistic - the realist in me says that there will be some sites that will take months to get patched, because the approval process for big corporations and government agencies is some cumbersome that they can't say \"emergency override\", and fix the problem quickly.]</p><p>But there’s three other classes of sites we should also be concerned about.</p><ol><li>First, there’s the medium sized companies – too big to use an outsourced hosting provider that will automatically do the patching for them, but not big enough that they have a well-defined process for rolling out an emergency patch to production web servers.  A lot of e-commerce sites fit into this category – and these may well be the riskiest sites.  Those using hosting providers – like the mom &amp; pop pizza shop – may get upgraded by the provider, but probably won’t know that they need to replace their certificates.  Certificate Authorities should reach out to their customers to encourage them to get a replacement – but unless they offer significant discounts, that offer may fall on deaf ears.</li><li>Second, the products out there that aren’t web servers, but still use OpenSSL.  There’s lots of these sorts of products, and in many cases the organizations that use them have no idea that OpenSSL is buried deep inside – and the vendor itself may not be aware, since OpenSSL may be embedded in a library that gets embedded, or it may have been inserted by a programmer who left the company years ago.  (We saw a scenario similar to this a few years ago when there was a serious vulnerability in a low-end Microsoft database product – and many products had it embedded but no one knew about it.)</li><li>Third, and scariest, are the embedded devices.  How many ATMs, manufacturing devices, monitoring cameras, etc use OpenSSL because vendors got burned when it came out that their communications were unencrypted?  So they did the “right” thing, embedded OpenSSL – and now perhaps made things even worse.  True, these devices aren’t likely to have a lot of passwords to be stolen from memory via the Heartbleed vulnerability, but there may be other sensitive information that can be retrieved.</li></ol><p>Obviously there’s some overlap between the second and third of these, but I separate them out because 2 is fundamentally about “computers” in the traditional sense that are not running web servers, and 3 is about embedded devices that happen to be running web servers.</p><p>The threat that every password and every private key have been stolen are almost certainly overblown.  But at the same time, we shouldn’t draw the line too narrowly – there are a lot of things beyond just “Apache running OpenSSL” that need to be examined.</p>" "https://freedom-to-tinker.com/blog/jeremyepstein/heartsick-about-heartbleed/" (21318 32056) new 3 nil nil ((title nil "Heartsick about Heartbleed") (link nil "https://freedom-to-tinker.com/blog/jeremyepstein/heartsick-about-heartbleed/") (comments nil "https://freedom-to-tinker.com/blog/jeremyepstein/heartsick-about-heartbleed/#comments") (pubDate nil "Thu, 10 Apr 2014 11:15:04 +0000") (dc:creator nil "Jeremy Epstein") (category nil "Heartbleed") (category nil "OpenSSL") (category nil "vulnerabilities") (guid ((isPermaLink . "false")) "https://freedom-to-tinker.com/?p=9784") (description nil "Ed Felten provides good advice on this blog about what to do in the wake of Heartbleed, and I&#8217;ve read some good technical discussions of the technical problem (see this for a particularly understandable explanation). In this brief posting, I want to look at a different angle &#8211; what&#8217;s the scope of the vulnerability? I&#8217;m [...]") (content:encoded nil "<p>Ed Felten <a href=\"https://freedom-to-tinker.com/blog/felten/how-to-protect-yourself-from-heartbleed/\">provides good advice</a> on this blog about what to do in the wake of Heartbleed, and I&#8217;ve read some good technical discussions of the technical problem (see <a href=\"http://blog.existentialize.com/diagnosis-of-the-openssl-heartbleed-bug.html\">this</a> for a particularly understandable explanation).</p><p>In this brief posting, I want to look at a different angle &#8211; what&#8217;s the scope of the vulnerability? I&#8217;m going to be (moderately) optimistic and suggest that within a week, major sites of all shapes and sizes (banks, e-shopping, government) will have installed the patches to their web servers and generated new keys/certificates, so it&#8217;s safe to visit them to change your password (if it&#8217;s an important account), and move on with your life. [That's being optimistic - the realist in me says that there will be some sites that will take months to get patched, because the approval process for big corporations and government agencies is some cumbersome that they can't say \"emergency override\", and fix the problem quickly.]</p><p>But there&#8217;s three other classes of sites we should also be concerned about.</p><ol><li>First, there&#8217;s the medium sized companies &#8211; too big to use an outsourced hosting provider that will automatically do the patching for them, but not big enough that they have a well-defined process for rolling out an emergency patch to production web servers.  A lot of e-commerce sites fit into this category &#8211; and these may well be the riskiest sites.  Those using hosting providers &#8211; like the mom &amp; pop pizza shop &#8211; may get upgraded by the provider, but probably won&#8217;t know that they need to replace their certificates.  Certificate Authorities should reach out to their customers to encourage them to get a replacement &#8211; but unless they offer significant discounts, that offer may fall on deaf ears.</li><li>Second, the products out there that aren&#8217;t web servers, but still use OpenSSL.  There&#8217;s lots of these sorts of products, and in many cases the organizations that use them have no idea that OpenSSL is buried deep inside &#8211; and the vendor itself may not be aware, since OpenSSL may be embedded in a library that gets embedded, or it may have been inserted by a programmer who left the company years ago.  (We saw a scenario similar to this a few years ago when there was a serious vulnerability in a low-end Microsoft database product &#8211; and many products had it embedded but no one knew about it.)</li><li>Third, and scariest, are the embedded devices.  How many ATMs, manufacturing devices, monitoring cameras, etc use OpenSSL because vendors got burned when it came out that their communications were unencrypted?  So they did the &#8220;right&#8221; thing, embedded OpenSSL &#8211; and now perhaps made things even worse.  True, these devices aren&#8217;t likely to have a lot of passwords to be stolen from memory via the Heartbleed vulnerability, but there may be other sensitive information that can be retrieved.</li></ol><p>Obviously there&#8217;s some overlap between the second and third of these, but I separate them out because 2 is fundamentally about &#8220;computers&#8221; in the traditional sense that are not running web servers, and 3 is about embedded devices that happen to be running web servers.</p><p>The threat that every password and every private key have been stolen are almost certainly overblown.  But at the same time, we shouldn&#8217;t draw the line too narrowly &#8211; there are a lot of things beyond just &#8220;Apache running OpenSSL&#8221; that need to be examined.</p>
") (wfw:commentRss nil "https://freedom-to-tinker.com/blog/jeremyepstein/heartsick-about-heartbleed/feed/") (slash:comments nil "0"))) ("Heartbleed and passwords: don’t panic" "<div id=\"magicdomid4\">The <a href=\"http://heartbleed.com/\">Heartbleed bug</a> has captured public attention this week like few security vulnerabilities before it. This is a good thing, as indeed this is a catastrophic flaw. Many people have focused on its impact on passwords with headlines like “<a title=\"http://hereandnow.wbur.org/2014/04/09/heartbleed-security-flaw\" href=\"http://hereandnow.wbur.org/2014/04/09/heartbleed-security-flaw\">Security Flaw Exposes Millions Of Passwords</a>” and “<a title=\"http://money.cnn.com/2014/04/10/technology/security/heartbleed-passwords/\" href=\"http://money.cnn.com/2014/04/10/technology/security/heartbleed-passwords/\">Change these passwords right now</a>.” Heartbleed certainly <i>could </i>have been used to steal millions of passwords. However, while Heartbleed gives the security community plenty of new problems to worry about, it doesn’t introduce any problems for passwords that haven’t existed for a long time and I’d discourage widespread panic about passwords.</div><div id=\"magicdomid5\"><b>Was/is Heartbleed used for stealing large numbers of passwords?</b></div><div id=\"magicdomid6\">I doubt it, though this is impossible to rule out and the security community is still searching for and analyzing evidence of Heartbleed exploits in the wild. Heartbleed isn’t targeted, so large-scale password collection would have required a large amount of Heartbleed traffic to login servers. This would possibly have tripped intrusion-detection systems and it almost surely would have left evidence that will be found in logs sooner rather than later. Every day which passes without this evidence strengthens the likelihood that Heartbleed was never exploited at scale to steal passwords.</div><div></div><div>Furthermore, to an attacker with a zero-day exploit as powerful as Heartbleed the risk of burning it to collect mundane passwords doesn’t seem worth the benefit. It’s much more likely that Heartbleed would have been used to go after server keys, or possibly in targeted attacks after observing a specific high-value user log in somewhere. It’s possible some passwords were stolen as a byproduct of more targeted attacks, but I doubt that was on a large scale.</div><div id=\"magicdomid7\"><b>If Heartbleed were used to collect large numbers of passwords, wouldn’t that be a disaster?</b></div><div id=\"magicdomid2413\">If so, that disaster would already have occurred. Acquiring large numbers of passwords isn’t a new risk, there are <a title=\"http://thepasswordproject.com/leaked_password_lists_and_dictionaries\" href=\"http://thepasswordproject.com/leaked_password_lists_and_dictionaries\">regular leaks</a> and <a title=\"https://pwnedlist.com\" href=\"https://pwnedlist.com/\">one source</a> has compiled over 250 million leaked passwords in the past 2 years alone. Those are just the leaks that go public. I’ve personally seen credible evidence of at least this volume of passwords in private leaks and there are probably many, many more. Of course, with Heartbleed passwords can be collected in plaintext, but most sites <a title=\"http://www.lightbluetouchpaper.org/2010/07/27/passwords-in-the-wild-part-i-the-gap-between-theory-and-implementation/\" href=\"http://www.lightbluetouchpaper.org/2010/07/27/passwords-in-the-wild-part-i-the-gap-between-theory-and-implementation/\">don’t hash at all or only do so poorly</a> and the majority of users’ passwords are recoverable from hashes anyways.</div><div></div><div id=\"magicdomid2523\">We survive the deluge of compromised passwords because turning <a title=\"http://research.microsoft.com/pubs/161829/EverythingWeKnow.pdf\" href=\"http://research.microsoft.com/pubs/161829/EverythingWeKnow.pdf\">credentials into cash is hard</a>. If lots of private keys were stolen with Heartbleed that would be a possibly-unprecedented disaster. Even if lots of passwords were stolen, it would be neither unprecedented nor a disaster.</div><div><div id=\"magicdomid7\"><b>What about session cookies?</b></div><div>Session cookies need to stay in memory for much longer than passwords, so a password-stealing attack with Heartbleed would obtain many times more session cookies as bycatch. Of course, session cookies don’t last forever and hence are less valuable to attackers. For the same reasons as above, I’d be doubtful these were collected at scale. This problem also <em>should</em> be fixable now with no user intervention as system administrators can revoke outstanding session cookies after upgrading their servers (though many won’t).</div></div><div id=\"magicdomid10\"><b>Should I change all of my passwords?</b></div><div id=\"magicdomid3254\">It wouldn’t hurt, but for the reasons above I consider it unlikely that anybody has stolen your passwords using Heartbleed. It’s more likely that they had already stolen them using another method. If you weren’t worried about that, there’s not much new reason to worry here, not to mention the complexity that changing passwords before servers are fixed won’t help. I wouldn’t recommend panic unless evidence comes out that this was exploited on a large scale. If you’re going to change a password, change the one to your email account, since that usually can be used to reset all others.</div><div id=\"magicdomid2619\"><b>Would choosing stronger passwords have helped?</b></div><div id=\"magicdomid13\">No. As <a href=\"http://www.lightbluetouchpaper.org/2012/09/04/password-cracking-part-ii-when-does-password-cracking-matter/\">is usually the case</a> with potential password compromises, Heartbleed had nothing to do with individual passwords being good or bad. Media stories often focus on the password angle with security news, even when it’s completely irrelevant. For the most part I’d say ignore discussions of “stronger passwords” and focus on less password reuse.</div><div id=\"magicdomid2632\"><b>Would using a password manager have helped?</b></div><div id=\"magicdomid407\">Somewhat, in that they can help cut down on reuse if deployed properly. In general password managers are a great idea if you can find one that fits your browsing habits. But against Heartbleed you would have lost your passwords in exactly the same scenarios and changing them all would still be a headache (though somewhat easier in that you wouldn’t need to memorize new passwords).</div><div id=\"magicdomid16\"><b>Would two-factor authentication have helped?</b></div><div id=\"magicdomid17\">Likely yes, although for second-factor schemes with a secret key there’s a chance the login server had to read that key into memory to verify your second factor and it could have been stolen along with your password. You’re safe if the login server called some other backend server to verify your second factor input, which may be the case for engineering reasons. In general, second-factor schemes won’t survive a complete server compromise unless your second factor is doing public-key crypto, but there’s a good chance they’re resilient in practice to Heartbleed.</div><div id=\"magicdomid2637\"><b>Will this help rally support for replacing passwords with something more secure?</b></div><div id=\"magicdomid3252\">I highly doubt it. Much as we all say we’d like to replace passwords with something better, I’ve written at length about why <a title=\"https://incentives are aligned against replacing passwords\" href=\"https://incentives%20are%20aligned%20against%20replacing%20passwords/\">incentives are aligned against replacing passwords</a> on a large scale. Heartbleed adds very little to the case for replacing them. Most users probably won’t notice any direct consequences and many proposed replacements would have had security consequences from Heartbleed as well.</div><div id=\"magicdomid20\"><b>So is Heartbleed actually a big deal?</b></div><div id=\"magicdomid2699\">For the security community, absolutely yes. Fixing the problem everywhere is a major engineering challenge that will take years. There will definitely be negative real-world impact and that’s a major black eye for security engineers everywhere. For most ordinary users though, the impact is probably negligible.</div><div id=\"magicdomid2158\"><b>If it isn’t such a big deal to me, why have I heard so much about it?</b></div><div id=\"magicdomid2299\">Like most security vulnerabilities, the impact of Heartbleed, particularly with regards to passwords, is likely overstated due to a number of biases:</div><div id=\"magicdomid2076\"><ul><li>We prefer to be safe rather than sorry. Prospect theory suggests that we are biased towards loss aversion and avoiding potentially large negative outcomes.</li></ul></div><div id=\"magicdomid2355\"><ul><li>It’s easy to enumerate potential negative costs of a security vulnerability and much harder to tabulate the cost of asking millions of people to change behavior (change passwords) let alone the cost of panicking them.</li></ul></div><div id=\"magicdomid2078\"><ul><li>Claiming the sky is falling lets us feel our job as security engineers is important, whereas admitting that even a very bad technical flaw may not impact the outside world much has the opposite effect.</li></ul></div><div id=\"magicdomid3494\"><ul><li>There are always a few cases of individual grandstanding and attention-seeking and this encourages dire predictions.</li></ul></div><div id=\"magicdomid2700\"><ul><li>Users want to do <i>something </i>in response and changing passwords is one of the few things they can do. Security engineers and reporters want to tell them something they can do besides “rely on a bunch of overworked sysadmins to patch this up with duct tape.”</li></ul></div><div id=\"magicdomid3493\"><ul><li>Passwords are the easiest component of this for users to relate to. It’s also the easiest component to write about, much easier than trying to explain what a private key is or discuss the layout of memory on the heap.</li></ul></div><div id=\"magicdomid22\"><b>Conclusion</b></div><div id=\"magicdomid3647\">Heartbleed is an embarrassing mess and it highlights some ugly facts about security infrastructure like slow patching cycles and the inability to rotate TLS keys gracefully. But it doesn’t tell us much new about passwords or suggest every password must be updated. Here’s another way to think about it: Heartbleed <i>could</i> have been used to steal large quantities of credit card numbers, just like passwords. But nobody is claiming that people should cancel all of their credit cards or that we need a new payment system.</div><div></div><div id=\"magicdomid2391\">If Heartbleed is a teachable moment which encourages people to change passwords or use a password manager, that’s a good thing. But passwords aren’t the main story here and even with no action Heartbleed shouldn’t have much impact on password security for the vast majority of people.</div>" "https://freedom-to-tinker.com/blog/jbonneau/heartbleed-and-passwords-dont-panic-2/" (21320 27746) new 2 nil nil ((title nil "Heartbleed and passwords: don’t panic") (link nil "https://freedom-to-tinker.com/blog/jbonneau/heartbleed-and-passwords-dont-panic-2/") (comments nil "https://freedom-to-tinker.com/blog/jbonneau/heartbleed-and-passwords-dont-panic-2/#comments") (pubDate nil "Fri, 11 Apr 2014 22:27:46 +0000") (dc:creator nil "Joseph Bonneau") (guid ((isPermaLink . "false")) "https://freedom-to-tinker.com/?p=9818") (description nil "The Heartbleed bug has captured public attention this week like few security vulnerabilities before it. This is a good thing, as indeed this is a catastrophic flaw. Many people have focused on its impact on passwords with headlines like &#8220;Security Flaw Exposes Millions Of Passwords&#8221; and &#8220;Change these passwords right now.&#8221; Heartbleed certainly could have been used [...]") (content:encoded nil "<div id=\"magicdomid4\">The <a href=\"http://heartbleed.com/\">Heartbleed bug</a> has captured public attention this week like few security vulnerabilities before it. This is a good thing, as indeed this is a catastrophic flaw. Many people have focused on its impact on passwords with headlines like &#8220;<a title=\"http://hereandnow.wbur.org/2014/04/09/heartbleed-security-flaw\" href=\"http://hereandnow.wbur.org/2014/04/09/heartbleed-security-flaw\">Security Flaw Exposes Millions Of Passwords</a>&#8221; and &#8220;<a title=\"http://money.cnn.com/2014/04/10/technology/security/heartbleed-passwords/\" href=\"http://money.cnn.com/2014/04/10/technology/security/heartbleed-passwords/\">Change these passwords right now</a>.&#8221; Heartbleed certainly <i>could </i>have been used to steal millions of passwords. However, while Heartbleed gives the security community plenty of new problems to worry about, it doesn&#8217;t introduce any problems for passwords that haven&#8217;t existed for a long time and I&#8217;d discourage widespread panic about passwords.</div><div id=\"magicdomid5\"><b>Was/is Heartbleed used for stealing large numbers of passwords?</b></div><div id=\"magicdomid6\">I doubt it, though this is impossible to rule out and the security community is still searching for and analyzing evidence of Heartbleed exploits in the wild. Heartbleed isn&#8217;t targeted, so large-scale password collection would have required a large amount of Heartbleed traffic to login servers. This would possibly have tripped intrusion-detection systems and it almost surely would have left evidence that will be found in logs sooner rather than later. Every day which passes without this evidence strengthens the likelihood that Heartbleed was never exploited at scale to steal passwords.</div><div></div><div>Furthermore, to an attacker with a zero-day exploit as powerful as Heartbleed the risk of burning it to collect mundane passwords doesn&#8217;t seem worth the benefit. It&#8217;s much more likely that Heartbleed would have been used to go after server keys, or possibly in targeted attacks after observing a specific high-value user log in somewhere. It&#8217;s possible some passwords were stolen as a byproduct of more targeted attacks, but I doubt that was on a large scale.</div><div id=\"magicdomid7\"><b>If Heartbleed were used to collect large numbers of passwords, wouldn&#8217;t that be a disaster?</b></div><div id=\"magicdomid2413\">If so, that disaster would already have occurred. Acquiring large numbers of passwords isn&#8217;t a new risk, there are <a title=\"http://thepasswordproject.com/leaked_password_lists_and_dictionaries\" href=\"http://thepasswordproject.com/leaked_password_lists_and_dictionaries\">regular leaks</a> and <a title=\"https://pwnedlist.com\" href=\"https://pwnedlist.com/\">one source</a> has compiled over 250 million leaked passwords in the past 2 years alone. Those are just the leaks that go public. I&#8217;ve personally seen credible evidence of at least this volume of passwords in private leaks and there are probably many, many more. Of course, with Heartbleed passwords can be collected in plaintext, but most sites <a title=\"http://www.lightbluetouchpaper.org/2010/07/27/passwords-in-the-wild-part-i-the-gap-between-theory-and-implementation/\" href=\"http://www.lightbluetouchpaper.org/2010/07/27/passwords-in-the-wild-part-i-the-gap-between-theory-and-implementation/\">don&#8217;t hash at all or only do so poorly</a> and the majority of users&#8217; passwords are recoverable from hashes anyways.</div><div></div><div id=\"magicdomid2523\">We survive the deluge of compromised passwords because turning <a title=\"http://research.microsoft.com/pubs/161829/EverythingWeKnow.pdf\" href=\"http://research.microsoft.com/pubs/161829/EverythingWeKnow.pdf\">credentials into cash is hard</a>. If lots of private keys were stolen with Heartbleed that would be a possibly-unprecedented disaster. Even if lots of passwords were stolen, it would be neither unprecedented nor a disaster.</div><div><div id=\"magicdomid7\"><b>What about session cookies?</b></div><div>Session cookies need to stay in memory for much longer than passwords, so a password-stealing attack with Heartbleed would obtain many times more session cookies as bycatch. Of course, session cookies don&#8217;t last forever and hence are less valuable to attackers. For the same reasons as above, I&#8217;d be doubtful these were collected at scale. This problem also <em>should</em> be fixable now with no user intervention as system administrators can revoke outstanding session cookies after upgrading their servers (though many won&#8217;t).</div></div><div id=\"magicdomid10\"><b>Should I change all of my passwords?</b></div><div id=\"magicdomid3254\">It wouldn&#8217;t hurt, but for the reasons above I consider it unlikely that anybody has stolen your passwords using Heartbleed. It&#8217;s more likely that they had already stolen them using another method. If you weren&#8217;t worried about that, there&#8217;s not much new reason to worry here, not to mention the complexity that changing passwords before servers are fixed won&#8217;t help. I wouldn&#8217;t recommend panic unless evidence comes out that this was exploited on a large scale. If you&#8217;re going to change a password, change the one to your email account, since that usually can be used to reset all others.</div><div id=\"magicdomid2619\"><b>Would choosing stronger passwords have helped?</b></div><div id=\"magicdomid13\">No. As <a href=\"http://www.lightbluetouchpaper.org/2012/09/04/password-cracking-part-ii-when-does-password-cracking-matter/\">is usually the case</a> with potential password compromises, Heartbleed had nothing to do with individual passwords being good or bad. Media stories often focus on the password angle with security news, even when it&#8217;s completely irrelevant. For the most part I&#8217;d say ignore discussions of &#8220;stronger passwords&#8221; and focus on less password reuse.</div><div id=\"magicdomid2632\"><b>Would using a password manager have helped?</b></div><div id=\"magicdomid407\">Somewhat, in that they can help cut down on reuse if deployed properly. In general password managers are a great idea if you can find one that fits your browsing habits. But against Heartbleed you would have lost your passwords in exactly the same scenarios and changing them all would still be a headache (though somewhat easier in that you wouldn&#8217;t need to memorize new passwords).</div><div id=\"magicdomid16\"><b>Would two-factor authentication have helped?</b></div><div id=\"magicdomid17\">Likely yes, although for second-factor schemes with a secret key there&#8217;s a chance the login server had to read that key into memory to verify your second factor and it could have been stolen along with your password. You&#8217;re safe if the login server called some other backend server to verify your second factor input, which may be the case for engineering reasons. In general, second-factor schemes won&#8217;t survive a complete server compromise unless your second factor is doing public-key crypto, but there&#8217;s a good chance they&#8217;re resilient in practice to Heartbleed.</div><div id=\"magicdomid2637\"><b>Will this help rally support for replacing passwords with something more secure?</b></div><div id=\"magicdomid3252\">I highly doubt it. Much as we all say we&#8217;d like to replace passwords with something better, I&#8217;ve written at length about why <a title=\"https://incentives are aligned against replacing passwords\" href=\"https://incentives%20are%20aligned%20against%20replacing%20passwords/\">incentives are aligned against replacing passwords</a> on a large scale. Heartbleed adds very little to the case for replacing them. Most users probably won&#8217;t notice any direct consequences and many proposed replacements would have had security consequences from Heartbleed as well.</div><div id=\"magicdomid20\"><b>So is Heartbleed actually a big deal?</b></div><div id=\"magicdomid2699\">For the security community, absolutely yes. Fixing the problem everywhere is a major engineering challenge that will take years. There will definitely be negative real-world impact and that&#8217;s a major black eye for security engineers everywhere. For most ordinary users though, the impact is probably negligible.</div><div id=\"magicdomid2158\"><b>If it isn&#8217;t such a big deal to me, why have I heard so much about it?</b></div><div id=\"magicdomid2299\">Like most security vulnerabilities, the impact of Heartbleed, particularly with regards to passwords, is likely overstated due to a number of biases:</div><div id=\"magicdomid2076\"><ul><li>We prefer to be safe rather than sorry. Prospect theory suggests that we are biased towards loss aversion and avoiding potentially large negative outcomes.</li></ul></div><div id=\"magicdomid2355\"><ul><li>It&#8217;s easy to enumerate potential negative costs of a security vulnerability and much harder to tabulate the cost of asking millions of people to change behavior (change passwords) let alone the cost of panicking them.</li></ul></div><div id=\"magicdomid2078\"><ul><li>Claiming the sky is falling lets us feel our job as security engineers is important, whereas admitting that even a very bad technical flaw may not impact the outside world much has the opposite effect.</li></ul></div><div id=\"magicdomid3494\"><ul><li>There are always a few cases of individual grandstanding and attention-seeking and this encourages dire predictions.</li></ul></div><div id=\"magicdomid2700\"><ul><li>Users want to do <i>something </i>in response and changing passwords is one of the few things they can do. Security engineers and reporters want to tell them something they can do besides &#8220;rely on a bunch of overworked sysadmins to patch this up with duct tape.&#8221;</li></ul></div><div id=\"magicdomid3493\"><ul><li>Passwords are the easiest component of this for users to relate to. It&#8217;s also the easiest component to write about, much easier than trying to explain what a private key is or discuss the layout of memory on the heap.</li></ul></div><div id=\"magicdomid22\"><b>Conclusion</b></div><div id=\"magicdomid3647\">Heartbleed is an embarrassing mess and it highlights some ugly facts about security infrastructure like slow patching cycles and the inability to rotate TLS keys gracefully. But it doesn&#8217;t tell us much new about passwords or suggest every password must be updated. Here&#8217;s another way to think about it: Heartbleed <i>could</i> have been used to steal large quantities of credit card numbers, just like passwords. But nobody is claiming that people should cancel all of their credit cards or that we need a new payment system.</div><div></div><div id=\"magicdomid2391\">If Heartbleed is a teachable moment which encourages people to change passwords or use a password manager, that&#8217;s a good thing. But passwords aren&#8217;t the main story here and even with no action Heartbleed shouldn&#8217;t have much impact on password security for the vast majority of people.</div>
") (wfw:commentRss nil "https://freedom-to-tinker.com/blog/jbonneau/heartbleed-and-passwords-dont-panic-2/feed/") (slash:comments nil "0"))) ("Bitcoin hacks and thefts: The underlying reason" "<p dir=\"ltr\">Emin Gün Sirer has a <a href=\"http://hackingdistributed.com/2014/04/06/another-one-bites-the-dust-flexcoin/\">fascinating post</a> about how the use of NoSQL caused technical failures that led to the demise of Bitcoin exchanges Flexcoin and Poloniex. But these are only the latest in a <a href=\"https://bitcointalk.org/index.php?topic=83794.0\">long line</a> of hacks of exchanges, other services, and individuals; a wide variety of bugs have been implicated. This suggests that there’s some underlying reason why Bitcoiners keep building systems that get exploited. In this post I’ll examine why.</p><p dir=\"ltr\">Let’s step back for a minute and talk about how we keep buildings physically secure. Locks are the first thing that come to mind, but they’re only a small part of the picture. <strong>Physical security is not just <em>preventive</em> but also <em>reactive</em> and <em>corrective</em>.</strong> We have intrusion-detection systems and ways of going after criminals. In particular, stolen goods are difficult to convert into cash. In the absence of the state and the rule of law, locks by themselves would do little to keep buildings secure.</p><p dir=\"ltr\"><strong>Software security is exactly like that.</strong> Keeping attackers out is only the first line of defense; companies spend as much on intrusion detection. As the Heartbleed bug demonstrates, we don’t have processes that will produce code that’s free of vulnerabilities given the practical constraints of software development. Relying on prevention alone, then, is simply not an option. But the extent to which practical security relies on detection over prevention may be surprising. For example, my colleague Joseph Bonneau has argued that authentication is becoming a <a href=\"http://www.lightbluetouchpaper.org/2012/12/14/authentication-is-machine-learning/\">machine learning problem</a>. The upshot is that on many or most sites where security matters, stealing a password is not by itself sufficient to impersonate the user.</p><p dir=\"ltr\">Perhaps most crucially for e-commerce, banks can reverse fraudulent transactions and law enforcement of digital financial crimes is relatively competent. As a result, <a href=\"https://research.microsoft.com/pubs/161829/EverythingWeKnow.pdf\">stolen passwords</a> and credit card numbers are worth only <a href=\"https://research.microsoft.com/pubs/80034/nobodysellsgoldforthepriceofsilver.pdf\">fractions of a penny on the dollar</a>. Viewed in this context, the role of cryptography and access control is merely to raise the bar sufficiently for attackers so that the risk of getting caught combined with the diminished ability to monetize break-ins skew the economics in favor of the defender.</p><p dir=\"ltr\"><strong>Bitcoin’s design destroys this delicate balance of prevention, detection, and correction</strong>, and puts the entire onus on preventive measures. [*] If an attacker breaks into a server containing private keys, he can steal the bitcoins immediately and irreversibly. Furthermore, a stolen bitcoin is still a bitcoin. [**] While there’s been talk of taint-tracking mechanisms to prevent thieves from cashing out, these haven’t materialized and there are fundamental technical and political difficulties with such proposals.</p><p dir=\"ltr\">I suspect that developers of Bitcoin services who are responsible for security consistently and dramatically underestimate what it takes to build a secure Bitcoin service. Coding and operational practices that are perfectly adequate for building a typical e-commerce site turn out to be utterly inadequate for, say, a Bitcoin exchange. Going back to the lock analogy, developers think they need a door lock when in fact they need Fort Knox. And software security as a field has simply not matured to the point where we’re even capable of building systems that rely primarily on preventive technological mechanisms in the face of persistent, financially motivated adversaries.</p><p dir=\"ltr\"><strong>This analysis suggests that Bitcoin businesses will continue to face a rocky future</strong>, considering that the state of software security will not improve overnight. This is why research into techniques like <a href=\"https://freedom-to-tinker.com/blog/stevenag/new-research-better-wallet-security-for-bitcoin/\">threshold cryptography</a> is so important; these measures can help secure wallets even when the underlying environment is vulnerable. At the same time, perhaps the security needs of the Bitcoin ecosystem will finally provide the kick in the pants needed to improve coding practices, security reviews and audits, adversarial testing, and operational security to the point where we can build systems that are secure by design. If this happens, it will have a huge, lasting, positive impact on the overall state of Internet security.</p><p dir=\"ltr\">[*] These differences seem to be largely inherent, but they can be mitigated a little bit by measures such as keeping bitcoins in <a href=\"https://en.bitcoin.it/wiki/Cold_storage\">cold storage</a>.</p><p dir=\"ltr\">[**] A <a href=\"http://cseweb.ucsd.edu/~smeiklejohn/files/imc13.pdf\">recent paper</a> led by Sarah Meiklejohn argues that it currently is difficult for thieves to launder large sums of bitcoins. If this changes, we can expect that the incentives will shift even further in favor of attackers.</p><p>Thanks to Joseph Bonneau and Ed Felten for reviewing a draft.</p>" "https://freedom-to-tinker.com/blog/randomwalker/bitcoin-hacks-and-thefts-the-underlying-reason/" (21325 14671) new 1 nil nil ((title nil "Bitcoin hacks and thefts: The underlying reason") (link nil "https://freedom-to-tinker.com/blog/randomwalker/bitcoin-hacks-and-thefts-the-underlying-reason/") (comments nil "https://freedom-to-tinker.com/blog/randomwalker/bitcoin-hacks-and-thefts-the-underlying-reason/#comments") (pubDate nil "Tue, 15 Apr 2014 13:51:11 +0000") (dc:creator nil "Arvind Narayanan") (guid ((isPermaLink . "false")) "https://freedom-to-tinker.com/?p=9863") (description nil "Emin Gün Sirer has a fascinating post about how the use of NoSQL caused technical failures that led to the demise of Bitcoin exchanges Flexcoin and Poloniex. But these are only the latest in a long line of hacks of exchanges, other services, and individuals; a wide variety of bugs have been implicated. This suggests [...]") (content:encoded nil "<p dir=\"ltr\">Emin Gün Sirer has a <a href=\"http://hackingdistributed.com/2014/04/06/another-one-bites-the-dust-flexcoin/\">fascinating post</a> about how the use of NoSQL caused technical failures that led to the demise of Bitcoin exchanges Flexcoin and Poloniex. But these are only the latest in a <a href=\"https://bitcointalk.org/index.php?topic=83794.0\">long line</a> of hacks of exchanges, other services, and individuals; a wide variety of bugs have been implicated. This suggests that there’s some underlying reason why Bitcoiners keep building systems that get exploited. In this post I’ll examine why.</p><p dir=\"ltr\">Let’s step back for a minute and talk about how we keep buildings physically secure. Locks are the first thing that come to mind, but they’re only a small part of the picture. <strong>Physical security is not just <em>preventive</em> but also <em>reactive</em> and <em>corrective</em>.</strong> We have intrusion-detection systems and ways of going after criminals. In particular, stolen goods are difficult to convert into cash. In the absence of the state and the rule of law, locks by themselves would do little to keep buildings secure.</p><p dir=\"ltr\"><strong>Software security is exactly like that.</strong> Keeping attackers out is only the first line of defense; companies spend as much on intrusion detection. As the Heartbleed bug demonstrates, we don’t have processes that will produce code that’s free of vulnerabilities given the practical constraints of software development. Relying on prevention alone, then, is simply not an option. But the extent to which practical security relies on detection over prevention may be surprising. For example, my colleague Joseph Bonneau has argued that authentication is becoming a <a href=\"http://www.lightbluetouchpaper.org/2012/12/14/authentication-is-machine-learning/\">machine learning problem</a>. The upshot is that on many or most sites where security matters, stealing a password is not by itself sufficient to impersonate the user.</p><p dir=\"ltr\">Perhaps most crucially for e-commerce, banks can reverse fraudulent transactions and law enforcement of digital financial crimes is relatively competent. As a result, <a href=\"https://research.microsoft.com/pubs/161829/EverythingWeKnow.pdf\">stolen passwords</a> and credit card numbers are worth only <a href=\"https://research.microsoft.com/pubs/80034/nobodysellsgoldforthepriceofsilver.pdf\">fractions of a penny on the dollar</a>. Viewed in this context, the role of cryptography and access control is merely to raise the bar sufficiently for attackers so that the risk of getting caught combined with the diminished ability to monetize break-ins skew the economics in favor of the defender.</p><p dir=\"ltr\"><strong>Bitcoin’s design destroys this delicate balance of prevention, detection, and correction</strong>, and puts the entire onus on preventive measures. [*] If an attacker breaks into a server containing private keys, he can steal the bitcoins immediately and irreversibly. Furthermore, a stolen bitcoin is still a bitcoin. [**] While there’s been talk of taint-tracking mechanisms to prevent thieves from cashing out, these haven’t materialized and there are fundamental technical and political difficulties with such proposals.</p><p dir=\"ltr\">I suspect that developers of Bitcoin services who are responsible for security consistently and dramatically underestimate what it takes to build a secure Bitcoin service. Coding and operational practices that are perfectly adequate for building a typical e-commerce site turn out to be utterly inadequate for, say, a Bitcoin exchange. Going back to the lock analogy, developers think they need a door lock when in fact they need Fort Knox. And software security as a field has simply not matured to the point where we’re even capable of building systems that rely primarily on preventive technological mechanisms in the face of persistent, financially motivated adversaries.</p><p dir=\"ltr\"><strong>This analysis suggests that Bitcoin businesses will continue to face a rocky future</strong>, considering that the state of software security will not improve overnight. This is why research into techniques like <a href=\"https://freedom-to-tinker.com/blog/stevenag/new-research-better-wallet-security-for-bitcoin/\">threshold cryptography</a> is so important; these measures can help secure wallets even when the underlying environment is vulnerable. At the same time, perhaps the security needs of the Bitcoin ecosystem will finally provide the kick in the pants needed to improve coding practices, security reviews and audits, adversarial testing, and operational security to the point where we can build systems that are secure by design. If this happens, it will have a huge, lasting, positive impact on the overall state of Internet security.</p><p dir=\"ltr\">[*] These differences seem to be largely inherent, but they can be mitigated a little bit by measures such as keeping bitcoins in <a href=\"https://en.bitcoin.it/wiki/Cold_storage\">cold storage</a>.</p><p dir=\"ltr\">[**] A <a href=\"http://cseweb.ucsd.edu/~smeiklejohn/files/imc13.pdf\">recent paper</a> led by Sarah Meiklejohn argues that it currently is difficult for thieves to launder large sums of bitcoins. If this changes, we can expect that the incentives will shift even further in favor of attackers.</p><p>Thanks to Joseph Bonneau and Ed Felten for reviewing a draft.</p>
") (wfw:commentRss nil "https://freedom-to-tinker.com/blog/randomwalker/bitcoin-hacks-and-thefts-the-underlying-reason/feed/") (slash:comments nil "1"))))