;; -*- coding: utf-8 -*-
(("Paper Trail" "Computer Systems, Distributed Algorithms and Databases" "http://the-paper-trail.org/blog" (21317 36648 570579 599000) feed 0 nil nil ((title nil "Paper Trail") (atom:link ((href . "http://the-paper-trail.org/blog/feed/") (rel . "self") (type . "application/rss+xml"))) (link nil "http://the-paper-trail.org/blog") (description nil "Computer Systems, Distributed Algorithms and Databases") (lastBuildDate nil "Thu, 13 Mar 2014 05:17:51 +0000") (language nil "en-US") (sy:updatePeriod nil "hourly") (sy:updateFrequency nil "1") (generator nil "http://wordpress.org/?v=3.7.2") (item nil (title nil "Étale cohomology") (link nil "http://the-paper-trail.org/blog/etale-cohomology/") (comments nil "http://the-paper-trail.org/blog/etale-cohomology/#comments") (pubDate nil "Wed, 05 Mar 2014 06:22:25 +0000") (dc:creator nil "Henry") (category nil "mathematics") (guid ((isPermaLink . "false")) "http://the-paper-trail.org/blog/?p=554") (description nil "The second in an extremely irregular series of posts made on behalf of my father, who has spent much of his retirement so far doing very hard mathematics. What is attached here is the essay he wrote for the Part III of the Cambridge Mathematical Tripos, a one year taught course. The subject is the [&#8230;]") (content:encoded nil "<p><em>The second in an extremely irregular series of posts made on behalf of my father, who has spent much of his retirement so far doing very hard mathematics. What is attached here is the essay he wrote for the <a href=\"http://en.wikipedia.org/wiki/Part_III_of_the_Mathematical_Tripos\" title=\"Cambridge Mathematics Part III\">Part III of the Cambridge Mathematical Tripos</a>, a one year taught course. The subject is the <a href=\"http://en.wikipedia.org/wiki/%C3%89tale_cohomology\">Étale cohomology</a>.</em></p><p><em>Says my Dad:</em> &#8220;I am afraid that I have been lured away from the translation of SGA 4.5 for some time by the attraction of working on Wolfgang Krull&#8217;s report on &#8220;Idealtheorie&#8221; from 1935 (again I am not aware of an English version anywhere) which is yet another important classic. However during a year at Cambridge I did write an essay as a very basic introduction to Étale Cohomology which was based on the first part of SGA 4.5. So with the usual imprecation of caveat lector, here it is as a temporising partial substitute should any other beginner be interested.&#8221;</p><p><em>Here&#8217;s part of the introduction:</em></p><blockquote>This essay has been written as part of the one year Certificate of Advanced Study in Mathematics (CASM) course at Cambridge University which coincides with Part III of the Mathematical Tripos. The starting point is, of necessity, roughly that reached in the lectures which in this particular year did not include much in the way of schemes and sheaves, nor, in the case of the author, much in the way of algebraic number theory.
Thus the frontiers of the subject can safely rest undisturbed by the contents of this essay. Rather it has been written with a reader in mind corresponding roughly to the author at the start of the enterprise. That is someone who is interested to find out what all the fuss was with the French algebraic geometers in the 1960s but is in need of some fairly elementary background to map out the abstractions involved and with any luck to avoid drowning in the “rising sea”.</blockquote><p>And here&#8217;s the <a href=\"http://the-paper-trail.org/blog/wp-content/uploads/2014/03/EC-Essay-1.pdf\">essay itself</a>!</p>
") (wfw:commentRss nil "http://the-paper-trail.org/blog/etale-cohomology/feed/") (slash:comments nil "0")) (item nil (title nil "ByteArrayOutputStream is really, really slow sometimes in JDK6") (link nil "http://the-paper-trail.org/blog/535/") (comments nil "http://the-paper-trail.org/blog/535/#comments") (pubDate nil "Fri, 10 Jan 2014 22:57:41 +0000") (dc:creator nil "Henry") (category nil "Uncategorized") (category nil "Java") (guid ((isPermaLink . "false")) "http://the-paper-trail.org/blog/?p=535") (description nil "TLDR: Yesterday I mentioned on Twitter that I&#8217;d found a bad performance problem when writing to a large ByteArrayOutputStream in Java. After some digging, it appears to be the case that there&#8217;s a bad bug in JDK6 that doesn&#8217;t affect correctness, but does cause performance to nosedive when a ByteArrayOutputStream gets large. This post explains [&#8230;]") (content:encoded nil "<p>TLDR: Yesterday I <a href=\"https://twitter.com/HenryR/status/421415424807297024\" title=\"Twitter\">mentioned on Twitter</a> that I&#8217;d found a bad performance problem when writing to a large <a href=\"http://docs.oracle.com/javase/6/docs/api/java/io/ByteArrayOutputStream.html\" title=\"ByteArrayOutputStream Javadoc\"><code>ByteArrayOutputStream</code></a> in Java. After some digging, it appears to be the case that there&#8217;s a bad bug in JDK6 that doesn&#8217;t affect correctness, but does cause performance to nosedive when a <code>ByteArrayOutputStream</code> gets large. This post explains why.</p><p><span id=\"more-535\"></span></p><p>Two of <a href=\"https://github.com/cloudera/Impala\" title=\"Impala on Github\">Impala&#8217;s</a> server processes have both C++ and Java components (for reasons both historic and pragmatic). We often need to pass data structures from C++ to Java and vice versa, and mapping the C++ representation onto a Java one via JNI is too painful to contemplate. So instead we take advantage of the fact that <a href=\"http://thrift.apache.org/\" title=\"Apache Thrift\">Thrift</a> is very good at generating equivalent data structures in different languages, and make every parameter to methods on the JNI boundary a serialised Thrift structure. That is, it&#8217;s a byte array that Thrift on both sides knows how to convert into a Thrift structure. So we pass byte arrays back and forth, and use Thrift to convert them to language-readable data structures. This works pretty well. (To see exactly how, start by reading <a href=\"https://github.com/cloudera/Impala/blob/master/be/src/service/frontend.cc#L62\" title=\"frontend.cc\">frontend.cc</a> and <a href=\"https://github.com/cloudera/Impala/blob/master/fe/src/main/java/com/cloudera/impala/service/JniFrontend.java\" title=\"JniFrontend.java\">JniFrontend.java</a>). We pay an extra copy or two, plus the CPU overhead of the serialisation, but the benefits in terms of usability and maintainability of the interface vastly outweigh some pretty nominal performance hits.</p><p>If the performance hit isn&#8217;t nominal, however, we have a problem. And this is what we observed earlier this week: one of the JNI methods was trying to pass a huge data structure back from Java to C++. Doing so was taking a long time &#8211; on the order of minutes. What was particularly of interest was that the performance dropped off a cliff: a data structure half the size was happily serialising in about 500ms. So we have a non-linear relationship between the size of the input and the cost of serialising it. We can&#8217;t really absorb that cost, so we had to understand the problem.</p><p>So how did we get there? Thrift&#8217;s <a href=\"https://github.com/apache/thrift/blob/master/lib/java/src/org/apache/thrift/TSerializer.java#L77\" title=\"TSerializer.java\">Java serialisation implementation</a> works by having a <code>TSerializer</code> object, which contains a <code>ByteArrayOutputStream</code>, call <code>write()</code> on a Thrift structure with its <code>ByteArrayOutputStream</code> as an argument. The Thrift structure then walks its members and writes object headers and then serialised data for each field in turn. The result is lots of small <code>write()</code> calls to the <code>ByteArrayOutputStream</code>.</p><p>The first thing was to connect a profiler (<a href=\"http://www.yourkit.com\" title=\"YourKit Java Profiler\">YourKit</a>, but honestly repeated <code>SIGHUP</code> to get the stack trace would have worked). During the long serialisation period, almost all the time was spent inside <code>java.util.Arrays.copyOf</code>, inside a method to write a <code>byte[]</code> to a <code>ByteArrayOutputStream</code>. Progress was being made &#8211; the item being written to the <code>ByteArrayOutputStream</code> was changing &#8211; but it was taking an unreasonably long time to write each field.</p><p>A <code>ByteArrayOutputStream</code> is not necessarily initialised with any estimate of the ultimate size of the byte array it wraps. So it needs a mechanism to resize when more space is required. The source for <a href=\"http://grepcode.com/file/repository.grepcode.com/java/root/jdk/openjdk/6-b14/java/io/ByteArrayOutputStream.java#1\" title=\"ByteArrayOutputStream JDK6 source code\"><code>ByteArrayOutputStream.write(byte[], int, int)</code> in JDK6</a> shows the (very standard) strategy it uses.</p><div class=\"wp_syntax\"><table><tr><td class=\"line_numbers\"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre></td><td class=\"code\"><pre class=\"java\" style=\"font-family:monospace;\"><span style=\"color: #000000; font-weight: bold;\">public</span><span style=\"color: #000000; font-weight: bold;\">synchronized</span><span style=\"color: #000066; font-weight: bold;\">void</span> write<span style=\"color: #009900;\">&#40;</span><span style=\"color: #000066; font-weight: bold;\">byte</span> b<span style=\"color: #009900;\">&#91;</span><span style=\"color: #009900;\">&#93;</span>, <span style=\"color: #000066; font-weight: bold;\">int</span> off, <span style=\"color: #000066; font-weight: bold;\">int</span> len<span style=\"color: #009900;\">&#41;</span><span style=\"color: #009900;\">&#123;</span><span style=\"color: #000000; font-weight: bold;\">if</span><span style=\"color: #009900;\">&#40;</span><span style=\"color: #009900;\">&#40;</span>off <span style=\"color: #339933;\">&lt;</span><span style=\"color: #cc66cc;\">0</span><span style=\"color: #009900;\">&#41;</span><span style=\"color: #339933;\">||</span><span style=\"color: #009900;\">&#40;</span>off <span style=\"color: #339933;\">&gt;</span> b.<span style=\"color: #006633;\">length</span><span style=\"color: #009900;\">&#41;</span><span style=\"color: #339933;\">||</span><span style=\"color: #009900;\">&#40;</span>len <span style=\"color: #339933;\">&lt;</span><span style=\"color: #cc66cc;\">0</span><span style=\"color: #009900;\">&#41;</span><span style=\"color: #339933;\">||</span><span style=\"color: #009900;\">&#40;</span><span style=\"color: #009900;\">&#40;</span>off <span style=\"color: #339933;\">+</span> len<span style=\"color: #009900;\">&#41;</span><span style=\"color: #339933;\">&gt;</span> b.<span style=\"color: #006633;\">length</span><span style=\"color: #009900;\">&#41;</span><span style=\"color: #339933;\">||</span><span style=\"color: #009900;\">&#40;</span><span style=\"color: #009900;\">&#40;</span>off <span style=\"color: #339933;\">+</span> len<span style=\"color: #009900;\">&#41;</span><span style=\"color: #339933;\">&lt;</span><span style=\"color: #cc66cc;\">0</span><span style=\"color: #009900;\">&#41;</span><span style=\"color: #009900;\">&#41;</span><span style=\"color: #009900;\">&#123;</span><span style=\"color: #000000; font-weight: bold;\">throw</span><span style=\"color: #000000; font-weight: bold;\">new</span><span style=\"color: #003399;\">IndexOutOfBoundsException</span><span style=\"color: #009900;\">&#40;</span><span style=\"color: #009900;\">&#41;</span><span style=\"color: #339933;\">;</span><span style=\"color: #009900;\">&#125;</span><span style=\"color: #000000; font-weight: bold;\">else</span><span style=\"color: #000000; font-weight: bold;\">if</span><span style=\"color: #009900;\">&#40;</span>len <span style=\"color: #339933;\">==</span><span style=\"color: #cc66cc;\">0</span><span style=\"color: #009900;\">&#41;</span><span style=\"color: #009900;\">&#123;</span><span style=\"color: #000000; font-weight: bold;\">return</span><span style=\"color: #339933;\">;</span><span style=\"color: #009900;\">&#125;</span><span style=\"color: #000066; font-weight: bold;\">int</span> newcount <span style=\"color: #339933;\">=</span> count <span style=\"color: #339933;\">+</span> len<span style=\"color: #339933;\">;</span><span style=\"color: #000000; font-weight: bold;\">if</span><span style=\"color: #009900;\">&#40;</span>newcount <span style=\"color: #339933;\">&gt;</span> buf.<span style=\"color: #006633;\">length</span><span style=\"color: #009900;\">&#41;</span><span style=\"color: #009900;\">&#123;</span>
        buf <span style=\"color: #339933;\">=</span><span style=\"color: #003399;\">Arrays</span>.<span style=\"color: #006633;\">copyOf</span><span style=\"color: #009900;\">&#40;</span>buf, <span style=\"color: #003399;\">Math</span>.<span style=\"color: #006633;\">max</span><span style=\"color: #009900;\">&#40;</span>buf.<span style=\"color: #006633;\">length</span><span style=\"color: #339933;\">&lt;&lt;</span><span style=\"color: #cc66cc;\">1</span>, newcount<span style=\"color: #009900;\">&#41;</span><span style=\"color: #009900;\">&#41;</span><span style=\"color: #339933;\">;</span><span style=\"color: #009900;\">&#125;</span><span style=\"color: #003399;\">System</span>.<span style=\"color: #006633;\">arraycopy</span><span style=\"color: #009900;\">&#40;</span>b, off, buf, count, len<span style=\"color: #009900;\">&#41;</span><span style=\"color: #339933;\">;</span>
    count <span style=\"color: #339933;\">=</span> newcount<span style=\"color: #339933;\">;</span><span style=\"color: #009900;\">&#125;</span></pre></td></tr></table></div><p>The first six lines just deal with parameter validation; they can be ignored from here on. Lines 8-9 are interesting: we compute the new size of the array after the write completes, and then, if that size is larger than the current size, we need to do something to compensate.</p><p>Line 10 is where that compensation happens. <code>Arrays.copyOf()</code> creates a new array containing all the bytes from the original array, but with a larger size. The size of the new array is the maximum of twice the current length <code>(buf.length &lt;&lt; 1)</code> and the requested size of the array after the write completes (this is so that a large write that more than doubles the current size of the array can be accommodated). Performing this copy is expensive, but since the size of the array should grow exponentially, frequent copies are hopefully unlikely. C++&#8217;s vector does the same thing.</p><p>After that (lines 12-13) we copy in the argument, and update the tracked number of bytes in the array.</p><p>My working hypothesis was that <code>copyOf()</code> was being called on every <code>write()</code> (since the matched up with what the profiler was telling us). The source code tells us the only way that can happen is if <code>newcount</code> is always larger than <code>buf.length</code>. This leads to two possibilities: <code>newcount</code> is getting large quickly, or <code>buf.length</code> is getting large slowly. The former seems unlikely &#8211; Thrift serialisation works by writing many small byte arrays &#8211; so to support my hypothesis, <code>buf.length</code> had to be growing slowly so that the <code>copyOf()</code> branch was being taken much more frequently than we expected.</p><p>A session with <a href=\"http://docs.oracle.com/javase/7/docs/technotes/tools/windows/jdb.html\" title=\"JDB, the Java Debugger\">JDB</a> (a terrible, terrible debugger) confirmed this. During the slow serialisation period, the size of the array increased on every write only by the amount required to contain the write in progress. On every write of say 2 bytes, the array size would increase by exactly those 2 bytes and a copy would be taken. The array itself was about 1GB in size, so the copy was really expensive.</p><p>This leads us to the bug. The size of the array is determined by <code>Math.max(buf.length &lt;&lt; 1, newcount)</code>. Ordinarily, <code>buf.length &lt;&lt; 1</code> returns double<code> buf.length</code>, which would always be much larger than <code>newcount</code> for a 2 byte write. Why was it not?</p><p>The problem is that for all integers larger than <code>Integer.MAX_INTEGER / 2</code>, shifting left by one place causes overflow, setting the sign bit. The result is a <em>negative</em> integer, which is always less than newcount. So for all byte arrays  larger than 1073741824 bytes (i.e. one GB), <strong>any write will cause the array to resize</strong>, and only to exactly the size required.</p><p>You could argue that this is by design for the following reason: the maximum size of any array in Java is <code>Integer.MAX_INTEGER</code> (minus a few bytes for preamble). Any array larger than <code>Integer.MAX_INTEGER / 2</code> bytes long would become larger than that limit when doubling in size. However, the source for <code>ByteArrayOutputStream.write()</code> could handle this case by setting the new length to <code>Integer.MAX_INTEGER</code> if <code>buf.length > Integer.MAX_INTEGER / 2</code> to give the array the maximum chance to grow with few copies.</p><p>The true fix is for us to cut down the size of the object we want to marshal, or to come up with some less expensive way of doing so (we could use a different <code>TSerializer</code> implementation, for example). Still, it&#8217;s an unfortunate degradation an a fairly commonly used class, even if there are other, better ways of achieving the same thing.</p><h3>Postscript</h3><p>In fact, <a href=\"http://grepcode.com/file/repository.grepcode.com/java/root/jdk/openjdk/7-b147/java/io/ByteArrayOutputStream.java#ByteArrayOutputStream.write%28byte%5B%5D%2Cint%2Cint%29\" title=\"ByteArrayOutputStream JDK7 source code\">JDK7 &#8216;fixed&#8217; the issue by correctly dealing with overflow</a>, but if the resulting doubled array-length was larger than <code>Integer.MAX_INTEGER</code>, an exception is thrown. You can check by running this code on both JDK6 and JDK7:</p><div class=\"wp_syntax\"><table><tr><td class=\"line_numbers\"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre></td><td class=\"code\"><pre class=\"java\" style=\"font-family:monospace;\"><span style=\"color: #000000; font-weight: bold;\">import</span><span style=\"color: #006699;\">java.io.ByteArrayOutputStream</span><span style=\"color: #339933;\">;</span>
&nbsp;
<span style=\"color: #000000; font-weight: bold;\">public</span><span style=\"color: #000000; font-weight: bold;\">class</span> TestByteArray <span style=\"color: #009900;\">&#123;</span>
&nbsp;
  <span style=\"color: #000000; font-weight: bold;\">static</span><span style=\"color: #000066; font-weight: bold;\">byte</span><span style=\"color: #009900;\">&#91;</span><span style=\"color: #009900;\">&#93;</span> chunk <span style=\"color: #339933;\">=</span><span style=\"color: #000000; font-weight: bold;\">new</span><span style=\"color: #000066; font-weight: bold;\">byte</span><span style=\"color: #009900;\">&#91;</span><span style=\"color: #cc66cc;\">1024</span><span style=\"color: #339933;\">*</span><span style=\"color: #cc66cc;\">1024</span><span style=\"color: #009900;\">&#93;</span><span style=\"color: #339933;\">;</span><span style=\"color: #000000; font-weight: bold;\">public</span><span style=\"color: #000000; font-weight: bold;\">static</span><span style=\"color: #000066; font-weight: bold;\">void</span> main<span style=\"color: #009900;\">&#40;</span><span style=\"color: #003399;\">String</span><span style=\"color: #009900;\">&#91;</span><span style=\"color: #009900;\">&#93;</span> args<span style=\"color: #009900;\">&#41;</span><span style=\"color: #009900;\">&#123;</span><span style=\"color: #003399;\">ByteArrayOutputStream</span> baos <span style=\"color: #339933;\">=</span><span style=\"color: #000000; font-weight: bold;\">new</span><span style=\"color: #003399;\">ByteArrayOutputStream</span><span style=\"color: #009900;\">&#40;</span><span style=\"color: #009900;\">&#41;</span><span style=\"color: #339933;\">;</span><span style=\"color: #000066; font-weight: bold;\">int</span> numChunks <span style=\"color: #339933;\">=</span><span style=\"color: #cc66cc;\">2</span><span style=\"color: #339933;\">*</span><span style=\"color: #cc66cc;\">1024</span><span style=\"color: #339933;\">*</span><span style=\"color: #cc66cc;\">1024</span><span style=\"color: #339933;\">;</span><span style=\"color: #000000; font-weight: bold;\">for</span><span style=\"color: #009900;\">&#40;</span><span style=\"color: #000066; font-weight: bold;\">int</span>  i <span style=\"color: #339933;\">=</span><span style=\"color: #cc66cc;\">0</span><span style=\"color: #339933;\">;</span> i <span style=\"color: #339933;\">&lt;</span> numChunks<span style=\"color: #339933;\">;</span><span style=\"color: #339933;\">++</span>i<span style=\"color: #009900;\">&#41;</span><span style=\"color: #009900;\">&#123;</span><span style=\"color: #000066; font-weight: bold;\">long</span> start <span style=\"color: #339933;\">=</span><span style=\"color: #003399;\">System</span>.<span style=\"color: #006633;\">currentTimeMillis</span><span style=\"color: #009900;\">&#40;</span><span style=\"color: #009900;\">&#41;</span><span style=\"color: #339933;\">;</span>
      baos.<span style=\"color: #006633;\">write</span><span style=\"color: #009900;\">&#40;</span>chunk, <span style=\"color: #cc66cc;\">0</span>, chunk.<span style=\"color: #006633;\">length</span><span style=\"color: #009900;\">&#41;</span><span style=\"color: #339933;\">;</span><span style=\"color: #000066; font-weight: bold;\">long</span> end <span style=\"color: #339933;\">=</span><span style=\"color: #003399;\">System</span>.<span style=\"color: #006633;\">currentTimeMillis</span><span style=\"color: #009900;\">&#40;</span><span style=\"color: #009900;\">&#41;</span><span style=\"color: #339933;\">;</span><span style=\"color: #003399;\">System</span>.<span style=\"color: #006633;\">out</span>.<span style=\"color: #006633;\">println</span><span style=\"color: #009900;\">&#40;</span><span style=\"color: #0000ff;\">&quot;Chunk &quot;</span><span style=\"color: #339933;\">+</span> i <span style=\"color: #339933;\">+</span><span style=\"color: #0000ff;\">&quot; of &quot;</span><span style=\"color: #339933;\">+</span> numChunks <span style=\"color: #339933;\">+</span><span style=\"color: #0000ff;\">&quot; took: &quot;</span><span style=\"color: #339933;\">+</span><span style=\"color: #009900;\">&#40;</span><span style=\"color: #009900;\">&#40;</span>end <span style=\"color: #339933;\">-</span> start<span style=\"color: #009900;\">&#41;</span><span style=\"color: #339933;\">/</span><span style=\"color: #cc66cc;\">1000.0</span><span style=\"color: #009900;\">&#41;</span><span style=\"color: #339933;\">+</span><span style=\"color: #0000ff;\">&quot;s, total written: &quot;</span><span style=\"color: #339933;\">+</span><span style=\"color: #009900;\">&#40;</span>i <span style=\"color: #339933;\">*</span> chunk.<span style=\"color: #006633;\">length</span><span style=\"color: #009900;\">&#41;</span><span style=\"color: #339933;\">+</span><span style=\"color: #0000ff;\">&quot; bytes&quot;</span><span style=\"color: #009900;\">&#41;</span><span style=\"color: #339933;\">;</span><span style=\"color: #009900;\">&#125;</span><span style=\"color: #009900;\">&#125;</span><span style=\"color: #009900;\">&#125;</span></pre></td></tr></table></div><p>On JDK6:</p><div class=\"wp_syntax\"><table><tr><td class=\"code\"><pre class=\"text\" style=\"font-family:monospace;\">...
Chunk 1015 of 2097152 took: 0.0010s, total written: 1064304640 bytes
Chunk 1016 of 2097152 took: 0.0s, total written: 1065353216 bytes
Chunk 1017 of 2097152 took: 0.0010s, total written: 1066401792 bytes
Chunk 1018 of 2097152 took: 0.0s, total written: 1067450368 bytes
Chunk 1019 of 2097152 took: 0.0s, total written: 1068498944 bytes
Chunk 1020 of 2097152 took: 0.0010s, total written: 1069547520 bytes
Chunk 1021 of 2097152 took: 0.0s, total written: 1070596096 bytes
Chunk 1022 of 2097152 took: 0.0s, total written: 1071644672 bytes
Chunk 1023 of 2097152 took: 0.0010s, total written: 1072693248 bytes
Chunk 1024 of 2097152 took: 1.163s, total written: 1073741824 bytes &lt;-- &gt;1s per write!
Chunk 1025 of 2097152 took: 0.979s, total written: 1074790400 bytes
Chunk 1026 of 2097152 took: 0.948s, total written: 1075838976 bytes
Chunk 1027 of 2097152 took: 1.053s, total written: 1076887552 bytes
Chunk 1028 of 2097152 took: 1.033s, total written: 1077936128 bytes
Chunk 1029 of 2097152 took: 1.123s, total written: 1078984704 bytes
Chunk 1030 of 2097152 took: 0.723s, total written: 1080033280 bytes
Chunk 1031 of 2097152 took: 0.603s, total written: 1081081856 bytes
...</pre></td></tr></table></div><p>On JDK7:</p><div class=\"wp_syntax\"><table><tr><td class=\"code\"><pre class=\"text\" style=\"font-family:monospace;\">...
Chunk 1015 of 2097152 took: 0.0s, total written: 1064304640 bytes
Chunk 1016 of 2097152 took: 0.0s, total written: 1065353216 bytes
Chunk 1017 of 2097152 took: 0.0s, total written: 1066401792 bytes
Chunk 1018 of 2097152 took: 0.0s, total written: 1067450368 bytes
Chunk 1019 of 2097152 took: 0.0s, total written: 1068498944 bytes
Chunk 1020 of 2097152 took: 0.0s, total written: 1069547520 bytes
Chunk 1021 of 2097152 took: 0.001s, total written: 1070596096 bytes
Chunk 1022 of 2097152 took: 0.0s, total written: 1071644672 bytes
Chunk 1023 of 2097152 took: 0.001s, total written: 1072693248 bytes
Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Requested array size exceeds VM limit
        at java.util.Arrays.copyOf(Arrays.java:2271)
        at java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:113)
        at java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)
        at java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:140)
        at TestByteArray.main(TestByteArray.java:11)</pre></td></tr></table></div>

") (wfw:commentRss nil "http://the-paper-trail.org/blog/535/feed/") (slash:comments nil "0")) (item nil (title nil "On Raft, briefly") (link nil "http://the-paper-trail.org/blog/on-raft-briefly/") (comments nil "http://the-paper-trail.org/blog/on-raft-briefly/#comments") (pubDate nil "Thu, 31 Oct 2013 19:03:51 +0000") (dc:creator nil "Henry") (category nil "Uncategorized") (guid ((isPermaLink . "false")) "http://the-paper-trail.org/blog/?p=528") (description nil "Raft is a new-ish consensus implementation whose great benefit, to my mind it, is its applicability for real systems. We briefly discussed it internally at Cloudera, and I thought I&#8217;d share what I contributed, below. There&#8217;s an underlying theme here regarding the role of distributed systems research in practitioners&#8217; daily work, and how the act [&#8230;]") (content:encoded nil "<p><a href=\"https://ramcloud.stanford.edu/wiki/download/attachments/11370504/raft.pdf\">Raft</a> is a new-ish consensus implementation whose great benefit, to my mind it, is its applicability for real systems. We briefly discussed it internally at Cloudera, and I thought I&#8217;d share what I contributed, below. There&#8217;s an underlying theme here regarding the role of distributed systems research in practitioners&#8217; daily work, and how the act of building a distributed system has not yet been sufficiently well commoditised to render a familiarity with the original research unnecessary. I think I&#8217;d argue that bridging that gap further is necessary: no matter how much fun it is to read all these papers, it shouldn&#8217;t be a pre-requisite to being successful in implementing a distributed system. I have more to write on this.</p><blockquote>&#8220;The trouble with Paxos is that it&#8217;s &#8216;only&#8217; a consensus algorithm; a theoretical achievement but not one necessarily suited to building practical systems. Remember that the demonstration that a correct, message-optimal protocol even existed was the main contribution. To that end, a lot of practical considerations were left by the wayside. Leader election is an exercise for the reader (since Paxos is robust to bad implementations where there are several leaders, it doesn&#8217;t matter what election scheme is used). Paxos is not concerned with &#8216;logs&#8217; at all; that it can be used to build replicated-state machines with durable logs is a corollary, not the main theorem. 

Raft fills in a ton of these gaps, and more power to them for doing so. The leader election algorithm is set in stone. There are additional constraints to ensure that updates are seen and processed in hole-free order (Paxos doesn&#8217;t guarantee this), which is exactly what you want from a distributed log. Raft also specifies a view-change algorithm, which Paxos does not, but VS replication does. The huge effort required to get <a href=\"https://issues.apache.org/jira/browse/ZOOKEEPER-107\">ZOOKEEPER-107</a> committed shows how hard this is to retrofit onto an existing system.

So: there&#8217;s a tendency to conflate &#8216;distributed replicated <blah> with strong consistency properties&#8217; with &#8216;consensus algorithm&#8217;. Consensus shows you can agree on a single value, multi-Paxos shows you can agree on a bunch of them, but neither give you a complete system for a replicated log which is actually what most of our distributed systems want to interact with.&#8221;</blockquote>
") (wfw:commentRss nil "http://the-paper-trail.org/blog/on-raft-briefly/feed/") (slash:comments nil "1")) (item nil (title nil "Some miscellanea") (link nil "http://the-paper-trail.org/blog/some-miscellanea/") (comments nil "http://the-paper-trail.org/blog/some-miscellanea/#comments") (pubDate nil "Mon, 20 May 2013 05:39:57 +0000") (dc:creator nil "Henry") (category nil "Distributed systems") (category nil "link") (category nil "Note") (guid ((isPermaLink . "false")) "http://the-paper-trail.org/blog/?p=510") (description nil "CAP FAQ I wrote an FAQ on The CAP Theorem. The aim is to definitively settle some of the common misconceptions around CAP so as to help prevent its invocation in useless places. If someone says they got around CAP, refer them to the FAQ. It should be a pretty simple introduction to the theorem [&#8230;]") (content:encoded nil "<h4>CAP FAQ</h4><p>I wrote an FAQ on <a href=\"http://henryr.github.io/cap-faq/\">The CAP Theorem</a></strong>. The aim is to definitively settle some of the common misconceptions around CAP so as to help prevent its invocation in useless places. If someone says they got around CAP, refer them to the FAQ. It should be a pretty simple introduction to the theorem as well. I think that CAP itself is a pretty uninteresting result, but it does at least shine a light on tradeoffs implicit in distributed systems. I have a couple of residual thoughts about failures rather than partitions that I might write up at some point in the future, but otherwise I hope the FAQ helps move the conversation on.</p><h4>Impala and aggregation trees</h4><p>I also wrote a quick answer on <a href=\"http://qr.ae/pyS1G\">Quora</a> about Impala&#8217;s execution trees, and how deeper trees help do aggregation more effectively. There&#8217;s a lot more of interest to write about planning, partitioning and scheduling queries.</p><h4>Not so HotOS</h4><p>Matt Welsh talks about <a href=\"http://matt-welsh.blogspot.com/2013/05/what-i-wish-systems-researchers-would.html\">what he wishes systems researchers would work on</a>. I partially agree: there are few papers in the <a href=\"https://www.usenix.org/conference/hotos13/tech-schedule/technical-sessions\">HotOS 2013 program</a> that pass the &#8220;if this were true, a lot of our assumptions would be wrong&#8221; test. I don&#8217;t think that IO is an unworthy topic however, but the main problem with improving IO interfaces is inertia rather than want for better ideas. I hope that SSDs and / or flash-as-RAM will be forcing functions here. Otherwise his big topics are all worthy research challenges, but I have always seen HotOS as a venue for new ideas, not new topics &#8211; despite its name. If it really were intended to be a venue for the fashionable areas of study in systems it would have much less potential value.</p><h4>Building distributed systems</h4><p>Andy Gross (Basho VP Eng) gave a <a href=\"https://speakerdeck.com/argv0/lessons-learned-and-questions-raised-from-building-distributed-systems\">closing keynote</a> calling for more reusable primitives in distributed systems. I couldn&#8217;t agree more (and have been gently complaining about this for years to anyone who would listen), although I think doing this right is not straightforward and requires a lot of careful thought about RPC mechanisms, libraries vs. services and much more. I have some thoughts on this that I want to wrap up in a blog post sometime soon.</p><h4>Highly available transactions</h4><p>Peter Bailis, a Berkeley PhD candidate, has some solid work on <a href=\"http://www.bailis.org/blog/when-is-acid-acid-rarely/\">Highly Available Transactions</a>, based on exploring the space of consistency models available to databases and finding that there are demonstrably useful consistency guarantees that can be made when availability is kept high. This is the right way to move on from all the CAP arguments &#8211; given that we are stuck with certain impossibility results, let&#8217;s map out the vast terrain that we <i>can</i> conquer.</p>
") (wfw:commentRss nil "http://the-paper-trail.org/blog/some-miscellanea/feed/") (slash:comments nil "0")) (item nil (title nil "Columnar Storage") (link nil "http://the-paper-trail.org/blog/columnar-storage/") (comments nil "http://the-paper-trail.org/blog/columnar-storage/#comments") (pubDate nil "Thu, 31 Jan 2013 03:46:31 +0000") (dc:creator nil "Henry") (category nil "Databases") (guid ((isPermaLink . "false")) "http://the-paper-trail.org/blog/?p=452") (description nil "You&#8217;re going to hear a lot about columnar storage formats in the next few months, as a variety of distributed execution engines are beginning to consider them for their IO efficiency, and the optimisations that they open up for query execution. In this post, I&#8217;ll explain why we care so much about IO efficiency and [&#8230;]") (content:encoded nil "<p><em>You&#8217;re going to hear a lot about columnar storage formats in the next few months, as a variety of distributed execution engines are beginning to consider them for their IO efficiency, and the optimisations that they open up for query execution. In this post, I&#8217;ll explain why we care so much about IO efficiency and show how columnar storage &#8211; which is a simple idea &#8211; can drastically improve performance for certain workloads.</p><p>Caveat: This is a personal, general research summary post, and as usual doesn&#8217;t neccessarily reflect our thinking at Cloudera about columnar storage.</em></p><p>Disks are still the major bottleneck in query execution over large datasets. Even a machine with twelve disks running in parallel (for an aggregate bandwidth of north of 1GB/s) can&#8217;t keep all the cores busy; running a query against memory-cached data can get tens of GB/s of throughput. IO bandwidth matters. Therefore, the best thing an engineer can do to improve the performance of disk-based query engines (like RDBMs and Impala) usually is to improve the performance of reading bytes from disk. This can mean decreasing the latency (for small queries where the time to find the data to read might dominate), but most usually this means improving the effective throughput of reads from disk.</p><p>The traditional way to improve disk bandwidth has been to wait, and allow disks to get faster. However, disks are not getting faster very quickly (having settled at roughly 100 MB/s, with ~12 disks per server), and SSDs can&#8217;t yet achieve the storage density to be directly competitive with HDDs on a per-server basis.</p><p>The other way to improve disk performance is to maximise the ratio of &#8216;useful&#8217; bytes read to total bytes read. The idea is not to read more data than is absolutely necessary to serve a query, so the useful bandwidth realised is increased without actually improving the performance of the IO subsystem. Enter <em>columnar storage</em>, a principle for file format design that aims to do exactly that for query engines that deal with record-based data.</p><p><span id=\"more-452\"></span></p><p>&lt;</p><p>h2>Columns vs. Rows</h3></p><p>Traditional database file format store data in rows, where each row is comprised of a contiguous collection of column values. On disk, that looks roughly like the following:</p><p><a href=\"http://the-paper-trail.org/blog/wp-content/uploads/2013/01/row-major-formats.png\"><img src=\"http://the-paper-trail.org/blog/wp-content/uploads/2013/01/row-major-formats.png\" alt=\"Row-major On-disk Layout\" width=\"588\" height=\"267\" class=\"aligncenter size-full wp-image-482\" /></a></p><p>This <em>row-major</em> layout usually has a header for each row that describes, for example, which columns in the row are NULL. Each column value is then stored contiguously after the header, followed by another row with its own header, and so on.</p><p>Both HDDs and SSDs are at their most efficient when reading data sequentially from disk (for HDDs the benefits are particularly pronounced). In fact, even a read of a few bytes usually brings in an entire block of 4096 bytes from disk, because it is effectively the same cost to read (and the operating system usually deals with data in 4k page-sized chunks). For row-major formats it&#8217;s therefore most efficient to read entire rows at a time.</p><p>Queries that do full table-scans &#8211; i.e. those that don&#8217;t take advantage of any kind of indexing and need to visit every row &#8211; are common in analytical workloads; with row-major formats a full scan of a table will read every single byte of the table from disk. For certain queries, this is appropriate. Trivially, <tt>SELECT * FROM table</tt> requires returning every single column of every single row in the table, and so the IO costs for executing that query on a row-major format are a single-seek and a single large contiguous read (although that is likely to be broken up for pipelining purposes). The read is unavoidable, as is the single seek; therefore row-major formats allow for optimal IO usage. More generally, <tt>SELECT &lt;col_set&gt; FROM table WHERE &lt;predicate_set&gt;</tt> will be relatively efficient for row-major formats if either a) evaluating the <tt>predicate_set</tt> requires reading a large subset of the set of columns or b) <tt>col_set</tt> is a large subset of the set of columns (i.e. the <em>projectivity</em> is high) and the set of rows returned by the evaluation of the predicates over the table is a large proportion of the total set of rows (i.e. the <em>selectivity</em> is high). More simply, a query is going to be efficient if it requires reading most of the columns of most of the rows. In these cases, row-major formats allow the query execution engine to achieve good IO efficiency.</p><p>However, there is a general consensus that these <tt>SELECT *</tt> kinds of queries are not  representative of typical analytical workloads; instead either a large number of columns are not projected, or they are projected only for a small subset of rows where only a few columns are required to decide which rows to return. Coupled with a general trend towards very wide tables with high column counts, the total number of bytes that are required to satisfy a query are often a relatively small fraction of the size on disk of the target table. In these cases, row-major formats often are quite wasteful in the amount of IO they require to execute a query.</p><p>Instead of a format that makes it efficient to read entire rows, it&#8217;s advantageous for analytical workloads to make it efficient to read entire <em>columns</em> at once. Based on our understanding of what makes disks efficient, we can see that the obvious approach is to store columns values densely and contiguously on disk. This is the basic idea behind columnar file formats. The following diagram shows what this looks like on disk:</p><p><a href=\"http://the-paper-trail.org/blog/wp-content/uploads/2013/01/column-major-formats.png\"><img src=\"http://the-paper-trail.org/blog/wp-content/uploads/2013/01/column-major-formats.png\" alt=\"Column-Major On-disk Layout\" width=\"588\" height=\"474\" class=\"aligncenter size-full wp-image-481\" /></a></p><p>A row is split across several column blocks, which may even be separate files on disk. Reading an entire column now requires a single seek plus a large contiguous read, but the read length is much less than for extracting a single column from a row-major format. In this figure we have organised the columns so that they are all ordered in the same way; later we&#8217;ll see how we can relax that restriction and use different orderings to make different queries more efficient.</p><h2>Query Execution</h2><p>The diagram below shows what a simple query plan for <tt>SELECT col_b FROM table WHERE col_a > 5</tt> might look like for a query engine reading from a traditional row-major file format. A scan node reads every row in turn from disk, and streams the rows to a predicate evaluation node, which looks at the value of <tt>col_a</tt> in each row. Those rows that pass the predicate are sent to a projection node which constructs result tuples containing <tt>col_b</tt>.</p><p><a href=\"http://the-paper-trail.org/blog/wp-content/uploads/2013/01/row-query-plan.png\"><img src=\"http://the-paper-trail.org/blog/wp-content/uploads/2013/01/row-query-plan.png\" alt=\"Row Query Plan\" width=\"549\" height=\"137\" class=\"aligncenter size-full wp-image-487\" /></a></p><p>Compare that to the query plan below, for a query engine reading from columnar storage. Each column referenced in the query is read independently. The predicate is evaluated over <tt>col_a</tt> to produce a list of matching row IDs. <tt>col_b</tt> is then scanned with respect to that list of IDs, and each matching value is returned as a query result. This query plan performs two IO seeks (to find the beginning of both column files), instead of one, and issues two consecutive reads rather than one large read. The pattern of using IDs for each column value is very common to make reconstructing rows easier; usually columns are all sorted on the same key so the Nth value of <tt>col_a</tt> belongs to the same row as the Nth value of <tt>col_b</tt>.</p><p><a href=\"http://the-paper-trail.org/blog/wp-content/uploads/2013/01/columnar-query-plan.png\"><img src=\"http://the-paper-trail.org/blog/wp-content/uploads/2013/01/columnar-query-plan.png\" alt=\"Columnar Query Plan\" width=\"497\" height=\"137\" class=\"aligncenter size-full wp-image-478\" /></a></p><p>The extra IO cost for the row-format query is therefore the time it takes to read all those extra columns. Let&#8217;s assume the table is 10 columns wide, ten million rows long and each value is 4 bytes, which are all conservative estimates. Then there is an extra 8 * 1M * 4 bytes, or 32MB of extra data read, which is ~3.20s on a query that would likely otherwise take 800ms; an overhead of 300%. When disks are less performant, or column widths wider, the effect becomes exaggerated.</p><p>This, then, is the basic idea of columnar storage: we recognise that analytical workloads rarely require full scans of all table data, but do often require full scans of a small subset of the columns, and so we arrange to make column scans cheap at the expense of extra cost reading individual rows.</p><h2>The Cost of Columnar</h2><p>Is this a free lunch? Should every analytical database go out and change every file format to be column-major? Obviously the story is more complicated than that. There are some query archetypes that suffer when data is stored in a columnar format.</p><p>The obvious drawback is that it is expensive to reassemble a row, since the separate values that comprise it are spread far across the disk. Every column included in a projection implies an extra disk seek, and this can add up when the projectivity of a query is high. Therefore, for highly projective queries, row-major formats can be more efficient (and therefore columnar formats are not strictly better than row-major storage even from a pure IO perspective).</p><p>There are more subtle repurcussions of each row being scattered across the disk. When a row-major format is read into memory, and ultimately into CPU cache, it is in a format that permits cheap reference to multiple columns at a time. Row-major formats have good in-memory spatial locality, and there are common operations that benefit enormously from this.</p><p>For example, a query that selects the sum of two columns can sometimes be executed (once the data is in memory) faster on row-major formats, since the columns are almost always in the same cache line for each row. Columnar representations are less well suited; each column must be brought into memory at the same time and moved through in lockstep (yet this is still not cache efficient if each column is ordered differently), or the initial column must be scanned, each value buffered and then the second column scanned separately to complete the half-finished output tuple.</p><p>The same general problem arises when preparing each tuple to write out as a result of (non-aggregating) query. Selecting several columns at once requires &#8216;row reconstruction&#8217; at some point in the query lifecycle. Deciding when to do this is a complicated process, and (as we shall see) the literature has not yet developed a good rule of thumb. Many databases are row-major internally, and therefore a columnar format is transposed into a row-major one relatively early in the scanning process. As described above, this can require buffering half-constructed tuples in memory. For this reason, columnar formats are often partiioned into &#8216;row-groups&#8217;; each column chunk N contains rows (K*N) to ((K+1) * N). This reduces the amount of buffering required, at the cost of a few more disk seeks.</p><h2>Further Aspects of Columnar Storage</h2><h4>Fully column-oriented execution engines</h4><p><em>Relevant papers:
  <a href=\"http://people.csail.mit.edu/tdanford/6830papers/stonebraker-cstore.pdf\">C-Store: A Column-oriented DBMS</a><a href=\"http://vldb.org/pvldb/vol5/p1790_andrewlamb_vldb2012.pdf\">The Vertica Analytic Database: C-Store 7 Years Later</a><a href=\"http://db.lcs.mit.edu/projects/cstore/abadiicde2007.pdf\">Materialization Strategies in a Column-Oriented DBMS</a><a href=\"http://db.csail.mit.edu/projects/cstore/VLDB06.pdf\">Performance Tradeoffs in Read-Optimized Databases</a><a href=\"http://db.csail.mit.edu/projects/cstore/abadi-sigmod08.pdf\">Column-Stores vs. Row-Stores: How Different Are They Really?</a></em>
In this post, I&#8217;ve talked mostly about the benefits of columnar storage for scans &#8211; query operators that read data from disk, but whose ultimate output is a batch of rows for the rest of the query plan to operate on. In fact, columnar data can be integrated into pretty much every operator in a query execution engine. C-Store, the research project precursor to Vertica, explored a lot of the consequences of keeping data in columns until later on in the query plan. Eventually, of course, the columns have to be converted to rows, since the user expects a result in row-major format. The choice of when to perform this conversion is called <em>late or early materialisation</em>; viewed this way column-stores and row-stores can be considered two points on a spectrum of early to late materialisation strategies. Materialisation is studied in detail in the materialisation strategies paper above. Their conclusions are that the correct time to construct a tuple depends on the query plan (two broad patterns are considered: pipelining and parallel scans) and the query selectivity. Unfortunately, supporting both strategies would involve significant implementation cost &#8211; each operator would have to support two interfaces, and two parallel execution engines would effectively be frankensteined together. In general, late materialisation can lead to significant advantages: for example, by delaying the cost of reconstructing a tuple, it can be avoided if the tuple is ultimately filtered out by a predicate.</p><p>The difference between row-based and columnar execution engines is studied in the <em>Performance Tradeoffs&#8230;</em> and <em>Column-Stores vs. Row-Stores&#8230;</em> papers. The former takes a detailed look at when each strategy is superior &#8211; coming out in favour mostly of column-stores, but only with simple queries and basic query plans. The latter tries to implement common column-store optimisations in a traditional row-store, without changing the code. This means a number of increasingly brittle hacks to emulate columnar storage.</p><h4>Compression</h4><p><em>Relevant papers: 
  <a href=\"http://db.lcs.mit.edu/projects/cstore/abadisigmod06.pdf\">Integrating Compression and Execution on Column-Oriented Database Systems</a></em></p><p>A column of values drawn from the same set (like item price, say) is likely to be highly amenable to compression since the values contained are similar, and often identical. Compressing a column has at least two significant advantages on IO cost: less space is required on disk, and less IO required to bring a column into memory (at the cost of some CPU to decompress which is usually going spare). Some compression formats &#8211; for example run-length encoding &#8211; allow execution engines to operate on the compressed data directly, filtering large chunks at a time without first decompressing them. This is another advantage of late materialisation &#8211; by keeping the data compressed until late in the query plan, these optimisations become available to many operators, not just the scan.</p><h4>Hybrid approaches</h4><p><em>Relevant papers:
  <a href=\"http://www.vldb.org/conf/2001/P169.pdf\">Weaving Relations for Cache Performance</a></em>
Since neither row-major nor column-major is strictly superior on every workload, it&#8217;s natural that some research has been done into hybrid approaches that can achieve the best of both worlds. The most commonly known approach is PAX &#8211; Partition Attributes Across &#8211; which splits the table into page-sized groups of rows, and inside those groups formats the rows in column-major order. This is the same approach as the row-groups used to prevent excessive buffering described earlier, but this is not the aim of PAX; with PAX the original intention was to make CPU processing more efficient by having individual columns available contiguously to perform filtering, but also to have all the columns for a particular row nearby inside a group to make tuple reconstruction cheaper. The result of this approach is that IO costs don&#8217;t go down (because each row-group is only a page long, and is therefore read in its entirety), but reconstruction and filtering is cheaper than for true columnar formats.</p>
") (wfw:commentRss nil "http://the-paper-trail.org/blog/columnar-storage/feed/") (slash:comments nil "5")) (item nil (title nil "Cloudera Impala") (link nil "http://the-paper-trail.org/blog/cloudera-impala/") (comments nil "http://the-paper-trail.org/blog/cloudera-impala/#comments") (pubDate nil "Mon, 05 Nov 2012 02:12:12 +0000") (dc:creator nil "Henry") (category nil "Cloudera Impala") (category nil "Distributed systems") (guid ((isPermaLink . "false")) "http://the-paper-trail.org/blog/?p=438") (description nil "If you have a strong background in either databases or distributed systems, and fancy working on such an exciting technology, send me a note! It&#8217;s great to finally be able to say something about what I&#8217;ve been working at Cloudera for nearly a year. At StrataConf / Hadoop World in New York a couple of [&#8230;]") (content:encoded nil "<p><em>If you have a strong background in either databases or distributed systems, and fancy working on such an exciting technology, <a href=\"mailto:henry@cloudera.com\">send me a note!</a></em></p><p>It&#8217;s great to finally be able to say something about what I&#8217;ve been working at <a href=\"http://www.cloudera.com\">Cloudera</a> for nearly a year. At StrataConf / Hadoop World in New York a couple of weeks ago we announced <a href=\"http://blog.cloudera.com/blog/2012/10/cloudera-impala-real-time-queries-in-apache-hadoop-for-real/\">Cloudera Impala</a>. Impala is a distributed query execution engine that understands a subset of SQL, and critically runs over HDFS and HBase as storage managers. It&#8217;s very similar in functionality to Apache Hive, but it is much, much, much (anecdotally up to 100x) faster.
<span id=\"more-438\"></span>
Why do I think this is important? (and bear in mind I&#8217;m speaking for myself, not Cloudera here). The way I view what we do at Cloudera is that we&#8217;re really participating in a revolution in data storage. The great contribution of the <a href=\"http://research.google.com/archive/gfs.html\">Google</a><a href=\"http://research.google.com/archive/mapreduce.html\">papers</a> was the application of commodity hardware to enterprise problems. Storing your data reliably on commodity servers with relatively cheap hard disks is enabled by the extreme cheapness of storage density (which means that replicating three times for fault-tolerance is suddenly a viable design choice, for example), and this completely changes the cost / benefit equation for data storage. You can have a lot more of it, and you can have it a lot cheaper. This is where the whole &#8216;big data&#8217; idea arguably springs from &#8211; now you can store more data than ever before. What do you do with it?</p><p>Well, you analyse it. But that&#8217;s easier said than done. Traditional data analytics platforms are extremely powerful, but rely on an integrated approach &#8211; you don&#8217;t buy a couple of servers and throw a data warehouse that you downloaded on them, you buy a fully integrated solution that includes hardware and software. The hardware is tuned to the requirements of the software, and the data layout is carefully managed to get great performance on supported queries. This is a very serious platform archetype, and one that I believe will continue to be important to the market, but it&#8217;s fundamentally not configured to process data at the scale that the storage substrate now enables, because you would have to move data into the processing platform to do so, which is a very costly proposition. So typically what you do is identify an important subset of your data that requires the full analytics power to your integrated solution, and move that and only that. But that blunts the advantage of keeping all of that data in the first place &#8211; if you can only process some of it, why are you keeping all of it?</p><p>This is where Apache Hadoop originally came in. Hadoop shines for heavy-lifting batch-processing jobs that have high tolerance for latency but need to touch most bytes in your dataset. Where it doesn&#8217;t shine is for interactive analyses, where a user might be refining the analytic questions they ask iteratively. It&#8217;s useless to wait for 30 minutes just to find that you probably should have grouped by a different columns. Similarly, users of popular BI tools will want to construct reports that they can interact with. Impala is the tool for these use cases; by allowing for relatively low-latency queries over the great unwashed masses of your data you get the value of the data coupled with some of the processing power of the integrated engines. We&#8217;ve brought some of the execution engine magic of massively-parallel distributed databases to the incredibly flexible storage engine model of HDFS and HBase.</p><p>Technically, of course, this is a complete blast to work on &#8211; a large-scale distributed system that does highly non-trivial stuff at each node. Bliss.  Impala&#8217;s been the result of the great effort of a small team. That means I&#8217;ve written code in lots of different parts of the system. Our <tt>INSERT</tt> support is mostly me, as is our DDL support (we don&#8217;t do <tt>CREATE TABLE</tt> yet, but we do <tt>SHOW</tt> / <tt>DESCRIBE</tt> etc.). I also wrote the failure-detection framework that runs on both the state-store (to evict Impala backends that have failed from the current view of cluster membership) and on each Impala backend (to detect when the state-store has failed). In fact there are a ton of things that I&#8217;ve been involved with. Some of the most exciting parts of the code base are the query execution engine itself, which compiles query fragments into a highly optimised program fragment via LLVM, although the planner is also a very complex bit of software.</p><p>The source code is available <a href=\"https://github.com/cloudera/impala\">here</a>. At this point, I should acknowledge that the Github repo doesn&#8217;t build out of the box, and we haven&#8217;t yet provided instructions on how to do so. There&#8217;s no great conspiracy behind this, just the annoying consequence of the number of hours in the day being finite. We can&#8217;t post the repo exactly as we have it internally at Cloudera for a couple of reasons: we rely on internal infrastructure for some of the build steps which can&#8217;t be easily replicated externally, and some of our test suites are customer-confidential. We were rushing (as ever) to get a release out the door, and we made the decision to postpone sorting out the build for the public repo until after the launch. Since that&#8217;s&#8230; now, I&#8217;ve been spending a little time figuring out what we can do. Build systems are not my expertise, and Impala&#8217;s is a little capricious due to the extent that we mix C++ (for the execution engine) and Java code (for the planning and metastore interaction). I hope to have something that can build &#8211; without tests &#8211; by the end of next week, that is by roughly November 9th.</p><p>Otherwise we&#8217;re working on our roadmap for moving from the current beta to GA, and I have a long list of bugs and bits of polish that I&#8217;m looking forward to getting a few minutes to work on. We have some pretty exciting plans coming up, and it&#8217;s going to be great to be able to talk about them a little more publicly.</p><p>From the perspective of this blog, this means I&#8217;ve been reading a ton of interesting database papers (I know distributed systems, but I&#8217;m only just getting up to speed with all the database literature). That means a good opportunity to restart some of the paper reviews, although I&#8217;m even more likely to say something stupid on a less firm technical footing!</p><p>There&#8217;s been a whole bunch of buzz about Impala, which has been very gratifying.</p><ul><li><a href=\"http://www.quora.com/Cloudera/Does-Cloudera-Impala-have-any-drawbacks-when-compared-with-Hive\">These</a><a href=\"http://www.quora.com/Cloudera-Impala/Is-Impala-aiming-to-be-an-open-source-alternative-to-existing-MPP-solutions\">questions</a><a href=\"http://www.quora.com/Cloudera-Impala/How-does-Cloudera-Impala-compare-to-Vertica\">at</a><a href=\"http://www.quora.com/Cloudera-Impala/How-does-Cloudera-Impala-compare-to-Hadapt\">Quora</a> about how Impala compares to similar systems (including <a href=\"http://www.quora.com/Cloudera-Impala/Isnt-Cloudera-Impala-doing-the-same-job-as-Apache-Drill-incubator-project\">my answer about Apache Drill</a>)</li><li>Curt Monash has a <a href=\"http://www.dbms2.com/2012/11/01/more-on-cloudera-impala/\">writeup</a> (although he does make it sound like no query will return in under one second, which isn&#8217;t the case &#8211; query start-up latency is very important to us since that&#8217;s an area we can get a huge gain over Hive&#8217;s Hadoop implementation; in the case of a simple <tt>SELECT 1</tt> the query should return in ~100ms under ideal conditions). </li><li>Marcel Kornacker is the tech lead for Impala &#8211; really, my technical boss &#8211; and a very interesting guy. He was Joe Hellerstein&#8217;s first graduate student (I think), and recently worked at Google on F1.  Wired did a <a href=\"http://www.wired.com/wiredenterprise/2012/10/kornacker-cloudera-google/\">write-up</a> on him which is equal parts awesome and hilarious. Marcel&#8217;s bread is <em>fantastic</em> though.</li><li>Wired also did a pretty decent piece on <a href=\"http://www.wired.com/wiredenterprise/2012/10/cloudera-impala-hadoop/\">Impala</a> itself.</li><li>There&#8217;s a good <a href=\"http://blog.cloudera.com/blog/2012/10/cloudera-impala-real-time-queries-in-apache-hadoop-for-real/\">introductory blog post</a> by Justin and Marcel on the new Cloudera blog site</li><li><a href=\"http://lizclimo.tumblr.com/post/31611767071/how-to-be-cool\">Impalas make you cool, according to rap music.</a></li></ul>
") (wfw:commentRss nil "http://the-paper-trail.org/blog/cloudera-impala/feed/") (slash:comments nil "2")) (item nil (title nil "On some subtleties of Paxos") (link nil "http://the-paper-trail.org/blog/on-some-subtleties-of-paxos/") (comments nil "http://the-paper-trail.org/blog/on-some-subtleties-of-paxos/#comments") (pubDate nil "Sun, 04 Nov 2012 02:02:22 +0000") (dc:creator nil "Henry") (category nil "Distributed systems") (guid ((isPermaLink . "false")) "http://the-paper-trail.org/blog/?p=427") (description nil "There&#8217;s one particular aspect of the Paxos protocol that gives readers of this blog &#8211; and for some time, me! &#8211; some difficulty. This short post tries to clear up some confusion on a part of the protocol that is poorly explained in pretty much every major description. This is the observation that causes problems: [&#8230;]") (content:encoded nil "<p>There&#8217;s one particular aspect of the Paxos protocol that gives readers of this blog &#8211; and for some time, me! &#8211; some difficulty. This short post tries to clear up some confusion on a part of the protocol that is poorly explained in pretty much every major description. 
<span id=\"more-427\"></span>
This is the observation that causes problems: two different nodes can validly accept different proposals for the same Paxos instance. That means that we could have a situation where node <img src='http://s.wordpress.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='A' title='A' class='latex' /> has accepted a proposal <img src='http://s.wordpress.com/latex.php?latex=P%3D%28S%2C%20V%29&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='P=(S, V)' title='P=(S, V)' class='latex' />, and node <img src='http://s.wordpress.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='E' title='E' class='latex' /> has accepted a proposal <img src='http://s.wordpress.com/latex.php?latex=P%27%3D%28S%27%2C%20V%27%29&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='P&#039;=(S&#039;, V&#039;)' title='P&#039;=(S&#039;, V&#039;)' class='latex' />. We can get there very easily by having two competing proposers that interleave their prepare phases, and crash after sending an accept to one node each. On the face of it, this is a very concerning situation &#8211; how can two nodes both believe a different value has been accepted? Doesn&#8217;t this violate one of the consensus guarantees of uniformity?</p><p>The answer lies in the fact that the nodes doing the accepting are not (necessarily) the nodes that &#8216;learn&#8217; about the agreed value. Paxos calls for a distinguished category of nodes, called &#8216;learners&#8217;, which hear about acceptance events from the nodes doing the accepting. We call the latter nodes &#8216;acceptors&#8217;, and say that learners &#8216;commit&#8217; to a value once they can be sure it&#8217;s never going to change for a given Paxos instance.</p><p>But when does a learner know that a value has really been accepted? It can&#8217;t just go on the first acceptance that it receives (since as we have shown, two different acceptors can have accepted different values and may race to send their values to the learners). Instead, a learner must wait for a majority of acceptors to return the same proposal. Once <img src='http://s.wordpress.com/latex.php?latex=N%2F2%20%2B%201&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='N/2 + 1' title='N/2 + 1' class='latex' /> acceptors are in agreement, the learner can commit the value to its log, or whatever is required once consensus is reached. The rest of this post shows why this is both necessary and sufficient.</p><p>If no majority of acceptors have accepted the same value, it&#8217;s trivial to see why a learner cannot commit to a value sent by any acceptor, for the same race-based argument made earlier. A more interesting case is the following: suppose that a majority of acceptors have accepted a proposal with the same value, but with different sequence numbers (i.e. proposed by a different proposer). Can a learner commit to that value once it has learnt about all the acceptances? In the following section we show that it can.</p><h3>Conditions for learner commit</h3><p><strong>Theorem:</strong><i>Let a majority of acceptors have accepted some proposal with value <img src='http://s.wordpress.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='V' title='V' class='latex' />, and let <img src='http://s.wordpress.com/latex.php?latex=P%20%3D%20%28S%2CV%29&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='P = (S,V)' title='P = (S,V)' class='latex' /> be the proposal with the largest sequence number <img src='http://s.wordpress.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='S' title='S' class='latex' /> amongst all those acceptors. Then there is no proposal <img src='http://s.wordpress.com/latex.php?latex=P%27%20%3D%20%28S%27%2C%20V%27%29&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='P&#039; = (S&#039;, V&#039;)' title='P&#039; = (S&#039;, V&#039;)' class='latex' /> that is accepted at any node with <img src='http://s.wordpress.com/latex.php?latex=S%27%3ES&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='S&#039;&gt;S' title='S&#039;&gt;S' class='latex' /> and <img src='http://s.wordpress.com/latex.php?latex=V%27%20%5Cneq%20V&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='V&#039; \\neq V' title='V&#039; \\neq V' class='latex' />.</i></p><p><strong>Proof:</strong> We proceed in two steps. The first shows that when <img src='http://s.wordpress.com/latex.php?latex=P&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='P' title='P' class='latex' /> is accepted, there is no proposal already accepted at any node with a later sequence number. Assume that this is false, and some node has accepted <img src='http://s.wordpress.com/latex.php?latex=P%27&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='P&#039;' title='P&#039;' class='latex' />. Then a majority of acceptors must have promised to accept only proposals with sequence number <img src='http://s.wordpress.com/latex.php?latex=S%27%27%20%3E%20S%27&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='S&#039;&#039; &gt; S&#039;' title='S&#039;&#039; &gt; S&#039;' class='latex' />. Since <img src='http://s.wordpress.com/latex.php?latex=S%20%3C%20S%27&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='S &lt; S&#039;' title='S &lt; S&#039;' class='latex' />, <img src='http://s.wordpress.com/latex.php?latex=P&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='P' title='P' class='latex' /> cannot be accepted by a majority of acceptors, contradicting the assumption.</p><p>Second, we prove by a very similar argument that once <img src='http://s.wordpress.com/latex.php?latex=P&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='P' title='P' class='latex' /> has been accepted, no node will accept a proposal like <img src='http://s.wordpress.com/latex.php?latex=P%27&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='P&#039;' title='P&#039;' class='latex' />.  Again, assume this is false. Then a majority of acceptors must have sent a <tt>promise</tt> of <img src='http://s.wordpress.com/latex.php?latex=%28S%27%2C%20V%27%29&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='(S&#039;, V&#039;)' title='(S&#039;, V&#039;)' class='latex' /> in order for the proposer of <img src='http://s.wordpress.com/latex.php?latex=P%27&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='P&#039;' title='P&#039;' class='latex' /> to be sending <tt>accept</tt> messages. If so, then either that same majority should have ignored the <tt>accept</tt> message for <img src='http://s.wordpress.com/latex.php?latex=P&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='P' title='P' class='latex' /> (since <img src='http://s.wordpress.com/latex.php?latex=S%20%3C%20S%27&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='S &lt; S&#039;' title='S &lt; S&#039;' class='latex' />), or <img src='http://s.wordpress.com/latex.php?latex=V%27%20%3D%20V&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='V&#039; = V' title='V&#039; = V' class='latex' /> if the <tt>accept</tt> of <img src='http://s.wordpress.com/latex.php?latex=P&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='P' title='P' class='latex' /> happened before the proposal of <img src='http://s.wordpress.com/latex.php?latex=P%27&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='P&#039;' title='P&#039;' class='latex' /> (by the first half of this proof we know that there is no proposal with a later sequence number than <img src='http://s.wordpress.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='S' title='S' class='latex' /> already accepted, so the proposer is guaranteed to choose <img src='http://s.wordpress.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='V' title='V' class='latex' /> as the already accepted value with the largest sequence number). In either case there is a contradiction; <img src='http://s.wordpress.com/latex.php?latex=P&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='P' title='P' class='latex' /> has not been accepted or <img src='http://s.wordpress.com/latex.php?latex=V%20%3D%20V%27&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='V = V&#039;' title='V = V&#039;' class='latex' />.</p><p>What this theorem shows is that once a value has been accepted by a majority of acceptors, no proposal can change it. The sequence number might change (consider what happens if a new proposer comes along and runs another proposal over the same instance &#8211; the sequence number will increase at some acceptors, but the proposer must choose the majority value for its accept message). But since the majority-accepted value will never change, the learners can commit a value when they hear it from a majority of acceptors.</p><h3>Fault tolerance</h3><p>Now it&#8217;s instructive to think about what this means for Paxos&#8217; fault-tolerance guarantees. Imagine that a proposal was accepted at a minimal (i.e. <img src='http://s.wordpress.com/latex.php?latex=N%2F2%2B1&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='N/2+1' title='N/2+1' class='latex' /> nodes) majority of acceptors before the proposer crashed. In order for the value to be committed by a learner, every one of those acceptors must successfully send its accepted value on to the learners. So if a single node in that majority fails, that Paxos instance will not terminate for all learners. That appears to be not as fault-tolerant as we were promised.</p><p>There are several ways to interpret this fact. The first is that Paxos only guarantees that it will continue to be correct, and live, with up to <img src='http://s.wordpress.com/latex.php?latex=N%2F2%20%2B%201&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='N/2 + 1' title='N/2 + 1' class='latex' /> failures; and <i>failing to reach agreement for a single proposal does not contravene these properties</i>. It&#8217;s also true that if the proposer dies before sending any accept messages, that proposal will also never complete. However, another proposer can always come along and finish that instance of the protocol; it&#8217;s this that is no longer true if a majority of acceptors fail.</p><p>The second interpretation is that it makes sense for acceptors to also act as learners, so that they can update their values for a given Paxos instance once they realise that consensus is complete. It&#8217;s often true that learners and acceptors are the same thing in a real Paxos deployment, and the aim is usually to have as many acceptors up-to-date as possible.</p><p>So that&#8217;s a short look at how the distribution of accepted proposals can evolve during Paxos, and how the protocol guarantees that eventually the cluster will converge on a value that will never change.</p>
") (wfw:commentRss nil "http://the-paper-trail.org/blog/on-some-subtleties-of-paxos/feed/") (slash:comments nil "1")) (item nil (title nil "Links") (link nil "http://the-paper-trail.org/blog/links/") (comments nil "http://the-paper-trail.org/blog/links/#comments") (pubDate nil "Mon, 06 Aug 2012 21:05:50 +0000") (dc:creator nil "Henry") (category nil "Uncategorized") (guid ((isPermaLink . "false")) "http://the-paper-trail.org/blog/?p=414") (description nil "Reasoning about Knowledge Toward a Cloud Computing Research Agenda (2009) &#8211; &#8220;One of the LADIS attendees commented at some point that Byzantine Consensus could be used to improve Chubby, making it tolerant of faults that could disrupt it as currently implemented. But for our keynote speakers, enhancing Chubby to tolerate such faults turns out to [&#8230;]") (content:encoded nil "<ul><li><a href=\"http://www.bigredbits.com/archives/382\">Reasoning about Knowledge</a></li><li><a href=\"http://www.cs.cornell.edu/projects/quicksilver/public_pdfs/sigact2.pdf\">Toward a Cloud Computing Research Agenda</a> (2009) &#8211; <blockquote>&#8220;One of the LADIS attendees commented at some point that Byzantine Consensus could be used to improve Chubby, making it tolerant of faults that could disrupt it as currently implemented. But for our keynote speakers, enhancing Chubby to tolerate such faults turns out to be of purely academic interest.&#8221;</blockquote><li><a href=\"https://github.com/johnj/llds\">Low-level data structures</a> &#8211; <blockquote>The llds general working thesis is: for large memory applications, virtual memory layers can hurt application performance due to increased memory latency when dealing with large data structures. Specifically, data page tables/directories within the kernel and increased DRAM requests can be avoided to boost application memory access.</blockquote></li><li><a href=\"http://arxiv.org/pdf/1201.0228v1.pdf\">High-Performance Concurrency Control for Main-Memory Databases</a> (via <a href=\"http://highscalability.com/blog/2012/8/6/paper-high-performance-concurrency-control-mechanisms-for-ma.html\">High Scalability</a>) &#8211; <a href=\"http://en.wikipedia.org/wiki/Multiversion_concurrency_control\">MVCC</a> is interesting and elegant, and also underpins some datastores with persistence, like HBase. I like <a href=\"http://staff.ustc.edu.cn/~jpq/paper/flash/1983-TODS-Multiversion%20Concurrency%20Control-Theory%20and%20Algorithms.pdf\">this paper</a> as the best survey.</li></ul>
") (wfw:commentRss nil "http://the-paper-trail.org/blog/links/feed/") (slash:comments nil "0")) (item nil (title nil "Something a bit different: translations of classic mathematical texts (!)") (link nil "http://the-paper-trail.org/blog/something-a-bit-different-translations-of-classic-mathematical-texts/") (comments nil "http://the-paper-trail.org/blog/something-a-bit-different-translations-of-classic-mathematical-texts/#comments") (pubDate nil "Sat, 04 Aug 2012 21:50:18 +0000") (dc:creator nil "Henry") (category nil "Uncategorized") (guid ((isPermaLink . "false")) "http://the-paper-trail.org/blog/?p=409") (description nil "During his retirement, my father has been able to spend much time indulging his love of mathematics. This included, amongst other impressive endeavours, attending Cambridge at a more advanced age than average to take (and pass!) the Part III of the Mathematical Tripos, often considered one of the hardest taught courses in maths in the [&#8230;]") (content:encoded nil "<p>During his retirement, my father has been able to spend much time indulging his love of mathematics. This included, amongst other impressive endeavours, attending Cambridge at a more advanced age than average to take (and pass!) the <a href=\"http://en.wikipedia.org/wiki/Part_III_of_the_Mathematical_Tripos\">Part III of the Mathematical Tripos</a>, often considered one of the hardest taught courses in maths in the world.</p><p>Since then, he has hardly been idle, and has recently been undertaking a translation of a classic work in modern algebra by <a href=\"http://en.wikipedia.org/wiki/Richard_Dedekind\">Dedekind</a> and <a href=\"http://en.wikipedia.org/wiki/Heinrich_Martin_Weber\">Weber</a> from its original 100+ pages of German into English.</p><p>Having completed this monumental piece of work, it seemed only proper to share it a little more widely so that other students might benefit from his efforts &#8211; and that&#8217;s where I come in, since I&#8217;m the one with the website. So if you have any passing interest in 19th / 20th century modern algebra, I encourage you to check out Noel Robinson&#8217;s <a href=\"http://the-paper-trail.org/blog/dedekind-and-weber-theory-of-the-algebraic-functions-of-one-variable/\">translation of &#8220;Theory of Algebraic Functions of One Variable&#8221;</a>, hosted on this site.</p>
") (wfw:commentRss nil "http://the-paper-trail.org/blog/something-a-bit-different-translations-of-classic-mathematical-texts/feed/") (slash:comments nil "0")) (item nil (title nil "EuroSys 2012 blog notes") (link nil "http://the-paper-trail.org/blog/eurosys-2012-blog-notes/") (comments nil "http://the-paper-trail.org/blog/eurosys-2012-blog-notes/#comments") (pubDate nil "Mon, 16 Apr 2012 01:20:33 +0000") (dc:creator nil "Henry") (category nil "Uncategorized") (guid ((isPermaLink . "false")) "http://the-paper-trail.org/blog/?p=374") (description nil "EuroSys 2012 was last week &#8211; one of the premier European systems conferences. Over at the Cambridge System Research Group&#8217;s blog, various people from the group have written notes on the papers presented. They&#8217;re very well-written summaries, and worth checking out for an overview of the research presented. Day 1 Day 2 Day 3") (content:encoded nil "<p>EuroSys 2012 was last week &#8211; one of the premier European systems conferences. Over at the Cambridge System Research Group&#8217;s <a href=\"http://www.syslog.cl.cam.ac.uk/\">blog</a>, various people from the group have written notes on the papers presented. They&#8217;re very well-written summaries, and worth checking out for an overview of the research presented.</p><ul><li><a href=\"http://www.syslog.cl.cam.ac.uk/2012/04/11/liveblog-eurosys-2012-day-1/\">Day 1</a></li><li><a href=\"http://www.syslog.cl.cam.ac.uk/2012/04/12/liveblog-eurosys-2012-day-2/\">Day 2</a></li><li><a href=\"http://www.syslog.cl.cam.ac.uk/2012/04/13/liveblog-eurosys-2012-day-3/\">Day 3</a></li></ul>
") (wfw:commentRss nil "http://the-paper-trail.org/blog/eurosys-2012-blog-notes/feed/") (slash:comments nil "1")))) ("Étale cohomology" "<p><em>The second in an extremely irregular series of posts made on behalf of my father, who has spent much of his retirement so far doing very hard mathematics. What is attached here is the essay he wrote for the <a href=\"http://en.wikipedia.org/wiki/Part_III_of_the_Mathematical_Tripos\" title=\"Cambridge Mathematics Part III\">Part III of the Cambridge Mathematical Tripos</a>, a one year taught course. The subject is the <a href=\"http://en.wikipedia.org/wiki/%C3%89tale_cohomology\">Étale cohomology</a>.</em></p><p><em>Says my Dad:</em> “I am afraid that I have been lured away from the translation of SGA 4.5 for some time by the attraction of working on Wolfgang Krull’s report on “Idealtheorie” from 1935 (again I am not aware of an English version anywhere) which is yet another important classic. However during a year at Cambridge I did write an essay as a very basic introduction to Étale Cohomology which was based on the first part of SGA 4.5. So with the usual imprecation of caveat lector, here it is as a temporising partial substitute should any other beginner be interested.”</p><p><em>Here’s part of the introduction:</em></p><blockquote>This essay has been written as part of the one year Certificate of Advanced Study in Mathematics (CASM) course at Cambridge University which coincides with Part III of the Mathematical Tripos. The starting point is, of necessity, roughly that reached in the lectures which in this particular year did not include much in the way of schemes and sheaves, nor, in the case of the author, much in the way of algebraic number theory.
Thus the frontiers of the subject can safely rest undisturbed by the contents of this essay. Rather it has been written with a reader in mind corresponding roughly to the author at the start of the enterprise. That is someone who is interested to find out what all the fuss was with the French algebraic geometers in the 1960s but is in need of some fairly elementary background to map out the abstractions involved and with any luck to avoid drowning in the “rising sea”.</blockquote><p>And here’s the <a href=\"http://the-paper-trail.org/blog/wp-content/uploads/2014/03/EC-Essay-1.pdf\">essay itself</a>!</p>" "http://the-paper-trail.org/blog/etale-cohomology/" (21270 49825) new 1 nil nil ((title nil "Étale cohomology") (link nil "http://the-paper-trail.org/blog/etale-cohomology/") (comments nil "http://the-paper-trail.org/blog/etale-cohomology/#comments") (pubDate nil "Wed, 05 Mar 2014 06:22:25 +0000") (dc:creator nil "Henry") (category nil "mathematics") (guid ((isPermaLink . "false")) "http://the-paper-trail.org/blog/?p=554") (description nil "The second in an extremely irregular series of posts made on behalf of my father, who has spent much of his retirement so far doing very hard mathematics. What is attached here is the essay he wrote for the Part III of the Cambridge Mathematical Tripos, a one year taught course. The subject is the [&#8230;]") (content:encoded nil "<p><em>The second in an extremely irregular series of posts made on behalf of my father, who has spent much of his retirement so far doing very hard mathematics. What is attached here is the essay he wrote for the <a href=\"http://en.wikipedia.org/wiki/Part_III_of_the_Mathematical_Tripos\" title=\"Cambridge Mathematics Part III\">Part III of the Cambridge Mathematical Tripos</a>, a one year taught course. The subject is the <a href=\"http://en.wikipedia.org/wiki/%C3%89tale_cohomology\">Étale cohomology</a>.</em></p><p><em>Says my Dad:</em> &#8220;I am afraid that I have been lured away from the translation of SGA 4.5 for some time by the attraction of working on Wolfgang Krull&#8217;s report on &#8220;Idealtheorie&#8221; from 1935 (again I am not aware of an English version anywhere) which is yet another important classic. However during a year at Cambridge I did write an essay as a very basic introduction to Étale Cohomology which was based on the first part of SGA 4.5. So with the usual imprecation of caveat lector, here it is as a temporising partial substitute should any other beginner be interested.&#8221;</p><p><em>Here&#8217;s part of the introduction:</em></p><blockquote>This essay has been written as part of the one year Certificate of Advanced Study in Mathematics (CASM) course at Cambridge University which coincides with Part III of the Mathematical Tripos. The starting point is, of necessity, roughly that reached in the lectures which in this particular year did not include much in the way of schemes and sheaves, nor, in the case of the author, much in the way of algebraic number theory.
Thus the frontiers of the subject can safely rest undisturbed by the contents of this essay. Rather it has been written with a reader in mind corresponding roughly to the author at the start of the enterprise. That is someone who is interested to find out what all the fuss was with the French algebraic geometers in the 1960s but is in need of some fairly elementary background to map out the abstractions involved and with any luck to avoid drowning in the “rising sea”.</blockquote><p>And here&#8217;s the <a href=\"http://the-paper-trail.org/blog/wp-content/uploads/2014/03/EC-Essay-1.pdf\">essay itself</a>!</p>
") (wfw:commentRss nil "http://the-paper-trail.org/blog/etale-cohomology/feed/") (slash:comments nil "0"))) ("ByteArrayOutputStream is really, really slow sometimes in JDK6" "<p>TLDR: Yesterday I <a href=\"https://twitter.com/HenryR/status/421415424807297024\" title=\"Twitter\">mentioned on Twitter</a> that I’d found a bad performance problem when writing to a large <a href=\"http://docs.oracle.com/javase/6/docs/api/java/io/ByteArrayOutputStream.html\" title=\"ByteArrayOutputStream Javadoc\"><code>ByteArrayOutputStream</code></a> in Java. After some digging, it appears to be the case that there’s a bad bug in JDK6 that doesn’t affect correctness, but does cause performance to nosedive when a <code>ByteArrayOutputStream</code> gets large. This post explains why.</p><p><span id=\"more-535\"></span></p><p>Two of <a href=\"https://github.com/cloudera/Impala\" title=\"Impala on Github\">Impala’s</a> server processes have both C++ and Java components (for reasons both historic and pragmatic). We often need to pass data structures from C++ to Java and vice versa, and mapping the C++ representation onto a Java one via JNI is too painful to contemplate. So instead we take advantage of the fact that <a href=\"http://thrift.apache.org/\" title=\"Apache Thrift\">Thrift</a> is very good at generating equivalent data structures in different languages, and make every parameter to methods on the JNI boundary a serialised Thrift structure. That is, it’s a byte array that Thrift on both sides knows how to convert into a Thrift structure. So we pass byte arrays back and forth, and use Thrift to convert them to language-readable data structures. This works pretty well. (To see exactly how, start by reading <a href=\"https://github.com/cloudera/Impala/blob/master/be/src/service/frontend.cc#L62\" title=\"frontend.cc\">frontend.cc</a> and <a href=\"https://github.com/cloudera/Impala/blob/master/fe/src/main/java/com/cloudera/impala/service/JniFrontend.java\" title=\"JniFrontend.java\">JniFrontend.java</a>). We pay an extra copy or two, plus the CPU overhead of the serialisation, but the benefits in terms of usability and maintainability of the interface vastly outweigh some pretty nominal performance hits.</p><p>If the performance hit isn’t nominal, however, we have a problem. And this is what we observed earlier this week: one of the JNI methods was trying to pass a huge data structure back from Java to C++. Doing so was taking a long time – on the order of minutes. What was particularly of interest was that the performance dropped off a cliff: a data structure half the size was happily serialising in about 500ms. So we have a non-linear relationship between the size of the input and the cost of serialising it. We can’t really absorb that cost, so we had to understand the problem.</p><p>So how did we get there? Thrift’s <a href=\"https://github.com/apache/thrift/blob/master/lib/java/src/org/apache/thrift/TSerializer.java#L77\" title=\"TSerializer.java\">Java serialisation implementation</a> works by having a <code>TSerializer</code> object, which contains a <code>ByteArrayOutputStream</code>, call <code>write()</code> on a Thrift structure with its <code>ByteArrayOutputStream</code> as an argument. The Thrift structure then walks its members and writes object headers and then serialised data for each field in turn. The result is lots of small <code>write()</code> calls to the <code>ByteArrayOutputStream</code>.</p><p>The first thing was to connect a profiler (<a href=\"http://www.yourkit.com\" title=\"YourKit Java Profiler\">YourKit</a>, but honestly repeated <code>SIGHUP</code> to get the stack trace would have worked). During the long serialisation period, almost all the time was spent inside <code>java.util.Arrays.copyOf</code>, inside a method to write a <code>byte[]</code> to a <code>ByteArrayOutputStream</code>. Progress was being made – the item being written to the <code>ByteArrayOutputStream</code> was changing – but it was taking an unreasonably long time to write each field.</p><p>A <code>ByteArrayOutputStream</code> is not necessarily initialised with any estimate of the ultimate size of the byte array it wraps. So it needs a mechanism to resize when more space is required. The source for <a href=\"http://grepcode.com/file/repository.grepcode.com/java/root/jdk/openjdk/6-b14/java/io/ByteArrayOutputStream.java#1\" title=\"ByteArrayOutputStream JDK6 source code\"><code>ByteArrayOutputStream.write(byte[], int, int)</code> in JDK6</a> shows the (very standard) strategy it uses.</p><div class=\"wp_syntax\"><table><tr><td class=\"line_numbers\"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre></td><td class=\"code\"><pre class=\"java\" style=\"font-family:monospace;\"><span style=\"color: #000000; font-weight: bold;\">public</span><span style=\"color: #000000; font-weight: bold;\">synchronized</span><span style=\"color: #000066; font-weight: bold;\">void</span> write<span style=\"color: #009900;\">(</span><span style=\"color: #000066; font-weight: bold;\">byte</span> b<span style=\"color: #009900;\">[</span><span style=\"color: #009900;\">]</span>, <span style=\"color: #000066; font-weight: bold;\">int</span> off, <span style=\"color: #000066; font-weight: bold;\">int</span> len<span style=\"color: #009900;\">)</span><span style=\"color: #009900;\">{</span><span style=\"color: #000000; font-weight: bold;\">if</span><span style=\"color: #009900;\">(</span><span style=\"color: #009900;\">(</span>off <span style=\"color: #339933;\">&lt;</span><span style=\"color: #cc66cc;\">0</span><span style=\"color: #009900;\">)</span><span style=\"color: #339933;\">||</span><span style=\"color: #009900;\">(</span>off <span style=\"color: #339933;\">&gt;</span> b.<span style=\"color: #006633;\">length</span><span style=\"color: #009900;\">)</span><span style=\"color: #339933;\">||</span><span style=\"color: #009900;\">(</span>len <span style=\"color: #339933;\">&lt;</span><span style=\"color: #cc66cc;\">0</span><span style=\"color: #009900;\">)</span><span style=\"color: #339933;\">||</span><span style=\"color: #009900;\">(</span><span style=\"color: #009900;\">(</span>off <span style=\"color: #339933;\">+</span> len<span style=\"color: #009900;\">)</span><span style=\"color: #339933;\">&gt;</span> b.<span style=\"color: #006633;\">length</span><span style=\"color: #009900;\">)</span><span style=\"color: #339933;\">||</span><span style=\"color: #009900;\">(</span><span style=\"color: #009900;\">(</span>off <span style=\"color: #339933;\">+</span> len<span style=\"color: #009900;\">)</span><span style=\"color: #339933;\">&lt;</span><span style=\"color: #cc66cc;\">0</span><span style=\"color: #009900;\">)</span><span style=\"color: #009900;\">)</span><span style=\"color: #009900;\">{</span><span style=\"color: #000000; font-weight: bold;\">throw</span><span style=\"color: #000000; font-weight: bold;\">new</span><span style=\"color: #003399;\">IndexOutOfBoundsException</span><span style=\"color: #009900;\">(</span><span style=\"color: #009900;\">)</span><span style=\"color: #339933;\">;</span><span style=\"color: #009900;\">}</span><span style=\"color: #000000; font-weight: bold;\">else</span><span style=\"color: #000000; font-weight: bold;\">if</span><span style=\"color: #009900;\">(</span>len <span style=\"color: #339933;\">==</span><span style=\"color: #cc66cc;\">0</span><span style=\"color: #009900;\">)</span><span style=\"color: #009900;\">{</span><span style=\"color: #000000; font-weight: bold;\">return</span><span style=\"color: #339933;\">;</span><span style=\"color: #009900;\">}</span><span style=\"color: #000066; font-weight: bold;\">int</span> newcount <span style=\"color: #339933;\">=</span> count <span style=\"color: #339933;\">+</span> len<span style=\"color: #339933;\">;</span><span style=\"color: #000000; font-weight: bold;\">if</span><span style=\"color: #009900;\">(</span>newcount <span style=\"color: #339933;\">&gt;</span> buf.<span style=\"color: #006633;\">length</span><span style=\"color: #009900;\">)</span><span style=\"color: #009900;\">{</span>
buf <span style=\"color: #339933;\">=</span><span style=\"color: #003399;\">Arrays</span>.<span style=\"color: #006633;\">copyOf</span><span style=\"color: #009900;\">(</span>buf, <span style=\"color: #003399;\">Math</span>.<span style=\"color: #006633;\">max</span><span style=\"color: #009900;\">(</span>buf.<span style=\"color: #006633;\">length</span><span style=\"color: #339933;\">&lt;&lt;</span><span style=\"color: #cc66cc;\">1</span>, newcount<span style=\"color: #009900;\">)</span><span style=\"color: #009900;\">)</span><span style=\"color: #339933;\">;</span><span style=\"color: #009900;\">}</span><span style=\"color: #003399;\">System</span>.<span style=\"color: #006633;\">arraycopy</span><span style=\"color: #009900;\">(</span>b, off, buf, count, len<span style=\"color: #009900;\">)</span><span style=\"color: #339933;\">;</span>
count <span style=\"color: #339933;\">=</span> newcount<span style=\"color: #339933;\">;</span><span style=\"color: #009900;\">}</span></pre></td></tr></table></div><p>The first six lines just deal with parameter validation; they can be ignored from here on. Lines 8-9 are interesting: we compute the new size of the array after the write completes, and then, if that size is larger than the current size, we need to do something to compensate.</p><p>Line 10 is where that compensation happens. <code>Arrays.copyOf()</code> creates a new array containing all the bytes from the original array, but with a larger size. The size of the new array is the maximum of twice the current length <code>(buf.length &lt;&lt; 1)</code> and the requested size of the array after the write completes (this is so that a large write that more than doubles the current size of the array can be accommodated). Performing this copy is expensive, but since the size of the array should grow exponentially, frequent copies are hopefully unlikely. C++’s vector does the same thing.</p><p>After that (lines 12-13) we copy in the argument, and update the tracked number of bytes in the array.</p><p>My working hypothesis was that <code>copyOf()</code> was being called on every <code>write()</code> (since the matched up with what the profiler was telling us). The source code tells us the only way that can happen is if <code>newcount</code> is always larger than <code>buf.length</code>. This leads to two possibilities: <code>newcount</code> is getting large quickly, or <code>buf.length</code> is getting large slowly. The former seems unlikely – Thrift serialisation works by writing many small byte arrays – so to support my hypothesis, <code>buf.length</code> had to be growing slowly so that the <code>copyOf()</code> branch was being taken much more frequently than we expected.</p><p>A session with <a href=\"http://docs.oracle.com/javase/7/docs/technotes/tools/windows/jdb.html\" title=\"JDB, the Java Debugger\">JDB</a> (a terrible, terrible debugger) confirmed this. During the slow serialisation period, the size of the array increased on every write only by the amount required to contain the write in progress. On every write of say 2 bytes, the array size would increase by exactly those 2 bytes and a copy would be taken. The array itself was about 1GB in size, so the copy was really expensive.</p><p>This leads us to the bug. The size of the array is determined by <code>Math.max(buf.length &lt;&lt; 1, newcount)</code>. Ordinarily, <code>buf.length &lt;&lt; 1</code> returns double<code> buf.length</code>, which would always be much larger than <code>newcount</code> for a 2 byte write. Why was it not?</p><p>The problem is that for all integers larger than <code>Integer.MAX_INTEGER / 2</code>, shifting left by one place causes overflow, setting the sign bit. The result is a <em>negative</em> integer, which is always less than newcount. So for all byte arrays  larger than 1073741824 bytes (i.e. one GB), <strong>any write will cause the array to resize</strong>, and only to exactly the size required.</p><p>You could argue that this is by design for the following reason: the maximum size of any array in Java is <code>Integer.MAX_INTEGER</code> (minus a few bytes for preamble). Any array larger than <code>Integer.MAX_INTEGER / 2</code> bytes long would become larger than that limit when doubling in size. However, the source for <code>ByteArrayOutputStream.write()</code> could handle this case by setting the new length to <code>Integer.MAX_INTEGER</code> if <code>buf.length > Integer.MAX_INTEGER / 2</code> to give the array the maximum chance to grow with few copies.</p><p>The true fix is for us to cut down the size of the object we want to marshal, or to come up with some less expensive way of doing so (we could use a different <code>TSerializer</code> implementation, for example). Still, it’s an unfortunate degradation an a fairly commonly used class, even if there are other, better ways of achieving the same thing.</p><h3>Postscript</h3><p>In fact, <a href=\"http://grepcode.com/file/repository.grepcode.com/java/root/jdk/openjdk/7-b147/java/io/ByteArrayOutputStream.java#ByteArrayOutputStream.write%28byte%5B%5D%2Cint%2Cint%29\" title=\"ByteArrayOutputStream JDK7 source code\">JDK7 ‘fixed’ the issue by correctly dealing with overflow</a>, but if the resulting doubled array-length was larger than <code>Integer.MAX_INTEGER</code>, an exception is thrown. You can check by running this code on both JDK6 and JDK7:</p><div class=\"wp_syntax\"><table><tr><td class=\"line_numbers\"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre></td><td class=\"code\"><pre class=\"java\" style=\"font-family:monospace;\"><span style=\"color: #000000; font-weight: bold;\">import</span><span style=\"color: #006699;\">java.io.ByteArrayOutputStream</span><span style=\"color: #339933;\">;</span>
&nbsp;
<span style=\"color: #000000; font-weight: bold;\">public</span><span style=\"color: #000000; font-weight: bold;\">class</span> TestByteArray <span style=\"color: #009900;\">{</span>
&nbsp;
<span style=\"color: #000000; font-weight: bold;\">static</span><span style=\"color: #000066; font-weight: bold;\">byte</span><span style=\"color: #009900;\">[</span><span style=\"color: #009900;\">]</span> chunk <span style=\"color: #339933;\">=</span><span style=\"color: #000000; font-weight: bold;\">new</span><span style=\"color: #000066; font-weight: bold;\">byte</span><span style=\"color: #009900;\">[</span><span style=\"color: #cc66cc;\">1024</span><span style=\"color: #339933;\">*</span><span style=\"color: #cc66cc;\">1024</span><span style=\"color: #009900;\">]</span><span style=\"color: #339933;\">;</span><span style=\"color: #000000; font-weight: bold;\">public</span><span style=\"color: #000000; font-weight: bold;\">static</span><span style=\"color: #000066; font-weight: bold;\">void</span> main<span style=\"color: #009900;\">(</span><span style=\"color: #003399;\">String</span><span style=\"color: #009900;\">[</span><span style=\"color: #009900;\">]</span> args<span style=\"color: #009900;\">)</span><span style=\"color: #009900;\">{</span><span style=\"color: #003399;\">ByteArrayOutputStream</span> baos <span style=\"color: #339933;\">=</span><span style=\"color: #000000; font-weight: bold;\">new</span><span style=\"color: #003399;\">ByteArrayOutputStream</span><span style=\"color: #009900;\">(</span><span style=\"color: #009900;\">)</span><span style=\"color: #339933;\">;</span><span style=\"color: #000066; font-weight: bold;\">int</span> numChunks <span style=\"color: #339933;\">=</span><span style=\"color: #cc66cc;\">2</span><span style=\"color: #339933;\">*</span><span style=\"color: #cc66cc;\">1024</span><span style=\"color: #339933;\">*</span><span style=\"color: #cc66cc;\">1024</span><span style=\"color: #339933;\">;</span><span style=\"color: #000000; font-weight: bold;\">for</span><span style=\"color: #009900;\">(</span><span style=\"color: #000066; font-weight: bold;\">int</span>  i <span style=\"color: #339933;\">=</span><span style=\"color: #cc66cc;\">0</span><span style=\"color: #339933;\">;</span> i <span style=\"color: #339933;\">&lt;</span> numChunks<span style=\"color: #339933;\">;</span><span style=\"color: #339933;\">++</span>i<span style=\"color: #009900;\">)</span><span style=\"color: #009900;\">{</span><span style=\"color: #000066; font-weight: bold;\">long</span> start <span style=\"color: #339933;\">=</span><span style=\"color: #003399;\">System</span>.<span style=\"color: #006633;\">currentTimeMillis</span><span style=\"color: #009900;\">(</span><span style=\"color: #009900;\">)</span><span style=\"color: #339933;\">;</span>
baos.<span style=\"color: #006633;\">write</span><span style=\"color: #009900;\">(</span>chunk, <span style=\"color: #cc66cc;\">0</span>, chunk.<span style=\"color: #006633;\">length</span><span style=\"color: #009900;\">)</span><span style=\"color: #339933;\">;</span><span style=\"color: #000066; font-weight: bold;\">long</span> end <span style=\"color: #339933;\">=</span><span style=\"color: #003399;\">System</span>.<span style=\"color: #006633;\">currentTimeMillis</span><span style=\"color: #009900;\">(</span><span style=\"color: #009900;\">)</span><span style=\"color: #339933;\">;</span><span style=\"color: #003399;\">System</span>.<span style=\"color: #006633;\">out</span>.<span style=\"color: #006633;\">println</span><span style=\"color: #009900;\">(</span><span style=\"color: #0000ff;\">&quot;Chunk &quot;</span><span style=\"color: #339933;\">+</span> i <span style=\"color: #339933;\">+</span><span style=\"color: #0000ff;\">&quot; of &quot;</span><span style=\"color: #339933;\">+</span> numChunks <span style=\"color: #339933;\">+</span><span style=\"color: #0000ff;\">&quot; took: &quot;</span><span style=\"color: #339933;\">+</span><span style=\"color: #009900;\">(</span><span style=\"color: #009900;\">(</span>end <span style=\"color: #339933;\">-</span> start<span style=\"color: #009900;\">)</span><span style=\"color: #339933;\">/</span><span style=\"color: #cc66cc;\">1000.0</span><span style=\"color: #009900;\">)</span><span style=\"color: #339933;\">+</span><span style=\"color: #0000ff;\">&quot;s, total written: &quot;</span><span style=\"color: #339933;\">+</span><span style=\"color: #009900;\">(</span>i <span style=\"color: #339933;\">*</span> chunk.<span style=\"color: #006633;\">length</span><span style=\"color: #009900;\">)</span><span style=\"color: #339933;\">+</span><span style=\"color: #0000ff;\">&quot; bytes&quot;</span><span style=\"color: #009900;\">)</span><span style=\"color: #339933;\">;</span><span style=\"color: #009900;\">}</span><span style=\"color: #009900;\">}</span><span style=\"color: #009900;\">}</span></pre></td></tr></table></div><p>On JDK6:</p><div class=\"wp_syntax\"><table><tr><td class=\"code\"><pre class=\"text\" style=\"font-family:monospace;\">...
Chunk 1015 of 2097152 took: 0.0010s, total written: 1064304640 bytes
Chunk 1016 of 2097152 took: 0.0s, total written: 1065353216 bytes
Chunk 1017 of 2097152 took: 0.0010s, total written: 1066401792 bytes
Chunk 1018 of 2097152 took: 0.0s, total written: 1067450368 bytes
Chunk 1019 of 2097152 took: 0.0s, total written: 1068498944 bytes
Chunk 1020 of 2097152 took: 0.0010s, total written: 1069547520 bytes
Chunk 1021 of 2097152 took: 0.0s, total written: 1070596096 bytes
Chunk 1022 of 2097152 took: 0.0s, total written: 1071644672 bytes
Chunk 1023 of 2097152 took: 0.0010s, total written: 1072693248 bytes
Chunk 1024 of 2097152 took: 1.163s, total written: 1073741824 bytes &lt;-- &gt;1s per write!
Chunk 1025 of 2097152 took: 0.979s, total written: 1074790400 bytes
Chunk 1026 of 2097152 took: 0.948s, total written: 1075838976 bytes
Chunk 1027 of 2097152 took: 1.053s, total written: 1076887552 bytes
Chunk 1028 of 2097152 took: 1.033s, total written: 1077936128 bytes
Chunk 1029 of 2097152 took: 1.123s, total written: 1078984704 bytes
Chunk 1030 of 2097152 took: 0.723s, total written: 1080033280 bytes
Chunk 1031 of 2097152 took: 0.603s, total written: 1081081856 bytes
...</pre></td></tr></table></div><p>On JDK7:</p><div class=\"wp_syntax\"><table><tr><td class=\"code\"><pre class=\"text\" style=\"font-family:monospace;\">...
Chunk 1015 of 2097152 took: 0.0s, total written: 1064304640 bytes
Chunk 1016 of 2097152 took: 0.0s, total written: 1065353216 bytes
Chunk 1017 of 2097152 took: 0.0s, total written: 1066401792 bytes
Chunk 1018 of 2097152 took: 0.0s, total written: 1067450368 bytes
Chunk 1019 of 2097152 took: 0.0s, total written: 1068498944 bytes
Chunk 1020 of 2097152 took: 0.0s, total written: 1069547520 bytes
Chunk 1021 of 2097152 took: 0.001s, total written: 1070596096 bytes
Chunk 1022 of 2097152 took: 0.0s, total written: 1071644672 bytes
Chunk 1023 of 2097152 took: 0.001s, total written: 1072693248 bytes
Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Requested array size exceeds VM limit
at java.util.Arrays.copyOf(Arrays.java:2271)
at java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:113)
at java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)
at java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:140)
at TestByteArray.main(TestByteArray.java:11)</pre></td></tr></table></div>" "http://the-paper-trail.org/blog/535/" (21200 31461) new 2 nil nil ((title nil "ByteArrayOutputStream is really, really slow sometimes in JDK6") (link nil "http://the-paper-trail.org/blog/535/") (comments nil "http://the-paper-trail.org/blog/535/#comments") (pubDate nil "Fri, 10 Jan 2014 22:57:41 +0000") (dc:creator nil "Henry") (category nil "Uncategorized") (category nil "Java") (guid ((isPermaLink . "false")) "http://the-paper-trail.org/blog/?p=535") (description nil "TLDR: Yesterday I mentioned on Twitter that I&#8217;d found a bad performance problem when writing to a large ByteArrayOutputStream in Java. After some digging, it appears to be the case that there&#8217;s a bad bug in JDK6 that doesn&#8217;t affect correctness, but does cause performance to nosedive when a ByteArrayOutputStream gets large. This post explains [&#8230;]") (content:encoded nil "<p>TLDR: Yesterday I <a href=\"https://twitter.com/HenryR/status/421415424807297024\" title=\"Twitter\">mentioned on Twitter</a> that I&#8217;d found a bad performance problem when writing to a large <a href=\"http://docs.oracle.com/javase/6/docs/api/java/io/ByteArrayOutputStream.html\" title=\"ByteArrayOutputStream Javadoc\"><code>ByteArrayOutputStream</code></a> in Java. After some digging, it appears to be the case that there&#8217;s a bad bug in JDK6 that doesn&#8217;t affect correctness, but does cause performance to nosedive when a <code>ByteArrayOutputStream</code> gets large. This post explains why.</p><p><span id=\"more-535\"></span></p><p>Two of <a href=\"https://github.com/cloudera/Impala\" title=\"Impala on Github\">Impala&#8217;s</a> server processes have both C++ and Java components (for reasons both historic and pragmatic). We often need to pass data structures from C++ to Java and vice versa, and mapping the C++ representation onto a Java one via JNI is too painful to contemplate. So instead we take advantage of the fact that <a href=\"http://thrift.apache.org/\" title=\"Apache Thrift\">Thrift</a> is very good at generating equivalent data structures in different languages, and make every parameter to methods on the JNI boundary a serialised Thrift structure. That is, it&#8217;s a byte array that Thrift on both sides knows how to convert into a Thrift structure. So we pass byte arrays back and forth, and use Thrift to convert them to language-readable data structures. This works pretty well. (To see exactly how, start by reading <a href=\"https://github.com/cloudera/Impala/blob/master/be/src/service/frontend.cc#L62\" title=\"frontend.cc\">frontend.cc</a> and <a href=\"https://github.com/cloudera/Impala/blob/master/fe/src/main/java/com/cloudera/impala/service/JniFrontend.java\" title=\"JniFrontend.java\">JniFrontend.java</a>). We pay an extra copy or two, plus the CPU overhead of the serialisation, but the benefits in terms of usability and maintainability of the interface vastly outweigh some pretty nominal performance hits.</p><p>If the performance hit isn&#8217;t nominal, however, we have a problem. And this is what we observed earlier this week: one of the JNI methods was trying to pass a huge data structure back from Java to C++. Doing so was taking a long time &#8211; on the order of minutes. What was particularly of interest was that the performance dropped off a cliff: a data structure half the size was happily serialising in about 500ms. So we have a non-linear relationship between the size of the input and the cost of serialising it. We can&#8217;t really absorb that cost, so we had to understand the problem.</p><p>So how did we get there? Thrift&#8217;s <a href=\"https://github.com/apache/thrift/blob/master/lib/java/src/org/apache/thrift/TSerializer.java#L77\" title=\"TSerializer.java\">Java serialisation implementation</a> works by having a <code>TSerializer</code> object, which contains a <code>ByteArrayOutputStream</code>, call <code>write()</code> on a Thrift structure with its <code>ByteArrayOutputStream</code> as an argument. The Thrift structure then walks its members and writes object headers and then serialised data for each field in turn. The result is lots of small <code>write()</code> calls to the <code>ByteArrayOutputStream</code>.</p><p>The first thing was to connect a profiler (<a href=\"http://www.yourkit.com\" title=\"YourKit Java Profiler\">YourKit</a>, but honestly repeated <code>SIGHUP</code> to get the stack trace would have worked). During the long serialisation period, almost all the time was spent inside <code>java.util.Arrays.copyOf</code>, inside a method to write a <code>byte[]</code> to a <code>ByteArrayOutputStream</code>. Progress was being made &#8211; the item being written to the <code>ByteArrayOutputStream</code> was changing &#8211; but it was taking an unreasonably long time to write each field.</p><p>A <code>ByteArrayOutputStream</code> is not necessarily initialised with any estimate of the ultimate size of the byte array it wraps. So it needs a mechanism to resize when more space is required. The source for <a href=\"http://grepcode.com/file/repository.grepcode.com/java/root/jdk/openjdk/6-b14/java/io/ByteArrayOutputStream.java#1\" title=\"ByteArrayOutputStream JDK6 source code\"><code>ByteArrayOutputStream.write(byte[], int, int)</code> in JDK6</a> shows the (very standard) strategy it uses.</p><div class=\"wp_syntax\"><table><tr><td class=\"line_numbers\"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre></td><td class=\"code\"><pre class=\"java\" style=\"font-family:monospace;\"><span style=\"color: #000000; font-weight: bold;\">public</span><span style=\"color: #000000; font-weight: bold;\">synchronized</span><span style=\"color: #000066; font-weight: bold;\">void</span> write<span style=\"color: #009900;\">&#40;</span><span style=\"color: #000066; font-weight: bold;\">byte</span> b<span style=\"color: #009900;\">&#91;</span><span style=\"color: #009900;\">&#93;</span>, <span style=\"color: #000066; font-weight: bold;\">int</span> off, <span style=\"color: #000066; font-weight: bold;\">int</span> len<span style=\"color: #009900;\">&#41;</span><span style=\"color: #009900;\">&#123;</span><span style=\"color: #000000; font-weight: bold;\">if</span><span style=\"color: #009900;\">&#40;</span><span style=\"color: #009900;\">&#40;</span>off <span style=\"color: #339933;\">&lt;</span><span style=\"color: #cc66cc;\">0</span><span style=\"color: #009900;\">&#41;</span><span style=\"color: #339933;\">||</span><span style=\"color: #009900;\">&#40;</span>off <span style=\"color: #339933;\">&gt;</span> b.<span style=\"color: #006633;\">length</span><span style=\"color: #009900;\">&#41;</span><span style=\"color: #339933;\">||</span><span style=\"color: #009900;\">&#40;</span>len <span style=\"color: #339933;\">&lt;</span><span style=\"color: #cc66cc;\">0</span><span style=\"color: #009900;\">&#41;</span><span style=\"color: #339933;\">||</span><span style=\"color: #009900;\">&#40;</span><span style=\"color: #009900;\">&#40;</span>off <span style=\"color: #339933;\">+</span> len<span style=\"color: #009900;\">&#41;</span><span style=\"color: #339933;\">&gt;</span> b.<span style=\"color: #006633;\">length</span><span style=\"color: #009900;\">&#41;</span><span style=\"color: #339933;\">||</span><span style=\"color: #009900;\">&#40;</span><span style=\"color: #009900;\">&#40;</span>off <span style=\"color: #339933;\">+</span> len<span style=\"color: #009900;\">&#41;</span><span style=\"color: #339933;\">&lt;</span><span style=\"color: #cc66cc;\">0</span><span style=\"color: #009900;\">&#41;</span><span style=\"color: #009900;\">&#41;</span><span style=\"color: #009900;\">&#123;</span><span style=\"color: #000000; font-weight: bold;\">throw</span><span style=\"color: #000000; font-weight: bold;\">new</span><span style=\"color: #003399;\">IndexOutOfBoundsException</span><span style=\"color: #009900;\">&#40;</span><span style=\"color: #009900;\">&#41;</span><span style=\"color: #339933;\">;</span><span style=\"color: #009900;\">&#125;</span><span style=\"color: #000000; font-weight: bold;\">else</span><span style=\"color: #000000; font-weight: bold;\">if</span><span style=\"color: #009900;\">&#40;</span>len <span style=\"color: #339933;\">==</span><span style=\"color: #cc66cc;\">0</span><span style=\"color: #009900;\">&#41;</span><span style=\"color: #009900;\">&#123;</span><span style=\"color: #000000; font-weight: bold;\">return</span><span style=\"color: #339933;\">;</span><span style=\"color: #009900;\">&#125;</span><span style=\"color: #000066; font-weight: bold;\">int</span> newcount <span style=\"color: #339933;\">=</span> count <span style=\"color: #339933;\">+</span> len<span style=\"color: #339933;\">;</span><span style=\"color: #000000; font-weight: bold;\">if</span><span style=\"color: #009900;\">&#40;</span>newcount <span style=\"color: #339933;\">&gt;</span> buf.<span style=\"color: #006633;\">length</span><span style=\"color: #009900;\">&#41;</span><span style=\"color: #009900;\">&#123;</span>
        buf <span style=\"color: #339933;\">=</span><span style=\"color: #003399;\">Arrays</span>.<span style=\"color: #006633;\">copyOf</span><span style=\"color: #009900;\">&#40;</span>buf, <span style=\"color: #003399;\">Math</span>.<span style=\"color: #006633;\">max</span><span style=\"color: #009900;\">&#40;</span>buf.<span style=\"color: #006633;\">length</span><span style=\"color: #339933;\">&lt;&lt;</span><span style=\"color: #cc66cc;\">1</span>, newcount<span style=\"color: #009900;\">&#41;</span><span style=\"color: #009900;\">&#41;</span><span style=\"color: #339933;\">;</span><span style=\"color: #009900;\">&#125;</span><span style=\"color: #003399;\">System</span>.<span style=\"color: #006633;\">arraycopy</span><span style=\"color: #009900;\">&#40;</span>b, off, buf, count, len<span style=\"color: #009900;\">&#41;</span><span style=\"color: #339933;\">;</span>
    count <span style=\"color: #339933;\">=</span> newcount<span style=\"color: #339933;\">;</span><span style=\"color: #009900;\">&#125;</span></pre></td></tr></table></div><p>The first six lines just deal with parameter validation; they can be ignored from here on. Lines 8-9 are interesting: we compute the new size of the array after the write completes, and then, if that size is larger than the current size, we need to do something to compensate.</p><p>Line 10 is where that compensation happens. <code>Arrays.copyOf()</code> creates a new array containing all the bytes from the original array, but with a larger size. The size of the new array is the maximum of twice the current length <code>(buf.length &lt;&lt; 1)</code> and the requested size of the array after the write completes (this is so that a large write that more than doubles the current size of the array can be accommodated). Performing this copy is expensive, but since the size of the array should grow exponentially, frequent copies are hopefully unlikely. C++&#8217;s vector does the same thing.</p><p>After that (lines 12-13) we copy in the argument, and update the tracked number of bytes in the array.</p><p>My working hypothesis was that <code>copyOf()</code> was being called on every <code>write()</code> (since the matched up with what the profiler was telling us). The source code tells us the only way that can happen is if <code>newcount</code> is always larger than <code>buf.length</code>. This leads to two possibilities: <code>newcount</code> is getting large quickly, or <code>buf.length</code> is getting large slowly. The former seems unlikely &#8211; Thrift serialisation works by writing many small byte arrays &#8211; so to support my hypothesis, <code>buf.length</code> had to be growing slowly so that the <code>copyOf()</code> branch was being taken much more frequently than we expected.</p><p>A session with <a href=\"http://docs.oracle.com/javase/7/docs/technotes/tools/windows/jdb.html\" title=\"JDB, the Java Debugger\">JDB</a> (a terrible, terrible debugger) confirmed this. During the slow serialisation period, the size of the array increased on every write only by the amount required to contain the write in progress. On every write of say 2 bytes, the array size would increase by exactly those 2 bytes and a copy would be taken. The array itself was about 1GB in size, so the copy was really expensive.</p><p>This leads us to the bug. The size of the array is determined by <code>Math.max(buf.length &lt;&lt; 1, newcount)</code>. Ordinarily, <code>buf.length &lt;&lt; 1</code> returns double<code> buf.length</code>, which would always be much larger than <code>newcount</code> for a 2 byte write. Why was it not?</p><p>The problem is that for all integers larger than <code>Integer.MAX_INTEGER / 2</code>, shifting left by one place causes overflow, setting the sign bit. The result is a <em>negative</em> integer, which is always less than newcount. So for all byte arrays  larger than 1073741824 bytes (i.e. one GB), <strong>any write will cause the array to resize</strong>, and only to exactly the size required.</p><p>You could argue that this is by design for the following reason: the maximum size of any array in Java is <code>Integer.MAX_INTEGER</code> (minus a few bytes for preamble). Any array larger than <code>Integer.MAX_INTEGER / 2</code> bytes long would become larger than that limit when doubling in size. However, the source for <code>ByteArrayOutputStream.write()</code> could handle this case by setting the new length to <code>Integer.MAX_INTEGER</code> if <code>buf.length > Integer.MAX_INTEGER / 2</code> to give the array the maximum chance to grow with few copies.</p><p>The true fix is for us to cut down the size of the object we want to marshal, or to come up with some less expensive way of doing so (we could use a different <code>TSerializer</code> implementation, for example). Still, it&#8217;s an unfortunate degradation an a fairly commonly used class, even if there are other, better ways of achieving the same thing.</p><h3>Postscript</h3><p>In fact, <a href=\"http://grepcode.com/file/repository.grepcode.com/java/root/jdk/openjdk/7-b147/java/io/ByteArrayOutputStream.java#ByteArrayOutputStream.write%28byte%5B%5D%2Cint%2Cint%29\" title=\"ByteArrayOutputStream JDK7 source code\">JDK7 &#8216;fixed&#8217; the issue by correctly dealing with overflow</a>, but if the resulting doubled array-length was larger than <code>Integer.MAX_INTEGER</code>, an exception is thrown. You can check by running this code on both JDK6 and JDK7:</p><div class=\"wp_syntax\"><table><tr><td class=\"line_numbers\"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre></td><td class=\"code\"><pre class=\"java\" style=\"font-family:monospace;\"><span style=\"color: #000000; font-weight: bold;\">import</span><span style=\"color: #006699;\">java.io.ByteArrayOutputStream</span><span style=\"color: #339933;\">;</span>
&nbsp;
<span style=\"color: #000000; font-weight: bold;\">public</span><span style=\"color: #000000; font-weight: bold;\">class</span> TestByteArray <span style=\"color: #009900;\">&#123;</span>
&nbsp;
  <span style=\"color: #000000; font-weight: bold;\">static</span><span style=\"color: #000066; font-weight: bold;\">byte</span><span style=\"color: #009900;\">&#91;</span><span style=\"color: #009900;\">&#93;</span> chunk <span style=\"color: #339933;\">=</span><span style=\"color: #000000; font-weight: bold;\">new</span><span style=\"color: #000066; font-weight: bold;\">byte</span><span style=\"color: #009900;\">&#91;</span><span style=\"color: #cc66cc;\">1024</span><span style=\"color: #339933;\">*</span><span style=\"color: #cc66cc;\">1024</span><span style=\"color: #009900;\">&#93;</span><span style=\"color: #339933;\">;</span><span style=\"color: #000000; font-weight: bold;\">public</span><span style=\"color: #000000; font-weight: bold;\">static</span><span style=\"color: #000066; font-weight: bold;\">void</span> main<span style=\"color: #009900;\">&#40;</span><span style=\"color: #003399;\">String</span><span style=\"color: #009900;\">&#91;</span><span style=\"color: #009900;\">&#93;</span> args<span style=\"color: #009900;\">&#41;</span><span style=\"color: #009900;\">&#123;</span><span style=\"color: #003399;\">ByteArrayOutputStream</span> baos <span style=\"color: #339933;\">=</span><span style=\"color: #000000; font-weight: bold;\">new</span><span style=\"color: #003399;\">ByteArrayOutputStream</span><span style=\"color: #009900;\">&#40;</span><span style=\"color: #009900;\">&#41;</span><span style=\"color: #339933;\">;</span><span style=\"color: #000066; font-weight: bold;\">int</span> numChunks <span style=\"color: #339933;\">=</span><span style=\"color: #cc66cc;\">2</span><span style=\"color: #339933;\">*</span><span style=\"color: #cc66cc;\">1024</span><span style=\"color: #339933;\">*</span><span style=\"color: #cc66cc;\">1024</span><span style=\"color: #339933;\">;</span><span style=\"color: #000000; font-weight: bold;\">for</span><span style=\"color: #009900;\">&#40;</span><span style=\"color: #000066; font-weight: bold;\">int</span>  i <span style=\"color: #339933;\">=</span><span style=\"color: #cc66cc;\">0</span><span style=\"color: #339933;\">;</span> i <span style=\"color: #339933;\">&lt;</span> numChunks<span style=\"color: #339933;\">;</span><span style=\"color: #339933;\">++</span>i<span style=\"color: #009900;\">&#41;</span><span style=\"color: #009900;\">&#123;</span><span style=\"color: #000066; font-weight: bold;\">long</span> start <span style=\"color: #339933;\">=</span><span style=\"color: #003399;\">System</span>.<span style=\"color: #006633;\">currentTimeMillis</span><span style=\"color: #009900;\">&#40;</span><span style=\"color: #009900;\">&#41;</span><span style=\"color: #339933;\">;</span>
      baos.<span style=\"color: #006633;\">write</span><span style=\"color: #009900;\">&#40;</span>chunk, <span style=\"color: #cc66cc;\">0</span>, chunk.<span style=\"color: #006633;\">length</span><span style=\"color: #009900;\">&#41;</span><span style=\"color: #339933;\">;</span><span style=\"color: #000066; font-weight: bold;\">long</span> end <span style=\"color: #339933;\">=</span><span style=\"color: #003399;\">System</span>.<span style=\"color: #006633;\">currentTimeMillis</span><span style=\"color: #009900;\">&#40;</span><span style=\"color: #009900;\">&#41;</span><span style=\"color: #339933;\">;</span><span style=\"color: #003399;\">System</span>.<span style=\"color: #006633;\">out</span>.<span style=\"color: #006633;\">println</span><span style=\"color: #009900;\">&#40;</span><span style=\"color: #0000ff;\">&quot;Chunk &quot;</span><span style=\"color: #339933;\">+</span> i <span style=\"color: #339933;\">+</span><span style=\"color: #0000ff;\">&quot; of &quot;</span><span style=\"color: #339933;\">+</span> numChunks <span style=\"color: #339933;\">+</span><span style=\"color: #0000ff;\">&quot; took: &quot;</span><span style=\"color: #339933;\">+</span><span style=\"color: #009900;\">&#40;</span><span style=\"color: #009900;\">&#40;</span>end <span style=\"color: #339933;\">-</span> start<span style=\"color: #009900;\">&#41;</span><span style=\"color: #339933;\">/</span><span style=\"color: #cc66cc;\">1000.0</span><span style=\"color: #009900;\">&#41;</span><span style=\"color: #339933;\">+</span><span style=\"color: #0000ff;\">&quot;s, total written: &quot;</span><span style=\"color: #339933;\">+</span><span style=\"color: #009900;\">&#40;</span>i <span style=\"color: #339933;\">*</span> chunk.<span style=\"color: #006633;\">length</span><span style=\"color: #009900;\">&#41;</span><span style=\"color: #339933;\">+</span><span style=\"color: #0000ff;\">&quot; bytes&quot;</span><span style=\"color: #009900;\">&#41;</span><span style=\"color: #339933;\">;</span><span style=\"color: #009900;\">&#125;</span><span style=\"color: #009900;\">&#125;</span><span style=\"color: #009900;\">&#125;</span></pre></td></tr></table></div><p>On JDK6:</p><div class=\"wp_syntax\"><table><tr><td class=\"code\"><pre class=\"text\" style=\"font-family:monospace;\">...
Chunk 1015 of 2097152 took: 0.0010s, total written: 1064304640 bytes
Chunk 1016 of 2097152 took: 0.0s, total written: 1065353216 bytes
Chunk 1017 of 2097152 took: 0.0010s, total written: 1066401792 bytes
Chunk 1018 of 2097152 took: 0.0s, total written: 1067450368 bytes
Chunk 1019 of 2097152 took: 0.0s, total written: 1068498944 bytes
Chunk 1020 of 2097152 took: 0.0010s, total written: 1069547520 bytes
Chunk 1021 of 2097152 took: 0.0s, total written: 1070596096 bytes
Chunk 1022 of 2097152 took: 0.0s, total written: 1071644672 bytes
Chunk 1023 of 2097152 took: 0.0010s, total written: 1072693248 bytes
Chunk 1024 of 2097152 took: 1.163s, total written: 1073741824 bytes &lt;-- &gt;1s per write!
Chunk 1025 of 2097152 took: 0.979s, total written: 1074790400 bytes
Chunk 1026 of 2097152 took: 0.948s, total written: 1075838976 bytes
Chunk 1027 of 2097152 took: 1.053s, total written: 1076887552 bytes
Chunk 1028 of 2097152 took: 1.033s, total written: 1077936128 bytes
Chunk 1029 of 2097152 took: 1.123s, total written: 1078984704 bytes
Chunk 1030 of 2097152 took: 0.723s, total written: 1080033280 bytes
Chunk 1031 of 2097152 took: 0.603s, total written: 1081081856 bytes
...</pre></td></tr></table></div><p>On JDK7:</p><div class=\"wp_syntax\"><table><tr><td class=\"code\"><pre class=\"text\" style=\"font-family:monospace;\">...
Chunk 1015 of 2097152 took: 0.0s, total written: 1064304640 bytes
Chunk 1016 of 2097152 took: 0.0s, total written: 1065353216 bytes
Chunk 1017 of 2097152 took: 0.0s, total written: 1066401792 bytes
Chunk 1018 of 2097152 took: 0.0s, total written: 1067450368 bytes
Chunk 1019 of 2097152 took: 0.0s, total written: 1068498944 bytes
Chunk 1020 of 2097152 took: 0.0s, total written: 1069547520 bytes
Chunk 1021 of 2097152 took: 0.001s, total written: 1070596096 bytes
Chunk 1022 of 2097152 took: 0.0s, total written: 1071644672 bytes
Chunk 1023 of 2097152 took: 0.001s, total written: 1072693248 bytes
Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Requested array size exceeds VM limit
        at java.util.Arrays.copyOf(Arrays.java:2271)
        at java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:113)
        at java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)
        at java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:140)
        at TestByteArray.main(TestByteArray.java:11)</pre></td></tr></table></div>

") (wfw:commentRss nil "http://the-paper-trail.org/blog/535/feed/") (slash:comments nil "0"))) ("On Raft, briefly" "<p><a href=\"https://ramcloud.stanford.edu/wiki/download/attachments/11370504/raft.pdf\">Raft</a> is a new-ish consensus implementation whose great benefit, to my mind it, is its applicability for real systems. We briefly discussed it internally at Cloudera, and I thought I’d share what I contributed, below. There’s an underlying theme here regarding the role of distributed systems research in practitioners’ daily work, and how the act of building a distributed system has not yet been sufficiently well commoditised to render a familiarity with the original research unnecessary. I think I’d argue that bridging that gap further is necessary: no matter how much fun it is to read all these papers, it shouldn’t be a pre-requisite to being successful in implementing a distributed system. I have more to write on this.</p><blockquote>“The trouble with Paxos is that it’s ‘only’ a consensus algorithm; a theoretical achievement but not one necessarily suited to building practical systems. Remember that the demonstration that a correct, message-optimal protocol even existed was the main contribution. To that end, a lot of practical considerations were left by the wayside. Leader election is an exercise for the reader (since Paxos is robust to bad implementations where there are several leaders, it doesn’t matter what election scheme is used). Paxos is not concerned with ‘logs’ at all; that it can be used to build replicated-state machines with durable logs is a corollary, not the main theorem.
Raft fills in a ton of these gaps, and more power to them for doing so. The leader election algorithm is set in stone. There are additional constraints to ensure that updates are seen and processed in hole-free order (Paxos doesn’t guarantee this), which is exactly what you want from a distributed log. Raft also specifies a view-change algorithm, which Paxos does not, but VS replication does. The huge effort required to get <a href=\"https://issues.apache.org/jira/browse/ZOOKEEPER-107\">ZOOKEEPER-107</a> committed shows how hard this is to retrofit onto an existing system.
So: there’s a tendency to conflate ‘distributed replicated <blah> with strong consistency properties’ with ‘consensus algorithm’. Consensus shows you can agree on a single value, multi-Paxos shows you can agree on a bunch of them, but neither give you a complete system for a replicated log which is actually what most of our distributed systems want to interact with.”</blockquote>" "http://the-paper-trail.org/blog/on-raft-briefly/" (21106 43415) new 3 nil nil ((title nil "On Raft, briefly") (link nil "http://the-paper-trail.org/blog/on-raft-briefly/") (comments nil "http://the-paper-trail.org/blog/on-raft-briefly/#comments") (pubDate nil "Thu, 31 Oct 2013 19:03:51 +0000") (dc:creator nil "Henry") (category nil "Uncategorized") (guid ((isPermaLink . "false")) "http://the-paper-trail.org/blog/?p=528") (description nil "Raft is a new-ish consensus implementation whose great benefit, to my mind it, is its applicability for real systems. We briefly discussed it internally at Cloudera, and I thought I&#8217;d share what I contributed, below. There&#8217;s an underlying theme here regarding the role of distributed systems research in practitioners&#8217; daily work, and how the act [&#8230;]") (content:encoded nil "<p><a href=\"https://ramcloud.stanford.edu/wiki/download/attachments/11370504/raft.pdf\">Raft</a> is a new-ish consensus implementation whose great benefit, to my mind it, is its applicability for real systems. We briefly discussed it internally at Cloudera, and I thought I&#8217;d share what I contributed, below. There&#8217;s an underlying theme here regarding the role of distributed systems research in practitioners&#8217; daily work, and how the act of building a distributed system has not yet been sufficiently well commoditised to render a familiarity with the original research unnecessary. I think I&#8217;d argue that bridging that gap further is necessary: no matter how much fun it is to read all these papers, it shouldn&#8217;t be a pre-requisite to being successful in implementing a distributed system. I have more to write on this.</p><blockquote>&#8220;The trouble with Paxos is that it&#8217;s &#8216;only&#8217; a consensus algorithm; a theoretical achievement but not one necessarily suited to building practical systems. Remember that the demonstration that a correct, message-optimal protocol even existed was the main contribution. To that end, a lot of practical considerations were left by the wayside. Leader election is an exercise for the reader (since Paxos is robust to bad implementations where there are several leaders, it doesn&#8217;t matter what election scheme is used). Paxos is not concerned with &#8216;logs&#8217; at all; that it can be used to build replicated-state machines with durable logs is a corollary, not the main theorem. 

Raft fills in a ton of these gaps, and more power to them for doing so. The leader election algorithm is set in stone. There are additional constraints to ensure that updates are seen and processed in hole-free order (Paxos doesn&#8217;t guarantee this), which is exactly what you want from a distributed log. Raft also specifies a view-change algorithm, which Paxos does not, but VS replication does. The huge effort required to get <a href=\"https://issues.apache.org/jira/browse/ZOOKEEPER-107\">ZOOKEEPER-107</a> committed shows how hard this is to retrofit onto an existing system.

So: there&#8217;s a tendency to conflate &#8216;distributed replicated <blah> with strong consistency properties&#8217; with &#8216;consensus algorithm&#8217;. Consensus shows you can agree on a single value, multi-Paxos shows you can agree on a bunch of them, but neither give you a complete system for a replicated log which is actually what most of our distributed systems want to interact with.&#8221;</blockquote>
") (wfw:commentRss nil "http://the-paper-trail.org/blog/on-raft-briefly/feed/") (slash:comments nil "1"))) ("Some miscellanea" "<h4>CAP FAQ</h4><p>I wrote an FAQ on <a href=\"http://henryr.github.io/cap-faq/\">The CAP Theorem</a></strong>. The aim is to definitively settle some of the common misconceptions around CAP so as to help prevent its invocation in useless places. If someone says they got around CAP, refer them to the FAQ. It should be a pretty simple introduction to the theorem as well. I think that CAP itself is a pretty uninteresting result, but it does at least shine a light on tradeoffs implicit in distributed systems. I have a couple of residual thoughts about failures rather than partitions that I might write up at some point in the future, but otherwise I hope the FAQ helps move the conversation on.</p><h4>Impala and aggregation trees</h4><p>I also wrote a quick answer on <a href=\"http://qr.ae/pyS1G\">Quora</a> about Impala’s execution trees, and how deeper trees help do aggregation more effectively. There’s a lot more of interest to write about planning, partitioning and scheduling queries.</p><h4>Not so HotOS</h4><p>Matt Welsh talks about <a href=\"http://matt-welsh.blogspot.com/2013/05/what-i-wish-systems-researchers-would.html\">what he wishes systems researchers would work on</a>. I partially agree: there are few papers in the <a href=\"https://www.usenix.org/conference/hotos13/tech-schedule/technical-sessions\">HotOS 2013 program</a> that pass the “if this were true, a lot of our assumptions would be wrong” test. I don’t think that IO is an unworthy topic however, but the main problem with improving IO interfaces is inertia rather than want for better ideas. I hope that SSDs and / or flash-as-RAM will be forcing functions here. Otherwise his big topics are all worthy research challenges, but I have always seen HotOS as a venue for new ideas, not new topics – despite its name. If it really were intended to be a venue for the fashionable areas of study in systems it would have much less potential value.</p><h4>Building distributed systems</h4><p>Andy Gross (Basho VP Eng) gave a <a href=\"https://speakerdeck.com/argv0/lessons-learned-and-questions-raised-from-building-distributed-systems\">closing keynote</a> calling for more reusable primitives in distributed systems. I couldn’t agree more (and have been gently complaining about this for years to anyone who would listen), although I think doing this right is not straightforward and requires a lot of careful thought about RPC mechanisms, libraries vs. services and much more. I have some thoughts on this that I want to wrap up in a blog post sometime soon.</p><h4>Highly available transactions</h4><p>Peter Bailis, a Berkeley PhD candidate, has some solid work on <a href=\"http://www.bailis.org/blog/when-is-acid-acid-rarely/\">Highly Available Transactions</a>, based on exploring the space of consistency models available to databases and finding that there are demonstrably useful consistency guarantees that can be made when availability is kept high. This is the right way to move on from all the CAP arguments – given that we are stuck with certain impossibility results, let’s map out the vast terrain that we <i>can</i> conquer.</p>" "http://the-paper-trail.org/blog/some-miscellanea/" (20889 46893) new 4 nil nil ((title nil "Some miscellanea") (link nil "http://the-paper-trail.org/blog/some-miscellanea/") (comments nil "http://the-paper-trail.org/blog/some-miscellanea/#comments") (pubDate nil "Mon, 20 May 2013 05:39:57 +0000") (dc:creator nil "Henry") (category nil "Distributed systems") (category nil "link") (category nil "Note") (guid ((isPermaLink . "false")) "http://the-paper-trail.org/blog/?p=510") (description nil "CAP FAQ I wrote an FAQ on The CAP Theorem. The aim is to definitively settle some of the common misconceptions around CAP so as to help prevent its invocation in useless places. If someone says they got around CAP, refer them to the FAQ. It should be a pretty simple introduction to the theorem [&#8230;]") (content:encoded nil "<h4>CAP FAQ</h4><p>I wrote an FAQ on <a href=\"http://henryr.github.io/cap-faq/\">The CAP Theorem</a></strong>. The aim is to definitively settle some of the common misconceptions around CAP so as to help prevent its invocation in useless places. If someone says they got around CAP, refer them to the FAQ. It should be a pretty simple introduction to the theorem as well. I think that CAP itself is a pretty uninteresting result, but it does at least shine a light on tradeoffs implicit in distributed systems. I have a couple of residual thoughts about failures rather than partitions that I might write up at some point in the future, but otherwise I hope the FAQ helps move the conversation on.</p><h4>Impala and aggregation trees</h4><p>I also wrote a quick answer on <a href=\"http://qr.ae/pyS1G\">Quora</a> about Impala&#8217;s execution trees, and how deeper trees help do aggregation more effectively. There&#8217;s a lot more of interest to write about planning, partitioning and scheduling queries.</p><h4>Not so HotOS</h4><p>Matt Welsh talks about <a href=\"http://matt-welsh.blogspot.com/2013/05/what-i-wish-systems-researchers-would.html\">what he wishes systems researchers would work on</a>. I partially agree: there are few papers in the <a href=\"https://www.usenix.org/conference/hotos13/tech-schedule/technical-sessions\">HotOS 2013 program</a> that pass the &#8220;if this were true, a lot of our assumptions would be wrong&#8221; test. I don&#8217;t think that IO is an unworthy topic however, but the main problem with improving IO interfaces is inertia rather than want for better ideas. I hope that SSDs and / or flash-as-RAM will be forcing functions here. Otherwise his big topics are all worthy research challenges, but I have always seen HotOS as a venue for new ideas, not new topics &#8211; despite its name. If it really were intended to be a venue for the fashionable areas of study in systems it would have much less potential value.</p><h4>Building distributed systems</h4><p>Andy Gross (Basho VP Eng) gave a <a href=\"https://speakerdeck.com/argv0/lessons-learned-and-questions-raised-from-building-distributed-systems\">closing keynote</a> calling for more reusable primitives in distributed systems. I couldn&#8217;t agree more (and have been gently complaining about this for years to anyone who would listen), although I think doing this right is not straightforward and requires a lot of careful thought about RPC mechanisms, libraries vs. services and much more. I have some thoughts on this that I want to wrap up in a blog post sometime soon.</p><h4>Highly available transactions</h4><p>Peter Bailis, a Berkeley PhD candidate, has some solid work on <a href=\"http://www.bailis.org/blog/when-is-acid-acid-rarely/\">Highly Available Transactions</a>, based on exploring the space of consistency models available to databases and finding that there are demonstrably useful consistency guarantees that can be made when availability is kept high. This is the right way to move on from all the CAP arguments &#8211; given that we are stuck with certain impossibility results, let&#8217;s map out the vast terrain that we <i>can</i> conquer.</p>
") (wfw:commentRss nil "http://the-paper-trail.org/blog/some-miscellanea/feed/") (slash:comments nil "0"))) ("Columnar Storage" "<p><em>You’re going to hear a lot about columnar storage formats in the next few months, as a variety of distributed execution engines are beginning to consider them for their IO efficiency, and the optimisations that they open up for query execution. In this post, I’ll explain why we care so much about IO efficiency and show how columnar storage – which is a simple idea – can drastically improve performance for certain workloads.</p><p>Caveat: This is a personal, general research summary post, and as usual doesn’t neccessarily reflect our thinking at Cloudera about columnar storage.</em></p><p>Disks are still the major bottleneck in query execution over large datasets. Even a machine with twelve disks running in parallel (for an aggregate bandwidth of north of 1GB/s) can’t keep all the cores busy; running a query against memory-cached data can get tens of GB/s of throughput. IO bandwidth matters. Therefore, the best thing an engineer can do to improve the performance of disk-based query engines (like RDBMs and Impala) usually is to improve the performance of reading bytes from disk. This can mean decreasing the latency (for small queries where the time to find the data to read might dominate), but most usually this means improving the effective throughput of reads from disk.</p><p>The traditional way to improve disk bandwidth has been to wait, and allow disks to get faster. However, disks are not getting faster very quickly (having settled at roughly 100 MB/s, with ~12 disks per server), and SSDs can’t yet achieve the storage density to be directly competitive with HDDs on a per-server basis.</p><p>The other way to improve disk performance is to maximise the ratio of ‘useful’ bytes read to total bytes read. The idea is not to read more data than is absolutely necessary to serve a query, so the useful bandwidth realised is increased without actually improving the performance of the IO subsystem. Enter <em>columnar storage</em>, a principle for file format design that aims to do exactly that for query engines that deal with record-based data.</p><p><span id=\"more-452\"></span></p><p>&lt;</p><p>h2>Columns vs. Rows</h3></p><p>Traditional database file format store data in rows, where each row is comprised of a contiguous collection of column values. On disk, that looks roughly like the following:</p><p><a href=\"http://the-paper-trail.org/blog/wp-content/uploads/2013/01/row-major-formats.png\"><img src=\"http://the-paper-trail.org/blog/wp-content/uploads/2013/01/row-major-formats.png\" alt=\"Row-major On-disk Layout\" width=\"588\" height=\"267\" class=\"aligncenter size-full wp-image-482\" /></a></p><p>This <em>row-major</em> layout usually has a header for each row that describes, for example, which columns in the row are NULL. Each column value is then stored contiguously after the header, followed by another row with its own header, and so on.</p><p>Both HDDs and SSDs are at their most efficient when reading data sequentially from disk (for HDDs the benefits are particularly pronounced). In fact, even a read of a few bytes usually brings in an entire block of 4096 bytes from disk, because it is effectively the same cost to read (and the operating system usually deals with data in 4k page-sized chunks). For row-major formats it’s therefore most efficient to read entire rows at a time.</p><p>Queries that do full table-scans – i.e. those that don’t take advantage of any kind of indexing and need to visit every row – are common in analytical workloads; with row-major formats a full scan of a table will read every single byte of the table from disk. For certain queries, this is appropriate. Trivially, <tt>SELECT * FROM table</tt> requires returning every single column of every single row in the table, and so the IO costs for executing that query on a row-major format are a single-seek and a single large contiguous read (although that is likely to be broken up for pipelining purposes). The read is unavoidable, as is the single seek; therefore row-major formats allow for optimal IO usage. More generally, <tt>SELECT &lt;col_set&gt; FROM table WHERE &lt;predicate_set&gt;</tt> will be relatively efficient for row-major formats if either a) evaluating the <tt>predicate_set</tt> requires reading a large subset of the set of columns or b) <tt>col_set</tt> is a large subset of the set of columns (i.e. the <em>projectivity</em> is high) and the set of rows returned by the evaluation of the predicates over the table is a large proportion of the total set of rows (i.e. the <em>selectivity</em> is high). More simply, a query is going to be efficient if it requires reading most of the columns of most of the rows. In these cases, row-major formats allow the query execution engine to achieve good IO efficiency.</p><p>However, there is a general consensus that these <tt>SELECT *</tt> kinds of queries are not  representative of typical analytical workloads; instead either a large number of columns are not projected, or they are projected only for a small subset of rows where only a few columns are required to decide which rows to return. Coupled with a general trend towards very wide tables with high column counts, the total number of bytes that are required to satisfy a query are often a relatively small fraction of the size on disk of the target table. In these cases, row-major formats often are quite wasteful in the amount of IO they require to execute a query.</p><p>Instead of a format that makes it efficient to read entire rows, it’s advantageous for analytical workloads to make it efficient to read entire <em>columns</em> at once. Based on our understanding of what makes disks efficient, we can see that the obvious approach is to store columns values densely and contiguously on disk. This is the basic idea behind columnar file formats. The following diagram shows what this looks like on disk:</p><p><a href=\"http://the-paper-trail.org/blog/wp-content/uploads/2013/01/column-major-formats.png\"><img src=\"http://the-paper-trail.org/blog/wp-content/uploads/2013/01/column-major-formats.png\" alt=\"Column-Major On-disk Layout\" width=\"588\" height=\"474\" class=\"aligncenter size-full wp-image-481\" /></a></p><p>A row is split across several column blocks, which may even be separate files on disk. Reading an entire column now requires a single seek plus a large contiguous read, but the read length is much less than for extracting a single column from a row-major format. In this figure we have organised the columns so that they are all ordered in the same way; later we’ll see how we can relax that restriction and use different orderings to make different queries more efficient.</p><h2>Query Execution</h2><p>The diagram below shows what a simple query plan for <tt>SELECT col_b FROM table WHERE col_a > 5</tt> might look like for a query engine reading from a traditional row-major file format. A scan node reads every row in turn from disk, and streams the rows to a predicate evaluation node, which looks at the value of <tt>col_a</tt> in each row. Those rows that pass the predicate are sent to a projection node which constructs result tuples containing <tt>col_b</tt>.</p><p><a href=\"http://the-paper-trail.org/blog/wp-content/uploads/2013/01/row-query-plan.png\"><img src=\"http://the-paper-trail.org/blog/wp-content/uploads/2013/01/row-query-plan.png\" alt=\"Row Query Plan\" width=\"549\" height=\"137\" class=\"aligncenter size-full wp-image-487\" /></a></p><p>Compare that to the query plan below, for a query engine reading from columnar storage. Each column referenced in the query is read independently. The predicate is evaluated over <tt>col_a</tt> to produce a list of matching row IDs. <tt>col_b</tt> is then scanned with respect to that list of IDs, and each matching value is returned as a query result. This query plan performs two IO seeks (to find the beginning of both column files), instead of one, and issues two consecutive reads rather than one large read. The pattern of using IDs for each column value is very common to make reconstructing rows easier; usually columns are all sorted on the same key so the Nth value of <tt>col_a</tt> belongs to the same row as the Nth value of <tt>col_b</tt>.</p><p><a href=\"http://the-paper-trail.org/blog/wp-content/uploads/2013/01/columnar-query-plan.png\"><img src=\"http://the-paper-trail.org/blog/wp-content/uploads/2013/01/columnar-query-plan.png\" alt=\"Columnar Query Plan\" width=\"497\" height=\"137\" class=\"aligncenter size-full wp-image-478\" /></a></p><p>The extra IO cost for the row-format query is therefore the time it takes to read all those extra columns. Let’s assume the table is 10 columns wide, ten million rows long and each value is 4 bytes, which are all conservative estimates. Then there is an extra 8 * 1M * 4 bytes, or 32MB of extra data read, which is ~3.20s on a query that would likely otherwise take 800ms; an overhead of 300%. When disks are less performant, or column widths wider, the effect becomes exaggerated.</p><p>This, then, is the basic idea of columnar storage: we recognise that analytical workloads rarely require full scans of all table data, but do often require full scans of a small subset of the columns, and so we arrange to make column scans cheap at the expense of extra cost reading individual rows.</p><h2>The Cost of Columnar</h2><p>Is this a free lunch? Should every analytical database go out and change every file format to be column-major? Obviously the story is more complicated than that. There are some query archetypes that suffer when data is stored in a columnar format.</p><p>The obvious drawback is that it is expensive to reassemble a row, since the separate values that comprise it are spread far across the disk. Every column included in a projection implies an extra disk seek, and this can add up when the projectivity of a query is high. Therefore, for highly projective queries, row-major formats can be more efficient (and therefore columnar formats are not strictly better than row-major storage even from a pure IO perspective).</p><p>There are more subtle repurcussions of each row being scattered across the disk. When a row-major format is read into memory, and ultimately into CPU cache, it is in a format that permits cheap reference to multiple columns at a time. Row-major formats have good in-memory spatial locality, and there are common operations that benefit enormously from this.</p><p>For example, a query that selects the sum of two columns can sometimes be executed (once the data is in memory) faster on row-major formats, since the columns are almost always in the same cache line for each row. Columnar representations are less well suited; each column must be brought into memory at the same time and moved through in lockstep (yet this is still not cache efficient if each column is ordered differently), or the initial column must be scanned, each value buffered and then the second column scanned separately to complete the half-finished output tuple.</p><p>The same general problem arises when preparing each tuple to write out as a result of (non-aggregating) query. Selecting several columns at once requires ‘row reconstruction’ at some point in the query lifecycle. Deciding when to do this is a complicated process, and (as we shall see) the literature has not yet developed a good rule of thumb. Many databases are row-major internally, and therefore a columnar format is transposed into a row-major one relatively early in the scanning process. As described above, this can require buffering half-constructed tuples in memory. For this reason, columnar formats are often partiioned into ‘row-groups’; each column chunk N contains rows (K*N) to ((K+1) * N). This reduces the amount of buffering required, at the cost of a few more disk seeks.</p><h2>Further Aspects of Columnar Storage</h2><h4>Fully column-oriented execution engines</h4><p><em>Relevant papers:
<a href=\"http://people.csail.mit.edu/tdanford/6830papers/stonebraker-cstore.pdf\">C-Store: A Column-oriented DBMS</a><a href=\"http://vldb.org/pvldb/vol5/p1790_andrewlamb_vldb2012.pdf\">The Vertica Analytic Database: C-Store 7 Years Later</a><a href=\"http://db.lcs.mit.edu/projects/cstore/abadiicde2007.pdf\">Materialization Strategies in a Column-Oriented DBMS</a><a href=\"http://db.csail.mit.edu/projects/cstore/VLDB06.pdf\">Performance Tradeoffs in Read-Optimized Databases</a><a href=\"http://db.csail.mit.edu/projects/cstore/abadi-sigmod08.pdf\">Column-Stores vs. Row-Stores: How Different Are They Really?</a></em>
In this post, I’ve talked mostly about the benefits of columnar storage for scans – query operators that read data from disk, but whose ultimate output is a batch of rows for the rest of the query plan to operate on. In fact, columnar data can be integrated into pretty much every operator in a query execution engine. C-Store, the research project precursor to Vertica, explored a lot of the consequences of keeping data in columns until later on in the query plan. Eventually, of course, the columns have to be converted to rows, since the user expects a result in row-major format. The choice of when to perform this conversion is called <em>late or early materialisation</em>; viewed this way column-stores and row-stores can be considered two points on a spectrum of early to late materialisation strategies. Materialisation is studied in detail in the materialisation strategies paper above. Their conclusions are that the correct time to construct a tuple depends on the query plan (two broad patterns are considered: pipelining and parallel scans) and the query selectivity. Unfortunately, supporting both strategies would involve significant implementation cost – each operator would have to support two interfaces, and two parallel execution engines would effectively be frankensteined together. In general, late materialisation can lead to significant advantages: for example, by delaying the cost of reconstructing a tuple, it can be avoided if the tuple is ultimately filtered out by a predicate.</p><p>The difference between row-based and columnar execution engines is studied in the <em>Performance Tradeoffs…</em> and <em>Column-Stores vs. Row-Stores…</em> papers. The former takes a detailed look at when each strategy is superior – coming out in favour mostly of column-stores, but only with simple queries and basic query plans. The latter tries to implement common column-store optimisations in a traditional row-store, without changing the code. This means a number of increasingly brittle hacks to emulate columnar storage.</p><h4>Compression</h4><p><em>Relevant papers:
<a href=\"http://db.lcs.mit.edu/projects/cstore/abadisigmod06.pdf\">Integrating Compression and Execution on Column-Oriented Database Systems</a></em></p><p>A column of values drawn from the same set (like item price, say) is likely to be highly amenable to compression since the values contained are similar, and often identical. Compressing a column has at least two significant advantages on IO cost: less space is required on disk, and less IO required to bring a column into memory (at the cost of some CPU to decompress which is usually going spare). Some compression formats – for example run-length encoding – allow execution engines to operate on the compressed data directly, filtering large chunks at a time without first decompressing them. This is another advantage of late materialisation – by keeping the data compressed until late in the query plan, these optimisations become available to many operators, not just the scan.</p><h4>Hybrid approaches</h4><p><em>Relevant papers:
<a href=\"http://www.vldb.org/conf/2001/P169.pdf\">Weaving Relations for Cache Performance</a></em>
Since neither row-major nor column-major is strictly superior on every workload, it’s natural that some research has been done into hybrid approaches that can achieve the best of both worlds. The most commonly known approach is PAX – Partition Attributes Across – which splits the table into page-sized groups of rows, and inside those groups formats the rows in column-major order. This is the same approach as the row-groups used to prevent excessive buffering described earlier, but this is not the aim of PAX; with PAX the original intention was to make CPU processing more efficient by having individual columns available contiguously to perform filtering, but also to have all the columns for a particular row nearby inside a group to make tuple reconstruction cheaper. The result of this approach is that IO costs don’t go down (because each row-group is only a page long, and is therefore read in its entirety), but reconstruction and filtering is cheaper than for true columnar formats.</p>" "http://the-paper-trail.org/blog/columnar-storage/" (20745 59671) new 5 nil nil ((title nil "Columnar Storage") (link nil "http://the-paper-trail.org/blog/columnar-storage/") (comments nil "http://the-paper-trail.org/blog/columnar-storage/#comments") (pubDate nil "Thu, 31 Jan 2013 03:46:31 +0000") (dc:creator nil "Henry") (category nil "Databases") (guid ((isPermaLink . "false")) "http://the-paper-trail.org/blog/?p=452") (description nil "You&#8217;re going to hear a lot about columnar storage formats in the next few months, as a variety of distributed execution engines are beginning to consider them for their IO efficiency, and the optimisations that they open up for query execution. In this post, I&#8217;ll explain why we care so much about IO efficiency and [&#8230;]") (content:encoded nil "<p><em>You&#8217;re going to hear a lot about columnar storage formats in the next few months, as a variety of distributed execution engines are beginning to consider them for their IO efficiency, and the optimisations that they open up for query execution. In this post, I&#8217;ll explain why we care so much about IO efficiency and show how columnar storage &#8211; which is a simple idea &#8211; can drastically improve performance for certain workloads.</p><p>Caveat: This is a personal, general research summary post, and as usual doesn&#8217;t neccessarily reflect our thinking at Cloudera about columnar storage.</em></p><p>Disks are still the major bottleneck in query execution over large datasets. Even a machine with twelve disks running in parallel (for an aggregate bandwidth of north of 1GB/s) can&#8217;t keep all the cores busy; running a query against memory-cached data can get tens of GB/s of throughput. IO bandwidth matters. Therefore, the best thing an engineer can do to improve the performance of disk-based query engines (like RDBMs and Impala) usually is to improve the performance of reading bytes from disk. This can mean decreasing the latency (for small queries where the time to find the data to read might dominate), but most usually this means improving the effective throughput of reads from disk.</p><p>The traditional way to improve disk bandwidth has been to wait, and allow disks to get faster. However, disks are not getting faster very quickly (having settled at roughly 100 MB/s, with ~12 disks per server), and SSDs can&#8217;t yet achieve the storage density to be directly competitive with HDDs on a per-server basis.</p><p>The other way to improve disk performance is to maximise the ratio of &#8216;useful&#8217; bytes read to total bytes read. The idea is not to read more data than is absolutely necessary to serve a query, so the useful bandwidth realised is increased without actually improving the performance of the IO subsystem. Enter <em>columnar storage</em>, a principle for file format design that aims to do exactly that for query engines that deal with record-based data.</p><p><span id=\"more-452\"></span></p><p>&lt;</p><p>h2>Columns vs. Rows</h3></p><p>Traditional database file format store data in rows, where each row is comprised of a contiguous collection of column values. On disk, that looks roughly like the following:</p><p><a href=\"http://the-paper-trail.org/blog/wp-content/uploads/2013/01/row-major-formats.png\"><img src=\"http://the-paper-trail.org/blog/wp-content/uploads/2013/01/row-major-formats.png\" alt=\"Row-major On-disk Layout\" width=\"588\" height=\"267\" class=\"aligncenter size-full wp-image-482\" /></a></p><p>This <em>row-major</em> layout usually has a header for each row that describes, for example, which columns in the row are NULL. Each column value is then stored contiguously after the header, followed by another row with its own header, and so on.</p><p>Both HDDs and SSDs are at their most efficient when reading data sequentially from disk (for HDDs the benefits are particularly pronounced). In fact, even a read of a few bytes usually brings in an entire block of 4096 bytes from disk, because it is effectively the same cost to read (and the operating system usually deals with data in 4k page-sized chunks). For row-major formats it&#8217;s therefore most efficient to read entire rows at a time.</p><p>Queries that do full table-scans &#8211; i.e. those that don&#8217;t take advantage of any kind of indexing and need to visit every row &#8211; are common in analytical workloads; with row-major formats a full scan of a table will read every single byte of the table from disk. For certain queries, this is appropriate. Trivially, <tt>SELECT * FROM table</tt> requires returning every single column of every single row in the table, and so the IO costs for executing that query on a row-major format are a single-seek and a single large contiguous read (although that is likely to be broken up for pipelining purposes). The read is unavoidable, as is the single seek; therefore row-major formats allow for optimal IO usage. More generally, <tt>SELECT &lt;col_set&gt; FROM table WHERE &lt;predicate_set&gt;</tt> will be relatively efficient for row-major formats if either a) evaluating the <tt>predicate_set</tt> requires reading a large subset of the set of columns or b) <tt>col_set</tt> is a large subset of the set of columns (i.e. the <em>projectivity</em> is high) and the set of rows returned by the evaluation of the predicates over the table is a large proportion of the total set of rows (i.e. the <em>selectivity</em> is high). More simply, a query is going to be efficient if it requires reading most of the columns of most of the rows. In these cases, row-major formats allow the query execution engine to achieve good IO efficiency.</p><p>However, there is a general consensus that these <tt>SELECT *</tt> kinds of queries are not  representative of typical analytical workloads; instead either a large number of columns are not projected, or they are projected only for a small subset of rows where only a few columns are required to decide which rows to return. Coupled with a general trend towards very wide tables with high column counts, the total number of bytes that are required to satisfy a query are often a relatively small fraction of the size on disk of the target table. In these cases, row-major formats often are quite wasteful in the amount of IO they require to execute a query.</p><p>Instead of a format that makes it efficient to read entire rows, it&#8217;s advantageous for analytical workloads to make it efficient to read entire <em>columns</em> at once. Based on our understanding of what makes disks efficient, we can see that the obvious approach is to store columns values densely and contiguously on disk. This is the basic idea behind columnar file formats. The following diagram shows what this looks like on disk:</p><p><a href=\"http://the-paper-trail.org/blog/wp-content/uploads/2013/01/column-major-formats.png\"><img src=\"http://the-paper-trail.org/blog/wp-content/uploads/2013/01/column-major-formats.png\" alt=\"Column-Major On-disk Layout\" width=\"588\" height=\"474\" class=\"aligncenter size-full wp-image-481\" /></a></p><p>A row is split across several column blocks, which may even be separate files on disk. Reading an entire column now requires a single seek plus a large contiguous read, but the read length is much less than for extracting a single column from a row-major format. In this figure we have organised the columns so that they are all ordered in the same way; later we&#8217;ll see how we can relax that restriction and use different orderings to make different queries more efficient.</p><h2>Query Execution</h2><p>The diagram below shows what a simple query plan for <tt>SELECT col_b FROM table WHERE col_a > 5</tt> might look like for a query engine reading from a traditional row-major file format. A scan node reads every row in turn from disk, and streams the rows to a predicate evaluation node, which looks at the value of <tt>col_a</tt> in each row. Those rows that pass the predicate are sent to a projection node which constructs result tuples containing <tt>col_b</tt>.</p><p><a href=\"http://the-paper-trail.org/blog/wp-content/uploads/2013/01/row-query-plan.png\"><img src=\"http://the-paper-trail.org/blog/wp-content/uploads/2013/01/row-query-plan.png\" alt=\"Row Query Plan\" width=\"549\" height=\"137\" class=\"aligncenter size-full wp-image-487\" /></a></p><p>Compare that to the query plan below, for a query engine reading from columnar storage. Each column referenced in the query is read independently. The predicate is evaluated over <tt>col_a</tt> to produce a list of matching row IDs. <tt>col_b</tt> is then scanned with respect to that list of IDs, and each matching value is returned as a query result. This query plan performs two IO seeks (to find the beginning of both column files), instead of one, and issues two consecutive reads rather than one large read. The pattern of using IDs for each column value is very common to make reconstructing rows easier; usually columns are all sorted on the same key so the Nth value of <tt>col_a</tt> belongs to the same row as the Nth value of <tt>col_b</tt>.</p><p><a href=\"http://the-paper-trail.org/blog/wp-content/uploads/2013/01/columnar-query-plan.png\"><img src=\"http://the-paper-trail.org/blog/wp-content/uploads/2013/01/columnar-query-plan.png\" alt=\"Columnar Query Plan\" width=\"497\" height=\"137\" class=\"aligncenter size-full wp-image-478\" /></a></p><p>The extra IO cost for the row-format query is therefore the time it takes to read all those extra columns. Let&#8217;s assume the table is 10 columns wide, ten million rows long and each value is 4 bytes, which are all conservative estimates. Then there is an extra 8 * 1M * 4 bytes, or 32MB of extra data read, which is ~3.20s on a query that would likely otherwise take 800ms; an overhead of 300%. When disks are less performant, or column widths wider, the effect becomes exaggerated.</p><p>This, then, is the basic idea of columnar storage: we recognise that analytical workloads rarely require full scans of all table data, but do often require full scans of a small subset of the columns, and so we arrange to make column scans cheap at the expense of extra cost reading individual rows.</p><h2>The Cost of Columnar</h2><p>Is this a free lunch? Should every analytical database go out and change every file format to be column-major? Obviously the story is more complicated than that. There are some query archetypes that suffer when data is stored in a columnar format.</p><p>The obvious drawback is that it is expensive to reassemble a row, since the separate values that comprise it are spread far across the disk. Every column included in a projection implies an extra disk seek, and this can add up when the projectivity of a query is high. Therefore, for highly projective queries, row-major formats can be more efficient (and therefore columnar formats are not strictly better than row-major storage even from a pure IO perspective).</p><p>There are more subtle repurcussions of each row being scattered across the disk. When a row-major format is read into memory, and ultimately into CPU cache, it is in a format that permits cheap reference to multiple columns at a time. Row-major formats have good in-memory spatial locality, and there are common operations that benefit enormously from this.</p><p>For example, a query that selects the sum of two columns can sometimes be executed (once the data is in memory) faster on row-major formats, since the columns are almost always in the same cache line for each row. Columnar representations are less well suited; each column must be brought into memory at the same time and moved through in lockstep (yet this is still not cache efficient if each column is ordered differently), or the initial column must be scanned, each value buffered and then the second column scanned separately to complete the half-finished output tuple.</p><p>The same general problem arises when preparing each tuple to write out as a result of (non-aggregating) query. Selecting several columns at once requires &#8216;row reconstruction&#8217; at some point in the query lifecycle. Deciding when to do this is a complicated process, and (as we shall see) the literature has not yet developed a good rule of thumb. Many databases are row-major internally, and therefore a columnar format is transposed into a row-major one relatively early in the scanning process. As described above, this can require buffering half-constructed tuples in memory. For this reason, columnar formats are often partiioned into &#8216;row-groups&#8217;; each column chunk N contains rows (K*N) to ((K+1) * N). This reduces the amount of buffering required, at the cost of a few more disk seeks.</p><h2>Further Aspects of Columnar Storage</h2><h4>Fully column-oriented execution engines</h4><p><em>Relevant papers:
  <a href=\"http://people.csail.mit.edu/tdanford/6830papers/stonebraker-cstore.pdf\">C-Store: A Column-oriented DBMS</a><a href=\"http://vldb.org/pvldb/vol5/p1790_andrewlamb_vldb2012.pdf\">The Vertica Analytic Database: C-Store 7 Years Later</a><a href=\"http://db.lcs.mit.edu/projects/cstore/abadiicde2007.pdf\">Materialization Strategies in a Column-Oriented DBMS</a><a href=\"http://db.csail.mit.edu/projects/cstore/VLDB06.pdf\">Performance Tradeoffs in Read-Optimized Databases</a><a href=\"http://db.csail.mit.edu/projects/cstore/abadi-sigmod08.pdf\">Column-Stores vs. Row-Stores: How Different Are They Really?</a></em>
In this post, I&#8217;ve talked mostly about the benefits of columnar storage for scans &#8211; query operators that read data from disk, but whose ultimate output is a batch of rows for the rest of the query plan to operate on. In fact, columnar data can be integrated into pretty much every operator in a query execution engine. C-Store, the research project precursor to Vertica, explored a lot of the consequences of keeping data in columns until later on in the query plan. Eventually, of course, the columns have to be converted to rows, since the user expects a result in row-major format. The choice of when to perform this conversion is called <em>late or early materialisation</em>; viewed this way column-stores and row-stores can be considered two points on a spectrum of early to late materialisation strategies. Materialisation is studied in detail in the materialisation strategies paper above. Their conclusions are that the correct time to construct a tuple depends on the query plan (two broad patterns are considered: pipelining and parallel scans) and the query selectivity. Unfortunately, supporting both strategies would involve significant implementation cost &#8211; each operator would have to support two interfaces, and two parallel execution engines would effectively be frankensteined together. In general, late materialisation can lead to significant advantages: for example, by delaying the cost of reconstructing a tuple, it can be avoided if the tuple is ultimately filtered out by a predicate.</p><p>The difference between row-based and columnar execution engines is studied in the <em>Performance Tradeoffs&#8230;</em> and <em>Column-Stores vs. Row-Stores&#8230;</em> papers. The former takes a detailed look at when each strategy is superior &#8211; coming out in favour mostly of column-stores, but only with simple queries and basic query plans. The latter tries to implement common column-store optimisations in a traditional row-store, without changing the code. This means a number of increasingly brittle hacks to emulate columnar storage.</p><h4>Compression</h4><p><em>Relevant papers: 
  <a href=\"http://db.lcs.mit.edu/projects/cstore/abadisigmod06.pdf\">Integrating Compression and Execution on Column-Oriented Database Systems</a></em></p><p>A column of values drawn from the same set (like item price, say) is likely to be highly amenable to compression since the values contained are similar, and often identical. Compressing a column has at least two significant advantages on IO cost: less space is required on disk, and less IO required to bring a column into memory (at the cost of some CPU to decompress which is usually going spare). Some compression formats &#8211; for example run-length encoding &#8211; allow execution engines to operate on the compressed data directly, filtering large chunks at a time without first decompressing them. This is another advantage of late materialisation &#8211; by keeping the data compressed until late in the query plan, these optimisations become available to many operators, not just the scan.</p><h4>Hybrid approaches</h4><p><em>Relevant papers:
  <a href=\"http://www.vldb.org/conf/2001/P169.pdf\">Weaving Relations for Cache Performance</a></em>
Since neither row-major nor column-major is strictly superior on every workload, it&#8217;s natural that some research has been done into hybrid approaches that can achieve the best of both worlds. The most commonly known approach is PAX &#8211; Partition Attributes Across &#8211; which splits the table into page-sized groups of rows, and inside those groups formats the rows in column-major order. This is the same approach as the row-groups used to prevent excessive buffering described earlier, but this is not the aim of PAX; with PAX the original intention was to make CPU processing more efficient by having individual columns available contiguously to perform filtering, but also to have all the columns for a particular row nearby inside a group to make tuple reconstruction cheaper. The result of this approach is that IO costs don&#8217;t go down (because each row-group is only a page long, and is therefore read in its entirety), but reconstruction and filtering is cheaper than for true columnar formats.</p>
") (wfw:commentRss nil "http://the-paper-trail.org/blog/columnar-storage/feed/") (slash:comments nil "5"))) ("Cloudera Impala" "<p><em>If you have a strong background in either databases or distributed systems, and fancy working on such an exciting technology, <a href=\"mailto:henry@cloudera.com\">send me a note!</a></em></p><p>It’s great to finally be able to say something about what I’ve been working at <a href=\"http://www.cloudera.com\">Cloudera</a> for nearly a year. At StrataConf / Hadoop World in New York a couple of weeks ago we announced <a href=\"http://blog.cloudera.com/blog/2012/10/cloudera-impala-real-time-queries-in-apache-hadoop-for-real/\">Cloudera Impala</a>. Impala is a distributed query execution engine that understands a subset of SQL, and critically runs over HDFS and HBase as storage managers. It’s very similar in functionality to Apache Hive, but it is much, much, much (anecdotally up to 100x) faster.
<span id=\"more-438\"></span>
Why do I think this is important? (and bear in mind I’m speaking for myself, not Cloudera here). The way I view what we do at Cloudera is that we’re really participating in a revolution in data storage. The great contribution of the <a href=\"http://research.google.com/archive/gfs.html\">Google</a><a href=\"http://research.google.com/archive/mapreduce.html\">papers</a> was the application of commodity hardware to enterprise problems. Storing your data reliably on commodity servers with relatively cheap hard disks is enabled by the extreme cheapness of storage density (which means that replicating three times for fault-tolerance is suddenly a viable design choice, for example), and this completely changes the cost / benefit equation for data storage. You can have a lot more of it, and you can have it a lot cheaper. This is where the whole ‘big data’ idea arguably springs from – now you can store more data than ever before. What do you do with it?</p><p>Well, you analyse it. But that’s easier said than done. Traditional data analytics platforms are extremely powerful, but rely on an integrated approach – you don’t buy a couple of servers and throw a data warehouse that you downloaded on them, you buy a fully integrated solution that includes hardware and software. The hardware is tuned to the requirements of the software, and the data layout is carefully managed to get great performance on supported queries. This is a very serious platform archetype, and one that I believe will continue to be important to the market, but it’s fundamentally not configured to process data at the scale that the storage substrate now enables, because you would have to move data into the processing platform to do so, which is a very costly proposition. So typically what you do is identify an important subset of your data that requires the full analytics power to your integrated solution, and move that and only that. But that blunts the advantage of keeping all of that data in the first place – if you can only process some of it, why are you keeping all of it?</p><p>This is where Apache Hadoop originally came in. Hadoop shines for heavy-lifting batch-processing jobs that have high tolerance for latency but need to touch most bytes in your dataset. Where it doesn’t shine is for interactive analyses, where a user might be refining the analytic questions they ask iteratively. It’s useless to wait for 30 minutes just to find that you probably should have grouped by a different columns. Similarly, users of popular BI tools will want to construct reports that they can interact with. Impala is the tool for these use cases; by allowing for relatively low-latency queries over the great unwashed masses of your data you get the value of the data coupled with some of the processing power of the integrated engines. We’ve brought some of the execution engine magic of massively-parallel distributed databases to the incredibly flexible storage engine model of HDFS and HBase.</p><p>Technically, of course, this is a complete blast to work on – a large-scale distributed system that does highly non-trivial stuff at each node. Bliss.  Impala’s been the result of the great effort of a small team. That means I’ve written code in lots of different parts of the system. Our <tt>INSERT</tt> support is mostly me, as is our DDL support (we don’t do <tt>CREATE TABLE</tt> yet, but we do <tt>SHOW</tt> / <tt>DESCRIBE</tt> etc.). I also wrote the failure-detection framework that runs on both the state-store (to evict Impala backends that have failed from the current view of cluster membership) and on each Impala backend (to detect when the state-store has failed). In fact there are a ton of things that I’ve been involved with. Some of the most exciting parts of the code base are the query execution engine itself, which compiles query fragments into a highly optimised program fragment via LLVM, although the planner is also a very complex bit of software.</p><p>The source code is available <a href=\"https://github.com/cloudera/impala\">here</a>. At this point, I should acknowledge that the Github repo doesn’t build out of the box, and we haven’t yet provided instructions on how to do so. There’s no great conspiracy behind this, just the annoying consequence of the number of hours in the day being finite. We can’t post the repo exactly as we have it internally at Cloudera for a couple of reasons: we rely on internal infrastructure for some of the build steps which can’t be easily replicated externally, and some of our test suites are customer-confidential. We were rushing (as ever) to get a release out the door, and we made the decision to postpone sorting out the build for the public repo until after the launch. Since that’s… now, I’ve been spending a little time figuring out what we can do. Build systems are not my expertise, and Impala’s is a little capricious due to the extent that we mix C++ (for the execution engine) and Java code (for the planning and metastore interaction). I hope to have something that can build – without tests – by the end of next week, that is by roughly November 9th.</p><p>Otherwise we’re working on our roadmap for moving from the current beta to GA, and I have a long list of bugs and bits of polish that I’m looking forward to getting a few minutes to work on. We have some pretty exciting plans coming up, and it’s going to be great to be able to talk about them a little more publicly.</p><p>From the perspective of this blog, this means I’ve been reading a ton of interesting database papers (I know distributed systems, but I’m only just getting up to speed with all the database literature). That means a good opportunity to restart some of the paper reviews, although I’m even more likely to say something stupid on a less firm technical footing!</p><p>There’s been a whole bunch of buzz about Impala, which has been very gratifying.</p><ul><li><a href=\"http://www.quora.com/Cloudera/Does-Cloudera-Impala-have-any-drawbacks-when-compared-with-Hive\">These</a><a href=\"http://www.quora.com/Cloudera-Impala/Is-Impala-aiming-to-be-an-open-source-alternative-to-existing-MPP-solutions\">questions</a><a href=\"http://www.quora.com/Cloudera-Impala/How-does-Cloudera-Impala-compare-to-Vertica\">at</a><a href=\"http://www.quora.com/Cloudera-Impala/How-does-Cloudera-Impala-compare-to-Hadapt\">Quora</a> about how Impala compares to similar systems (including <a href=\"http://www.quora.com/Cloudera-Impala/Isnt-Cloudera-Impala-doing-the-same-job-as-Apache-Drill-incubator-project\">my answer about Apache Drill</a>)</li><li>Curt Monash has a <a href=\"http://www.dbms2.com/2012/11/01/more-on-cloudera-impala/\">writeup</a> (although he does make it sound like no query will return in under one second, which isn’t the case – query start-up latency is very important to us since that’s an area we can get a huge gain over Hive’s Hadoop implementation; in the case of a simple <tt>SELECT 1</tt> the query should return in ~100ms under ideal conditions). </li><li>Marcel Kornacker is the tech lead for Impala – really, my technical boss – and a very interesting guy. He was Joe Hellerstein’s first graduate student (I think), and recently worked at Google on F1.  Wired did a <a href=\"http://www.wired.com/wiredenterprise/2012/10/kornacker-cloudera-google/\">write-up</a> on him which is equal parts awesome and hilarious. Marcel’s bread is <em>fantastic</em> though.</li><li>Wired also did a pretty decent piece on <a href=\"http://www.wired.com/wiredenterprise/2012/10/cloudera-impala-hadoop/\">Impala</a> itself.</li><li>There’s a good <a href=\"http://blog.cloudera.com/blog/2012/10/cloudera-impala-real-time-queries-in-apache-hadoop-for-real/\">introductory blog post</a> by Justin and Marcel on the new Cloudera blog site</li><li><a href=\"http://lizclimo.tumblr.com/post/31611767071/how-to-be-cool\">Impalas make you cool, according to rap music.</a></li></ul>" "http://the-paper-trail.org/blog/cloudera-impala/" (20631 8316) new 6 nil nil ((title nil "Cloudera Impala") (link nil "http://the-paper-trail.org/blog/cloudera-impala/") (comments nil "http://the-paper-trail.org/blog/cloudera-impala/#comments") (pubDate nil "Mon, 05 Nov 2012 02:12:12 +0000") (dc:creator nil "Henry") (category nil "Cloudera Impala") (category nil "Distributed systems") (guid ((isPermaLink . "false")) "http://the-paper-trail.org/blog/?p=438") (description nil "If you have a strong background in either databases or distributed systems, and fancy working on such an exciting technology, send me a note! It&#8217;s great to finally be able to say something about what I&#8217;ve been working at Cloudera for nearly a year. At StrataConf / Hadoop World in New York a couple of [&#8230;]") (content:encoded nil "<p><em>If you have a strong background in either databases or distributed systems, and fancy working on such an exciting technology, <a href=\"mailto:henry@cloudera.com\">send me a note!</a></em></p><p>It&#8217;s great to finally be able to say something about what I&#8217;ve been working at <a href=\"http://www.cloudera.com\">Cloudera</a> for nearly a year. At StrataConf / Hadoop World in New York a couple of weeks ago we announced <a href=\"http://blog.cloudera.com/blog/2012/10/cloudera-impala-real-time-queries-in-apache-hadoop-for-real/\">Cloudera Impala</a>. Impala is a distributed query execution engine that understands a subset of SQL, and critically runs over HDFS and HBase as storage managers. It&#8217;s very similar in functionality to Apache Hive, but it is much, much, much (anecdotally up to 100x) faster.
<span id=\"more-438\"></span>
Why do I think this is important? (and bear in mind I&#8217;m speaking for myself, not Cloudera here). The way I view what we do at Cloudera is that we&#8217;re really participating in a revolution in data storage. The great contribution of the <a href=\"http://research.google.com/archive/gfs.html\">Google</a><a href=\"http://research.google.com/archive/mapreduce.html\">papers</a> was the application of commodity hardware to enterprise problems. Storing your data reliably on commodity servers with relatively cheap hard disks is enabled by the extreme cheapness of storage density (which means that replicating three times for fault-tolerance is suddenly a viable design choice, for example), and this completely changes the cost / benefit equation for data storage. You can have a lot more of it, and you can have it a lot cheaper. This is where the whole &#8216;big data&#8217; idea arguably springs from &#8211; now you can store more data than ever before. What do you do with it?</p><p>Well, you analyse it. But that&#8217;s easier said than done. Traditional data analytics platforms are extremely powerful, but rely on an integrated approach &#8211; you don&#8217;t buy a couple of servers and throw a data warehouse that you downloaded on them, you buy a fully integrated solution that includes hardware and software. The hardware is tuned to the requirements of the software, and the data layout is carefully managed to get great performance on supported queries. This is a very serious platform archetype, and one that I believe will continue to be important to the market, but it&#8217;s fundamentally not configured to process data at the scale that the storage substrate now enables, because you would have to move data into the processing platform to do so, which is a very costly proposition. So typically what you do is identify an important subset of your data that requires the full analytics power to your integrated solution, and move that and only that. But that blunts the advantage of keeping all of that data in the first place &#8211; if you can only process some of it, why are you keeping all of it?</p><p>This is where Apache Hadoop originally came in. Hadoop shines for heavy-lifting batch-processing jobs that have high tolerance for latency but need to touch most bytes in your dataset. Where it doesn&#8217;t shine is for interactive analyses, where a user might be refining the analytic questions they ask iteratively. It&#8217;s useless to wait for 30 minutes just to find that you probably should have grouped by a different columns. Similarly, users of popular BI tools will want to construct reports that they can interact with. Impala is the tool for these use cases; by allowing for relatively low-latency queries over the great unwashed masses of your data you get the value of the data coupled with some of the processing power of the integrated engines. We&#8217;ve brought some of the execution engine magic of massively-parallel distributed databases to the incredibly flexible storage engine model of HDFS and HBase.</p><p>Technically, of course, this is a complete blast to work on &#8211; a large-scale distributed system that does highly non-trivial stuff at each node. Bliss.  Impala&#8217;s been the result of the great effort of a small team. That means I&#8217;ve written code in lots of different parts of the system. Our <tt>INSERT</tt> support is mostly me, as is our DDL support (we don&#8217;t do <tt>CREATE TABLE</tt> yet, but we do <tt>SHOW</tt> / <tt>DESCRIBE</tt> etc.). I also wrote the failure-detection framework that runs on both the state-store (to evict Impala backends that have failed from the current view of cluster membership) and on each Impala backend (to detect when the state-store has failed). In fact there are a ton of things that I&#8217;ve been involved with. Some of the most exciting parts of the code base are the query execution engine itself, which compiles query fragments into a highly optimised program fragment via LLVM, although the planner is also a very complex bit of software.</p><p>The source code is available <a href=\"https://github.com/cloudera/impala\">here</a>. At this point, I should acknowledge that the Github repo doesn&#8217;t build out of the box, and we haven&#8217;t yet provided instructions on how to do so. There&#8217;s no great conspiracy behind this, just the annoying consequence of the number of hours in the day being finite. We can&#8217;t post the repo exactly as we have it internally at Cloudera for a couple of reasons: we rely on internal infrastructure for some of the build steps which can&#8217;t be easily replicated externally, and some of our test suites are customer-confidential. We were rushing (as ever) to get a release out the door, and we made the decision to postpone sorting out the build for the public repo until after the launch. Since that&#8217;s&#8230; now, I&#8217;ve been spending a little time figuring out what we can do. Build systems are not my expertise, and Impala&#8217;s is a little capricious due to the extent that we mix C++ (for the execution engine) and Java code (for the planning and metastore interaction). I hope to have something that can build &#8211; without tests &#8211; by the end of next week, that is by roughly November 9th.</p><p>Otherwise we&#8217;re working on our roadmap for moving from the current beta to GA, and I have a long list of bugs and bits of polish that I&#8217;m looking forward to getting a few minutes to work on. We have some pretty exciting plans coming up, and it&#8217;s going to be great to be able to talk about them a little more publicly.</p><p>From the perspective of this blog, this means I&#8217;ve been reading a ton of interesting database papers (I know distributed systems, but I&#8217;m only just getting up to speed with all the database literature). That means a good opportunity to restart some of the paper reviews, although I&#8217;m even more likely to say something stupid on a less firm technical footing!</p><p>There&#8217;s been a whole bunch of buzz about Impala, which has been very gratifying.</p><ul><li><a href=\"http://www.quora.com/Cloudera/Does-Cloudera-Impala-have-any-drawbacks-when-compared-with-Hive\">These</a><a href=\"http://www.quora.com/Cloudera-Impala/Is-Impala-aiming-to-be-an-open-source-alternative-to-existing-MPP-solutions\">questions</a><a href=\"http://www.quora.com/Cloudera-Impala/How-does-Cloudera-Impala-compare-to-Vertica\">at</a><a href=\"http://www.quora.com/Cloudera-Impala/How-does-Cloudera-Impala-compare-to-Hadapt\">Quora</a> about how Impala compares to similar systems (including <a href=\"http://www.quora.com/Cloudera-Impala/Isnt-Cloudera-Impala-doing-the-same-job-as-Apache-Drill-incubator-project\">my answer about Apache Drill</a>)</li><li>Curt Monash has a <a href=\"http://www.dbms2.com/2012/11/01/more-on-cloudera-impala/\">writeup</a> (although he does make it sound like no query will return in under one second, which isn&#8217;t the case &#8211; query start-up latency is very important to us since that&#8217;s an area we can get a huge gain over Hive&#8217;s Hadoop implementation; in the case of a simple <tt>SELECT 1</tt> the query should return in ~100ms under ideal conditions). </li><li>Marcel Kornacker is the tech lead for Impala &#8211; really, my technical boss &#8211; and a very interesting guy. He was Joe Hellerstein&#8217;s first graduate student (I think), and recently worked at Google on F1.  Wired did a <a href=\"http://www.wired.com/wiredenterprise/2012/10/kornacker-cloudera-google/\">write-up</a> on him which is equal parts awesome and hilarious. Marcel&#8217;s bread is <em>fantastic</em> though.</li><li>Wired also did a pretty decent piece on <a href=\"http://www.wired.com/wiredenterprise/2012/10/cloudera-impala-hadoop/\">Impala</a> itself.</li><li>There&#8217;s a good <a href=\"http://blog.cloudera.com/blog/2012/10/cloudera-impala-real-time-queries-in-apache-hadoop-for-real/\">introductory blog post</a> by Justin and Marcel on the new Cloudera blog site</li><li><a href=\"http://lizclimo.tumblr.com/post/31611767071/how-to-be-cool\">Impalas make you cool, according to rap music.</a></li></ul>
") (wfw:commentRss nil "http://the-paper-trail.org/blog/cloudera-impala/feed/") (slash:comments nil "2"))) ("On some subtleties of Paxos" "<p>There’s one particular aspect of the Paxos protocol that gives readers of this blog – and for some time, me! – some difficulty. This short post tries to clear up some confusion on a part of the protocol that is poorly explained in pretty much every major description.
<span id=\"more-427\"></span>
This is the observation that causes problems: two different nodes can validly accept different proposals for the same Paxos instance. That means that we could have a situation where node <img src='http://s.wordpress.com/latex.php?latex=A&bg=ffffff&fg=000000&s=0' alt='A' title='A' class='latex' /> has accepted a proposal <img src='http://s.wordpress.com/latex.php?latex=P%3D%28S%2C%20V%29&bg=ffffff&fg=000000&s=0' alt='P=(S, V)' title='P=(S, V)' class='latex' />, and node <img src='http://s.wordpress.com/latex.php?latex=E&bg=ffffff&fg=000000&s=0' alt='E' title='E' class='latex' /> has accepted a proposal <img src='http://s.wordpress.com/latex.php?latex=P%27%3D%28S%27%2C%20V%27%29&bg=ffffff&fg=000000&s=0' alt='P'=(S', V')' title='P'=(S', V')' class='latex' />. We can get there very easily by having two competing proposers that interleave their prepare phases, and crash after sending an accept to one node each. On the face of it, this is a very concerning situation – how can two nodes both believe a different value has been accepted? Doesn’t this violate one of the consensus guarantees of uniformity?</p><p>The answer lies in the fact that the nodes doing the accepting are not (necessarily) the nodes that ‘learn’ about the agreed value. Paxos calls for a distinguished category of nodes, called ‘learners’, which hear about acceptance events from the nodes doing the accepting. We call the latter nodes ‘acceptors’, and say that learners ‘commit’ to a value once they can be sure it’s never going to change for a given Paxos instance.</p><p>But when does a learner know that a value has really been accepted? It can’t just go on the first acceptance that it receives (since as we have shown, two different acceptors can have accepted different values and may race to send their values to the learners). Instead, a learner must wait for a majority of acceptors to return the same proposal. Once <img src='http://s.wordpress.com/latex.php?latex=N%2F2%20%2B%201&bg=ffffff&fg=000000&s=0' alt='N/2 + 1' title='N/2 + 1' class='latex' /> acceptors are in agreement, the learner can commit the value to its log, or whatever is required once consensus is reached. The rest of this post shows why this is both necessary and sufficient.</p><p>If no majority of acceptors have accepted the same value, it’s trivial to see why a learner cannot commit to a value sent by any acceptor, for the same race-based argument made earlier. A more interesting case is the following: suppose that a majority of acceptors have accepted a proposal with the same value, but with different sequence numbers (i.e. proposed by a different proposer). Can a learner commit to that value once it has learnt about all the acceptances? In the following section we show that it can.</p><h3>Conditions for learner commit</h3><p><strong>Theorem:</strong><i>Let a majority of acceptors have accepted some proposal with value <img src='http://s.wordpress.com/latex.php?latex=V&bg=ffffff&fg=000000&s=0' alt='V' title='V' class='latex' />, and let <img src='http://s.wordpress.com/latex.php?latex=P%20%3D%20%28S%2CV%29&bg=ffffff&fg=000000&s=0' alt='P = (S,V)' title='P = (S,V)' class='latex' /> be the proposal with the largest sequence number <img src='http://s.wordpress.com/latex.php?latex=S&bg=ffffff&fg=000000&s=0' alt='S' title='S' class='latex' /> amongst all those acceptors. Then there is no proposal <img src='http://s.wordpress.com/latex.php?latex=P%27%20%3D%20%28S%27%2C%20V%27%29&bg=ffffff&fg=000000&s=0' alt='P' = (S', V')' title='P' = (S', V')' class='latex' /> that is accepted at any node with <img src='http://s.wordpress.com/latex.php?latex=S%27%3ES&bg=ffffff&fg=000000&s=0' alt='S'&gt;S' title='S'&gt;S' class='latex' /> and <img src='http://s.wordpress.com/latex.php?latex=V%27%20%5Cneq%20V&bg=ffffff&fg=000000&s=0' alt='V' \\neq V' title='V' \\neq V' class='latex' />.</i></p><p><strong>Proof:</strong> We proceed in two steps. The first shows that when <img src='http://s.wordpress.com/latex.php?latex=P&bg=ffffff&fg=000000&s=0' alt='P' title='P' class='latex' /> is accepted, there is no proposal already accepted at any node with a later sequence number. Assume that this is false, and some node has accepted <img src='http://s.wordpress.com/latex.php?latex=P%27&bg=ffffff&fg=000000&s=0' alt='P'' title='P'' class='latex' />. Then a majority of acceptors must have promised to accept only proposals with sequence number <img src='http://s.wordpress.com/latex.php?latex=S%27%27%20%3E%20S%27&bg=ffffff&fg=000000&s=0' alt='S'' &gt; S'' title='S'' &gt; S'' class='latex' />. Since <img src='http://s.wordpress.com/latex.php?latex=S%20%3C%20S%27&bg=ffffff&fg=000000&s=0' alt='S &lt; S'' title='S &lt; S'' class='latex' />, <img src='http://s.wordpress.com/latex.php?latex=P&bg=ffffff&fg=000000&s=0' alt='P' title='P' class='latex' /> cannot be accepted by a majority of acceptors, contradicting the assumption.</p><p>Second, we prove by a very similar argument that once <img src='http://s.wordpress.com/latex.php?latex=P&bg=ffffff&fg=000000&s=0' alt='P' title='P' class='latex' /> has been accepted, no node will accept a proposal like <img src='http://s.wordpress.com/latex.php?latex=P%27&bg=ffffff&fg=000000&s=0' alt='P'' title='P'' class='latex' />.  Again, assume this is false. Then a majority of acceptors must have sent a <tt>promise</tt> of <img src='http://s.wordpress.com/latex.php?latex=%28S%27%2C%20V%27%29&bg=ffffff&fg=000000&s=0' alt='(S', V')' title='(S', V')' class='latex' /> in order for the proposer of <img src='http://s.wordpress.com/latex.php?latex=P%27&bg=ffffff&fg=000000&s=0' alt='P'' title='P'' class='latex' /> to be sending <tt>accept</tt> messages. If so, then either that same majority should have ignored the <tt>accept</tt> message for <img src='http://s.wordpress.com/latex.php?latex=P&bg=ffffff&fg=000000&s=0' alt='P' title='P' class='latex' /> (since <img src='http://s.wordpress.com/latex.php?latex=S%20%3C%20S%27&bg=ffffff&fg=000000&s=0' alt='S &lt; S'' title='S &lt; S'' class='latex' />), or <img src='http://s.wordpress.com/latex.php?latex=V%27%20%3D%20V&bg=ffffff&fg=000000&s=0' alt='V' = V' title='V' = V' class='latex' /> if the <tt>accept</tt> of <img src='http://s.wordpress.com/latex.php?latex=P&bg=ffffff&fg=000000&s=0' alt='P' title='P' class='latex' /> happened before the proposal of <img src='http://s.wordpress.com/latex.php?latex=P%27&bg=ffffff&fg=000000&s=0' alt='P'' title='P'' class='latex' /> (by the first half of this proof we know that there is no proposal with a later sequence number than <img src='http://s.wordpress.com/latex.php?latex=S&bg=ffffff&fg=000000&s=0' alt='S' title='S' class='latex' /> already accepted, so the proposer is guaranteed to choose <img src='http://s.wordpress.com/latex.php?latex=V&bg=ffffff&fg=000000&s=0' alt='V' title='V' class='latex' /> as the already accepted value with the largest sequence number). In either case there is a contradiction; <img src='http://s.wordpress.com/latex.php?latex=P&bg=ffffff&fg=000000&s=0' alt='P' title='P' class='latex' /> has not been accepted or <img src='http://s.wordpress.com/latex.php?latex=V%20%3D%20V%27&bg=ffffff&fg=000000&s=0' alt='V = V'' title='V = V'' class='latex' />.</p><p>What this theorem shows is that once a value has been accepted by a majority of acceptors, no proposal can change it. The sequence number might change (consider what happens if a new proposer comes along and runs another proposal over the same instance – the sequence number will increase at some acceptors, but the proposer must choose the majority value for its accept message). But since the majority-accepted value will never change, the learners can commit a value when they hear it from a majority of acceptors.</p><h3>Fault tolerance</h3><p>Now it’s instructive to think about what this means for Paxos’ fault-tolerance guarantees. Imagine that a proposal was accepted at a minimal (i.e. <img src='http://s.wordpress.com/latex.php?latex=N%2F2%2B1&bg=ffffff&fg=000000&s=0' alt='N/2+1' title='N/2+1' class='latex' /> nodes) majority of acceptors before the proposer crashed. In order for the value to be committed by a learner, every one of those acceptors must successfully send its accepted value on to the learners. So if a single node in that majority fails, that Paxos instance will not terminate for all learners. That appears to be not as fault-tolerant as we were promised.</p><p>There are several ways to interpret this fact. The first is that Paxos only guarantees that it will continue to be correct, and live, with up to <img src='http://s.wordpress.com/latex.php?latex=N%2F2%20%2B%201&bg=ffffff&fg=000000&s=0' alt='N/2 + 1' title='N/2 + 1' class='latex' /> failures; and <i>failing to reach agreement for a single proposal does not contravene these properties</i>. It’s also true that if the proposer dies before sending any accept messages, that proposal will also never complete. However, another proposer can always come along and finish that instance of the protocol; it’s this that is no longer true if a majority of acceptors fail.</p><p>The second interpretation is that it makes sense for acceptors to also act as learners, so that they can update their values for a given Paxos instance once they realise that consensus is complete. It’s often true that learners and acceptors are the same thing in a real Paxos deployment, and the aim is usually to have as many acceptors up-to-date as possible.</p><p>So that’s a short look at how the distribution of accepted proposals can evolve during Paxos, and how the protocol guarantees that eventually the cluster will converge on a value that will never change.</p>" "http://the-paper-trail.org/blog/on-some-subtleties-of-paxos/" (20629 52398) new 7 nil nil ((title nil "On some subtleties of Paxos") (link nil "http://the-paper-trail.org/blog/on-some-subtleties-of-paxos/") (comments nil "http://the-paper-trail.org/blog/on-some-subtleties-of-paxos/#comments") (pubDate nil "Sun, 04 Nov 2012 02:02:22 +0000") (dc:creator nil "Henry") (category nil "Distributed systems") (guid ((isPermaLink . "false")) "http://the-paper-trail.org/blog/?p=427") (description nil "There&#8217;s one particular aspect of the Paxos protocol that gives readers of this blog &#8211; and for some time, me! &#8211; some difficulty. This short post tries to clear up some confusion on a part of the protocol that is poorly explained in pretty much every major description. This is the observation that causes problems: [&#8230;]") (content:encoded nil "<p>There&#8217;s one particular aspect of the Paxos protocol that gives readers of this blog &#8211; and for some time, me! &#8211; some difficulty. This short post tries to clear up some confusion on a part of the protocol that is poorly explained in pretty much every major description. 
<span id=\"more-427\"></span>
This is the observation that causes problems: two different nodes can validly accept different proposals for the same Paxos instance. That means that we could have a situation where node <img src='http://s.wordpress.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='A' title='A' class='latex' /> has accepted a proposal <img src='http://s.wordpress.com/latex.php?latex=P%3D%28S%2C%20V%29&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='P=(S, V)' title='P=(S, V)' class='latex' />, and node <img src='http://s.wordpress.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='E' title='E' class='latex' /> has accepted a proposal <img src='http://s.wordpress.com/latex.php?latex=P%27%3D%28S%27%2C%20V%27%29&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='P&#039;=(S&#039;, V&#039;)' title='P&#039;=(S&#039;, V&#039;)' class='latex' />. We can get there very easily by having two competing proposers that interleave their prepare phases, and crash after sending an accept to one node each. On the face of it, this is a very concerning situation &#8211; how can two nodes both believe a different value has been accepted? Doesn&#8217;t this violate one of the consensus guarantees of uniformity?</p><p>The answer lies in the fact that the nodes doing the accepting are not (necessarily) the nodes that &#8216;learn&#8217; about the agreed value. Paxos calls for a distinguished category of nodes, called &#8216;learners&#8217;, which hear about acceptance events from the nodes doing the accepting. We call the latter nodes &#8216;acceptors&#8217;, and say that learners &#8216;commit&#8217; to a value once they can be sure it&#8217;s never going to change for a given Paxos instance.</p><p>But when does a learner know that a value has really been accepted? It can&#8217;t just go on the first acceptance that it receives (since as we have shown, two different acceptors can have accepted different values and may race to send their values to the learners). Instead, a learner must wait for a majority of acceptors to return the same proposal. Once <img src='http://s.wordpress.com/latex.php?latex=N%2F2%20%2B%201&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='N/2 + 1' title='N/2 + 1' class='latex' /> acceptors are in agreement, the learner can commit the value to its log, or whatever is required once consensus is reached. The rest of this post shows why this is both necessary and sufficient.</p><p>If no majority of acceptors have accepted the same value, it&#8217;s trivial to see why a learner cannot commit to a value sent by any acceptor, for the same race-based argument made earlier. A more interesting case is the following: suppose that a majority of acceptors have accepted a proposal with the same value, but with different sequence numbers (i.e. proposed by a different proposer). Can a learner commit to that value once it has learnt about all the acceptances? In the following section we show that it can.</p><h3>Conditions for learner commit</h3><p><strong>Theorem:</strong><i>Let a majority of acceptors have accepted some proposal with value <img src='http://s.wordpress.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='V' title='V' class='latex' />, and let <img src='http://s.wordpress.com/latex.php?latex=P%20%3D%20%28S%2CV%29&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='P = (S,V)' title='P = (S,V)' class='latex' /> be the proposal with the largest sequence number <img src='http://s.wordpress.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='S' title='S' class='latex' /> amongst all those acceptors. Then there is no proposal <img src='http://s.wordpress.com/latex.php?latex=P%27%20%3D%20%28S%27%2C%20V%27%29&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='P&#039; = (S&#039;, V&#039;)' title='P&#039; = (S&#039;, V&#039;)' class='latex' /> that is accepted at any node with <img src='http://s.wordpress.com/latex.php?latex=S%27%3ES&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='S&#039;&gt;S' title='S&#039;&gt;S' class='latex' /> and <img src='http://s.wordpress.com/latex.php?latex=V%27%20%5Cneq%20V&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='V&#039; \\neq V' title='V&#039; \\neq V' class='latex' />.</i></p><p><strong>Proof:</strong> We proceed in two steps. The first shows that when <img src='http://s.wordpress.com/latex.php?latex=P&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='P' title='P' class='latex' /> is accepted, there is no proposal already accepted at any node with a later sequence number. Assume that this is false, and some node has accepted <img src='http://s.wordpress.com/latex.php?latex=P%27&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='P&#039;' title='P&#039;' class='latex' />. Then a majority of acceptors must have promised to accept only proposals with sequence number <img src='http://s.wordpress.com/latex.php?latex=S%27%27%20%3E%20S%27&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='S&#039;&#039; &gt; S&#039;' title='S&#039;&#039; &gt; S&#039;' class='latex' />. Since <img src='http://s.wordpress.com/latex.php?latex=S%20%3C%20S%27&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='S &lt; S&#039;' title='S &lt; S&#039;' class='latex' />, <img src='http://s.wordpress.com/latex.php?latex=P&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='P' title='P' class='latex' /> cannot be accepted by a majority of acceptors, contradicting the assumption.</p><p>Second, we prove by a very similar argument that once <img src='http://s.wordpress.com/latex.php?latex=P&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='P' title='P' class='latex' /> has been accepted, no node will accept a proposal like <img src='http://s.wordpress.com/latex.php?latex=P%27&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='P&#039;' title='P&#039;' class='latex' />.  Again, assume this is false. Then a majority of acceptors must have sent a <tt>promise</tt> of <img src='http://s.wordpress.com/latex.php?latex=%28S%27%2C%20V%27%29&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='(S&#039;, V&#039;)' title='(S&#039;, V&#039;)' class='latex' /> in order for the proposer of <img src='http://s.wordpress.com/latex.php?latex=P%27&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='P&#039;' title='P&#039;' class='latex' /> to be sending <tt>accept</tt> messages. If so, then either that same majority should have ignored the <tt>accept</tt> message for <img src='http://s.wordpress.com/latex.php?latex=P&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='P' title='P' class='latex' /> (since <img src='http://s.wordpress.com/latex.php?latex=S%20%3C%20S%27&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='S &lt; S&#039;' title='S &lt; S&#039;' class='latex' />), or <img src='http://s.wordpress.com/latex.php?latex=V%27%20%3D%20V&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='V&#039; = V' title='V&#039; = V' class='latex' /> if the <tt>accept</tt> of <img src='http://s.wordpress.com/latex.php?latex=P&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='P' title='P' class='latex' /> happened before the proposal of <img src='http://s.wordpress.com/latex.php?latex=P%27&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='P&#039;' title='P&#039;' class='latex' /> (by the first half of this proof we know that there is no proposal with a later sequence number than <img src='http://s.wordpress.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='S' title='S' class='latex' /> already accepted, so the proposer is guaranteed to choose <img src='http://s.wordpress.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='V' title='V' class='latex' /> as the already accepted value with the largest sequence number). In either case there is a contradiction; <img src='http://s.wordpress.com/latex.php?latex=P&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='P' title='P' class='latex' /> has not been accepted or <img src='http://s.wordpress.com/latex.php?latex=V%20%3D%20V%27&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='V = V&#039;' title='V = V&#039;' class='latex' />.</p><p>What this theorem shows is that once a value has been accepted by a majority of acceptors, no proposal can change it. The sequence number might change (consider what happens if a new proposer comes along and runs another proposal over the same instance &#8211; the sequence number will increase at some acceptors, but the proposer must choose the majority value for its accept message). But since the majority-accepted value will never change, the learners can commit a value when they hear it from a majority of acceptors.</p><h3>Fault tolerance</h3><p>Now it&#8217;s instructive to think about what this means for Paxos&#8217; fault-tolerance guarantees. Imagine that a proposal was accepted at a minimal (i.e. <img src='http://s.wordpress.com/latex.php?latex=N%2F2%2B1&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='N/2+1' title='N/2+1' class='latex' /> nodes) majority of acceptors before the proposer crashed. In order for the value to be committed by a learner, every one of those acceptors must successfully send its accepted value on to the learners. So if a single node in that majority fails, that Paxos instance will not terminate for all learners. That appears to be not as fault-tolerant as we were promised.</p><p>There are several ways to interpret this fact. The first is that Paxos only guarantees that it will continue to be correct, and live, with up to <img src='http://s.wordpress.com/latex.php?latex=N%2F2%20%2B%201&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='N/2 + 1' title='N/2 + 1' class='latex' /> failures; and <i>failing to reach agreement for a single proposal does not contravene these properties</i>. It&#8217;s also true that if the proposer dies before sending any accept messages, that proposal will also never complete. However, another proposer can always come along and finish that instance of the protocol; it&#8217;s this that is no longer true if a majority of acceptors fail.</p><p>The second interpretation is that it makes sense for acceptors to also act as learners, so that they can update their values for a given Paxos instance once they realise that consensus is complete. It&#8217;s often true that learners and acceptors are the same thing in a real Paxos deployment, and the aim is usually to have as many acceptors up-to-date as possible.</p><p>So that&#8217;s a short look at how the distribution of accepted proposals can evolve during Paxos, and how the protocol guarantees that eventually the cluster will converge on a value that will never change.</p>
") (wfw:commentRss nil "http://the-paper-trail.org/blog/on-some-subtleties-of-paxos/feed/") (slash:comments nil "1"))) ("Links" "<ul><li><a href=\"http://www.bigredbits.com/archives/382\">Reasoning about Knowledge</a></li><li><a href=\"http://www.cs.cornell.edu/projects/quicksilver/public_pdfs/sigact2.pdf\">Toward a Cloud Computing Research Agenda</a> (2009) – <blockquote>“One of the LADIS attendees commented at some point that Byzantine Consensus could be used to improve Chubby, making it tolerant of faults that could disrupt it as currently implemented. But for our keynote speakers, enhancing Chubby to tolerate such faults turns out to be of purely academic interest.”</blockquote><li><a href=\"https://github.com/johnj/llds\">Low-level data structures</a> – <blockquote>The llds general working thesis is: for large memory applications, virtual memory layers can hurt application performance due to increased memory latency when dealing with large data structures. Specifically, data page tables/directories within the kernel and increased DRAM requests can be avoided to boost application memory access.</blockquote></li><li><a href=\"http://arxiv.org/pdf/1201.0228v1.pdf\">High-Performance Concurrency Control for Main-Memory Databases</a> (via <a href=\"http://highscalability.com/blog/2012/8/6/paper-high-performance-concurrency-control-mechanisms-for-ma.html\">High Scalability</a>) – <a href=\"http://en.wikipedia.org/wiki/Multiversion_concurrency_control\">MVCC</a> is interesting and elegant, and also underpins some datastores with persistence, like HBase. I like <a href=\"http://staff.ustc.edu.cn/~jpq/paper/flash/1983-TODS-Multiversion%20Concurrency%20Control-Theory%20and%20Algorithms.pdf\">this paper</a> as the best survey.</li></ul>" "http://the-paper-trail.org/blog/links/" (20512 12718) new 8 nil nil ((title nil "Links") (link nil "http://the-paper-trail.org/blog/links/") (comments nil "http://the-paper-trail.org/blog/links/#comments") (pubDate nil "Mon, 06 Aug 2012 21:05:50 +0000") (dc:creator nil "Henry") (category nil "Uncategorized") (guid ((isPermaLink . "false")) "http://the-paper-trail.org/blog/?p=414") (description nil "Reasoning about Knowledge Toward a Cloud Computing Research Agenda (2009) &#8211; &#8220;One of the LADIS attendees commented at some point that Byzantine Consensus could be used to improve Chubby, making it tolerant of faults that could disrupt it as currently implemented. But for our keynote speakers, enhancing Chubby to tolerate such faults turns out to [&#8230;]") (content:encoded nil "<ul><li><a href=\"http://www.bigredbits.com/archives/382\">Reasoning about Knowledge</a></li><li><a href=\"http://www.cs.cornell.edu/projects/quicksilver/public_pdfs/sigact2.pdf\">Toward a Cloud Computing Research Agenda</a> (2009) &#8211; <blockquote>&#8220;One of the LADIS attendees commented at some point that Byzantine Consensus could be used to improve Chubby, making it tolerant of faults that could disrupt it as currently implemented. But for our keynote speakers, enhancing Chubby to tolerate such faults turns out to be of purely academic interest.&#8221;</blockquote><li><a href=\"https://github.com/johnj/llds\">Low-level data structures</a> &#8211; <blockquote>The llds general working thesis is: for large memory applications, virtual memory layers can hurt application performance due to increased memory latency when dealing with large data structures. Specifically, data page tables/directories within the kernel and increased DRAM requests can be avoided to boost application memory access.</blockquote></li><li><a href=\"http://arxiv.org/pdf/1201.0228v1.pdf\">High-Performance Concurrency Control for Main-Memory Databases</a> (via <a href=\"http://highscalability.com/blog/2012/8/6/paper-high-performance-concurrency-control-mechanisms-for-ma.html\">High Scalability</a>) &#8211; <a href=\"http://en.wikipedia.org/wiki/Multiversion_concurrency_control\">MVCC</a> is interesting and elegant, and also underpins some datastores with persistence, like HBase. I like <a href=\"http://staff.ustc.edu.cn/~jpq/paper/flash/1983-TODS-Multiversion%20Concurrency%20Control-Theory%20and%20Algorithms.pdf\">this paper</a> as the best survey.</li></ul>
") (wfw:commentRss nil "http://the-paper-trail.org/blog/links/feed/") (slash:comments nil "0"))) ("Something a bit different: translations of classic mathematical texts (!)" "<p>During his retirement, my father has been able to spend much time indulging his love of mathematics. This included, amongst other impressive endeavours, attending Cambridge at a more advanced age than average to take (and pass!) the <a href=\"http://en.wikipedia.org/wiki/Part_III_of_the_Mathematical_Tripos\">Part III of the Mathematical Tripos</a>, often considered one of the hardest taught courses in maths in the world.</p><p>Since then, he has hardly been idle, and has recently been undertaking a translation of a classic work in modern algebra by <a href=\"http://en.wikipedia.org/wiki/Richard_Dedekind\">Dedekind</a> and <a href=\"http://en.wikipedia.org/wiki/Heinrich_Martin_Weber\">Weber</a> from its original 100+ pages of German into English.</p><p>Having completed this monumental piece of work, it seemed only proper to share it a little more widely so that other students might benefit from his efforts – and that’s where I come in, since I’m the one with the website. So if you have any passing interest in 19th / 20th century modern algebra, I encourage you to check out Noel Robinson’s <a href=\"http://the-paper-trail.org/blog/dedekind-and-weber-theory-of-the-algebraic-functions-of-one-variable/\">translation of “Theory of Algebraic Functions of One Variable”</a>, hosted on this site.</p>" "http://the-paper-trail.org/blog/something-a-bit-different-translations-of-classic-mathematical-texts/" (20509 39194) new 9 nil nil ((title nil "Something a bit different: translations of classic mathematical texts (!)") (link nil "http://the-paper-trail.org/blog/something-a-bit-different-translations-of-classic-mathematical-texts/") (comments nil "http://the-paper-trail.org/blog/something-a-bit-different-translations-of-classic-mathematical-texts/#comments") (pubDate nil "Sat, 04 Aug 2012 21:50:18 +0000") (dc:creator nil "Henry") (category nil "Uncategorized") (guid ((isPermaLink . "false")) "http://the-paper-trail.org/blog/?p=409") (description nil "During his retirement, my father has been able to spend much time indulging his love of mathematics. This included, amongst other impressive endeavours, attending Cambridge at a more advanced age than average to take (and pass!) the Part III of the Mathematical Tripos, often considered one of the hardest taught courses in maths in the [&#8230;]") (content:encoded nil "<p>During his retirement, my father has been able to spend much time indulging his love of mathematics. This included, amongst other impressive endeavours, attending Cambridge at a more advanced age than average to take (and pass!) the <a href=\"http://en.wikipedia.org/wiki/Part_III_of_the_Mathematical_Tripos\">Part III of the Mathematical Tripos</a>, often considered one of the hardest taught courses in maths in the world.</p><p>Since then, he has hardly been idle, and has recently been undertaking a translation of a classic work in modern algebra by <a href=\"http://en.wikipedia.org/wiki/Richard_Dedekind\">Dedekind</a> and <a href=\"http://en.wikipedia.org/wiki/Heinrich_Martin_Weber\">Weber</a> from its original 100+ pages of German into English.</p><p>Having completed this monumental piece of work, it seemed only proper to share it a little more widely so that other students might benefit from his efforts &#8211; and that&#8217;s where I come in, since I&#8217;m the one with the website. So if you have any passing interest in 19th / 20th century modern algebra, I encourage you to check out Noel Robinson&#8217;s <a href=\"http://the-paper-trail.org/blog/dedekind-and-weber-theory-of-the-algebraic-functions-of-one-variable/\">translation of &#8220;Theory of Algebraic Functions of One Variable&#8221;</a>, hosted on this site.</p>
") (wfw:commentRss nil "http://the-paper-trail.org/blog/something-a-bit-different-translations-of-classic-mathematical-texts/feed/") (slash:comments nil "0"))) ("EuroSys 2012 blog notes" "<p>EuroSys 2012 was last week – one of the premier European systems conferences. Over at the Cambridge System Research Group’s <a href=\"http://www.syslog.cl.cam.ac.uk/\">blog</a>, various people from the group have written notes on the papers presented. They’re very well-written summaries, and worth checking out for an overview of the research presented.</p><ul><li><a href=\"http://www.syslog.cl.cam.ac.uk/2012/04/11/liveblog-eurosys-2012-day-1/\">Day 1</a></li><li><a href=\"http://www.syslog.cl.cam.ac.uk/2012/04/12/liveblog-eurosys-2012-day-2/\">Day 2</a></li><li><a href=\"http://www.syslog.cl.cam.ac.uk/2012/04/13/liveblog-eurosys-2012-day-3/\">Day 3</a></li></ul>" "http://the-paper-trail.org/blog/eurosys-2012-blog-notes/" (20363 29665) new 10 nil nil ((title nil "EuroSys 2012 blog notes") (link nil "http://the-paper-trail.org/blog/eurosys-2012-blog-notes/") (comments nil "http://the-paper-trail.org/blog/eurosys-2012-blog-notes/#comments") (pubDate nil "Mon, 16 Apr 2012 01:20:33 +0000") (dc:creator nil "Henry") (category nil "Uncategorized") (guid ((isPermaLink . "false")) "http://the-paper-trail.org/blog/?p=374") (description nil "EuroSys 2012 was last week &#8211; one of the premier European systems conferences. Over at the Cambridge System Research Group&#8217;s blog, various people from the group have written notes on the papers presented. They&#8217;re very well-written summaries, and worth checking out for an overview of the research presented. Day 1 Day 2 Day 3") (content:encoded nil "<p>EuroSys 2012 was last week &#8211; one of the premier European systems conferences. Over at the Cambridge System Research Group&#8217;s <a href=\"http://www.syslog.cl.cam.ac.uk/\">blog</a>, various people from the group have written notes on the papers presented. They&#8217;re very well-written summaries, and worth checking out for an overview of the research presented.</p><ul><li><a href=\"http://www.syslog.cl.cam.ac.uk/2012/04/11/liveblog-eurosys-2012-day-1/\">Day 1</a></li><li><a href=\"http://www.syslog.cl.cam.ac.uk/2012/04/12/liveblog-eurosys-2012-day-2/\">Day 2</a></li><li><a href=\"http://www.syslog.cl.cam.ac.uk/2012/04/13/liveblog-eurosys-2012-day-3/\">Day 3</a></li></ul>
") (wfw:commentRss nil "http://the-paper-trail.org/blog/eurosys-2012-blog-notes/feed/") (slash:comments nil "1"))))