;; -*- coding: utf-8 -*-
(("33 Bits of Entropy" "The End of Anonymized Data and What to Do About It" "http://33bits.org" (21317 36648 219132 613000) feed 0 nil nil ((title nil "33 Bits of Entropy") (atom:link ((href . "http://33bits.org/feed/") (rel . "self") (type . "application/rss+xml"))) (link nil "http://33bits.org") (description nil "The End of Anonymized Data and What to Do About It") (lastBuildDate nil "Wed, 12 Mar 2014 15:57:59 +0000") (language nil "en") (sy:updatePeriod nil "hourly") (sy:updateFrequency nil "1") (generator nil "http://wordpress.com/") (cloud ((domain . "33bits.org") (port . "80") (path . "/?rsscloud=notify") (registerProcedure . "") (protocol . "http-post"))) (image nil (url nil "http://s2.wp.com/i/buttonw-com.png") (title nil "33 Bits of Entropy") (link nil "http://33bits.org")) (atom:link ((rel . "search") (type . "application/opensearchdescription+xml") (href . "http://33bits.org/osd.xml") (title . "33 Bits of Entropy"))) (atom:link ((rel . "hub") (href . "http://33bits.org/?pushpress=hub"))) (item nil (title nil "How to prepare a technical talk") (link nil "http://33bits.org/2013/11/26/how-to-prepare-a-technical-talk/") (comments nil "http://33bits.org/2013/11/26/how-to-prepare-a-technical-talk/#comments") (pubDate nil "Tue, 26 Nov 2013 14:29:27 +0000") (dc:creator nil "Arvind Narayanan") (category nil "Uncategorized") (guid ((isPermaLink . "false")) "http://33bits.org/?p=1138") (description nil "I used to suck at giving technical talks. I would usually confuse my audience, and often confuse myself. By the time I became a prof, I sucked a lot less. These days I enjoy giving technical talks and lectures more than non-technical ones, and my students seem to like them better as well. So something [&#8230;]<img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&#038;blog=5017838&#038;post=1138&#038;subd=33bits&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />") (content:encoded nil "<p dir=\"ltr\">I used to suck at giving technical talks. I would usually confuse my audience, and often confuse myself. By the time I became a prof, I sucked a lot less. These days I enjoy giving technical talks and lectures more than non-technical ones, and my students seem to like them better as well.</p><p dir=\"ltr\">So something had changed; I’d developed a process. The other day I sat down to see if I could extract what this process was. It turned out to be surprisingly formulaic, like an algorithm, so I’d like to share it with you. I’m guessing this is obvious to most professors who teach technical topics, but I hope it will be helpful to those who’re relatively new to the game.</p><p>There are three steps. They’re simple but not easy.
<ol><li>Identify the atomic concepts</li><li>Draw the dependency graph</li><li>Find a topological ordering of the graph</li></ol><p dir=\"ltr\"><strong>Identify atomic concepts.</strong> The key word here is atomic. The idea is to introduce only one key concept at one time and give the audience time to internalize the concept before moving on to the next one.</p><p dir=\"ltr\">This is hard for two reasons. First, concepts that seem atomic to an expert are often an amalgam of different concepts. Second, it’s audience-specific. You have to have a good mental model of which concepts are already familiar to your audience.</p><p dir=\"ltr\"><strong>Draw the dependency graph.</strong> Occasionally I use a whiteboard for this, but usually it’s in my head. This is a tricky step because it’s easy to miss dependencies. When the topic I’m teaching is the design of a technical system, I ask myself questions like, “what could go wrong in this component?” and “why wasn’t this alternative design used?” This helps me flesh out the internal logic of the system in the form of a graph.</p><p dir=\"ltr\"><strong>Find a topological ordering.</strong> This is just a fancy way of saying we want to order the concepts so that each concept only depends on the ones already introduced. Sometimes this is straightforward, but sometimes the dependency graph has cycles!</p><p dir=\"ltr\">Of the topics I’ve taught recently, Bitcoin seems especially difficult in this regard. Each concept is bootstrapped off of the others, but somehow the system magically works when you put everything together. What I do in these cases is introduce <em>intermediate steps</em> that <em>don’t exist</em> in the actual design I’m teaching, and remove them later [1].</p><p dir=\"ltr\">Think of a technical topic as a skyscraper. When it’s presented in a paper, it’s analogous to unveiling a finished building. The audience can admire it and check that it’s stable/correct (say, by verifying theorems or other technical arguments.) But just as staring at a building doesn’t help you learn how to build one, the presentation in a typical paper is all but useless for pedagogical purposes. Having dependencies between concepts is perfectly acceptable in papers, because papers are not meant to be read in a single pass.</p><p dir=\"ltr\">The instructor’s role, then, is to reverse engineer how the final concept might <em>plausibly</em> be built up step by step. This is analogous to showing the scaffolding of the building and explaining each step in its construction. Talks and lectures, unlike papers, must necessarily have this linear form because the audience can’t keep state in their heads.</p><p>[1] This process introduces new nodes in the dependency graph and removes some edges so that it is no longer cyclic.</p><p>To stay on top of future posts, <a href=\"http://33bits.org/feed/\">subscribe</a> to the RSS feed or follow me on <a href=\"https://twitter.com/random_walker\">Twitter</a> or <a href=\"https://plus.google.com/u/0/110908828231461227679\">Google+</a>.</p><br /><a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/gocomments/33bits.wordpress.com/1138/\"><img alt=\" \" border=\"0\" src=\"http://feeds.wordpress.com/1.0/comments/33bits.wordpress.com/1138/\" /></a><img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&#038;blog=5017838&#038;post=1138&#038;subd=33bits&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />") (wfw:commentRss nil "http://33bits.org/2013/11/26/how-to-prepare-a-technical-talk/feed/") (slash:comments nil "0") (media:content ((url . "http://1.gravatar.com/avatar/aa438b63ff1e9b75693aeabbeddae5eb?s=96&d=identicon&r=G") (medium . "image")) (media:title ((type . "html")) "randomwalker"))) (item nil (title nil "How to pick your first research project") (link nil "http://33bits.org/2013/11/01/how-to-pick-your-first-research-project/") (comments nil "http://33bits.org/2013/11/01/how-to-pick-your-first-research-project/#comments") (pubDate nil "Fri, 01 Nov 2013 23:58:09 +0000") (dc:creator nil "Arvind Narayanan") (category nil "Uncategorized") (guid ((isPermaLink . "false")) "http://33bits.org/?p=1132") (description nil "At Princeton I get to advise many gifted graduate and undergraduate students in doing research. Combining my experience as a mentor with reflecting on my experience as a student, I’d like to offer some guidance on how to pick your first research project. I’m writing this post because selecting a research problem to work on [&#8230;]<img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&#038;blog=5017838&#038;post=1132&#038;subd=33bits&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />") (content:encoded nil "<p dir=\"ltr\">At Princeton I get to advise many gifted graduate and undergraduate students in doing research. Combining my experience as a mentor with reflecting on my experience as a student, I’d like to offer some guidance on how to pick your first research project.</p><p dir=\"ltr\">I’m writing this post because selecting a research problem to work on is significantly harder than actually solving it. I mean the previous sentence quite literally and without exaggeration. As an undergraduate and early-stage graduate researcher, I repeatedly spent months at a time working on research problems only to have to abandon my efforts because I found out I was barking up the wrong tree. Scientific research, it turns out, is largely about learning to ask the right questions.</p><p dir=\"ltr\">The good news is that three simple criteria will help you avoid most of the common pitfalls.</p><p dir=\"ltr\"><strong>1. Novelty.</strong> Original research is supposed to be, well, original. There are two components to novelty. The first is to make sure the problem you’re trying to solve hasn’t already been solved. This is way trickier than it seems — you might miss previous research because you’re using different names for concepts compared to the standard terminology. But the issue is deeper: two ideas may be equivalent without sounding at all the same at a superficial level. Your advisor&#8217;s help will be crucial here.</p><p dir=\"ltr\">The other aspect to novelty is that you should have a convincing answer to the question “why has this problem not been solved yet?” Often this might involve a dataset that only recently became available, or some clever insight you’ve come up with that you suspect others missed. In practice, one often has an insight and then looks for a problem to apply it to. This means you have to put in a good bit of creative thinking even to pick a research question, and you must be able to estimate the difficulty level of solving it.</p><p dir=\"ltr\">If your answer to the question is, “because the others who tried it weren’t smart enough,” you should probably think twice. It may not be prudent to have the success of your first project ride on your intellectual abilities being truly superlative.</p><p dir=\"ltr\"><strong>2. Relevance.</strong> You must try to ensure that you select a problem that matters, one whose solution will impact the world directly or indirectly (and hopefully for the better). Again, your advisor’s help will be essential. (That said, professional researchers do produce massive volumes of research papers that <a href=\"https://twitter.com/peterhoneyman/status/396353165341126657\">no one cares about</a>.) I encourage my students to pick subproblems of my ongoing long-term research projects. This is a safe way to pick a problem that’s relevant.</p><p dir=\"ltr\"><strong>3. Measurable results.</strong> This one becomes automatic as you get experienced, but for beginning researchers it can be confusing. The output of your research should be measurable and reproducible; ideally you should be able to formulate your goals as a testable hypothesis. Measurability means that many interesting projects that are novel and make the world better are nevertheless unsuitable for research. (They may be ideal for a startup or a hobby project instead.) “Build a website for illiterate kids in poor countries to learn effectively” is an example of a task that’s hard to frame as a research question.</p><p dir=\"ltr\"><strong>Irrelevant criteria.</strong> Let me also point out what’s not on this list. First, the general life advice you often hear, to do something you’re passionate about, is unfortunately a terrible way to pick a research problem. If you start from something you’re passionate about, the chance that it will meet the three criteria above is pretty slim. Often one has to consider a dozen or more research ideas before settling on one to work on.</p><p dir=\"ltr\">You should definitely pick a research <em>area</em> you’re passionate about. But getting emotionally invested in a <em>specific idea</em> or research problem before you’ve done the due diligence is a classic mistake, one that I made a lot as a student.</p><p dir=\"ltr\">Second, the scope or importance of the problem is another criterion you shouldn’t fret much about for your first project. Your goal is as much to learn the process of research as to produce results. You probably have a limited amount of time in which you want to evaluate if this whole research thing is the right fit for you. While you should definitely pick a useful and relevant research task, it should be something that you have a reasonable chance of carrying to fruition. Don&#8217;t worry about curing cancer just yet.</p><p dir=\"ltr\">Note that the last point is at odds with advice given to more experienced researchers. Richard Hamming, in a famous talk titled “<a href=\"http://www.cs.virginia.edu/~robins/YouAndYourResearch.html\">You and your research</a>,” advised researchers to pick the most important problem that they have a shot at solving. I’ve written a version of the current post for those who&#8217;re in it for the long haul, and <a href=\"http://33bits.org/2013/01/02/embracing-failure-how-research-projects-are-like-startups/\">my advice there</a> is to embrace risk and go for the big hits.</p><p dir=\"ltr\">To stay on top of future posts, <a href=\"http://33bits.org/feed/\">subscribe</a> to the RSS feed or follow me on <a href=\"https://twitter.com/random_walker\">Twitter</a> or <a href=\"https://plus.google.com/u/0/110908828231461227679\">Google+</a>.</p><br /><a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/gocomments/33bits.wordpress.com/1132/\"><img alt=\" \" border=\"0\" src=\"http://feeds.wordpress.com/1.0/comments/33bits.wordpress.com/1132/\" /></a><img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&#038;blog=5017838&#038;post=1132&#038;subd=33bits&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />") (wfw:commentRss nil "http://33bits.org/2013/11/01/how-to-pick-your-first-research-project/feed/") (slash:comments nil "0") (media:content ((url . "http://1.gravatar.com/avatar/aa438b63ff1e9b75693aeabbeddae5eb?s=96&d=identicon&r=G") (medium . "image")) (media:title ((type . "html")) "randomwalker"))) (item nil (title nil "Academic publishing as (ruinous) competition: Is there a way out?") (link nil "http://33bits.org/2013/07/15/academic-publishing-as-ruinous-competition-is-there-a-way-out/") (comments nil "http://33bits.org/2013/07/15/academic-publishing-as-ruinous-competition-is-there-a-way-out/#comments") (pubDate nil "Mon, 15 Jul 2013 15:13:11 +0000") (dc:creator nil "Arvind Narayanan") (category nil "Uncategorized") (category nil "academia") (category nil "publishing") (category nil "research") (guid ((isPermaLink . "false")) "http://33bits.org/?p=1129") (description nil "Aaron Johnson invited me to speak as part of a panel on academic publishing at PETS 2013. This is a rough transcript of my talk, written from memory. Aaron mentioned he was looking for one more speaker for this panel, so that we could hear the view of someone naive and inexperienced, and asked if [&#8230;]<img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&#038;blog=5017838&#038;post=1129&#038;subd=33bits&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />") (content:encoded nil "<p dir=\"ltr\"><em><a href=\"http://www.ohmygodel.com/\">Aaron Johnson</a> invited me to speak as part of a <a href=\"http://petsymposium.org/2013/program.php#panel\">panel</a> on academic publishing at PETS 2013. This is a rough transcript of my talk, written from memory.</em></p><p dir=\"ltr\">Aaron mentioned he was looking for one more speaker for this panel, so that we could hear the view of someone naive and inexperienced, and asked if I was available. I said, “Great, I do that every day!” So that will be the tone of my comments today. I don’t have any concrete proposals that can be implemented next year or in two years. Instead these are blue-sky thoughts on how things could work someday and hopeful suggestions for moving in that direction. [1]</p><p dir=\"ltr\">I just finished my first year as a faculty member at Princeton. It’s still a bit surreal. I wasn’t expecting to have an academic career. In fact, back in grad school, especially the latter half, whenever someone asked me what I wanted to do after I graduated, my answer always was, “I don’t know for sure yet, but there’s one career I’m sure I <em>don’t</em> want — academia.”</p><p dir=\"ltr\">I won’t go into the story of why that was and how it changed. But it led to some unusual behavior. I ranted a lot about academia on Twitter, as Aaron already mentioned when he introduced me. Also, many times I “published” stuff by putting up a blog post. For instance I had a series of posts on the ability of a malicious website to deanonymize visitors (<a href=\"https://33bits.wordpress.com/2010/02/18/cookies-supercookies-and-ubercookies-stealing-the-identity-of-web-visitors/\">1</a>, <a href=\"https://33bits.wordpress.com/2010/02/19/ubercookies-history-stealing-social-web/\">2</a>, <a href=\"https://33bits.wordpress.com/2010/02/22/google-docs-leaks-identity/\">3</a>, <a href=\"https://33bits.wordpress.com/2010/03/09/history-stealing-its-all-shades-of-grey/\">4</a>, <a href=\"https://33bits.wordpress.com/2010/06/01/yet-another-identity-stealing-bug-will-creeping-normalcy-be-the-result/\">5</a>, <a href=\"https://33bits.wordpress.com/2010/09/28/instant-personalization-privacy-flaws/\">6</a>). People encouraged me to turn it into a paper, and I could have done that without much extra effort. But I refused, because my primary goal was to quickly disseminate the information, and I felt my blog posts had accomplished that adequately. True, I wouldn’t get academic karma, but why would I care? I wasn’t going to be an academic!</p><p dir=\"ltr\">When I eventually decided I wanted to apply for academic positions, I talked to a professor whose opinion I greatly respected. He expressed skepticism that I’d get any interviews, given that I’d been blogging instead of writing papers. I remember thinking, “oh shit, I’ve screwed up my career, haven’t I?” So I feel extremely lucky that my job search turned out successfully.</p><p dir=\"ltr\">At this point a sane person would have decided to quit while they were ahead, and start playing the academic game. But I guess sanity has never really been one of my strong points. So in the last year I’ve been thinking a lot about what the process of research collaboration and publishing would look like if we somehow magically didn’t have to worry at all about furthering our individual reputations.</p><p dir=\"ltr\"><strong>Polymath</strong></p><p dir=\"ltr\">Something that’s very close to my ideal model of collaboration is the <a href=\"https://en.wikipedia.org/wiki/Polymath_Project\">Polymath project</a>. I was fascinated when I heard about it a few years ago. It was started by mathematician <a href=\"https://en.wikipedia.org/wiki/Tim_Gowers\">Tim Gowers</a> in a blog post titled “<a href=\"http://gowers.wordpress.com/2009/01/27/is-massively-collaborative-mathematics-possible/\">Is massively collaborative mathematics possible?</a>” [2] He and <a href=\"https://en.wikipedia.org/wiki/Terence_Tao\">Terry Tao</a> are the leaders of the project. They’re among the world’s top mathematicians. There have been several of these collaborations so far and they’ve been quite successful, solving previously open math problems. So I’ve been telling computer scientists about these efforts and asking if our community could produce something like this. [3]</p><p dir=\"ltr\">To me there are three salient aspects of Polymath. The first is that the collaboration happens online, in blog posts and comments, rather than phone or physical meetings. When I tell people this they are usually enthusiastic and willing to try something like that. The second aspect is that it is open, in that there is no vetting of participants. Now people are a bit unsure, and say, “hmm, what’s the third?” Well, the third aspect is that there’s no keeping score of who contributed what. To which they react, “whoa, whoa, wait, what??!!”</p><p dir=\"ltr\">I’m sure we can all see the problem here. Gowers and Tao are famous and don’t have to worry about furthering their careers. The other participants who contribute ideas seem to do it partly altruistically and partly because of the novelty of it. But it’s hard to imagine this process being feasible on a bigger scale.</p><p dir=\"ltr\"><strong>Misaligned incentives</strong></p><p dir=\"ltr\">Let’s take a step back and ask why there’s this gap between doing good research and getting credit for it. In almost every industry, every human endeavor, we’ve tried to set things up so that the incentives for individuals and the broader societal goals of the activity align with each other. But sometimes individual incentives get misaligned with the societal goals, and that leads to problems.</p><p dir=\"ltr\">Let’s look at a few examples. Individual traders play the stock market with the hope of getting rich. But at the same time, it helps companies hedge against risk and improves overall financial stability. At least that’s the theory. We’ve seen it go wrong. Similarly, copyright is supposed to align the desire of creators to make money with the goal of the maximum number of people enjoying the maximum number of creative works. That’s gotten out of whack because of digital technology.</p><p dir=\"ltr\">My claim is that we’re seeing the same problem in academic research. There’s a metaphor that explains what’s going on in research really well, and to me it is the root of all of the ills that I want to talk about. And that metaphor is <em>publishing as competition</em>. What do I mean by that? Well, peer review is a contest. Succeeding at this contest is the immediate incentive that we as researchers have. And we hope that this will somehow lead to science that benefits humanity.</p><p dir=\"ltr\">To be clear, I’m far from the first one to make this observation. Let me quote someone who’s much better qualified to talk about this. <a href=\"http://www.wisdom.weizmann.ac.il/~oded/\">Oded Goldreich</a>, I’m sure most of you know of him, has a paper titled “<a href=\"http://www.wisdom.weizmann.ac.il/~oded/PDF/struggle.pdf\">On Struggle and Competition in Scientiﬁc Fields.</a>” Here’s my favorite quote from the paper. He’s talking about the flagship theory conferences.</p><blockquote><p dir=\"ltr\">Eventually, FOCSTOC may become a pure competition, deﬁned as a competition having no aim but its own existence (i.e., the existence of a competition). That is, pure competitions serve no <em>scientiﬁc</em> purpose. Did FOCSTOC reach this point or is close to it? Let me leave this question open, and note that my impression is that things are deﬁnitely evolving towards this direction. In any case, I think we should all be worried about the potential of such an evolution.</p></blockquote><p dir=\"ltr\">I’m don’t know enough about the theory community to have an opinion on how big a problem this is. Still, I’m sure we can agree with the sentiment of the last sentence.</p><p dir=\"ltr\">But here’s the very next paragraph. I think it gives us hope.</p><blockquote><p dir=\"ltr\">Other TOC conferences seem to suffer less from the aforementioned phenomena. This is mainly because they “count” less as evidence of importance (i.e., publications in them are either not counted by other competitions or their eﬀect on these competitions is less signiﬁcant). Thus, the vicious cycle described above is less powerful, and consequently these conferences may still serve the intended scientiﬁc purposes.</p></blockquote><p dir=\"ltr\">We see the same thing in the security and privacy community. Something I’ve seen commonly is a situation where you have a neat result, but nothing earth-shattering, and it’s not good enough as it is for a top tier venue. So what do you do? You pad it with bullshit and submit it, and it gets in. Another trend that this encourages is deliberately making a bad or inaccurate model so that you can solve a harder problem. But PETS publications and participants seem to suffer less from these effects. That’s why I’m happy to be discussing this issue with this group of people.</p><p dir=\"ltr\"><strong>Paper as final output</strong></p><p dir=\"ltr\">It seems like we’re at an impasse. We can agree that publishing-as-competition has all these problems, but hiring committees and tenure committees need competitions to identify good research and good researchers. But I claim that publishing as competition fails even at the supposed goal of identifying useful research.</p><p dir=\"ltr\">The reason for that is simple. Publishing as competition encourages or even forces viewing the paper as the final output. But it’s not! The hard work begins, not ends when the paper is published. This is unlike the math and theory communities, where the paper is in fact the final output. If publishing-as-competition is so bad for theory, it’s much worse for us.</p><p dir=\"ltr\">In security and privacy research, the paper is the starting point. Our goal is not to prove theorems but to more directly impact the world in some way.  By creating privacy technologies, for example. For research to have impact, authors have to do a variety of things after publication depending on the nature of the research. Build technology and get people to adopt it. Explain the work to policymakers or to other researchers who are building upon it. Or even just evangelize your ideas. Some people claim that ideas should stand on their own merit and compete with other ideas on a level playing field. I find this quite silly. I lean toward the view expressed in this famous quote you’ve probably heard: “if your ideas are any good you’ll have to shove them down people’s throats.”</p><p dir=\"ltr\">The upshot of this is that impact is heavily shortchanged in the publication-as-competition model. This is partly because of what I’ve talked about, we have no incentive to do any more work after getting the paper published. But an equally important reason is that the community can’t judge the impact of research at the point of publication. Deciding who “wins the prizes” at the point of publication, before the ideas have a chance to prove themselves, has disastrous consequences.</p><p dir=\"ltr\">So I hope I’ve convinced you that publication-as-competition is at the root of many of our problems. Let me give one more example. Many of us like the publish-then-filter model, where reviews are done in the open on publicly posted papers with anyone being able to comment. One major roadblock to moving to this model is that it screws up the competition aspect. The worry is that papers that receive a lot of popular attention will be reviewed favorably, and so forth. We want papers to be reviewed on a level playing field. But if the worth of a paper can’t be judged at publication time, that means all this fairness is toward an outcome that is meaningless anyway. Do we still want to keep this model at all costs?</p><p dir=\"ltr\"><strong>A way forward?</strong></p><p dir=\"ltr\">So far I’ve done a lot of complaining. Let me offer some suggestions now. I want to give two sets of suggestions that are complementary. The first is targeted at committees, whether tenure committees, hiring committees, award communities, or even program committees to an extent, and to the community in general. The second is targeted at authors.</p><p dir=\"ltr\">Here&#8217;s my suggestion for committees and the community: we can and should develop ways to incentivize and measure real impact. Let me give you a four examples. I have more that I&#8217;d be happy to discuss later. First, retrospective awards. That is, &#8220;best paper from this conference 10 years ago&#8221; or some such. I&#8217;ve been hearing more about these of late, and I think that&#8217;s good news. The idea is that impact is easier to evaluate 10 years after publication.</p><p dir=\"ltr\">Second, <a href=\"https://en.wikipedia.org/wiki/Overlay_journal\">overlay journals</a>. These are online journals that are a way of &#8220;blessing&#8221; papers that have already been published or made public. There is a lag between initial publication and inclusion in the overlay journal, and that’s a good thing. Recently the math community has come up with a technical infrastructure for running overlay journals. I&#8217;m very excited about this. [4]</p><p dir=\"ltr\">There are two more that are related. These are specific to our research field. For papers that are about a new tool, I think we should look at adoption numbers as an important component of the review process. Finally, such papers should also have an &#8220;incentives&#8221; section or subsection. Because all too often we write papers that we imagine unspecified parties will implement and deploy, but it turns out there isn&#8217;t the slightest economic incentive for any company or organization to do so.</p><p dir=\"ltr\">I think we should also find ways to measure contributions through blog posts and sharing data and code in publications. This seems more tricky. I&#8217;d be happy to hear suggestions on how to do it.</p><p dir=\"ltr\">Next, this is what I want to say to authors: the supposed lack of incentives for nontraditional ways of publishing is greatly exaggerated. I say this from my personal experience. I said earlier that I was very lucky that my job search turned out well. That&#8217;s true, but it wasn&#8217;t all luck. I found out to my surprise that my increased visibility through blogging and especially the policy work that came out of it made a huge difference to my prospects. If I&#8217;d had three times as many publications and no blog, I probably would have had about the same chances. I&#8217;m sure some departments didn&#8217;t like my style, but there are definitely others that truly value it.</p><p dir=\"ltr\"><strong>My Bitcoin experiment</strong></p><p dir=\"ltr\">I have one other personal experience to share with you. This is an experiment I&#8217;ve been doing over the last month or so. I&#8217;d been thinking about the possibility of designing a prediction market on top of Bitcoin that doesn&#8217;t have a central point of control. Some of you may know the sad story of Intrade. So I <a href=\"https://twitter.com/random_walker/status/339570757631885312\">tweeted</a> my interest in this problem, and asked if others had put thought into it. Several people responded. I started an email thread for this group, and we went to work.</p><p dir=\"ltr\">12,000 words and several conference calls later, we&#8217;re very happy with where we are, and we&#8217;ve started writing a paper presenting our design. What&#8217;s even better is who the participants are — <a href=\"http://people.scs.carleton.ca/~clark/\">Jeremy Clark</a> at Carleton, <a href=\"http://www.jbonneau.com/\">Joe Bonneau</a> who did his Ph.D. with Ross Anderson and is currently at Google, and Andrew Miller at UMD who is <a href=\"http://www.cs.umd.edu/~jkatz/\">Jon Katz&#8217;</a>s Ph.D. student. All these people are better qualified to write this paper than I am. By being proactive and reaching out online, I was able to assemble and work with this amazing team. [5]</p><p dir=\"ltr\">But this experiment didn&#8217;t go all the way. While I used Twitter to find the participants and was open to accepting anyone, the actual collaboration is being done through traditional channels. My original intent was to do it in public, but I realized quite early on that we had something publication-worthy and became risk-averse.</p><p dir=\"ltr\">I plan to do another experiment, this time with the explicit goal of doing it in public. This is again a Bitcoin-related paper that I want to write. Oddly enough, there is no proper tutorial of Bitcoin, nor is there a survey of the current state of research. I think combining these would make a great paper. The nature of the project makes it ideal to do online. I haven&#8217;t figured out the details yet, but I&#8217;m going to launch it on my blog and see how it goes. You&#8217;re all welcome to join me in this experiment. [6]</p><p dir=\"ltr\">So that&#8217;s basically what I wanted to share with you today. I think the current model of publication as competition has gone too far, and the consequences are starting to get ruinous. It&#8217;s time we put a stop to it. I believe that committees on one hand, and authors on the other both have the incentive to start changing things unilaterally. But if the two are combined, the results can be especially powerful. In fact, I hope that it can lead to a virtuous cycle. Thank you.</p><p dir=\"ltr\">[1] Aaron didn’t actually say that, of course. You probably got that. But who knows if nuances come across in transcripts.</p><p dir=\"ltr\">[2] At this point I polled the room to see who’d heard of Polymath before. Only three hands went up (!)</p><p dir=\"ltr\">[3] There is one example that’s closer to computer science that I’m aware of: <a href=\"http://homotopytypetheory.org/book/\">this book</a> on homotopy type theory written in a similar spirit as the Polymath project.</p><p dir=\"ltr\">[4] During my talk I incorrectly cited the URL for this infrastructure as <a href=\"http://selectedpapers.net\">selectedpapers.net</a>. That is a somewhat related but different project. It is actually the <a href=\"http://gowers.wordpress.com/2013/01/16/why-ive-also-joined-the-good-guys/\">Episciences project</a>.</p><p dir=\"ltr\">[5] Since the talk, we&#8217;ve had another excellent addition to the team: <a href=\"http://jkroll.com/\">Josh Kroll</a> at Princeton, who recently published a neat <a href=\"http://weis2013.econinfosec.org/papers/KrollDaveyFeltenWEIS2013.pdf\">paper</a> on the economics of Bitcoin mining with <a href=\"http://www.iandavey.net/\">Ian Davey</a> and <a href=\"http://www.cs.princeton.edu/~felten/\">Ed Felten</a>.</p><p>[6] Something that I meant to mention at the end but ran out of time for is Michael Neilsen’s excellent book <a href=\"http://michaelnielsen.org/blog/reinventing-discovery/\">Reinventing Discovery: The New Era of Networked Science</a>. If you find the topic of this post at all interesting, you should absolutely read this book.</p><p>To stay on top of future posts, <a href=\"http://33bits.org/feed/\">subscribe</a> to the RSS feed or follow me on <a href=\"https://twitter.com/random_walker\">Twitter</a> or <a href=\"https://plus.google.com/u/0/110908828231461227679\">Google+</a>.</p><br /><a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/gocomments/33bits.wordpress.com/1129/\"><img alt=\" \" border=\"0\" src=\"http://feeds.wordpress.com/1.0/comments/33bits.wordpress.com/1129/\" /></a><img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&#038;blog=5017838&#038;post=1129&#038;subd=33bits&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />") (wfw:commentRss nil "http://33bits.org/2013/07/15/academic-publishing-as-ruinous-competition-is-there-a-way-out/feed/") (slash:comments nil "10") (media:content ((url . "http://1.gravatar.com/avatar/aa438b63ff1e9b75693aeabbeddae5eb?s=96&d=identicon&r=G") (medium . "image")) (media:title ((type . "html")) "randomwalker"))) (item nil (title nil "Personalized coupons as a vehicle for perfect price discrimination") (link nil "http://33bits.org/2013/06/25/personalized-coupons-price-discrimination/") (comments nil "http://33bits.org/2013/06/25/personalized-coupons-price-discrimination/#comments") (pubDate nil "Tue, 25 Jun 2013 15:09:42 +0000") (dc:creator nil "Arvind Narayanan") (category nil "Uncategorized") (category nil "economics") (category nil "fairness") (category nil "price discrimination") (category nil "technology") (guid ((isPermaLink . "false")) "http://33bits.org/?p=1124") (description nil "Given the pervasive tracking and profiling of our shopping and browsing habits, one would expect that retailers would be very good at individualized price discrimination —  figuring out what you or I would be willing to pay for an item using data mining, and tailoring prices accordingly. But this doesn’t seem to be happening. Why [&#8230;]<img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&#038;blog=5017838&#038;post=1124&#038;subd=33bits&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />") (content:encoded nil "<p dir=\"ltr\">Given the pervasive tracking and profiling of our shopping and browsing habits, one would expect that retailers would be very good at individualized price discrimination —  figuring out what you or I would be willing to pay for an item using data mining, and tailoring prices accordingly. But this doesn’t seem to be happening. Why not?</p><p>This mystery isn’t new. Mathematician Andrew Odlyzko predicted a decade ago that data-driven price discrimination would become much more common and effective (<a href=\"http://www.dtc.umn.edu/~odlyzko/doc/privacy.economics.pdf\">paper</a>, <a href=\"http://www.businessweek.com/stories/2003-07-30/sharper-tools-fordiscriminatory-pricing\">interview</a>). Back then, he was far ahead of his time. But today, behavioral advertising at least has gotten good enough that it’s often creepy. The technology works; the impediment to price discrimination lies elsewhere. [1]</p><p>It looks like consumers’ perception of unfairness of price discrimination is <a href=\"http://33bits.org/2013/01/22/price-discrimination-and-the-illusion-of-fairness/\">surprisingly strong</a>, which is why firms <a href=\"http://33bits.org/2013/01/08/online-price-discrimination-conspicuous-by-its-absence/\">balk at overt price discrimination</a>, even though <a href=\"http://33bits.org/2011/06/02/price-discrimination-is-all-around-you/\">covert price discrimination is all too common</a>. But the covert form of price discrimination is not only less efficient, it also (ironically) has significant social costs — see #3 below for an example. Is there a form of pricing that allows for perfect discrimination (i.e., complete tailoring to individuals), in a way that consumers find acceptable? That would be the holy grail.</p><p>In this post, I will argue that the humble coupon, reborn in a high-tech form, could be the solution. Here’s why.</p><p><strong>1. Coupons tap into shopper psychology. Customers love them.</strong></p><p>Coupons, like sales, introduce unpredictability and rewards into shopping, which provides a tiny dopamine spike that gets us hooked. JC Penney’s recent <a href=\"http://www.nytimes.com/2013/04/14/business/for-penney-a-tough-lesson-in-shopper-psychology.html?pagewanted=all&amp;_r=0\">misadventure</a> in trying to eliminate sales and coupons provides an object lesson:</p><blockquote><p>“It may be a decent deal to buy that item for $5. But for someone like me, who’s always looking for a sale or a coupon — seeing that something is marked down 20 percent off, then being able to hand over the coupon to save, it just entices me. It’s a rush.”</p></blockquote><p>Some startups have exploited this to the hilt, introducing “gamification” into commerce. <a href=\"https://en.wikipedia.org/wiki/Shopkick\">Shopkick</a> is a prime example. I see this as a very important trend.</p><p><strong>2. Coupons aren’t perceived as unfair.</strong></p><p>Given the above, shoppers have at best a dim perception of coupons as a price discrimination mechanism. Even when they do, however, coupons aren’t perceived as unfair to nearly the same degree as listing different prices for different consumers, even if the result in either case is identical. [2]</p><p><strong>3. Traditional coupons are not personalized.</strong></p><p>While customers may have different reasons for liking coupons, from firms’ perspective the way in which traditional coupons aid price discrimination is pretty simple: by forcing customers to waste their time. Econ texts tend to lay it out bluntly. For example, <a href=\"http://www.mcafee.cc/Papers/PDF/ABAPriceDiscrimination.pdf\">R. Preston McAfee</a>:</p><blockquote><p>Individuals generally value their time at approximately their wages, so that people with low wages, who tend to be the most price-sensitive, also have the lowest value of time. &#8230; A thrifty shopper may be able to spend an hour sorting through the coupons in the newspaper and save $20 on a $200 shopping expedition &#8230; This is a good deal for a consumer who values time at less than $20 per hour, and a bad deal for the consumer that values time in excess of $20 per hour. Thus, relatively poor consumers choose to use coupons, which permits the seller to have a price cut that is approximately targeted at the more price-sensitive group.</p></blockquote><p>Clearly, for this to be effective, coupon redemption must be deliberately made time-consuming.</p><p>To the extent that there is coupon personalization, it seems to be for changing shopper behavior (e.g., getting them to try out a new product) rather than a pricing mechanism. The NYT story from last year about <a href=\"http://www.nytimes.com/2012/02/19/magazine/shopping-habits.html\">Target targeting pregnant women</a> falls into this category. That said, these different forms of personalization aren’t entirely distinct, which is a point I will return to in a later article.</p><p><strong>4. The traditional model doesn’t work well any more.</strong></p><p>Paper coupons have a limited future. As for digital coupons, there is a natural progression toward interfaces that make it easier to acquire and redeem them. In particular, as more shoppers start to pay using their phones in stores, I anticipate coupon redemption being integrated into payment apps, thus becoming almost frictionless.</p><p>An interesting side-effect of smartphone-based coupon redemption is that it gives the shopper <a href=\"http://33bits.org/2011/06/08/the-many-ways-in-which-the-internet-has-given-us-more-privacy/\">more privacy</a>, avoiding the awkwardness of pulling out coupons from a purse or wallet. This will further open up coupons to a wealthier demographic, making them even less effective at discriminating between wealthier shoppers and less affluent ones.</p><p><strong>5. The coupon is being reborn in a data-driven, personalized form.</strong></p><p>With behavioral profiling, companies can determine how much a consumer will pay for a product, and deliver coupons selectively so that each customer’s discount reflects what they are willing to pay. They key difference is what while in the past, customers decided whether or not to look for, collect, and use a coupon, in the new model companies will determine who gets which coupons.</p><p>In the extreme, coupons will be available for all purchases, and smart shopping software on our phones or browsers will automatically search, aggregate, manage, and redeem these coupons, showing coupon-adjusted prices when browsing for products. More realistically, the process won’t be completely frictionless, since that would lose the psychological benefit. Coupons will probably also merge with “rewards,” “points,” discounts, and various other incentives.</p><p>There have been rumblings of this shift <a href=\"http://www.cbsnews.com/8301-505124_162-42340692/the-future-of-online-coupons-scarily-personalized-offers-based-on-your-history/\">here</a> and <a href=\"http://www.forbes.com/sites/moneybuilder/2012/08/21/individualized-coupons-aid-price-discrimination/\">there</a> for a few years now, and it seems to be happening gradually. Google’s <a href=\"http://techcrunch.com/2012/11/28/google-acquires-incentive-targeting-to-power-targeted-coupon-programs/\">acquisition</a> of Incentive Targeting a few months ago seems significant, and at the very least demonstrates that tech companies are eyeing this space as well, and not just retailers. As <a href=\"https://citp.princeton.edu/event/narayanan/\">digital feudalism</a> takes root, it could accelerate the trend of individualized shopping experiences.</p><p>In summary, personalized coupons offer a vehicle for realizing the full potential of data mining for commerce by tailoring prices in a way that consumers seem to find acceptable. Neither coupons nor price discrimination should be viewed in isolation — together with rewards and various other incentive schemes, they are part of the trend of individualized, data mining-driven commerce that’s here to stay.</p><p><strong>Footnotes</strong></p><p>[1] Since I’m eschewing some academic terminology in this post, here are a few references and points of clarification. My interest is in first-degree price discrimination. Any price discrimination requires <a href=\"https://en.wikipedia.org/wiki/Market_power\">market power</a>; my assumption is that is the case in practice because competition is always <a href=\"http://faculty.chicagobooth.edu/lars.stole/papers/pdce.pdf\">imperfect</a>, and we should expect quite a bit of first-degree price discrimination. The observed level is puzzlingly low.</p><p>The impact of technology on the ability to personalize prices is complex, and behavioral profiling is only one aspect. Technology also makes competition less perfect by allowing firms to customize products to a greater degree, so that there are no exact substitutes. Finally, technology <em>hinders</em> first-degree price discrimination to an extent by allowing consumers to compare prices between different retailers more easily. The interaction between these effects is analyzed in <a href=\"http://vulkan.worc.ox.ac.uk/wp-content/images/combined-paper.pdf\">this paper</a>.</p><p dir=\"ltr\">Technology also increases the <em>incentive</em> to price discriminate. As production becomes more and more automated, marginal costs drop relative to fixed costs. In the extreme, digital goods have essentially zero marginal cost. When marginal production costs are low, firms will try to tailor prices since any sale above marginal cost increases profits.</p><p>My use of the terms <em>overt</em> and <em>covert</em> is rooted in the theory of price fairness in psychology and behavioral economics, and relates to the <em>presentation</em> of the transaction. While it is somewhat related to first- vs. second/third-degree price discrimination, it is better understood as a separate axis, one that is not captured by theories of rational firms and consumers.</p><p>[2] An exception is when non-coupon customers are made aware that others are getting a better deal. This happens, for example, when there is a prominent coupon-code form field in an online shopping checkout flow. See <a href=\"http://www.mikeshor.com/research/promotioncodes/informstalk.pdf\">here</a> for a study.</p><p><em>Thanks to Sebastian Gold for reviewing a draft, and to Justin Brickell for interesting conversations that led me to this line of thinking.</em></p><p>To stay on top of future posts, <a href=\"http://33bits.org/feed/\">subscribe</a> to the RSS feed or follow me on <a href=\"https://twitter.com/random_walker\">Twitter</a> or <a href=\"https://plus.google.com/u/0/110908828231461227679\">Google+</a>.</p><br /><a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/gocomments/33bits.wordpress.com/1124/\"><img alt=\" \" border=\"0\" src=\"http://feeds.wordpress.com/1.0/comments/33bits.wordpress.com/1124/\" /></a><img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&#038;blog=5017838&#038;post=1124&#038;subd=33bits&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />") (wfw:commentRss nil "http://33bits.org/2013/06/25/personalized-coupons-price-discrimination/feed/") (slash:comments nil "7") (media:content ((url . "http://1.gravatar.com/avatar/aa438b63ff1e9b75693aeabbeddae5eb?s=96&d=identicon&r=G") (medium . "image")) (media:title ((type . "html")) "randomwalker"))) (item nil (title nil "Reidentification as Basic Science") (link nil "http://33bits.org/2013/05/27/reidentification-as-basic-science/") (comments nil "http://33bits.org/2013/05/27/reidentification-as-basic-science/#comments") (pubDate nil "Mon, 27 May 2013 14:16:02 +0000") (dc:creator nil "Arvind Narayanan") (category nil "Uncategorized") (category nil "de-anonymization") (category nil "ethics") (category nil "re-identification") (guid ((isPermaLink . "false")) "http://33bits.org/?p=1116") (description nil "This essay originally appeared on the Bill of Health blog as part of a conversation on the law, ethics and science of reidentification demonstrations. What really drives reidentification researchers? Do we publish these demonstrations to alert individuals to privacy risks? To shame companies? For personal glory? If our goal is to improve privacy, are we doing it in [&#8230;]<img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&#038;blog=5017838&#038;post=1116&#038;subd=33bits&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />") (content:encoded nil "<p><em>This essay <a href=\"http://blogs.law.harvard.edu/billofhealth/2013/05/26/reidentification-as-basic-science/\">originally appeared</a> on the <a href=\"http://blogs.law.harvard.edu/billofhealth\">Bill of Health blog</a> as part of a conversation on the law, ethics and science of reidentification demonstrations.</em></p><p>What <em>really</em> drives reidentification researchers? Do we publish these demonstrations to alert individuals to privacy risks? To shame companies? For personal glory? If our goal is to improve privacy, are we doing it in the best way possible?</p><p>In this post I’d like to discuss my own motivations as a reidentification researcher, without speaking for anyone else. Certainly I care about improving privacy outcomes, in the sense of making sure that companies, governments and others don’t get away with mathematically unsound promises about the privacy of consumers’ data. But there is a quite different goal I care about at least as much: <strong><em>reidentification algorithms</em></strong>. These algorithms are my primary object of study, and so I see reidentification research partly as basic science.</p><p>Let me elaborate on why reidentification algorithms are interesting and important. First, they yield fundamental insights about people — our interests, preferences, behavior, and connections — as reflected in the datasets collected about us. Second, as is the case with most basic science, these algorithms turn out to have a variety of applications other than reidentification, both for good and bad. Let us consider some of these.</p><p>First and foremost, reidentification algorithms are directly applicable in digital forensics and intelligence. Analyzing the <a href=\"http://www.americanscientist.org/issues/pub/connecting-the-dots\">structure of a terrorist network</a> (say, based on surveillance of movement patterns and meetings) to assign identities to nodes is technically very similar to <a href=\"http://33bits.org/2009/03/19/de-anonymizing-social-networks/\">social network deanonymization</a>. A reidentification researcher that I know who is a U.S. citizen tells me he has been contacted more than once by intelligence agencies to apply his expertise to their data.</p><p>Homer et al’s work on <a href=\"http://www.plosgenetics.org/article/info%3Adoi%2F10.1371%2Fjournal.pgen.1000167\">identifying individuals in DNA mixtures</a> is another great example of how forensics algorithms are inextricably linked to privacy-infringing applications. In addition to DNA and network structure, <a href=\"http://33bits.org/2012/02/20/is-writing-style-sufficient-to-deanonymize-material-posted-online/\">writing style</a> and <a href=\"http://www.nature.com/srep/2013/130325/srep01376/full/srep01376.html\">location trails</a> are other attributes that have been utilized both in reidentification and forensics.</p><p>It is not a coincidence that the reidentification literature often uses the word “fingerprint” — this body of work has generalized the notion of a fingerprint beyond physical attributes to a variety of other characteristics. Just like physical fingerprints, there are good uses and bad, but regardless, finding generalized fingerprints is a contribution to human knowledge. A fundamental question is how much information (i.e., uniqueness) there is in each of these types of attributes or characteristics. Reidentification research is gradually helping answer this question, but much remains unknown.</p><p>It is not only people that are fingerprintable — so are various physical devices. A wonderful set of (unrelated) research papers has shown that many types of devices, objects, and software systems, even supposedly identical ones, are have unique fingerprints: <a href=\"http://33bits.org/2011/09/13/everything-has-a-fingerprint-the-case-of-blank-paper/\">blank paper</a>, <a href=\"http://33bits.org/2011/09/19/digital-camera-fingerprinting/\">digital cameras</a>, <a href=\"http://33bits.org/2011/10/04/fingerprinting-of-rfid-tags-and-high-tech-stalking/\">RFID tags</a>, <a href=\"http://33bits.org/2011/10/11/everything-has-a-fingerprint-%e2%80%94-dont-forget-scanners-and-printers/\">scanners and printers</a>, and <a href=\"https://panopticlick.eff.org/\">web browsers</a>, among others. The techniques are similar to reidentification algorithms, and once again straddle security-enhancing and privacy-infringing applications.</p><p>Even more generally, reidentification algorithms are classification algorithms for the case when the number of classes is very large. Classification algorithms categorize observed data into one of several classes, i.e., categories. They are at the core of machine learning, but typical machine-learning applications rarely need to consider more than several hundred classes. Thus, reidentification science is helping develop our knowledge of how best to extend classification algorithms as the number of classes increases.</p><p>Moving on, research on reidentification and other types of “leakage” of information reveals a problem with the way data-mining contests are run. Most commonly, some elements of a dataset are withheld, and contest participants are required to predict these unknown values. Reidentification allows contestants to bypass the prediction process altogether by simply “looking up” the true values in the original data! For an example and more elaborate explanation, see <a href=\"http://33bits.org/2011/03/09/link-prediction-by-de-anonymization-how-we-won-the-kaggle-social-network-challenge/\">this post</a> on how my collaborators and I won the Kaggle social network challenge. Demonstrations of information leakage have spurred <a href=\"http://www.cs.umb.edu/~ding/history/470_670_fall_2011/papers/cs670_Tran_PreferredPaper_LeakingInDataMining.pdf\">research</a> on how to design contests without such flaws.</p><p>If reidentification can cause leakage and make things messy, it can also clean things up. In a general form, reidentification is about connecting common entities across two different databases. Quite often in real-world datasets there is no unique identifier, or it is missing or erroneous. Just about every programmer who does interesting things with data has dealt with this problem at some point. In the research world, William Winkler of the U.S. Census Bureau has authored a <a href=\"https://www.census.gov/srd/papers/pdf/rrs2006-02.pdf\">survey of “record linkage”</a>, covering well over a hundred papers. I’m not saying that the high-powered machinery of reidentification is necessary here, but the principles are certainly useful.</p><p>In my brief life as an entrepreneur, I utilized just such an algorithm for the back-end of the web application that my co-founders and I built. The task in question was to link a (musical) artist profile from last.fm to the corresponding Wikipedia article based on discography information (linking by name alone fails in any number of interesting ways.) On another occasion, for the <a href=\"http://feedworld.net/toc/\">theory of computing blog aggregator</a> that I run, I wrote code to link authors of papers uploaded to <a href=\"http://arxiv.org/\">arXiv</a> to their <a href=\"http://www.informatik.uni-trier.de/~ley/db/\">DBLP</a> profiles based on the list of coauthors.</p><p>There is more, but I’ll stop here. The point is that these algorithms are <em>everywhere</em>.</p><p>If the algorithms are the key, why perform demonstrations of privacy failures? To put it simply, algorithms can’t be studied in a vacuum; we need concrete cases to test how well they work. But it’s more complicated than that. First, as I mentioned earlier, keeping the privacy conversation intellectually honest is one of my motivations, and these demonstrations help. Second, in the majority of cases, my collaborators and I have chosen to examine pairs of datasets that were <em>already public</em>, and so our work <em>did not</em> uncover the identities of previously anonymous subjects, but merely helped to establish that this <em>could</em> happen in other instances of “anonymized” data sharing.</p><p>Third, and I consider this quite unfortunate, reidentification results are taken much more seriously if researchers do uncover identities, which naturally gives us an incentive to do so. I’ve seen this in my own work — the <a href=\"http://33bits.org/about/netflix-paper-home-page/\">Netflix paper</a> is the most straightforward and arguably the least scientifically interesting reidentification result that I’ve co-authored, and yet it received by far the most attention, all because it was carried out on an actual dataset published by a company rather than demonstrated hypothetically.</p><p>My primary focus on the fundamental research aspect of reidentification guides my work in an important way. There are many, many potential targets for reidentification — despite all the research, data holders often (<a href=\"http://33bits.org/2012/12/17/new-developments-in-deanonymization/\">rationally</a>) act like nothing has changed and continue to make data releases with <a href=\"http://www.cs.utexas.edu/~shmat/shmat_cacm10.pdf\">“PII”</a> removed. So which dataset should I pick to work on?</p><p>Focusing on the algorithms makes it a lot easier. One of my criteria for picking a reidentification question to work on is that <em>it must lead to a new algorithm</em>. I’m not at all saying that all reidentification researchers should do this, but for me it’s a good way to maximize the impact I can hope for from my research, while minimizing controversies about the privacy of the subjects in the datasets I study.</p><p>I hope this post has given you some insight into my goals, motivations, and research outputs, and an appreciation of the fact that there is more to reidentification algorithms than their application to breaching privacy. It will be useful to keep this fact in the back of our minds as we continue the conversation on the ethics of reidentification.</p><p><em>Thanks to <a href=\"http://www.cs.utexas.edu/~shmat/\">Vitaly Shmatikov</a> for reviewing a draft.</em></p><p>To stay on top of future posts, <a href=\"http://33bits.org/feed/\">subscribe</a> to the RSS feed or follow me on <a href=\"https://twitter.com/random_walker\">Twitter</a> or <a href=\"https://plus.google.com/u/0/110908828231461227679\">Google+</a>.</p><br /><a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/gocomments/33bits.wordpress.com/1116/\"><img alt=\" \" border=\"0\" src=\"http://feeds.wordpress.com/1.0/comments/33bits.wordpress.com/1116/\" /></a><img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&#038;blog=5017838&#038;post=1116&#038;subd=33bits&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />") (wfw:commentRss nil "http://33bits.org/2013/05/27/reidentification-as-basic-science/feed/") (slash:comments nil "0") (media:content ((url . "http://1.gravatar.com/avatar/aa438b63ff1e9b75693aeabbeddae5eb?s=96&d=identicon&r=G") (medium . "image")) (media:title ((type . "html")) "randomwalker"))) (item nil (title nil "Privacy technologies course roundup: Wiki, student projects, HotPETs") (link nil "http://33bits.org/2013/05/23/privacy-technologies-course-roundup-wiki-student-projects-hotpets/") (comments nil "http://33bits.org/2013/05/23/privacy-technologies-course-roundup-wiki-student-projects-hotpets/#comments") (pubDate nil "Thu, 23 May 2013 22:14:23 +0000") (dc:creator nil "Arvind Narayanan") (category nil "Uncategorized") (category nil "princeton") (category nil "privacy") (category nil "teaching") (guid ((isPermaLink . "false")) "http://33bits.org/?p=1113") (description nil "In earlier posts about the privacy technologies course I taught at Princeton during Fall 2012, I described how I refuted privacy myths, and presented an annotated syllabus. In this concluding post I will offer some additional tidbits about the course. Wiki. I referred to a Wiki a few times in my earlier post, and you [&#8230;]<img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&#038;blog=5017838&#038;post=1113&#038;subd=33bits&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />") (content:encoded nil "<p>In earlier posts about the privacy technologies course I taught at Princeton during Fall 2012, I described how I <a href=\"http://33bits.org/2013/04/11/how-i-utilized-expectation-failure-to-refute-privacy-myths/\">refuted privacy myths</a>, and presented an <a href=\"http://33bits.org/2013/04/16/privacy-technologies-an-annotated-syllabus/\">annotated syllabus</a>. In this concluding post I will offer some additional tidbits about the course.</p><p><strong>Wiki.</strong> I referred to a Wiki a few times in my earlier post, and you might wonder what that was about. The course included an online Wiki discussion component, and this was in fact the centerpiece. Students were required to participate in the online discussion of the day’s readings before coming to class. The in-class discussion would use the Wiki discussion as a starting point.</p><p dir=\"ltr\">The advantages of this approach are: 1. it gives the instructor a great degree of control in shaping the discussion of each paper, 2. the instructor can more closely monitor individual students’ progress 3. class discussion can focus on particularly tricky and/or contentious points, instead of rehashing the obvious.</p><p><strong>Student projects.</strong> Students picked a variety of final projects for the class, and on the whole exceeded my expectations. Here are two very different projects, in brief.</p><p>Nora Taranto, a History of Science major, wrote a policy paper about the privacy implications of the shift to electronic medical records. Nora writes:</p><blockquote><p>I wrote a paper about the privacy implications of patient-care institutions (in the United States) using electronic medical record (EMR) systems more and more frequently.  This topic had particular relevance given the huge number of privacy breaches that occurred in 2012 alone.  Meanwhile, there is a simultaneous criticism coming from care providers about the usability of such EMR systems.  As such, many different communities—in the information privacy sphere, in the medical community, in the general public, etc.—have many different things to say.  But, given the several privacy breaches that occurred within a couple of weeks in April 2012 and together implicated over a million individuals, concerns have been raised in particular about how secure EMR systems are.  These concerns are especially worrisome given the federal government’s push for their adoption nationwide beginning in 2009 when the American Recovery and Reinvestment Act granting funds to hospitals explicitly for the purpose of EMR implementation.</p><p>So I looked into the benefits and costs of such systems, with a particular slant towards the privacy benefits/costs.  Overall, these systems <i>do </i>have a number of protective mechanisms at their disposal, some preventative and others reactive.  While these protective barriers are all necessary, they are not sufficient to guarantee the patient his or her privacy rights in the modern day.  These protective mechanisms—authentication schemes, encryption, and data logs/anomaly-detection—need to be expanded and further developed to provide an adequate amount of protection for personal health information.  While the government is, at the moment, encouraging the adoption of EMR systems for maximal penetration, medical institutions ought to use caution in considering which systems to implement and ought to hold themselves to a higher standard.  Moreover, greater regulatory oversight of EMR systems on the market would help institutions maintain this cautious approach.</p></blockquote><p>Abu Saparov, Ajay Roopakalu, and Raﬁ Shamim, also undergraduates, designed an implemented an alternative to centralized key distribution. They write:</p><blockquote><p>Our project for the course was to create and implement a decentralized public key distribution protocol and show how it could be used. One of the initial goals of our project was to experience first-hand some of the things that made the design of a usable and useful privacy application so hard. Early on in the process, we decided to try to build some type of application that used cryptography to enhance the privacy of communication with friends. Some of the reasons that we chose this general topic were the fact that all of us had experience with network programming and that we thought some of the things that cryptography can achieve are uniquely cool. We were also somewhat motivated by the prospect of using our application to talk with each other and our other friends after we graduate. We eventually gravitated towards two ideas: (1) a completely peer-to-peer chat system that is encrypted from end-to-end, and (2) a &#8220;dumb&#8221; social network that allows users to share posts that only their friends (and not the server) can see. During the semester, our focus shifted to designing and implementing the underlying key distribution mechanism upon which these two systems could be built.</p><p>When we began to flesh out the designs for our two ideas, we realized that the act of retrieving a friend&#8217;s public cryptographic keys was the first challenge to solve. Certificate authorities are the most common way to obtain public keys, but require a large degree of trust to be placed in a small number of authorities. Web of Trust is another option, and is completely decentralized, but often proves difficult in practice because of the need for manual key signing. We decided to make our own decentralized protocol that exposes an easily usable API for clients to use in order to obtain public keys. Our protocol defines an overlay network that features regular nodes, as well as supernodes that are able to prove their trustworthiness, although the details of this are controllable through a policy delegate. The idea is for supernodes to share the task of remembering and verifying public keys through a majority vote of neighboring supernodes. Users running other nodes can ask the supernodes for a friend&#8217;s public key. In order to trick someone, an adversary would have to control over half of the supernodes from which a user requested a key. Our decision to go with an overlay network created a variety of issues such as synchronizing information between supernodes, being able to detect and report malicious supernodes, and getting new nodes incorporated into the network. These and the countless other design problems we faced definitely allowed us to appreciate the difficulty of writing a privacy application, but unfortunately, we were not fully able to test every element of our protocol and its implementation. After creating the protocol, we implemented small, bare-bones applications for our initial ideas of peer-to-peer chat and an encrypted social network.</p></blockquote><p>Master&#8217;s students Chris Eubank, <a href=\"http://www.cs.princeton.edu/~melara/\">Marcela Melara</a>, and <a href=\"http://www.cs.princeton.edu/~diegop/\">Diego Perez-Botero</a> did a project on mobile web tracking which, with some further work, turned into a <a href=\"http://w2spconf.com/2013/papers/s2p2.pdf\">research paper</a> that Chris will speak about at <a href=\"http://w2spconf.com/2013/\">W2SP</a> tomorrow.</p><p>Finally, I&#8217;m happy to say that I will be discussing the syllabus and my experiences teaching this class at <a href=\"http://petsymposium.org/2013/hotpets.php\">HotPETs</a> this year, in Bloomington, IN, in July.</p><p>To stay on top of future posts, <a href=\"http://33bits.org/feed/\">subscribe</a> to the RSS feed or follow me on <a href=\"https://twitter.com/random_walker\">Twitter</a> or <a href=\"https://plus.google.com/u/0/110908828231461227679\">Google+</a>.</p><br /><a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/gocomments/33bits.wordpress.com/1113/\"><img alt=\" \" border=\"0\" src=\"http://feeds.wordpress.com/1.0/comments/33bits.wordpress.com/1113/\" /></a><img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&#038;blog=5017838&#038;post=1113&#038;subd=33bits&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />") (wfw:commentRss nil "http://33bits.org/2013/05/23/privacy-technologies-course-roundup-wiki-student-projects-hotpets/feed/") (slash:comments nil "1") (media:content ((url . "http://1.gravatar.com/avatar/aa438b63ff1e9b75693aeabbeddae5eb?s=96&d=identicon&r=G") (medium . "image")) (media:title ((type . "html")) "randomwalker"))) (item nil (title nil "What Happened to the Crypto Dream? Now in a new and improved paper form!") (link nil "http://33bits.org/2013/04/29/what-happened-to-the-crypto-dream-now-in-a-new-and-improved-paper-form/") (comments nil "http://33bits.org/2013/04/29/what-happened-to-the-crypto-dream-now-in-a-new-and-improved-paper-form/#comments") (pubDate nil "Mon, 29 Apr 2013 20:06:53 +0000") (dc:creator nil "Arvind Narayanan") (category nil "Uncategorized") (category nil "cryptography") (category nil "cypherpunk") (category nil "economics") (category nil "privacy") (guid ((isPermaLink . "false")) "http://33bits.org/?p=1110") (description nil "Last October I gave a talk titled “What Happened to the Crypto Dream?” where I looked at why crypto seems to have done little for personal privacy. The reaction from the audience (physical and online) was quite encouraging — not that everyone agreed, but they seemed to find it thought provoking — and several people [&#8230;]<img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&#038;blog=5017838&#038;post=1110&#038;subd=33bits&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />") (content:encoded nil "<p dir=\"ltr\">Last October I gave a talk titled “<a href=\"https://citp.princeton.edu/event/arvind-narayanan/\">What Happened to the Crypto Dream?</a>” where I looked at why crypto seems to have done little for personal privacy. The reaction from the audience (physical and online) was quite encouraging — not that everyone agreed, but they seemed to find it thought provoking — and several people asked me if I’d turn it into a paper. So when Prof. Alessandro Acquisti invited me to contribute an essay to the “On the Horizon” column in IEEE S&amp;P magazine, I jumped at the chance, and suggested this topic.</p><p dir=\"ltr\">Thanks to some fantastic feedback from colleagues and many improvements to the prose by the editors, I’m happy with how the essay has turned out. Here it is in two parts: <strong><a href=\"http://randomwalker.info/publications/crypto-dream-part1.pdf\">Part 1</a></strong>, <strong><a href=\"http://randomwalker.info/publications/crypto-dream-part2.pdf\">Part 2</a></strong>.</p><p dir=\"ltr\">While I’m not saying anything earth shaking, I do make a somewhat nuanced argument — I distinguish between “crypto for security” and “crypto for privacy,” and further subdivide the latter into a spectrum between what I call “Cypherpunk Crypto” and “Pragmatic Crypto.” I identify different practical impediments that apply to those two flavors (in the latter case, a complex of related factors), and lay out a few avenues for action that can help privacy-enhancing crypto move in a direction more relevant to practice.</p><p>I’m aware that this is a contentious topic, especially since some people feel that the time is ripe for a resurgence of the cypherpunk vision. I’m happy to hear your reactions.</p><p>To stay on top of future posts, <a href=\"http://33bits.org/feed/\">subscribe</a> to the RSS feed or follow me on <a href=\"https://twitter.com/random_walker\">Twitter</a> or <a href=\"https://plus.google.com/u/0/110908828231461227679\">Google+</a>.</p><br /><a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/gocomments/33bits.wordpress.com/1110/\"><img alt=\" \" border=\"0\" src=\"http://feeds.wordpress.com/1.0/comments/33bits.wordpress.com/1110/\" /></a><img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&#038;blog=5017838&#038;post=1110&#038;subd=33bits&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />") (wfw:commentRss nil "http://33bits.org/2013/04/29/what-happened-to-the-crypto-dream-now-in-a-new-and-improved-paper-form/feed/") (slash:comments nil "0") (media:content ((url . "http://1.gravatar.com/avatar/aa438b63ff1e9b75693aeabbeddae5eb?s=96&d=identicon&r=G") (medium . "image")) (media:title ((type . "html")) "randomwalker"))) (item nil (title nil "Privacy technologies: An annotated syllabus") (link nil "http://33bits.org/2013/04/16/privacy-technologies-an-annotated-syllabus/") (comments nil "http://33bits.org/2013/04/16/privacy-technologies-an-annotated-syllabus/#comments") (pubDate nil "Tue, 16 Apr 2013 12:02:57 +0000") (dc:creator nil "Arvind Narayanan") (category nil "Uncategorized") (category nil "princeton") (category nil "privacy") (category nil "teaching") (guid ((isPermaLink . "false")) "http://33bits.org/?p=1105") (description nil "Last semester I taught a course on privacy technologies here at Princeton. Earlier I discussed how I refuted privacy myths that students brought into class. In this post I’d like to discuss the contents of the course. I hope it will be useful to other instructors who are interested in teaching this topic as well [&#8230;]<img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&#038;blog=5017838&#038;post=1105&#038;subd=33bits&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />") (content:encoded nil "<p>Last semester I taught a <span class=\"c7\"><a class=\"c5\" href=\"http://randomwalker.info/teaching/fall-2012-privacy-technologies/\">course</a></span> on privacy technologies here at Princeton. Earlier I discussed how I <span class=\"c7\"><a class=\"c5\" href=\"http://33bits.org/2013/04/11/how-i-utilized-expectation-failure-to-refute-privacy-myths/\">refuted privacy myths</a></span> that students brought into class. In this post I’d like to discuss the contents of the course. I hope it will be useful to other instructors who are interested in teaching this topic as well as for students undertaking self-study of privacy technologies. Beware: this post is quite <span class=\"c6\">long</span>.</p><p class=\"c0\">What should be taught in a class on privacy technologies? Before we answer that, let’s take a step back and ask, <strong><span class=\"c10\">how does one go about figuring out what should be taught in any class?</span></strong></p><p class=\"c0\">I’ve seen two approaches. The traditional, default, overwhelmingly common approach is to think of it in terms of “covering content” without much consideration to what students are getting out of it. The content that’s deemed relevant is often determined by what the fashionable research areas happen to be, or historical accident, or some combination thereof.</p><p class=\"c0\">A contrasting approach, promoted by authors like <span class=\"c7\"><a class=\"c5\" href=\"http://www.amazon.com/What-Best-College-Teachers-Do/dp/0674013255\">Bain</a></span>, applies a laser focus on skills that students will acquire and how they will apply them later in life. On teaching orientation day at Princeton, our instructor, who clearly subscribed to this approach, had each professor describe what students would do in the class they are teaching, then wrote down only the verbs from these descriptions. The point was that our thinking had to be centered around skills that students would take home.</p><p class=\"c0\">I prefer a middle ground. It should be apparent from my description of the traditional approach above that I’m not a fan. On the other hand, I have to wonder what skills our teaching coach would have suggested for a course on cosmology — avoiding falling into black holes? Alright, I’m exaggerating to make a point. The verbs in question are words like “synthesize” and “evaluate,” so there would be no particular difficulty in applying them to cosmology. But my point is that in a cosmology course, I’m not sure the instructor should start from these verbs.</p><p class=\"c0\">Sometimes we want students to be exposed to knowledge primarily because it is beautiful, and being able to perceive that beauty inspires us, instills us with a love of further learning, and I dare say satisfies a fundamental need. To me a lot of the crypto “magic” that goes into privacy technologies falls into that category (not that it doesn&#8217;t have practical applications).</p><p class=\"c0\">With that caveat, however, I agree with the emphasis on skills and life impact. I thought of my students primarily as developers of privacy technologies (and more generally, of technological systems that incorporate privacy considerations), but also as users and scholars of privacy technologies.</p><p class=\"c0\">I organized the course into sections, a short introductory section followed by five sections that alternated in the level of math/technical depth. Every time we studied a technology, we also discussed its social/economic/political aspects. I had a great deal of discretion in guiding where the conversation around the papers went by giving them questions/prompts on the class Wiki. Let us now jump in. The italicized text is from the <a href=\"http://randomwalker.info/teaching/fall-2012-privacy-technologies/\">course page</a>, the rest is my annotation.</p><p class=\"c0\"><strong><em><span class=\"c2 c10\">0. </span><span class=\"c2 c10\">Intro</span></em></strong></p><p class=\"c0\"><em><span class=\"c2\">Goals of this section: Why are we here? Who cares about privacy? What might the future look like?</span></em></p><ul><li class=\"c4 c0\"><em><span class=\"c2\">Dan Solove. </span><span class=\"c8 c14 c6\"><a class=\"c5\" href=\"http://chronicle.com/article/Why-Privacy-Matters-Even-if/127461/\">Why Privacy Matters Even if You Have &#8216;Nothing to Hide’</a></span><span class=\"c2\"> (Chronicle)</span></em></li><li class=\"c4 c0\"><em><span class=\"c2\">David Brin. </span><span class=\"c8 c14 c6\"><a class=\"c5\" href=\"http://www.wired.com/wired/archive/4.12/fftransparent_pr.html\">The Transparent Society</a></span><span class=\"c2\"> (WIRED, circa 1996, later expanded into a book)</span></em></li></ul><p class=\"c0\">In addition to helping flesh out the foundational assumptions of this course that I discussed in the <a href=\"http://33bits.org/2013/04/11/how-i-utilized-expectation-failure-to-refute-privacy-myths/\">previous post</a>, pairing these opposing views with each other helped make the point that there are few absolutes in this class, that privacy scholars may disagree with each other, and that the instructor doesn’t necessarily agree with the viewpoints in the assigned reading, much less expects students to.</p><p class=\"c0\"><em><strong><span class=\"c2 c10\">1. </span><span class=\"c2 c10\">Cryptography: power and limitations</span></strong></em></p><p class=\"c9 c0\"><em><span class=\"c6\">Goals. Travel back in time to the 80s and early 90s, understand the often-euphoric vision that many crypto pioneers and hobbyists had for the impact it would have. Understand how cryptographic building blocks were thought to be able to support this restructuring of society. Reason about why it didn&#8217;t happen.</span></em></p><p class=\"c9 c0\"><em><span class=\"c6\">Understand the motivations and mathematical underpinnings of the modern research on privacy-preserving computations. Experiment with various encryption tools, discover usability problems and other limitations of crypto.</span></em></p><ul><li class=\"c4 c0\"><em><span class=\"c2\">David Chaum. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.chaum.com/articles/Security_Wthout_Identification.htm\">Security without Identification: Card Computers to make Big Brother Obsolete</a></span><span class=\"c2\"> (1985)</span></em></li><li class=\"c4 c0\"><em><span class=\"c2\">Steven Levy. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.wired.com/wired/archive/1.02/crypto.rebels_pr.html\">Crypto Rebels</a></span><span class=\"c2\"> (WIRED, 1993; later a </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.amazon.com/Crypto-Rebels-Government-Privacy-Digital/dp/0140244328/\">2001 book</a></span><span class=\"c2\">)</span></em></li><li class=\"c4 c0\"><em><span class=\"c2\">Eric Hughes. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.activism.net/cypherpunk/manifesto.html\">A cypherpunk&#8217;s manifesto.</a></span><span class=\"c2\"> (short essay, 1993.)</span></em></li></ul><p class=\"c0 c11\">I think the Chaum paper is a phenomenal and underutilized resource for teaching. My goal was to really immerse students in an alternate reality where the legal underpinnings of commerce were replaced by cryptography, much as Chaum envisioned (and even going beyond that). I created a couple of e-commerce scenarios for Wiki discussion and had them reason about how various functions would be accomplished.</p><p class=\"c0 c11\">My own views on this topic are set forth in this <a href=\"https://citp.princeton.edu/event/arvind-narayanan/\">talk</a> (now a paper; coming soon). In general I aimed to shield students from my viewpoints, and saw my role as helping them discover (and be able to defend) their own. At least in this instance I succeeded. Some students took the position that the cypherpunk dream is just around the corner.</p><ul><li><em>The ‘Garbled Circuit Protocol’ (Yao&#8217;s theorem on secure two-party computation) and its implications (lecture)</em></li></ul><p class=\"c0\">This is one of the topics that sadly suffers from a lack of good expository material, so I instead lectured on it.</p><ul><li class=\"c4 c0\"><em><span class=\"c2\">Alma Whitten and Doug Tygar. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.gaudior.net/alma/johnny.pdf\">Why Johnny Can’t Encrypt: A Usability Evaluation of PGP 5.0</a></span></em></li><li class=\"c4 c0\"><em><span class=\"c2\">Nikita Borisov, Ian Goldberg, Eric Brewer. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.cypherpunks.ca/otr/otr-wpes.pdf\">Off-the-Record Communication, or, Why Not To Use PGP</a></span></em></li><li class=\"c4 c0\"><em><span class=\"c2\">Thomas Ptacek. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.matasano.com/articles/javascript-cryptography/\">Javascript Cryptography Considered Harmful</a></span></em></li></ul><p class=\"c0\">One of the exercises here was to install and use various crypto tools and rediscover the usability problems. The difficulties were even worse than I’d anticipated.</p><p class=\"c0\"><em><strong><span class=\"c2 c10\">2. Data collection and data mining, economics of personal data, behavioral economics of privacy</span></strong></em></p><p class=\"c0\"><em><span class=\"c6\">Goals. Jump forward in time to the present day and immerse ourselves in the world of ubiquitous data collection and surveillance. Discover what kinds of data collection and data mining are going on, and why. Discuss how and why the conversation has shifted from Government surveillance to data collection by private companies in the last 20 years.</span></em></p><p class=\"c9 c0\"><em><span class=\"c2\">Theme: first-party data collection.</span></em></p><ul><li><em><span class=\"c2\">New York Times. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.nytimes.com/2012/02/19/magazine/shopping-habits.html\">How Companies Learn Your Secrets</a></span></em></li><li><em><span class=\"c2\">Andrew Odlyzko. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.dtc.umn.edu/~odlyzko/doc/privacy.economics.pdf\">Privacy, Economics, and Price Discrimination on the Internet</a></span></em></li></ul><p class=\"c9 c0\"><em><span class=\"c2\">Theme: third-party data collection.</span></em></p><ul><li><em><span class=\"c2\">Julia Angwin. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://online.wsj.com/article/SB10001424052748703940904575395073512989404.html\">The Web&#8217;s New Gold Mine: Your Secrets</a></span><span class=\"c2\"> (First in the Wall Street Journal’s What They Know series)</span></em></li><li><em><span class=\"c2\">Jonathan R. Mayer and John C. Mitchell. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"https://www.stanford.edu/~jmayer/papers/trackingsurvey12.pdf\">Third-Party Web Tracking: Policy and Technology</a></span></em></li></ul><p class=\"c9 c0\"><em><span class=\"c2\">Theme: why companies act the way they do.</span></em></p><ul><li><em><span class=\"c2\">Joseph Bonneau and Sören Preibusch. The Privacy Jungle: </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://preibusch.de/publications/Bonneau_Preibusch__Privacy_Jungle__2009-05-26.pdf\">On the Market for Data Protection in Social Networks</a></span></em></li><li><em><span class=\"c2\">Bruce Schneier. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.wired.com/politics/security/commentary/securitymatters/2007/04/securitymatters_0419\">How Security Companies Sucker Us With Lemons</a></span><span class=\"c2\"> (WIRED)</span></em></li></ul><p class=\"c9 c0\"><em><span class=\"c2\">Theme: why people act the way they do.</span></em></p><ul><li><em><span class=\"c2\">Alessandro Acquisti and Jens Grossklags. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.heinz.cmu.edu/~acquisti/papers/Acquisti-Grossklags-Chapter-Etrics.pdf\">What Can Behavioral Economics Teach Us About Privacy?</a></span></em></li><li><em><span class=\"c2\">Alessandro Acquisti. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.heinz.cmu.edu/~acquisti/papers/privacy-gratification.pdf\">Privacy in Electronic Commerce and the Economics of Immediate Gratification</a></span></em></li></ul><p class=\"c0\">This section is rather self-explanatory. After the math-y flavor of the first section, this one has a good amount of economics, behavioral economics, and policy. One of the thought exercises was to project current trends into the future and imagine what ubiquitous tracking might lead to in five or ten years.</p><p class=\"c0\"><em><strong><span class=\"c2 c10\">3. </span><span class=\"c2 c10\">Anonymity and De-anonymization</span></strong></em></p><p class=\"c0 c9\"><em><span class=\"c2\">Important note: communications anonymity (e.g., Tor) and data anonymity/de-anonymization (e.g., identifying people in digital databases) are technically very different, but we will discuss them together because they raise some of the same ethical questions. Also, Bitcoin lies somewhere in between the two.</span></em></p><ul><li><em><span class=\"c2\">Roger Dingledine, Nick Mathewson, Paul Syverson. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"https://svn.torproject.org/svn/projects/design-paper/tor-design.pdf\">Tor: The Second-Generation Onion Router</a></span></em></li></ul><ul><li><em><span class=\"c2\">Satoshi Nakamoto. Bitcoin: </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://bitcoin.org/bitcoin.pdf\">A Peer-to-Peer Electronic Cash System</a></span></em></li></ul><p class=\"c0\">Tor and Bitcoin (especially the latter) were the hardest but also the most rewarding parts of the class, both for them and for me. Together they took up 4 classes. Bitcoin is extremely challenging to teach because it is technically intricate, the ecosystem is rapidly changing, and a lot of the information is in random blog/forum posts.</p><p class=\"c0\">In a way, I was betting on Bitcoin by deciding to teach it — if it had died with a whimper, their knowledge of it would be much less relevant. In general I think instructors should choose to make these such bets more often; most curricula are very conservative. I’m glad I did.</p><ul><li><em><span class=\"c2\">Nils Homer at al. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.plosgenetics.org/article/info%3Adoi%2F10.1371%2Fjournal.pgen.1000167\">Resolving Individuals Contributing Trace Amounts of DNA to Highly Complex Mixtures Using High-Density SNP Genotyping Microarrays</a></span></em></li><li><em><span class=\"c2\">[Optional] Arvind Narayanan, Elaine Shi, Benjamin I. P. Rubinstein. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://arxiv.org/pdf/1102.4374v1.pdf\">Link Prediction by De-anonymization: How We Won the Kaggle Social Network Challenge</a></span></em></li></ul><p class=\"c0\">It was a challenge to figure out which deanonymization paper to assign. I went with the DNA one because I wanted them to see that deanonymization isn&#8217;t a fact about data, but a fact about the world. Another thing I liked about this paper is that they’d have to extract the not-too-complex statistical methodology in this paper from the bioinformatics discussion in which it is embedded. This didn&#8217;t go as well as I’d hoped.</p><p class=\"c0\">I’ve co-authored a few deanonymization papers, but they’re not very well written and/or are poorly suited for pedagogical purposes. The Kaggle paper is one exception, which I made optional.</p><ul><li><em><span class=\"c2\">Paul Ohm. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1450006\">Broken Promises of Privacy: Responding to the Surprising Failure of Anonymization</a></span></em></li><li><em><span class=\"c2\">[Optional] Jane Yakowitz Bambauer. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1789749\">Tragedy of the Data Commons</a></span></em></li></ul><p class=\"c0\">This is another pair of papers with opposing views. Since the latter paper is optional, knowing that most of them wouldn&#8217;t have read it, I used the Wiki prompts to raise many of the issues that the author raises.</p><p class=\"c0\"><em><strong><span class=\"c2 c10\">4. </span><span class=\"c2 c10\">Lightweight Privacy Technologies and New Approaches to Information Privacy</span></strong></em></p><p class=\"c0\"><span class=\"c12\">While cryptography is the mechanism of choice for cypherpunk privacy and anonymity tools like Tor, it is too heavy a weapon in other contexts like social networking. In the latter context, it’s not so much users deploying privacy tools to protect themselves against all-powerful adversaries but rather a service provider attempting to cater to a more nuanced understanding of privacy that users bring to the system. </span><span class=\"c12\">The goal of this section is to consider a diverse spectrum of ideas applicable to this latter scenario that have been proposed in recent years in the fields of CS, HCI, law, and more. The technologies here are “lightweight” in comparison to cryptographic tools like Tor.</span></p><ul><li><em><span class=\"c2\">Scott Lederer, Jason Hong et al. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://repository.cmu.edu/cgi/viewcontent.cgi?article=1077&amp;context=hcii\">Personal Privacy through Understanding and Action: Five Pitfalls for Designers</a></span></em></li><li><em><span class=\"c2\">Franziska Roesner et al. </span><span class=\"c6 c8\"><a class=\"c5\" href=\"http://research.microsoft.com/apps/pubs/?id=152495\">User-Driven Access Control: Rethinking Permission Granting in Modern Operating Systems</a></span></em></li></ul><ul><li><em><span class=\"c2\">Fred Stutzman and Woodrow Hartzog. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://fredstutzman.com/papers/CSCW2012W_Stutzman.pdf\">Obscurity by Design: An Approach to Building Privacy into Social Media</a></span></em></li><li><em><span class=\"c2\">Woodrow Hartzog and Fred Stutzman. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1597745\">The Case for Online Obscurity</a></span></em></li></ul><ul><li class=\"c4 c0\"><em><span class=\"c2\">Jerry Kang et al. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.ntia.doc.gov/files/ntia/comments/101214614-0614-01/attachments/kang,%20shilton,%20estrin,%20burke,%20hansen,%20self-surveillance%20privacy%20v12.pdf\">Self-surveillance Privacy</a></span></em></li><li class=\"c4 c0\"><em><span class=\"c2\">[Optional] Ryan Calo. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1790144\">Against Notice Skepticism In Privacy (And Elsewhere)</a></span></em></li></ul><ul><li><em><span class=\"c2\">Helen Nissenbaum. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.amacad.org/publications/daedalus/11_fall_nissenbaum.pdf\">A Contextual Approach to Privacy Online</a></span></em></li></ul><p class=\"c0\"><em><strong><span class=\"c2 c10\">5. Purely technological approaches revisited</span></strong></em></p><p class=\"c0\"><span class=\"c12\">This final section doesn’t have a coherent theme (and I admitted as much in class). My goal with the first two papers was to contrast a privacy problem which seems amenable to a purely or primarily technological formulation and solution (statistical queries over databases of sensitive personal information) with one where such attempts have been less successful (the decentralized, own-your-data approach to social networking and e-commerce). </span></p><ul><li><em>Differential Privacy. (Lecture)</em><ul><li><em><span class=\"c2\">Cynthia Dwork. </span><span class=\"c8 c14 c6\"><a class=\"c5\" href=\"http://research.microsoft.com/pubs/64346/dwork.pdf\">Differential Privacy</a></span><span class=\"c6 c13\">.</span></em></li></ul></li></ul><p class=\"c0\">Differential privacy is another topic that is sorely lacking in expository material, especially from the point of view of students who’ve never done crypto before. So this was again a lecture.</p><ul><li><em><span class=\"c2\">Arvind Narayanan et al. </span><span class=\"c8 c14 c6\"><a class=\"c5\" href=\"http://randomwalker.info/publications/critical-look-at-decentralization-v1.pdf\">A Critical Look at Decentralized Personal Data Architectures</a></span></em></li></ul><ul><li><em><span class=\"c2\">John Perry Barlow </span><span class=\"c8 c14 c6\"><a class=\"c5\" href=\"https://projects.eff.org/~barlow/Declaration-Final.html\">A Declaration of the Independence of Cyberspace</a></span><span class=\"c2\"> (short essay, 1996)</span></em></li><li><em><span class=\"c2\">James Grimmelmann. </span><span class=\"c8 c6 c14\"><a class=\"c5\" href=\"http://illinoislawreview.org/wp-content/ilr-content/articles/2012/2/Grimmelmann.pdf\">Sealand, HavenCo, and the Rule of Law</a></span></em></li></ul><p class=\"c0\">These two essays aren’t directly related to privacy. One of the recurring threads in this course is the debate between purely technological and legal or other approaches to privacy; the theme here is to generalize it to a context broader than privacy. The Barlow essay asserts the exceptionalism of Cyberspace as an unregulable medium, whereas the Grimmelmann paper provides a much more nuanced view of the relationship between the law and new technological frontiers.</p><p class=\"c0\"><strong><span class=\"c10\">I’m making available the entire set of Wiki discussion prompts for the class</span></strong><b id=\"internal-source-marker_0.6116034584119916\">(<a href=\"http://randomwalker.info/teaching/fall-2012-privacy-technologies/discussion-prompts.html\">HTML</a>/<a href=\"http://randomwalker.info/teaching/fall-2012-privacy-technologies/discussion-prompts.pdf\">PDF</a>).</b> I consider this integral to the syllabus, for it shapes the discussion very significantly. I really hope other instructors and students find this useful as a teaching/study guide. For reference, each set of prompts (one set per class) took me about three hours to write on average.</p><p class=\"c0\">There are many more things I want to share about this class: the major take-home ideas, the rationale for the Wiki discussion format, the feedback I got from students, a description of a couple of student projects, some thoughts on the sociology of different communities studying privacy and how that impacted the class, and finally, links to similar courses that are being taught elsewhere. I’ll probably close this series with a round-up post including as many of the above topics as I can.</p><p class=\"c0\">To stay on top of future posts, <a href=\"http://33bits.org/feed/\">subscribe</a> to the RSS feed or follow me on <a href=\"https://twitter.com/random_walker\">Twitter</a> or <a href=\"https://plus.google.com/u/0/110908828231461227679\">Google+</a>.</p><br /><a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/gocomments/33bits.wordpress.com/1105/\"><img alt=\" \" border=\"0\" src=\"http://feeds.wordpress.com/1.0/comments/33bits.wordpress.com/1105/\" /></a><img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&#038;blog=5017838&#038;post=1105&#038;subd=33bits&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />") (wfw:commentRss nil "http://33bits.org/2013/04/16/privacy-technologies-an-annotated-syllabus/feed/") (slash:comments nil "2") (media:content ((url . "http://1.gravatar.com/avatar/aa438b63ff1e9b75693aeabbeddae5eb?s=96&d=identicon&r=G") (medium . "image")) (media:title ((type . "html")) "randomwalker"))) (item nil (title nil "How I utilized “expectation failure” to refute privacy myths") (link nil "http://33bits.org/2013/04/11/how-i-utilized-expectation-failure-to-refute-privacy-myths/") (comments nil "http://33bits.org/2013/04/11/how-i-utilized-expectation-failure-to-refute-privacy-myths/#comments") (pubDate nil "Thu, 11 Apr 2013 12:50:18 +0000") (dc:creator nil "Arvind Narayanan") (category nil "Uncategorized") (category nil "princeton") (category nil "privacy") (category nil "teaching") (guid ((isPermaLink . "false")) "http://33bits.org/?p=1101") (description nil "Last semester I taught a course on privacy technologies. Since it was a seminar, the class was a small, self-selected group of very motivated students. Based on the feedback, it seems to have been a success; it was certainly quite personally gratifying for me. This is the first in a series of posts on what [&#8230;]<img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&#038;blog=5017838&#038;post=1101&#038;subd=33bits&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />") (content:encoded nil "<p dir=\"ltr\">Last semester I taught a course on <a href=\"http://randomwalker.info/teaching/fall-2012-privacy-technologies/\">privacy technologies</a>. Since it was a seminar, the class was a small, self-selected group of very motivated students. Based on the feedback, it seems to have been a success; it was certainly quite personally gratifying for me. This is the first in a series of posts on what I learnt from teaching this course. In this post I will discuss some major misconceptions about privacy, how to refute them, and why it is important to do this right at the beginning of the course.</p><p><strong>Privacy’s primary pitfalls</strong></p><p>Instructors are often confronted with breaking down faulty mental models that students bring into class before actual learning can happen. This is especially true of the topic at hand. Luckily, misconceptions about privacy are so pervasive in the media and among the general public that it wasn&#8217;t too hard to identify the most common ones before the start of the course. And it didn&#8217;t take much class discussion to confirm that my students weren&#8217;t somehow exempt from these beliefs.</p><p>One cluster of myths is about the supposed lack of importance of privacy. 1. “There is no privacy in the digital age.” This is the most common and perhaps the most grotesquely fallacious of the misconceptions; more on this below. 2. “No one cares about privacy any more” (variant: young people don’t care about privacy.) 3. “If you haven’t done anything wrong you have <a href=\"https://chronicle.com/article/Why-Privacy-Matters-Even-if/127461/\">nothing to hide</a>.”</p><p>A second cluster of fallacious beliefs is very common among computer scientists and comes from the tendency to reduce everything to a black-and-white technical problem. In this view, privacy maps directly to access control and cryptography is the main technical mechanism for achieving privacy. It’s a view in which the world is full of <a href=\"http://33bits.org/2010/11/08/adversarial-thinking-considered-harmful-sometimes/\">adversaries</a> and there is no room for <a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1597745\">obscurity</a> or nontechnical ways of improving privacy.</p><p><strong>The first step in learning is to unlearn</strong></p><p dir=\"ltr\">Why is it important to spend time confronting faulty mental models? Why not simply teach the “right” ones? In my case, there was a particularly acute reason — to the extent that students believe that privacy is dead and that learning about privacy technologies is unimportant, they are not going to be invested in the class, which would be really bad. But even in the case of misconceptions that don’t lead to students doubting the fundamental premise of the class, there is a surprising reason why unlearning is important.</p><p dir=\"ltr\">A <a href=\"http://rmcfadden.wikispaces.com/file/view/bain_what_do_they_know_about_how_we_learn2.pdf\">famous experiment</a> in the &#8217;80s (I really <em>really</em> recommend reading the linked text) demonstrated what we now know about the ineffectiveness of the “information transmission” model of teaching. The researchers interviewed students after any of four introductory physics courses, and determined that they hadn&#8217;t actually learned what had been taught, such as Newton’s laws of motion; instead they just learned to pass the tests. When the researchers sat down with students to find out why, here’s what they found:<b><b> </b></b></p><p dir=\"ltr\"><em>What they heard astonished them: many of the students still refused to give up their mistaken ideas about motion. Instead, they argued that the experiment they had just witnessed did not exactly apply to the law of motion in question; it was a special case, or it didn&#8217;t quite fit the mistaken theory or law that they held as true.</em></p><p>A special case! Ha. What’s going on here? Well, learning new facts is easy. On the other hand, updating mental models is so cognitively expensive that we go to absurd lengths to avoid doing so. The societal-scale analog of this extreme reluctance is well-illustrated by the history of science — we patched the Ptolemaic model of the Universe, with the Earth at the center, for over a millennium before we were forced to accept that the Copernican system fit observations better.</p><p><strong>The instructor’s arsenal </strong></p><p dir=\"ltr\">The good news is that the instructor can utilize many effective strategies that fall under the umbrella of <a href=\"https://en.wikipedia.org/wiki/Active_learning\">active learning</a>. Ken Bain’s excellent <a href=\"http://www.amazon.com/What-Best-College-Teachers-Do/dp/0674013255/\">book</a> (which the preceding text describing the experiment is from) lays out a pattern in which the instructor creates an <a href=\"http://www.julianhermida.com/workshop2expect.htm\">expectation failure</a>, a situation in which existing mental models of reality will lead to faulty expectations. One of the prerequisites for this to work, according to the book, is to get students to care.</p><p dir=\"ltr\">Bain argues that expectation failure, done right, can be so powerful that students might need <em>emotional support</em> to cope. Fortunately, this wasn&#8217;t necessary in my class, but I have no doubt of it based on my personal experiences. For instance, back when I was in high school, learning how the Internet actually worked and realizing that my intuitions about the network had to be discarded entirely was such a disturbing experience that I remember my feelings to this day.<b><b> </b></b></p><p dir=\"ltr\">Let’s look at an example of expectation failure in my privacy class. To refute the “privacy is dying” myth, I found it useful to talk about Fifty Shades of Grey — specifically, why it succeeded even though publishers initially passed on it. One answer <a href=\"http://observer.com/2013/01/doubleday-to-publish-hardcover-fifty-shades-of-grey-trilogy/\">seems to be</a> that since it was first self-published as an e-book, it allowed readers to be discreet and avoid the stigma associated with the genre. (But following its runaway success in that form, the stigma disappeared, and it was released in paper form and flew off the shelves.)</p><p dir=\"ltr\">The relative privacy of e-books from prying strangers is one of the many ways in which digital technology affords <a href=\"http://33bits.org/2011/06/08/the-many-ways-in-which-the-internet-has-given-us-more-privacy/\">more privacy</a> for specific activities. Confronting students with an observed phenomenon whose explanation involves a fact that seems starkly contrary to the popular narrative creates an expectation failure. Telling personal stories about how technology has either improved or eroded privacy, and eliciting such stories from students, gets them to care. Once this has been accomplished, it’s productive to get into a nuanced discussion of how to reconcile the two views with each other, different meanings of privacy (e.g., <a href=\"http://www.guardian.co.uk/books/2012/aug/31/readers-privacy-under-threat\">tracking of reading habits</a>), how the Internet has affected each, and how society is adjusting to the changing technological landscape.</p><p dir=\"ltr\">I’m quite new to teaching — this is only my second semester at Princeton — but it’s been exciting to internalize the fact that learning is something that can be studied scientifically and teaching is an activity that can vary dramatically in effectiveness. I’m looking forward to getting better at it and experimenting with different methods. In the next post I will share some thoughts on the content of my course and what I tried to get students to take home from it.</p><p dir=\"ltr\"><em>Thanks to Josh Hug for reviewing a draft</em>.</p><p dir=\"ltr\">To stay on top of future posts, <a href=\"http://33bits.org/feed/\">subscribe</a> to the RSS feed or follow me on <a href=\"https://twitter.com/random_walker\">Twitter</a> or <a href=\"https://plus.google.com/u/0/110908828231461227679\">Google+</a>.</p><br /><a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/gocomments/33bits.wordpress.com/1101/\"><img alt=\" \" border=\"0\" src=\"http://feeds.wordpress.com/1.0/comments/33bits.wordpress.com/1101/\" /></a><img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&#038;blog=5017838&#038;post=1101&#038;subd=33bits&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />") (wfw:commentRss nil "http://33bits.org/2013/04/11/how-i-utilized-expectation-failure-to-refute-privacy-myths/feed/") (slash:comments nil "0") (media:content ((url . "http://1.gravatar.com/avatar/aa438b63ff1e9b75693aeabbeddae5eb?s=96&d=identicon&r=G") (medium . "image")) (media:title ((type . "html")) "randomwalker"))) (item nil (title nil "Unlikely Outcomes? A Distributed Discussion on Decentralized Personal Data Architectures") (link nil "http://33bits.org/2013/03/27/unlikely-outcomes-a-distributed-discussion-on-decentralized-personal-data-architectures/") (comments nil "http://33bits.org/2013/03/27/unlikely-outcomes-a-distributed-discussion-on-decentralized-personal-data-architectures/#comments") (pubDate nil "Wed, 27 Mar 2013 15:44:35 +0000") (dc:creator nil "Arvind Narayanan") (category nil "Uncategorized") (category nil "conference") (category nil "distributed social networks") (category nil "economics") (category nil "personal data stores") (category nil "policy") (category nil "privacy") (category nil "web") (guid ((isPermaLink . "false")) "http://33bits.org/?p=1098") (description nil "In recent years there has been a mushrooming of decentralized social networks, personal data stores and other such alternatives to the current paradigm of centralized services. In the academic paper A Critical Look at Decentralized Personal Data Architectures last year, my coauthors and I challenged the feasibility and desirability of these alternatives (I also gave [&#8230;]<img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&#038;blog=5017838&#038;post=1098&#038;subd=33bits&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />") (content:encoded nil "<p dir=\"ltr\">In recent years there has been a mushrooming of decentralized social networks, personal data stores and other such alternatives to the current paradigm of centralized services. In the academic paper <a href=\"http://randomwalker.info/publications/critical-look-at-decentralization-v1.pdf\">A Critical Look at Decentralized Personal Data Architectures</a> last year, my coauthors and I challenged the feasibility and desirability of these alternatives (I also gave a <a href=\"https://www.youtube.com/watch?v=8gvjwgGJuHA\">talk</a> about this work). Based on the feedback, we realized it would be useful to explicate some of our assumptions and implicit viewpoints, add context to our work, clarify some points that were unclear, and engage with our critics on some of the more contentious claims.</p><p dir=\"ltr\">We found the perfect opportunity to do this via an invitation from <a href=\"http://networkcultures.org/wpmu/portal/publication/unlike-us-reader-social-media-monopolies-and-their-alternatives/\">Unlike Us Reader</a>, produced by the <a href=\"http://networkcultures.org/\">Institute of Network Cultures</a> — it’s a magazine run by a humanities-oriented group of people, with a long-standing interest in digital culture, but they also attract some politically oriented developers. The <a href=\"http://networkcultures.org/wpmu/unlikeus/\">Unlike Us conference</a>, from which this edited volume stems, is also very interesting. [1]</p><p dir=\"ltr\">Three of the five original authors — Solon, Vincent and I — teamed up with the inimitable <a href=\"http://homes.esat.kuleuven.be/~sguerses/\">Seda Gürses</a> for an <strong><a href=\"http://randomwalker.info/publications/unlike-us.pdf\">interview-style conversation (PDF)</a></strong>. Seda is unique among privacy researchers — one of her interests is to understand and reconcile the often maddeningly divergent viewpoints of the different communities that study privacy, so she was the ideal person to play the role of interlocutor. Seda solicited feedback from about two dozen people in the hobbyist, activist and academic communities, and synthesized the responses into major themes. Then the three of us took turns responding to the prompts, which Solon, with Seda’s help, organized into a coherent whole. A majority of the commenters consented to making their feedback public, and Seda has collected the discussion into an <a href=\"http://networkcultures.org/wpmu/unlikeus/resources/articles/appendix/\">online appendix</a>.</p><p dir=\"ltr\">This was an unusual opportunity, and I’m grateful to everyone who made it happen, particularly Seda and Solon who put in an immense amount of work. My participation was very enjoyable. Research proceeds at such a pace that we rarely have the opportunity to look back and cogitate about the process; when we do, we’re often surprised by what we find. For example, here’s something I noted with amusement in one of my responses:</p><blockquote><p dir=\"ltr\">My interest in decentralized social networking apparently dates to 2009, as I just discovered by digging through my archives. I’d signed up to give a talk on pitfalls of social networking privacy at a <a href=\"https://crypto.stanford.edu/socialnetsec/\">Stanford workshop</a>, and while preparing for it I discovered the rich academic literature and the various hobbyist efforts in the decentralized model. My slides from that talk seem to anticipate several of the points we made about decentralized social networking in the paper (albeit in bullet-point form), along with the conclusion that they were “unlikely to disrupt walled gardens.” Funnily enough, I’d completely forgotten about having given this talk when we were writing the paper.</p></blockquote><p dir=\"ltr\">I would recommend reading this text as a companion to our original paper. Read it for extra context and clarifications, a discussion of controversial points, and as a way of stimulating thinking about the future prospects of alternative architectures. It may also be an interesting read as an example of how people writing an article together can have different views, and as a bit of a behind-the-scenes look at the research process.</p><p>[1] In particular, the <a href=\"http://networkcultures.org/wpmu/unlikeus/3-amsterdam/program/\">latest edition</a> of the conference that just concluded had a panel titled “Are you distributed? The Federated Web Show” moderated by Seda, with Vincent as one of the participants. It touched upon many of the same themes as our work.</p><p>To stay on top of future posts, <a href=\"http://33bits.org/feed/\">subscribe</a> to the RSS feed or follow me on <a href=\"https://twitter.com/random_walker\">Twitter</a> or <a href=\"https://plus.google.com/u/0/110908828231461227679\">Google+</a>.</p><br /><a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/gocomments/33bits.wordpress.com/1098/\"><img alt=\" \" border=\"0\" src=\"http://feeds.wordpress.com/1.0/comments/33bits.wordpress.com/1098/\" /></a><img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&#038;blog=5017838&#038;post=1098&#038;subd=33bits&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />") (wfw:commentRss nil "http://33bits.org/2013/03/27/unlikely-outcomes-a-distributed-discussion-on-decentralized-personal-data-architectures/feed/") (slash:comments nil "1") (media:content ((url . "http://1.gravatar.com/avatar/aa438b63ff1e9b75693aeabbeddae5eb?s=96&d=identicon&r=G") (medium . "image")) (media:title ((type . "html")) "randomwalker"))))) ("How to prepare a technical talk" "<p dir=\"ltr\">I used to suck at giving technical talks. I would usually confuse my audience, and often confuse myself. By the time I became a prof, I sucked a lot less. These days I enjoy giving technical talks and lectures more than non-technical ones, and my students seem to like them better as well.</p><p dir=\"ltr\">So something had changed; I’d developed a process. The other day I sat down to see if I could extract what this process was. It turned out to be surprisingly formulaic, like an algorithm, so I’d like to share it with you. I’m guessing this is obvious to most professors who teach technical topics, but I hope it will be helpful to those who’re relatively new to the game.</p><p>There are three steps. They’re simple but not easy.
<ol><li>Identify the atomic concepts</li><li>Draw the dependency graph</li><li>Find a topological ordering of the graph</li></ol><p dir=\"ltr\"><strong>Identify atomic concepts.</strong> The key word here is atomic. The idea is to introduce only one key concept at one time and give the audience time to internalize the concept before moving on to the next one.</p><p dir=\"ltr\">This is hard for two reasons. First, concepts that seem atomic to an expert are often an amalgam of different concepts. Second, it’s audience-specific. You have to have a good mental model of which concepts are already familiar to your audience.</p><p dir=\"ltr\"><strong>Draw the dependency graph.</strong> Occasionally I use a whiteboard for this, but usually it’s in my head. This is a tricky step because it’s easy to miss dependencies. When the topic I’m teaching is the design of a technical system, I ask myself questions like, “what could go wrong in this component?” and “why wasn’t this alternative design used?” This helps me flesh out the internal logic of the system in the form of a graph.</p><p dir=\"ltr\"><strong>Find a topological ordering.</strong> This is just a fancy way of saying we want to order the concepts so that each concept only depends on the ones already introduced. Sometimes this is straightforward, but sometimes the dependency graph has cycles!</p><p dir=\"ltr\">Of the topics I’ve taught recently, Bitcoin seems especially difficult in this regard. Each concept is bootstrapped off of the others, but somehow the system magically works when you put everything together. What I do in these cases is introduce <em>intermediate steps</em> that <em>don’t exist</em> in the actual design I’m teaching, and remove them later [1].</p><p dir=\"ltr\">Think of a technical topic as a skyscraper. When it’s presented in a paper, it’s analogous to unveiling a finished building. The audience can admire it and check that it’s stable/correct (say, by verifying theorems or other technical arguments.) But just as staring at a building doesn’t help you learn how to build one, the presentation in a typical paper is all but useless for pedagogical purposes. Having dependencies between concepts is perfectly acceptable in papers, because papers are not meant to be read in a single pass.</p><p dir=\"ltr\">The instructor’s role, then, is to reverse engineer how the final concept might <em>plausibly</em> be built up step by step. This is analogous to showing the scaffolding of the building and explaining each step in its construction. Talks and lectures, unlike papers, must necessarily have this linear form because the audience can’t keep state in their heads.</p><p>[1] This process introduces new nodes in the dependency graph and removes some edges so that it is no longer cyclic.</p><p>To stay on top of future posts, <a href=\"http://33bits.org/feed/\">subscribe</a> to the RSS feed or follow me on <a href=\"https://twitter.com/random_walker\">Twitter</a> or <a href=\"https://plus.google.com/u/0/110908828231461227679\">Google+</a>.</p><br /><a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/gocomments/33bits.wordpress.com/1138/\"><img alt=\" \" border=\"0\" src=\"http://feeds.wordpress.com/1.0/comments/33bits.wordpress.com/1138/\" /></a><img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&blog=5017838&post=1138&subd=33bits&ref=&feed=1\" width=\"1\" height=\"1\" />" "http://33bits.org/2013/11/26/how-to-prepare-a-technical-talk/" (21140 45127) new 1 nil nil ((title nil "How to prepare a technical talk") (link nil "http://33bits.org/2013/11/26/how-to-prepare-a-technical-talk/") (comments nil "http://33bits.org/2013/11/26/how-to-prepare-a-technical-talk/#comments") (pubDate nil "Tue, 26 Nov 2013 14:29:27 +0000") (dc:creator nil "Arvind Narayanan") (category nil "Uncategorized") (guid ((isPermaLink . "false")) "http://33bits.org/?p=1138") (description nil "I used to suck at giving technical talks. I would usually confuse my audience, and often confuse myself. By the time I became a prof, I sucked a lot less. These days I enjoy giving technical talks and lectures more than non-technical ones, and my students seem to like them better as well. So something [&#8230;]<img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&#038;blog=5017838&#038;post=1138&#038;subd=33bits&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />") (content:encoded nil "<p dir=\"ltr\">I used to suck at giving technical talks. I would usually confuse my audience, and often confuse myself. By the time I became a prof, I sucked a lot less. These days I enjoy giving technical talks and lectures more than non-technical ones, and my students seem to like them better as well.</p><p dir=\"ltr\">So something had changed; I’d developed a process. The other day I sat down to see if I could extract what this process was. It turned out to be surprisingly formulaic, like an algorithm, so I’d like to share it with you. I’m guessing this is obvious to most professors who teach technical topics, but I hope it will be helpful to those who’re relatively new to the game.</p><p>There are three steps. They’re simple but not easy.
<ol><li>Identify the atomic concepts</li><li>Draw the dependency graph</li><li>Find a topological ordering of the graph</li></ol><p dir=\"ltr\"><strong>Identify atomic concepts.</strong> The key word here is atomic. The idea is to introduce only one key concept at one time and give the audience time to internalize the concept before moving on to the next one.</p><p dir=\"ltr\">This is hard for two reasons. First, concepts that seem atomic to an expert are often an amalgam of different concepts. Second, it’s audience-specific. You have to have a good mental model of which concepts are already familiar to your audience.</p><p dir=\"ltr\"><strong>Draw the dependency graph.</strong> Occasionally I use a whiteboard for this, but usually it’s in my head. This is a tricky step because it’s easy to miss dependencies. When the topic I’m teaching is the design of a technical system, I ask myself questions like, “what could go wrong in this component?” and “why wasn’t this alternative design used?” This helps me flesh out the internal logic of the system in the form of a graph.</p><p dir=\"ltr\"><strong>Find a topological ordering.</strong> This is just a fancy way of saying we want to order the concepts so that each concept only depends on the ones already introduced. Sometimes this is straightforward, but sometimes the dependency graph has cycles!</p><p dir=\"ltr\">Of the topics I’ve taught recently, Bitcoin seems especially difficult in this regard. Each concept is bootstrapped off of the others, but somehow the system magically works when you put everything together. What I do in these cases is introduce <em>intermediate steps</em> that <em>don’t exist</em> in the actual design I’m teaching, and remove them later [1].</p><p dir=\"ltr\">Think of a technical topic as a skyscraper. When it’s presented in a paper, it’s analogous to unveiling a finished building. The audience can admire it and check that it’s stable/correct (say, by verifying theorems or other technical arguments.) But just as staring at a building doesn’t help you learn how to build one, the presentation in a typical paper is all but useless for pedagogical purposes. Having dependencies between concepts is perfectly acceptable in papers, because papers are not meant to be read in a single pass.</p><p dir=\"ltr\">The instructor’s role, then, is to reverse engineer how the final concept might <em>plausibly</em> be built up step by step. This is analogous to showing the scaffolding of the building and explaining each step in its construction. Talks and lectures, unlike papers, must necessarily have this linear form because the audience can’t keep state in their heads.</p><p>[1] This process introduces new nodes in the dependency graph and removes some edges so that it is no longer cyclic.</p><p>To stay on top of future posts, <a href=\"http://33bits.org/feed/\">subscribe</a> to the RSS feed or follow me on <a href=\"https://twitter.com/random_walker\">Twitter</a> or <a href=\"https://plus.google.com/u/0/110908828231461227679\">Google+</a>.</p><br /><a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/gocomments/33bits.wordpress.com/1138/\"><img alt=\" \" border=\"0\" src=\"http://feeds.wordpress.com/1.0/comments/33bits.wordpress.com/1138/\" /></a><img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&#038;blog=5017838&#038;post=1138&#038;subd=33bits&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />") (wfw:commentRss nil "http://33bits.org/2013/11/26/how-to-prepare-a-technical-talk/feed/") (slash:comments nil "0") (media:content ((url . "http://1.gravatar.com/avatar/aa438b63ff1e9b75693aeabbeddae5eb?s=96&d=identicon&r=G") (medium . "image")) (media:title ((type . "html")) "randomwalker")))) ("How to pick your first research project" "<p dir=\"ltr\">At Princeton I get to advise many gifted graduate and undergraduate students in doing research. Combining my experience as a mentor with reflecting on my experience as a student, I’d like to offer some guidance on how to pick your first research project.</p><p dir=\"ltr\">I’m writing this post because selecting a research problem to work on is significantly harder than actually solving it. I mean the previous sentence quite literally and without exaggeration. As an undergraduate and early-stage graduate researcher, I repeatedly spent months at a time working on research problems only to have to abandon my efforts because I found out I was barking up the wrong tree. Scientific research, it turns out, is largely about learning to ask the right questions.</p><p dir=\"ltr\">The good news is that three simple criteria will help you avoid most of the common pitfalls.</p><p dir=\"ltr\"><strong>1. Novelty.</strong> Original research is supposed to be, well, original. There are two components to novelty. The first is to make sure the problem you’re trying to solve hasn’t already been solved. This is way trickier than it seems — you might miss previous research because you’re using different names for concepts compared to the standard terminology. But the issue is deeper: two ideas may be equivalent without sounding at all the same at a superficial level. Your advisor’s help will be crucial here.</p><p dir=\"ltr\">The other aspect to novelty is that you should have a convincing answer to the question “why has this problem not been solved yet?” Often this might involve a dataset that only recently became available, or some clever insight you’ve come up with that you suspect others missed. In practice, one often has an insight and then looks for a problem to apply it to. This means you have to put in a good bit of creative thinking even to pick a research question, and you must be able to estimate the difficulty level of solving it.</p><p dir=\"ltr\">If your answer to the question is, “because the others who tried it weren’t smart enough,” you should probably think twice. It may not be prudent to have the success of your first project ride on your intellectual abilities being truly superlative.</p><p dir=\"ltr\"><strong>2. Relevance.</strong> You must try to ensure that you select a problem that matters, one whose solution will impact the world directly or indirectly (and hopefully for the better). Again, your advisor’s help will be essential. (That said, professional researchers do produce massive volumes of research papers that <a href=\"https://twitter.com/peterhoneyman/status/396353165341126657\">no one cares about</a>.) I encourage my students to pick subproblems of my ongoing long-term research projects. This is a safe way to pick a problem that’s relevant.</p><p dir=\"ltr\"><strong>3. Measurable results.</strong> This one becomes automatic as you get experienced, but for beginning researchers it can be confusing. The output of your research should be measurable and reproducible; ideally you should be able to formulate your goals as a testable hypothesis. Measurability means that many interesting projects that are novel and make the world better are nevertheless unsuitable for research. (They may be ideal for a startup or a hobby project instead.) “Build a website for illiterate kids in poor countries to learn effectively” is an example of a task that’s hard to frame as a research question.</p><p dir=\"ltr\"><strong>Irrelevant criteria.</strong> Let me also point out what’s not on this list. First, the general life advice you often hear, to do something you’re passionate about, is unfortunately a terrible way to pick a research problem. If you start from something you’re passionate about, the chance that it will meet the three criteria above is pretty slim. Often one has to consider a dozen or more research ideas before settling on one to work on.</p><p dir=\"ltr\">You should definitely pick a research <em>area</em> you’re passionate about. But getting emotionally invested in a <em>specific idea</em> or research problem before you’ve done the due diligence is a classic mistake, one that I made a lot as a student.</p><p dir=\"ltr\">Second, the scope or importance of the problem is another criterion you shouldn’t fret much about for your first project. Your goal is as much to learn the process of research as to produce results. You probably have a limited amount of time in which you want to evaluate if this whole research thing is the right fit for you. While you should definitely pick a useful and relevant research task, it should be something that you have a reasonable chance of carrying to fruition. Don’t worry about curing cancer just yet.</p><p dir=\"ltr\">Note that the last point is at odds with advice given to more experienced researchers. Richard Hamming, in a famous talk titled “<a href=\"http://www.cs.virginia.edu/~robins/YouAndYourResearch.html\">You and your research</a>,” advised researchers to pick the most important problem that they have a shot at solving. I’ve written a version of the current post for those who’re in it for the long haul, and <a href=\"http://33bits.org/2013/01/02/embracing-failure-how-research-projects-are-like-startups/\">my advice there</a> is to embrace risk and go for the big hits.</p><p dir=\"ltr\">To stay on top of future posts, <a href=\"http://33bits.org/feed/\">subscribe</a> to the RSS feed or follow me on <a href=\"https://twitter.com/random_walker\">Twitter</a> or <a href=\"https://plus.google.com/u/0/110908828231461227679\">Google+</a>.</p><br /><a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/gocomments/33bits.wordpress.com/1132/\"><img alt=\" \" border=\"0\" src=\"http://feeds.wordpress.com/1.0/comments/33bits.wordpress.com/1132/\" /></a><img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&blog=5017838&post=1132&subd=33bits&ref=&feed=1\" width=\"1\" height=\"1\" />" "http://33bits.org/2013/11/01/how-to-pick-your-first-research-project/" (21108 16401) new 2 nil nil ((title nil "How to pick your first research project") (link nil "http://33bits.org/2013/11/01/how-to-pick-your-first-research-project/") (comments nil "http://33bits.org/2013/11/01/how-to-pick-your-first-research-project/#comments") (pubDate nil "Fri, 01 Nov 2013 23:58:09 +0000") (dc:creator nil "Arvind Narayanan") (category nil "Uncategorized") (guid ((isPermaLink . "false")) "http://33bits.org/?p=1132") (description nil "At Princeton I get to advise many gifted graduate and undergraduate students in doing research. Combining my experience as a mentor with reflecting on my experience as a student, I’d like to offer some guidance on how to pick your first research project. I’m writing this post because selecting a research problem to work on [&#8230;]<img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&#038;blog=5017838&#038;post=1132&#038;subd=33bits&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />") (content:encoded nil "<p dir=\"ltr\">At Princeton I get to advise many gifted graduate and undergraduate students in doing research. Combining my experience as a mentor with reflecting on my experience as a student, I’d like to offer some guidance on how to pick your first research project.</p><p dir=\"ltr\">I’m writing this post because selecting a research problem to work on is significantly harder than actually solving it. I mean the previous sentence quite literally and without exaggeration. As an undergraduate and early-stage graduate researcher, I repeatedly spent months at a time working on research problems only to have to abandon my efforts because I found out I was barking up the wrong tree. Scientific research, it turns out, is largely about learning to ask the right questions.</p><p dir=\"ltr\">The good news is that three simple criteria will help you avoid most of the common pitfalls.</p><p dir=\"ltr\"><strong>1. Novelty.</strong> Original research is supposed to be, well, original. There are two components to novelty. The first is to make sure the problem you’re trying to solve hasn’t already been solved. This is way trickier than it seems — you might miss previous research because you’re using different names for concepts compared to the standard terminology. But the issue is deeper: two ideas may be equivalent without sounding at all the same at a superficial level. Your advisor&#8217;s help will be crucial here.</p><p dir=\"ltr\">The other aspect to novelty is that you should have a convincing answer to the question “why has this problem not been solved yet?” Often this might involve a dataset that only recently became available, or some clever insight you’ve come up with that you suspect others missed. In practice, one often has an insight and then looks for a problem to apply it to. This means you have to put in a good bit of creative thinking even to pick a research question, and you must be able to estimate the difficulty level of solving it.</p><p dir=\"ltr\">If your answer to the question is, “because the others who tried it weren’t smart enough,” you should probably think twice. It may not be prudent to have the success of your first project ride on your intellectual abilities being truly superlative.</p><p dir=\"ltr\"><strong>2. Relevance.</strong> You must try to ensure that you select a problem that matters, one whose solution will impact the world directly or indirectly (and hopefully for the better). Again, your advisor’s help will be essential. (That said, professional researchers do produce massive volumes of research papers that <a href=\"https://twitter.com/peterhoneyman/status/396353165341126657\">no one cares about</a>.) I encourage my students to pick subproblems of my ongoing long-term research projects. This is a safe way to pick a problem that’s relevant.</p><p dir=\"ltr\"><strong>3. Measurable results.</strong> This one becomes automatic as you get experienced, but for beginning researchers it can be confusing. The output of your research should be measurable and reproducible; ideally you should be able to formulate your goals as a testable hypothesis. Measurability means that many interesting projects that are novel and make the world better are nevertheless unsuitable for research. (They may be ideal for a startup or a hobby project instead.) “Build a website for illiterate kids in poor countries to learn effectively” is an example of a task that’s hard to frame as a research question.</p><p dir=\"ltr\"><strong>Irrelevant criteria.</strong> Let me also point out what’s not on this list. First, the general life advice you often hear, to do something you’re passionate about, is unfortunately a terrible way to pick a research problem. If you start from something you’re passionate about, the chance that it will meet the three criteria above is pretty slim. Often one has to consider a dozen or more research ideas before settling on one to work on.</p><p dir=\"ltr\">You should definitely pick a research <em>area</em> you’re passionate about. But getting emotionally invested in a <em>specific idea</em> or research problem before you’ve done the due diligence is a classic mistake, one that I made a lot as a student.</p><p dir=\"ltr\">Second, the scope or importance of the problem is another criterion you shouldn’t fret much about for your first project. Your goal is as much to learn the process of research as to produce results. You probably have a limited amount of time in which you want to evaluate if this whole research thing is the right fit for you. While you should definitely pick a useful and relevant research task, it should be something that you have a reasonable chance of carrying to fruition. Don&#8217;t worry about curing cancer just yet.</p><p dir=\"ltr\">Note that the last point is at odds with advice given to more experienced researchers. Richard Hamming, in a famous talk titled “<a href=\"http://www.cs.virginia.edu/~robins/YouAndYourResearch.html\">You and your research</a>,” advised researchers to pick the most important problem that they have a shot at solving. I’ve written a version of the current post for those who&#8217;re in it for the long haul, and <a href=\"http://33bits.org/2013/01/02/embracing-failure-how-research-projects-are-like-startups/\">my advice there</a> is to embrace risk and go for the big hits.</p><p dir=\"ltr\">To stay on top of future posts, <a href=\"http://33bits.org/feed/\">subscribe</a> to the RSS feed or follow me on <a href=\"https://twitter.com/random_walker\">Twitter</a> or <a href=\"https://plus.google.com/u/0/110908828231461227679\">Google+</a>.</p><br /><a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/gocomments/33bits.wordpress.com/1132/\"><img alt=\" \" border=\"0\" src=\"http://feeds.wordpress.com/1.0/comments/33bits.wordpress.com/1132/\" /></a><img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&#038;blog=5017838&#038;post=1132&#038;subd=33bits&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />") (wfw:commentRss nil "http://33bits.org/2013/11/01/how-to-pick-your-first-research-project/feed/") (slash:comments nil "0") (media:content ((url . "http://1.gravatar.com/avatar/aa438b63ff1e9b75693aeabbeddae5eb?s=96&d=identicon&r=G") (medium . "image")) (media:title ((type . "html")) "randomwalker")))) ("Academic publishing as (ruinous) competition: Is there a way out?" "<p dir=\"ltr\"><em><a href=\"http://www.ohmygodel.com/\">Aaron Johnson</a> invited me to speak as part of a <a href=\"http://petsymposium.org/2013/program.php#panel\">panel</a> on academic publishing at PETS 2013. This is a rough transcript of my talk, written from memory.</em></p><p dir=\"ltr\">Aaron mentioned he was looking for one more speaker for this panel, so that we could hear the view of someone naive and inexperienced, and asked if I was available. I said, “Great, I do that every day!” So that will be the tone of my comments today. I don’t have any concrete proposals that can be implemented next year or in two years. Instead these are blue-sky thoughts on how things could work someday and hopeful suggestions for moving in that direction. [1]</p><p dir=\"ltr\">I just finished my first year as a faculty member at Princeton. It’s still a bit surreal. I wasn’t expecting to have an academic career. In fact, back in grad school, especially the latter half, whenever someone asked me what I wanted to do after I graduated, my answer always was, “I don’t know for sure yet, but there’s one career I’m sure I <em>don’t</em> want — academia.”</p><p dir=\"ltr\">I won’t go into the story of why that was and how it changed. But it led to some unusual behavior. I ranted a lot about academia on Twitter, as Aaron already mentioned when he introduced me. Also, many times I “published” stuff by putting up a blog post. For instance I had a series of posts on the ability of a malicious website to deanonymize visitors (<a href=\"https://33bits.wordpress.com/2010/02/18/cookies-supercookies-and-ubercookies-stealing-the-identity-of-web-visitors/\">1</a>, <a href=\"https://33bits.wordpress.com/2010/02/19/ubercookies-history-stealing-social-web/\">2</a>, <a href=\"https://33bits.wordpress.com/2010/02/22/google-docs-leaks-identity/\">3</a>, <a href=\"https://33bits.wordpress.com/2010/03/09/history-stealing-its-all-shades-of-grey/\">4</a>, <a href=\"https://33bits.wordpress.com/2010/06/01/yet-another-identity-stealing-bug-will-creeping-normalcy-be-the-result/\">5</a>, <a href=\"https://33bits.wordpress.com/2010/09/28/instant-personalization-privacy-flaws/\">6</a>). People encouraged me to turn it into a paper, and I could have done that without much extra effort. But I refused, because my primary goal was to quickly disseminate the information, and I felt my blog posts had accomplished that adequately. True, I wouldn’t get academic karma, but why would I care? I wasn’t going to be an academic!</p><p dir=\"ltr\">When I eventually decided I wanted to apply for academic positions, I talked to a professor whose opinion I greatly respected. He expressed skepticism that I’d get any interviews, given that I’d been blogging instead of writing papers. I remember thinking, “oh shit, I’ve screwed up my career, haven’t I?” So I feel extremely lucky that my job search turned out successfully.</p><p dir=\"ltr\">At this point a sane person would have decided to quit while they were ahead, and start playing the academic game. But I guess sanity has never really been one of my strong points. So in the last year I’ve been thinking a lot about what the process of research collaboration and publishing would look like if we somehow magically didn’t have to worry at all about furthering our individual reputations.</p><p dir=\"ltr\"><strong>Polymath</strong></p><p dir=\"ltr\">Something that’s very close to my ideal model of collaboration is the <a href=\"https://en.wikipedia.org/wiki/Polymath_Project\">Polymath project</a>. I was fascinated when I heard about it a few years ago. It was started by mathematician <a href=\"https://en.wikipedia.org/wiki/Tim_Gowers\">Tim Gowers</a> in a blog post titled “<a href=\"http://gowers.wordpress.com/2009/01/27/is-massively-collaborative-mathematics-possible/\">Is massively collaborative mathematics possible?</a>” [2] He and <a href=\"https://en.wikipedia.org/wiki/Terence_Tao\">Terry Tao</a> are the leaders of the project. They’re among the world’s top mathematicians. There have been several of these collaborations so far and they’ve been quite successful, solving previously open math problems. So I’ve been telling computer scientists about these efforts and asking if our community could produce something like this. [3]</p><p dir=\"ltr\">To me there are three salient aspects of Polymath. The first is that the collaboration happens online, in blog posts and comments, rather than phone or physical meetings. When I tell people this they are usually enthusiastic and willing to try something like that. The second aspect is that it is open, in that there is no vetting of participants. Now people are a bit unsure, and say, “hmm, what’s the third?” Well, the third aspect is that there’s no keeping score of who contributed what. To which they react, “whoa, whoa, wait, what??!!”</p><p dir=\"ltr\">I’m sure we can all see the problem here. Gowers and Tao are famous and don’t have to worry about furthering their careers. The other participants who contribute ideas seem to do it partly altruistically and partly because of the novelty of it. But it’s hard to imagine this process being feasible on a bigger scale.</p><p dir=\"ltr\"><strong>Misaligned incentives</strong></p><p dir=\"ltr\">Let’s take a step back and ask why there’s this gap between doing good research and getting credit for it. In almost every industry, every human endeavor, we’ve tried to set things up so that the incentives for individuals and the broader societal goals of the activity align with each other. But sometimes individual incentives get misaligned with the societal goals, and that leads to problems.</p><p dir=\"ltr\">Let’s look at a few examples. Individual traders play the stock market with the hope of getting rich. But at the same time, it helps companies hedge against risk and improves overall financial stability. At least that’s the theory. We’ve seen it go wrong. Similarly, copyright is supposed to align the desire of creators to make money with the goal of the maximum number of people enjoying the maximum number of creative works. That’s gotten out of whack because of digital technology.</p><p dir=\"ltr\">My claim is that we’re seeing the same problem in academic research. There’s a metaphor that explains what’s going on in research really well, and to me it is the root of all of the ills that I want to talk about. And that metaphor is <em>publishing as competition</em>. What do I mean by that? Well, peer review is a contest. Succeeding at this contest is the immediate incentive that we as researchers have. And we hope that this will somehow lead to science that benefits humanity.</p><p dir=\"ltr\">To be clear, I’m far from the first one to make this observation. Let me quote someone who’s much better qualified to talk about this. <a href=\"http://www.wisdom.weizmann.ac.il/~oded/\">Oded Goldreich</a>, I’m sure most of you know of him, has a paper titled “<a href=\"http://www.wisdom.weizmann.ac.il/~oded/PDF/struggle.pdf\">On Struggle and Competition in Scientiﬁc Fields.</a>” Here’s my favorite quote from the paper. He’s talking about the flagship theory conferences.</p><blockquote><p dir=\"ltr\">Eventually, FOCSTOC may become a pure competition, deﬁned as a competition having no aim but its own existence (i.e., the existence of a competition). That is, pure competitions serve no <em>scientiﬁc</em> purpose. Did FOCSTOC reach this point or is close to it? Let me leave this question open, and note that my impression is that things are deﬁnitely evolving towards this direction. In any case, I think we should all be worried about the potential of such an evolution.</p></blockquote><p dir=\"ltr\">I’m don’t know enough about the theory community to have an opinion on how big a problem this is. Still, I’m sure we can agree with the sentiment of the last sentence.</p><p dir=\"ltr\">But here’s the very next paragraph. I think it gives us hope.</p><blockquote><p dir=\"ltr\">Other TOC conferences seem to suffer less from the aforementioned phenomena. This is mainly because they “count” less as evidence of importance (i.e., publications in them are either not counted by other competitions or their eﬀect on these competitions is less signiﬁcant). Thus, the vicious cycle described above is less powerful, and consequently these conferences may still serve the intended scientiﬁc purposes.</p></blockquote><p dir=\"ltr\">We see the same thing in the security and privacy community. Something I’ve seen commonly is a situation where you have a neat result, but nothing earth-shattering, and it’s not good enough as it is for a top tier venue. So what do you do? You pad it with bullshit and submit it, and it gets in. Another trend that this encourages is deliberately making a bad or inaccurate model so that you can solve a harder problem. But PETS publications and participants seem to suffer less from these effects. That’s why I’m happy to be discussing this issue with this group of people.</p><p dir=\"ltr\"><strong>Paper as final output</strong></p><p dir=\"ltr\">It seems like we’re at an impasse. We can agree that publishing-as-competition has all these problems, but hiring committees and tenure committees need competitions to identify good research and good researchers. But I claim that publishing as competition fails even at the supposed goal of identifying useful research.</p><p dir=\"ltr\">The reason for that is simple. Publishing as competition encourages or even forces viewing the paper as the final output. But it’s not! The hard work begins, not ends when the paper is published. This is unlike the math and theory communities, where the paper is in fact the final output. If publishing-as-competition is so bad for theory, it’s much worse for us.</p><p dir=\"ltr\">In security and privacy research, the paper is the starting point. Our goal is not to prove theorems but to more directly impact the world in some way.  By creating privacy technologies, for example. For research to have impact, authors have to do a variety of things after publication depending on the nature of the research. Build technology and get people to adopt it. Explain the work to policymakers or to other researchers who are building upon it. Or even just evangelize your ideas. Some people claim that ideas should stand on their own merit and compete with other ideas on a level playing field. I find this quite silly. I lean toward the view expressed in this famous quote you’ve probably heard: “if your ideas are any good you’ll have to shove them down people’s throats.”</p><p dir=\"ltr\">The upshot of this is that impact is heavily shortchanged in the publication-as-competition model. This is partly because of what I’ve talked about, we have no incentive to do any more work after getting the paper published. But an equally important reason is that the community can’t judge the impact of research at the point of publication. Deciding who “wins the prizes” at the point of publication, before the ideas have a chance to prove themselves, has disastrous consequences.</p><p dir=\"ltr\">So I hope I’ve convinced you that publication-as-competition is at the root of many of our problems. Let me give one more example. Many of us like the publish-then-filter model, where reviews are done in the open on publicly posted papers with anyone being able to comment. One major roadblock to moving to this model is that it screws up the competition aspect. The worry is that papers that receive a lot of popular attention will be reviewed favorably, and so forth. We want papers to be reviewed on a level playing field. But if the worth of a paper can’t be judged at publication time, that means all this fairness is toward an outcome that is meaningless anyway. Do we still want to keep this model at all costs?</p><p dir=\"ltr\"><strong>A way forward?</strong></p><p dir=\"ltr\">So far I’ve done a lot of complaining. Let me offer some suggestions now. I want to give two sets of suggestions that are complementary. The first is targeted at committees, whether tenure committees, hiring committees, award communities, or even program committees to an extent, and to the community in general. The second is targeted at authors.</p><p dir=\"ltr\">Here’s my suggestion for committees and the community: we can and should develop ways to incentivize and measure real impact. Let me give you a four examples. I have more that I’d be happy to discuss later. First, retrospective awards. That is, “best paper from this conference 10 years ago” or some such. I’ve been hearing more about these of late, and I think that’s good news. The idea is that impact is easier to evaluate 10 years after publication.</p><p dir=\"ltr\">Second, <a href=\"https://en.wikipedia.org/wiki/Overlay_journal\">overlay journals</a>. These are online journals that are a way of “blessing” papers that have already been published or made public. There is a lag between initial publication and inclusion in the overlay journal, and that’s a good thing. Recently the math community has come up with a technical infrastructure for running overlay journals. I’m very excited about this. [4]</p><p dir=\"ltr\">There are two more that are related. These are specific to our research field. For papers that are about a new tool, I think we should look at adoption numbers as an important component of the review process. Finally, such papers should also have an “incentives” section or subsection. Because all too often we write papers that we imagine unspecified parties will implement and deploy, but it turns out there isn’t the slightest economic incentive for any company or organization to do so.</p><p dir=\"ltr\">I think we should also find ways to measure contributions through blog posts and sharing data and code in publications. This seems more tricky. I’d be happy to hear suggestions on how to do it.</p><p dir=\"ltr\">Next, this is what I want to say to authors: the supposed lack of incentives for nontraditional ways of publishing is greatly exaggerated. I say this from my personal experience. I said earlier that I was very lucky that my job search turned out well. That’s true, but it wasn’t all luck. I found out to my surprise that my increased visibility through blogging and especially the policy work that came out of it made a huge difference to my prospects. If I’d had three times as many publications and no blog, I probably would have had about the same chances. I’m sure some departments didn’t like my style, but there are definitely others that truly value it.</p><p dir=\"ltr\"><strong>My Bitcoin experiment</strong></p><p dir=\"ltr\">I have one other personal experience to share with you. This is an experiment I’ve been doing over the last month or so. I’d been thinking about the possibility of designing a prediction market on top of Bitcoin that doesn’t have a central point of control. Some of you may know the sad story of Intrade. So I <a href=\"https://twitter.com/random_walker/status/339570757631885312\">tweeted</a> my interest in this problem, and asked if others had put thought into it. Several people responded. I started an email thread for this group, and we went to work.</p><p dir=\"ltr\">12,000 words and several conference calls later, we’re very happy with where we are, and we’ve started writing a paper presenting our design. What’s even better is who the participants are — <a href=\"http://people.scs.carleton.ca/~clark/\">Jeremy Clark</a> at Carleton, <a href=\"http://www.jbonneau.com/\">Joe Bonneau</a> who did his Ph.D. with Ross Anderson and is currently at Google, and Andrew Miller at UMD who is <a href=\"http://www.cs.umd.edu/~jkatz/\">Jon Katz’</a>s Ph.D. student. All these people are better qualified to write this paper than I am. By being proactive and reaching out online, I was able to assemble and work with this amazing team. [5]</p><p dir=\"ltr\">But this experiment didn’t go all the way. While I used Twitter to find the participants and was open to accepting anyone, the actual collaboration is being done through traditional channels. My original intent was to do it in public, but I realized quite early on that we had something publication-worthy and became risk-averse.</p><p dir=\"ltr\">I plan to do another experiment, this time with the explicit goal of doing it in public. This is again a Bitcoin-related paper that I want to write. Oddly enough, there is no proper tutorial of Bitcoin, nor is there a survey of the current state of research. I think combining these would make a great paper. The nature of the project makes it ideal to do online. I haven’t figured out the details yet, but I’m going to launch it on my blog and see how it goes. You’re all welcome to join me in this experiment. [6]</p><p dir=\"ltr\">So that’s basically what I wanted to share with you today. I think the current model of publication as competition has gone too far, and the consequences are starting to get ruinous. It’s time we put a stop to it. I believe that committees on one hand, and authors on the other both have the incentive to start changing things unilaterally. But if the two are combined, the results can be especially powerful. In fact, I hope that it can lead to a virtuous cycle. Thank you.</p><p dir=\"ltr\">[1] Aaron didn’t actually say that, of course. You probably got that. But who knows if nuances come across in transcripts.</p><p dir=\"ltr\">[2] At this point I polled the room to see who’d heard of Polymath before. Only three hands went up (!)</p><p dir=\"ltr\">[3] There is one example that’s closer to computer science that I’m aware of: <a href=\"http://homotopytypetheory.org/book/\">this book</a> on homotopy type theory written in a similar spirit as the Polymath project.</p><p dir=\"ltr\">[4] During my talk I incorrectly cited the URL for this infrastructure as <a href=\"http://selectedpapers.net\">selectedpapers.net</a>. That is a somewhat related but different project. It is actually the <a href=\"http://gowers.wordpress.com/2013/01/16/why-ive-also-joined-the-good-guys/\">Episciences project</a>.</p><p dir=\"ltr\">[5] Since the talk, we’ve had another excellent addition to the team: <a href=\"http://jkroll.com/\">Josh Kroll</a> at Princeton, who recently published a neat <a href=\"http://weis2013.econinfosec.org/papers/KrollDaveyFeltenWEIS2013.pdf\">paper</a> on the economics of Bitcoin mining with <a href=\"http://www.iandavey.net/\">Ian Davey</a> and <a href=\"http://www.cs.princeton.edu/~felten/\">Ed Felten</a>.</p><p>[6] Something that I meant to mention at the end but ran out of time for is Michael Neilsen’s excellent book <a href=\"http://michaelnielsen.org/blog/reinventing-discovery/\">Reinventing Discovery: The New Era of Networked Science</a>. If you find the topic of this post at all interesting, you should absolutely read this book.</p><p>To stay on top of future posts, <a href=\"http://33bits.org/feed/\">subscribe</a> to the RSS feed or follow me on <a href=\"https://twitter.com/random_walker\">Twitter</a> or <a href=\"https://plus.google.com/u/0/110908828231461227679\">Google+</a>.</p><br /><a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/gocomments/33bits.wordpress.com/1129/\"><img alt=\" \" border=\"0\" src=\"http://feeds.wordpress.com/1.0/comments/33bits.wordpress.com/1129/\" /></a><img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&blog=5017838&post=1129&subd=33bits&ref=&feed=1\" width=\"1\" height=\"1\" />" "http://33bits.org/2013/07/15/academic-publishing-as-ruinous-competition-is-there-a-way-out/" (20964 4487) new 3 nil nil ((title nil "Academic publishing as (ruinous) competition: Is there a way out?") (link nil "http://33bits.org/2013/07/15/academic-publishing-as-ruinous-competition-is-there-a-way-out/") (comments nil "http://33bits.org/2013/07/15/academic-publishing-as-ruinous-competition-is-there-a-way-out/#comments") (pubDate nil "Mon, 15 Jul 2013 15:13:11 +0000") (dc:creator nil "Arvind Narayanan") (category nil "Uncategorized") (category nil "academia") (category nil "publishing") (category nil "research") (guid ((isPermaLink . "false")) "http://33bits.org/?p=1129") (description nil "Aaron Johnson invited me to speak as part of a panel on academic publishing at PETS 2013. This is a rough transcript of my talk, written from memory. Aaron mentioned he was looking for one more speaker for this panel, so that we could hear the view of someone naive and inexperienced, and asked if [&#8230;]<img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&#038;blog=5017838&#038;post=1129&#038;subd=33bits&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />") (content:encoded nil "<p dir=\"ltr\"><em><a href=\"http://www.ohmygodel.com/\">Aaron Johnson</a> invited me to speak as part of a <a href=\"http://petsymposium.org/2013/program.php#panel\">panel</a> on academic publishing at PETS 2013. This is a rough transcript of my talk, written from memory.</em></p><p dir=\"ltr\">Aaron mentioned he was looking for one more speaker for this panel, so that we could hear the view of someone naive and inexperienced, and asked if I was available. I said, “Great, I do that every day!” So that will be the tone of my comments today. I don’t have any concrete proposals that can be implemented next year or in two years. Instead these are blue-sky thoughts on how things could work someday and hopeful suggestions for moving in that direction. [1]</p><p dir=\"ltr\">I just finished my first year as a faculty member at Princeton. It’s still a bit surreal. I wasn’t expecting to have an academic career. In fact, back in grad school, especially the latter half, whenever someone asked me what I wanted to do after I graduated, my answer always was, “I don’t know for sure yet, but there’s one career I’m sure I <em>don’t</em> want — academia.”</p><p dir=\"ltr\">I won’t go into the story of why that was and how it changed. But it led to some unusual behavior. I ranted a lot about academia on Twitter, as Aaron already mentioned when he introduced me. Also, many times I “published” stuff by putting up a blog post. For instance I had a series of posts on the ability of a malicious website to deanonymize visitors (<a href=\"https://33bits.wordpress.com/2010/02/18/cookies-supercookies-and-ubercookies-stealing-the-identity-of-web-visitors/\">1</a>, <a href=\"https://33bits.wordpress.com/2010/02/19/ubercookies-history-stealing-social-web/\">2</a>, <a href=\"https://33bits.wordpress.com/2010/02/22/google-docs-leaks-identity/\">3</a>, <a href=\"https://33bits.wordpress.com/2010/03/09/history-stealing-its-all-shades-of-grey/\">4</a>, <a href=\"https://33bits.wordpress.com/2010/06/01/yet-another-identity-stealing-bug-will-creeping-normalcy-be-the-result/\">5</a>, <a href=\"https://33bits.wordpress.com/2010/09/28/instant-personalization-privacy-flaws/\">6</a>). People encouraged me to turn it into a paper, and I could have done that without much extra effort. But I refused, because my primary goal was to quickly disseminate the information, and I felt my blog posts had accomplished that adequately. True, I wouldn’t get academic karma, but why would I care? I wasn’t going to be an academic!</p><p dir=\"ltr\">When I eventually decided I wanted to apply for academic positions, I talked to a professor whose opinion I greatly respected. He expressed skepticism that I’d get any interviews, given that I’d been blogging instead of writing papers. I remember thinking, “oh shit, I’ve screwed up my career, haven’t I?” So I feel extremely lucky that my job search turned out successfully.</p><p dir=\"ltr\">At this point a sane person would have decided to quit while they were ahead, and start playing the academic game. But I guess sanity has never really been one of my strong points. So in the last year I’ve been thinking a lot about what the process of research collaboration and publishing would look like if we somehow magically didn’t have to worry at all about furthering our individual reputations.</p><p dir=\"ltr\"><strong>Polymath</strong></p><p dir=\"ltr\">Something that’s very close to my ideal model of collaboration is the <a href=\"https://en.wikipedia.org/wiki/Polymath_Project\">Polymath project</a>. I was fascinated when I heard about it a few years ago. It was started by mathematician <a href=\"https://en.wikipedia.org/wiki/Tim_Gowers\">Tim Gowers</a> in a blog post titled “<a href=\"http://gowers.wordpress.com/2009/01/27/is-massively-collaborative-mathematics-possible/\">Is massively collaborative mathematics possible?</a>” [2] He and <a href=\"https://en.wikipedia.org/wiki/Terence_Tao\">Terry Tao</a> are the leaders of the project. They’re among the world’s top mathematicians. There have been several of these collaborations so far and they’ve been quite successful, solving previously open math problems. So I’ve been telling computer scientists about these efforts and asking if our community could produce something like this. [3]</p><p dir=\"ltr\">To me there are three salient aspects of Polymath. The first is that the collaboration happens online, in blog posts and comments, rather than phone or physical meetings. When I tell people this they are usually enthusiastic and willing to try something like that. The second aspect is that it is open, in that there is no vetting of participants. Now people are a bit unsure, and say, “hmm, what’s the third?” Well, the third aspect is that there’s no keeping score of who contributed what. To which they react, “whoa, whoa, wait, what??!!”</p><p dir=\"ltr\">I’m sure we can all see the problem here. Gowers and Tao are famous and don’t have to worry about furthering their careers. The other participants who contribute ideas seem to do it partly altruistically and partly because of the novelty of it. But it’s hard to imagine this process being feasible on a bigger scale.</p><p dir=\"ltr\"><strong>Misaligned incentives</strong></p><p dir=\"ltr\">Let’s take a step back and ask why there’s this gap between doing good research and getting credit for it. In almost every industry, every human endeavor, we’ve tried to set things up so that the incentives for individuals and the broader societal goals of the activity align with each other. But sometimes individual incentives get misaligned with the societal goals, and that leads to problems.</p><p dir=\"ltr\">Let’s look at a few examples. Individual traders play the stock market with the hope of getting rich. But at the same time, it helps companies hedge against risk and improves overall financial stability. At least that’s the theory. We’ve seen it go wrong. Similarly, copyright is supposed to align the desire of creators to make money with the goal of the maximum number of people enjoying the maximum number of creative works. That’s gotten out of whack because of digital technology.</p><p dir=\"ltr\">My claim is that we’re seeing the same problem in academic research. There’s a metaphor that explains what’s going on in research really well, and to me it is the root of all of the ills that I want to talk about. And that metaphor is <em>publishing as competition</em>. What do I mean by that? Well, peer review is a contest. Succeeding at this contest is the immediate incentive that we as researchers have. And we hope that this will somehow lead to science that benefits humanity.</p><p dir=\"ltr\">To be clear, I’m far from the first one to make this observation. Let me quote someone who’s much better qualified to talk about this. <a href=\"http://www.wisdom.weizmann.ac.il/~oded/\">Oded Goldreich</a>, I’m sure most of you know of him, has a paper titled “<a href=\"http://www.wisdom.weizmann.ac.il/~oded/PDF/struggle.pdf\">On Struggle and Competition in Scientiﬁc Fields.</a>” Here’s my favorite quote from the paper. He’s talking about the flagship theory conferences.</p><blockquote><p dir=\"ltr\">Eventually, FOCSTOC may become a pure competition, deﬁned as a competition having no aim but its own existence (i.e., the existence of a competition). That is, pure competitions serve no <em>scientiﬁc</em> purpose. Did FOCSTOC reach this point or is close to it? Let me leave this question open, and note that my impression is that things are deﬁnitely evolving towards this direction. In any case, I think we should all be worried about the potential of such an evolution.</p></blockquote><p dir=\"ltr\">I’m don’t know enough about the theory community to have an opinion on how big a problem this is. Still, I’m sure we can agree with the sentiment of the last sentence.</p><p dir=\"ltr\">But here’s the very next paragraph. I think it gives us hope.</p><blockquote><p dir=\"ltr\">Other TOC conferences seem to suffer less from the aforementioned phenomena. This is mainly because they “count” less as evidence of importance (i.e., publications in them are either not counted by other competitions or their eﬀect on these competitions is less signiﬁcant). Thus, the vicious cycle described above is less powerful, and consequently these conferences may still serve the intended scientiﬁc purposes.</p></blockquote><p dir=\"ltr\">We see the same thing in the security and privacy community. Something I’ve seen commonly is a situation where you have a neat result, but nothing earth-shattering, and it’s not good enough as it is for a top tier venue. So what do you do? You pad it with bullshit and submit it, and it gets in. Another trend that this encourages is deliberately making a bad or inaccurate model so that you can solve a harder problem. But PETS publications and participants seem to suffer less from these effects. That’s why I’m happy to be discussing this issue with this group of people.</p><p dir=\"ltr\"><strong>Paper as final output</strong></p><p dir=\"ltr\">It seems like we’re at an impasse. We can agree that publishing-as-competition has all these problems, but hiring committees and tenure committees need competitions to identify good research and good researchers. But I claim that publishing as competition fails even at the supposed goal of identifying useful research.</p><p dir=\"ltr\">The reason for that is simple. Publishing as competition encourages or even forces viewing the paper as the final output. But it’s not! The hard work begins, not ends when the paper is published. This is unlike the math and theory communities, where the paper is in fact the final output. If publishing-as-competition is so bad for theory, it’s much worse for us.</p><p dir=\"ltr\">In security and privacy research, the paper is the starting point. Our goal is not to prove theorems but to more directly impact the world in some way.  By creating privacy technologies, for example. For research to have impact, authors have to do a variety of things after publication depending on the nature of the research. Build technology and get people to adopt it. Explain the work to policymakers or to other researchers who are building upon it. Or even just evangelize your ideas. Some people claim that ideas should stand on their own merit and compete with other ideas on a level playing field. I find this quite silly. I lean toward the view expressed in this famous quote you’ve probably heard: “if your ideas are any good you’ll have to shove them down people’s throats.”</p><p dir=\"ltr\">The upshot of this is that impact is heavily shortchanged in the publication-as-competition model. This is partly because of what I’ve talked about, we have no incentive to do any more work after getting the paper published. But an equally important reason is that the community can’t judge the impact of research at the point of publication. Deciding who “wins the prizes” at the point of publication, before the ideas have a chance to prove themselves, has disastrous consequences.</p><p dir=\"ltr\">So I hope I’ve convinced you that publication-as-competition is at the root of many of our problems. Let me give one more example. Many of us like the publish-then-filter model, where reviews are done in the open on publicly posted papers with anyone being able to comment. One major roadblock to moving to this model is that it screws up the competition aspect. The worry is that papers that receive a lot of popular attention will be reviewed favorably, and so forth. We want papers to be reviewed on a level playing field. But if the worth of a paper can’t be judged at publication time, that means all this fairness is toward an outcome that is meaningless anyway. Do we still want to keep this model at all costs?</p><p dir=\"ltr\"><strong>A way forward?</strong></p><p dir=\"ltr\">So far I’ve done a lot of complaining. Let me offer some suggestions now. I want to give two sets of suggestions that are complementary. The first is targeted at committees, whether tenure committees, hiring committees, award communities, or even program committees to an extent, and to the community in general. The second is targeted at authors.</p><p dir=\"ltr\">Here&#8217;s my suggestion for committees and the community: we can and should develop ways to incentivize and measure real impact. Let me give you a four examples. I have more that I&#8217;d be happy to discuss later. First, retrospective awards. That is, &#8220;best paper from this conference 10 years ago&#8221; or some such. I&#8217;ve been hearing more about these of late, and I think that&#8217;s good news. The idea is that impact is easier to evaluate 10 years after publication.</p><p dir=\"ltr\">Second, <a href=\"https://en.wikipedia.org/wiki/Overlay_journal\">overlay journals</a>. These are online journals that are a way of &#8220;blessing&#8221; papers that have already been published or made public. There is a lag between initial publication and inclusion in the overlay journal, and that’s a good thing. Recently the math community has come up with a technical infrastructure for running overlay journals. I&#8217;m very excited about this. [4]</p><p dir=\"ltr\">There are two more that are related. These are specific to our research field. For papers that are about a new tool, I think we should look at adoption numbers as an important component of the review process. Finally, such papers should also have an &#8220;incentives&#8221; section or subsection. Because all too often we write papers that we imagine unspecified parties will implement and deploy, but it turns out there isn&#8217;t the slightest economic incentive for any company or organization to do so.</p><p dir=\"ltr\">I think we should also find ways to measure contributions through blog posts and sharing data and code in publications. This seems more tricky. I&#8217;d be happy to hear suggestions on how to do it.</p><p dir=\"ltr\">Next, this is what I want to say to authors: the supposed lack of incentives for nontraditional ways of publishing is greatly exaggerated. I say this from my personal experience. I said earlier that I was very lucky that my job search turned out well. That&#8217;s true, but it wasn&#8217;t all luck. I found out to my surprise that my increased visibility through blogging and especially the policy work that came out of it made a huge difference to my prospects. If I&#8217;d had three times as many publications and no blog, I probably would have had about the same chances. I&#8217;m sure some departments didn&#8217;t like my style, but there are definitely others that truly value it.</p><p dir=\"ltr\"><strong>My Bitcoin experiment</strong></p><p dir=\"ltr\">I have one other personal experience to share with you. This is an experiment I&#8217;ve been doing over the last month or so. I&#8217;d been thinking about the possibility of designing a prediction market on top of Bitcoin that doesn&#8217;t have a central point of control. Some of you may know the sad story of Intrade. So I <a href=\"https://twitter.com/random_walker/status/339570757631885312\">tweeted</a> my interest in this problem, and asked if others had put thought into it. Several people responded. I started an email thread for this group, and we went to work.</p><p dir=\"ltr\">12,000 words and several conference calls later, we&#8217;re very happy with where we are, and we&#8217;ve started writing a paper presenting our design. What&#8217;s even better is who the participants are — <a href=\"http://people.scs.carleton.ca/~clark/\">Jeremy Clark</a> at Carleton, <a href=\"http://www.jbonneau.com/\">Joe Bonneau</a> who did his Ph.D. with Ross Anderson and is currently at Google, and Andrew Miller at UMD who is <a href=\"http://www.cs.umd.edu/~jkatz/\">Jon Katz&#8217;</a>s Ph.D. student. All these people are better qualified to write this paper than I am. By being proactive and reaching out online, I was able to assemble and work with this amazing team. [5]</p><p dir=\"ltr\">But this experiment didn&#8217;t go all the way. While I used Twitter to find the participants and was open to accepting anyone, the actual collaboration is being done through traditional channels. My original intent was to do it in public, but I realized quite early on that we had something publication-worthy and became risk-averse.</p><p dir=\"ltr\">I plan to do another experiment, this time with the explicit goal of doing it in public. This is again a Bitcoin-related paper that I want to write. Oddly enough, there is no proper tutorial of Bitcoin, nor is there a survey of the current state of research. I think combining these would make a great paper. The nature of the project makes it ideal to do online. I haven&#8217;t figured out the details yet, but I&#8217;m going to launch it on my blog and see how it goes. You&#8217;re all welcome to join me in this experiment. [6]</p><p dir=\"ltr\">So that&#8217;s basically what I wanted to share with you today. I think the current model of publication as competition has gone too far, and the consequences are starting to get ruinous. It&#8217;s time we put a stop to it. I believe that committees on one hand, and authors on the other both have the incentive to start changing things unilaterally. But if the two are combined, the results can be especially powerful. In fact, I hope that it can lead to a virtuous cycle. Thank you.</p><p dir=\"ltr\">[1] Aaron didn’t actually say that, of course. You probably got that. But who knows if nuances come across in transcripts.</p><p dir=\"ltr\">[2] At this point I polled the room to see who’d heard of Polymath before. Only three hands went up (!)</p><p dir=\"ltr\">[3] There is one example that’s closer to computer science that I’m aware of: <a href=\"http://homotopytypetheory.org/book/\">this book</a> on homotopy type theory written in a similar spirit as the Polymath project.</p><p dir=\"ltr\">[4] During my talk I incorrectly cited the URL for this infrastructure as <a href=\"http://selectedpapers.net\">selectedpapers.net</a>. That is a somewhat related but different project. It is actually the <a href=\"http://gowers.wordpress.com/2013/01/16/why-ive-also-joined-the-good-guys/\">Episciences project</a>.</p><p dir=\"ltr\">[5] Since the talk, we&#8217;ve had another excellent addition to the team: <a href=\"http://jkroll.com/\">Josh Kroll</a> at Princeton, who recently published a neat <a href=\"http://weis2013.econinfosec.org/papers/KrollDaveyFeltenWEIS2013.pdf\">paper</a> on the economics of Bitcoin mining with <a href=\"http://www.iandavey.net/\">Ian Davey</a> and <a href=\"http://www.cs.princeton.edu/~felten/\">Ed Felten</a>.</p><p>[6] Something that I meant to mention at the end but ran out of time for is Michael Neilsen’s excellent book <a href=\"http://michaelnielsen.org/blog/reinventing-discovery/\">Reinventing Discovery: The New Era of Networked Science</a>. If you find the topic of this post at all interesting, you should absolutely read this book.</p><p>To stay on top of future posts, <a href=\"http://33bits.org/feed/\">subscribe</a> to the RSS feed or follow me on <a href=\"https://twitter.com/random_walker\">Twitter</a> or <a href=\"https://plus.google.com/u/0/110908828231461227679\">Google+</a>.</p><br /><a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/gocomments/33bits.wordpress.com/1129/\"><img alt=\" \" border=\"0\" src=\"http://feeds.wordpress.com/1.0/comments/33bits.wordpress.com/1129/\" /></a><img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&#038;blog=5017838&#038;post=1129&#038;subd=33bits&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />") (wfw:commentRss nil "http://33bits.org/2013/07/15/academic-publishing-as-ruinous-competition-is-there-a-way-out/feed/") (slash:comments nil "10") (media:content ((url . "http://1.gravatar.com/avatar/aa438b63ff1e9b75693aeabbeddae5eb?s=96&d=identicon&r=G") (medium . "image")) (media:title ((type . "html")) "randomwalker")))) ("Personalized coupons as a vehicle for perfect price discrimination" "<p dir=\"ltr\">Given the pervasive tracking and profiling of our shopping and browsing habits, one would expect that retailers would be very good at individualized price discrimination —  figuring out what you or I would be willing to pay for an item using data mining, and tailoring prices accordingly. But this doesn’t seem to be happening. Why not?</p><p>This mystery isn’t new. Mathematician Andrew Odlyzko predicted a decade ago that data-driven price discrimination would become much more common and effective (<a href=\"http://www.dtc.umn.edu/~odlyzko/doc/privacy.economics.pdf\">paper</a>, <a href=\"http://www.businessweek.com/stories/2003-07-30/sharper-tools-fordiscriminatory-pricing\">interview</a>). Back then, he was far ahead of his time. But today, behavioral advertising at least has gotten good enough that it’s often creepy. The technology works; the impediment to price discrimination lies elsewhere. [1]</p><p>It looks like consumers’ perception of unfairness of price discrimination is <a href=\"http://33bits.org/2013/01/22/price-discrimination-and-the-illusion-of-fairness/\">surprisingly strong</a>, which is why firms <a href=\"http://33bits.org/2013/01/08/online-price-discrimination-conspicuous-by-its-absence/\">balk at overt price discrimination</a>, even though <a href=\"http://33bits.org/2011/06/02/price-discrimination-is-all-around-you/\">covert price discrimination is all too common</a>. But the covert form of price discrimination is not only less efficient, it also (ironically) has significant social costs — see #3 below for an example. Is there a form of pricing that allows for perfect discrimination (i.e., complete tailoring to individuals), in a way that consumers find acceptable? That would be the holy grail.</p><p>In this post, I will argue that the humble coupon, reborn in a high-tech form, could be the solution. Here’s why.</p><p><strong>1. Coupons tap into shopper psychology. Customers love them.</strong></p><p>Coupons, like sales, introduce unpredictability and rewards into shopping, which provides a tiny dopamine spike that gets us hooked. JC Penney’s recent <a href=\"http://www.nytimes.com/2013/04/14/business/for-penney-a-tough-lesson-in-shopper-psychology.html?pagewanted=all&amp;_r=0\">misadventure</a> in trying to eliminate sales and coupons provides an object lesson:</p><blockquote><p>“It may be a decent deal to buy that item for $5. But for someone like me, who’s always looking for a sale or a coupon — seeing that something is marked down 20 percent off, then being able to hand over the coupon to save, it just entices me. It’s a rush.”</p></blockquote><p>Some startups have exploited this to the hilt, introducing “gamification” into commerce. <a href=\"https://en.wikipedia.org/wiki/Shopkick\">Shopkick</a> is a prime example. I see this as a very important trend.</p><p><strong>2. Coupons aren’t perceived as unfair.</strong></p><p>Given the above, shoppers have at best a dim perception of coupons as a price discrimination mechanism. Even when they do, however, coupons aren’t perceived as unfair to nearly the same degree as listing different prices for different consumers, even if the result in either case is identical. [2]</p><p><strong>3. Traditional coupons are not personalized.</strong></p><p>While customers may have different reasons for liking coupons, from firms’ perspective the way in which traditional coupons aid price discrimination is pretty simple: by forcing customers to waste their time. Econ texts tend to lay it out bluntly. For example, <a href=\"http://www.mcafee.cc/Papers/PDF/ABAPriceDiscrimination.pdf\">R. Preston McAfee</a>:</p><blockquote><p>Individuals generally value their time at approximately their wages, so that people with low wages, who tend to be the most price-sensitive, also have the lowest value of time. … A thrifty shopper may be able to spend an hour sorting through the coupons in the newspaper and save $20 on a $200 shopping expedition … This is a good deal for a consumer who values time at less than $20 per hour, and a bad deal for the consumer that values time in excess of $20 per hour. Thus, relatively poor consumers choose to use coupons, which permits the seller to have a price cut that is approximately targeted at the more price-sensitive group.</p></blockquote><p>Clearly, for this to be effective, coupon redemption must be deliberately made time-consuming.</p><p>To the extent that there is coupon personalization, it seems to be for changing shopper behavior (e.g., getting them to try out a new product) rather than a pricing mechanism. The NYT story from last year about <a href=\"http://www.nytimes.com/2012/02/19/magazine/shopping-habits.html\">Target targeting pregnant women</a> falls into this category. That said, these different forms of personalization aren’t entirely distinct, which is a point I will return to in a later article.</p><p><strong>4. The traditional model doesn’t work well any more.</strong></p><p>Paper coupons have a limited future. As for digital coupons, there is a natural progression toward interfaces that make it easier to acquire and redeem them. In particular, as more shoppers start to pay using their phones in stores, I anticipate coupon redemption being integrated into payment apps, thus becoming almost frictionless.</p><p>An interesting side-effect of smartphone-based coupon redemption is that it gives the shopper <a href=\"http://33bits.org/2011/06/08/the-many-ways-in-which-the-internet-has-given-us-more-privacy/\">more privacy</a>, avoiding the awkwardness of pulling out coupons from a purse or wallet. This will further open up coupons to a wealthier demographic, making them even less effective at discriminating between wealthier shoppers and less affluent ones.</p><p><strong>5. The coupon is being reborn in a data-driven, personalized form.</strong></p><p>With behavioral profiling, companies can determine how much a consumer will pay for a product, and deliver coupons selectively so that each customer’s discount reflects what they are willing to pay. They key difference is what while in the past, customers decided whether or not to look for, collect, and use a coupon, in the new model companies will determine who gets which coupons.</p><p>In the extreme, coupons will be available for all purchases, and smart shopping software on our phones or browsers will automatically search, aggregate, manage, and redeem these coupons, showing coupon-adjusted prices when browsing for products. More realistically, the process won’t be completely frictionless, since that would lose the psychological benefit. Coupons will probably also merge with “rewards,” “points,” discounts, and various other incentives.</p><p>There have been rumblings of this shift <a href=\"http://www.cbsnews.com/8301-505124_162-42340692/the-future-of-online-coupons-scarily-personalized-offers-based-on-your-history/\">here</a> and <a href=\"http://www.forbes.com/sites/moneybuilder/2012/08/21/individualized-coupons-aid-price-discrimination/\">there</a> for a few years now, and it seems to be happening gradually. Google’s <a href=\"http://techcrunch.com/2012/11/28/google-acquires-incentive-targeting-to-power-targeted-coupon-programs/\">acquisition</a> of Incentive Targeting a few months ago seems significant, and at the very least demonstrates that tech companies are eyeing this space as well, and not just retailers. As <a href=\"https://citp.princeton.edu/event/narayanan/\">digital feudalism</a> takes root, it could accelerate the trend of individualized shopping experiences.</p><p>In summary, personalized coupons offer a vehicle for realizing the full potential of data mining for commerce by tailoring prices in a way that consumers seem to find acceptable. Neither coupons nor price discrimination should be viewed in isolation — together with rewards and various other incentive schemes, they are part of the trend of individualized, data mining-driven commerce that’s here to stay.</p><p><strong>Footnotes</strong></p><p>[1] Since I’m eschewing some academic terminology in this post, here are a few references and points of clarification. My interest is in first-degree price discrimination. Any price discrimination requires <a href=\"https://en.wikipedia.org/wiki/Market_power\">market power</a>; my assumption is that is the case in practice because competition is always <a href=\"http://faculty.chicagobooth.edu/lars.stole/papers/pdce.pdf\">imperfect</a>, and we should expect quite a bit of first-degree price discrimination. The observed level is puzzlingly low.</p><p>The impact of technology on the ability to personalize prices is complex, and behavioral profiling is only one aspect. Technology also makes competition less perfect by allowing firms to customize products to a greater degree, so that there are no exact substitutes. Finally, technology <em>hinders</em> first-degree price discrimination to an extent by allowing consumers to compare prices between different retailers more easily. The interaction between these effects is analyzed in <a href=\"http://vulkan.worc.ox.ac.uk/wp-content/images/combined-paper.pdf\">this paper</a>.</p><p dir=\"ltr\">Technology also increases the <em>incentive</em> to price discriminate. As production becomes more and more automated, marginal costs drop relative to fixed costs. In the extreme, digital goods have essentially zero marginal cost. When marginal production costs are low, firms will try to tailor prices since any sale above marginal cost increases profits.</p><p>My use of the terms <em>overt</em> and <em>covert</em> is rooted in the theory of price fairness in psychology and behavioral economics, and relates to the <em>presentation</em> of the transaction. While it is somewhat related to first- vs. second/third-degree price discrimination, it is better understood as a separate axis, one that is not captured by theories of rational firms and consumers.</p><p>[2] An exception is when non-coupon customers are made aware that others are getting a better deal. This happens, for example, when there is a prominent coupon-code form field in an online shopping checkout flow. See <a href=\"http://www.mikeshor.com/research/promotioncodes/informstalk.pdf\">here</a> for a study.</p><p><em>Thanks to Sebastian Gold for reviewing a draft, and to Justin Brickell for interesting conversations that led me to this line of thinking.</em></p><p>To stay on top of future posts, <a href=\"http://33bits.org/feed/\">subscribe</a> to the RSS feed or follow me on <a href=\"https://twitter.com/random_walker\">Twitter</a> or <a href=\"https://plus.google.com/u/0/110908828231461227679\">Google+</a>.</p><br /><a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/gocomments/33bits.wordpress.com/1124/\"><img alt=\" \" border=\"0\" src=\"http://feeds.wordpress.com/1.0/comments/33bits.wordpress.com/1124/\" /></a><img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&blog=5017838&post=1124&subd=33bits&ref=&feed=1\" width=\"1\" height=\"1\" />" "http://33bits.org/2013/06/25/personalized-coupons-price-discrimination/" (20937 45750) new 4 nil nil ((title nil "Personalized coupons as a vehicle for perfect price discrimination") (link nil "http://33bits.org/2013/06/25/personalized-coupons-price-discrimination/") (comments nil "http://33bits.org/2013/06/25/personalized-coupons-price-discrimination/#comments") (pubDate nil "Tue, 25 Jun 2013 15:09:42 +0000") (dc:creator nil "Arvind Narayanan") (category nil "Uncategorized") (category nil "economics") (category nil "fairness") (category nil "price discrimination") (category nil "technology") (guid ((isPermaLink . "false")) "http://33bits.org/?p=1124") (description nil "Given the pervasive tracking and profiling of our shopping and browsing habits, one would expect that retailers would be very good at individualized price discrimination —  figuring out what you or I would be willing to pay for an item using data mining, and tailoring prices accordingly. But this doesn’t seem to be happening. Why [&#8230;]<img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&#038;blog=5017838&#038;post=1124&#038;subd=33bits&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />") (content:encoded nil "<p dir=\"ltr\">Given the pervasive tracking and profiling of our shopping and browsing habits, one would expect that retailers would be very good at individualized price discrimination —  figuring out what you or I would be willing to pay for an item using data mining, and tailoring prices accordingly. But this doesn’t seem to be happening. Why not?</p><p>This mystery isn’t new. Mathematician Andrew Odlyzko predicted a decade ago that data-driven price discrimination would become much more common and effective (<a href=\"http://www.dtc.umn.edu/~odlyzko/doc/privacy.economics.pdf\">paper</a>, <a href=\"http://www.businessweek.com/stories/2003-07-30/sharper-tools-fordiscriminatory-pricing\">interview</a>). Back then, he was far ahead of his time. But today, behavioral advertising at least has gotten good enough that it’s often creepy. The technology works; the impediment to price discrimination lies elsewhere. [1]</p><p>It looks like consumers’ perception of unfairness of price discrimination is <a href=\"http://33bits.org/2013/01/22/price-discrimination-and-the-illusion-of-fairness/\">surprisingly strong</a>, which is why firms <a href=\"http://33bits.org/2013/01/08/online-price-discrimination-conspicuous-by-its-absence/\">balk at overt price discrimination</a>, even though <a href=\"http://33bits.org/2011/06/02/price-discrimination-is-all-around-you/\">covert price discrimination is all too common</a>. But the covert form of price discrimination is not only less efficient, it also (ironically) has significant social costs — see #3 below for an example. Is there a form of pricing that allows for perfect discrimination (i.e., complete tailoring to individuals), in a way that consumers find acceptable? That would be the holy grail.</p><p>In this post, I will argue that the humble coupon, reborn in a high-tech form, could be the solution. Here’s why.</p><p><strong>1. Coupons tap into shopper psychology. Customers love them.</strong></p><p>Coupons, like sales, introduce unpredictability and rewards into shopping, which provides a tiny dopamine spike that gets us hooked. JC Penney’s recent <a href=\"http://www.nytimes.com/2013/04/14/business/for-penney-a-tough-lesson-in-shopper-psychology.html?pagewanted=all&amp;_r=0\">misadventure</a> in trying to eliminate sales and coupons provides an object lesson:</p><blockquote><p>“It may be a decent deal to buy that item for $5. But for someone like me, who’s always looking for a sale or a coupon — seeing that something is marked down 20 percent off, then being able to hand over the coupon to save, it just entices me. It’s a rush.”</p></blockquote><p>Some startups have exploited this to the hilt, introducing “gamification” into commerce. <a href=\"https://en.wikipedia.org/wiki/Shopkick\">Shopkick</a> is a prime example. I see this as a very important trend.</p><p><strong>2. Coupons aren’t perceived as unfair.</strong></p><p>Given the above, shoppers have at best a dim perception of coupons as a price discrimination mechanism. Even when they do, however, coupons aren’t perceived as unfair to nearly the same degree as listing different prices for different consumers, even if the result in either case is identical. [2]</p><p><strong>3. Traditional coupons are not personalized.</strong></p><p>While customers may have different reasons for liking coupons, from firms’ perspective the way in which traditional coupons aid price discrimination is pretty simple: by forcing customers to waste their time. Econ texts tend to lay it out bluntly. For example, <a href=\"http://www.mcafee.cc/Papers/PDF/ABAPriceDiscrimination.pdf\">R. Preston McAfee</a>:</p><blockquote><p>Individuals generally value their time at approximately their wages, so that people with low wages, who tend to be the most price-sensitive, also have the lowest value of time. &#8230; A thrifty shopper may be able to spend an hour sorting through the coupons in the newspaper and save $20 on a $200 shopping expedition &#8230; This is a good deal for a consumer who values time at less than $20 per hour, and a bad deal for the consumer that values time in excess of $20 per hour. Thus, relatively poor consumers choose to use coupons, which permits the seller to have a price cut that is approximately targeted at the more price-sensitive group.</p></blockquote><p>Clearly, for this to be effective, coupon redemption must be deliberately made time-consuming.</p><p>To the extent that there is coupon personalization, it seems to be for changing shopper behavior (e.g., getting them to try out a new product) rather than a pricing mechanism. The NYT story from last year about <a href=\"http://www.nytimes.com/2012/02/19/magazine/shopping-habits.html\">Target targeting pregnant women</a> falls into this category. That said, these different forms of personalization aren’t entirely distinct, which is a point I will return to in a later article.</p><p><strong>4. The traditional model doesn’t work well any more.</strong></p><p>Paper coupons have a limited future. As for digital coupons, there is a natural progression toward interfaces that make it easier to acquire and redeem them. In particular, as more shoppers start to pay using their phones in stores, I anticipate coupon redemption being integrated into payment apps, thus becoming almost frictionless.</p><p>An interesting side-effect of smartphone-based coupon redemption is that it gives the shopper <a href=\"http://33bits.org/2011/06/08/the-many-ways-in-which-the-internet-has-given-us-more-privacy/\">more privacy</a>, avoiding the awkwardness of pulling out coupons from a purse or wallet. This will further open up coupons to a wealthier demographic, making them even less effective at discriminating between wealthier shoppers and less affluent ones.</p><p><strong>5. The coupon is being reborn in a data-driven, personalized form.</strong></p><p>With behavioral profiling, companies can determine how much a consumer will pay for a product, and deliver coupons selectively so that each customer’s discount reflects what they are willing to pay. They key difference is what while in the past, customers decided whether or not to look for, collect, and use a coupon, in the new model companies will determine who gets which coupons.</p><p>In the extreme, coupons will be available for all purchases, and smart shopping software on our phones or browsers will automatically search, aggregate, manage, and redeem these coupons, showing coupon-adjusted prices when browsing for products. More realistically, the process won’t be completely frictionless, since that would lose the psychological benefit. Coupons will probably also merge with “rewards,” “points,” discounts, and various other incentives.</p><p>There have been rumblings of this shift <a href=\"http://www.cbsnews.com/8301-505124_162-42340692/the-future-of-online-coupons-scarily-personalized-offers-based-on-your-history/\">here</a> and <a href=\"http://www.forbes.com/sites/moneybuilder/2012/08/21/individualized-coupons-aid-price-discrimination/\">there</a> for a few years now, and it seems to be happening gradually. Google’s <a href=\"http://techcrunch.com/2012/11/28/google-acquires-incentive-targeting-to-power-targeted-coupon-programs/\">acquisition</a> of Incentive Targeting a few months ago seems significant, and at the very least demonstrates that tech companies are eyeing this space as well, and not just retailers. As <a href=\"https://citp.princeton.edu/event/narayanan/\">digital feudalism</a> takes root, it could accelerate the trend of individualized shopping experiences.</p><p>In summary, personalized coupons offer a vehicle for realizing the full potential of data mining for commerce by tailoring prices in a way that consumers seem to find acceptable. Neither coupons nor price discrimination should be viewed in isolation — together with rewards and various other incentive schemes, they are part of the trend of individualized, data mining-driven commerce that’s here to stay.</p><p><strong>Footnotes</strong></p><p>[1] Since I’m eschewing some academic terminology in this post, here are a few references and points of clarification. My interest is in first-degree price discrimination. Any price discrimination requires <a href=\"https://en.wikipedia.org/wiki/Market_power\">market power</a>; my assumption is that is the case in practice because competition is always <a href=\"http://faculty.chicagobooth.edu/lars.stole/papers/pdce.pdf\">imperfect</a>, and we should expect quite a bit of first-degree price discrimination. The observed level is puzzlingly low.</p><p>The impact of technology on the ability to personalize prices is complex, and behavioral profiling is only one aspect. Technology also makes competition less perfect by allowing firms to customize products to a greater degree, so that there are no exact substitutes. Finally, technology <em>hinders</em> first-degree price discrimination to an extent by allowing consumers to compare prices between different retailers more easily. The interaction between these effects is analyzed in <a href=\"http://vulkan.worc.ox.ac.uk/wp-content/images/combined-paper.pdf\">this paper</a>.</p><p dir=\"ltr\">Technology also increases the <em>incentive</em> to price discriminate. As production becomes more and more automated, marginal costs drop relative to fixed costs. In the extreme, digital goods have essentially zero marginal cost. When marginal production costs are low, firms will try to tailor prices since any sale above marginal cost increases profits.</p><p>My use of the terms <em>overt</em> and <em>covert</em> is rooted in the theory of price fairness in psychology and behavioral economics, and relates to the <em>presentation</em> of the transaction. While it is somewhat related to first- vs. second/third-degree price discrimination, it is better understood as a separate axis, one that is not captured by theories of rational firms and consumers.</p><p>[2] An exception is when non-coupon customers are made aware that others are getting a better deal. This happens, for example, when there is a prominent coupon-code form field in an online shopping checkout flow. See <a href=\"http://www.mikeshor.com/research/promotioncodes/informstalk.pdf\">here</a> for a study.</p><p><em>Thanks to Sebastian Gold for reviewing a draft, and to Justin Brickell for interesting conversations that led me to this line of thinking.</em></p><p>To stay on top of future posts, <a href=\"http://33bits.org/feed/\">subscribe</a> to the RSS feed or follow me on <a href=\"https://twitter.com/random_walker\">Twitter</a> or <a href=\"https://plus.google.com/u/0/110908828231461227679\">Google+</a>.</p><br /><a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/gocomments/33bits.wordpress.com/1124/\"><img alt=\" \" border=\"0\" src=\"http://feeds.wordpress.com/1.0/comments/33bits.wordpress.com/1124/\" /></a><img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&#038;blog=5017838&#038;post=1124&#038;subd=33bits&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />") (wfw:commentRss nil "http://33bits.org/2013/06/25/personalized-coupons-price-discrimination/feed/") (slash:comments nil "7") (media:content ((url . "http://1.gravatar.com/avatar/aa438b63ff1e9b75693aeabbeddae5eb?s=96&d=identicon&r=G") (medium . "image")) (media:title ((type . "html")) "randomwalker")))) ("Reidentification as Basic Science" "<p><em>This essay <a href=\"http://blogs.law.harvard.edu/billofhealth/2013/05/26/reidentification-as-basic-science/\">originally appeared</a> on the <a href=\"http://blogs.law.harvard.edu/billofhealth\">Bill of Health blog</a> as part of a conversation on the law, ethics and science of reidentification demonstrations.</em></p><p>What <em>really</em> drives reidentification researchers? Do we publish these demonstrations to alert individuals to privacy risks? To shame companies? For personal glory? If our goal is to improve privacy, are we doing it in the best way possible?</p><p>In this post I’d like to discuss my own motivations as a reidentification researcher, without speaking for anyone else. Certainly I care about improving privacy outcomes, in the sense of making sure that companies, governments and others don’t get away with mathematically unsound promises about the privacy of consumers’ data. But there is a quite different goal I care about at least as much: <strong><em>reidentification algorithms</em></strong>. These algorithms are my primary object of study, and so I see reidentification research partly as basic science.</p><p>Let me elaborate on why reidentification algorithms are interesting and important. First, they yield fundamental insights about people — our interests, preferences, behavior, and connections — as reflected in the datasets collected about us. Second, as is the case with most basic science, these algorithms turn out to have a variety of applications other than reidentification, both for good and bad. Let us consider some of these.</p><p>First and foremost, reidentification algorithms are directly applicable in digital forensics and intelligence. Analyzing the <a href=\"http://www.americanscientist.org/issues/pub/connecting-the-dots\">structure of a terrorist network</a> (say, based on surveillance of movement patterns and meetings) to assign identities to nodes is technically very similar to <a href=\"http://33bits.org/2009/03/19/de-anonymizing-social-networks/\">social network deanonymization</a>. A reidentification researcher that I know who is a U.S. citizen tells me he has been contacted more than once by intelligence agencies to apply his expertise to their data.</p><p>Homer et al’s work on <a href=\"http://www.plosgenetics.org/article/info%3Adoi%2F10.1371%2Fjournal.pgen.1000167\">identifying individuals in DNA mixtures</a> is another great example of how forensics algorithms are inextricably linked to privacy-infringing applications. In addition to DNA and network structure, <a href=\"http://33bits.org/2012/02/20/is-writing-style-sufficient-to-deanonymize-material-posted-online/\">writing style</a> and <a href=\"http://www.nature.com/srep/2013/130325/srep01376/full/srep01376.html\">location trails</a> are other attributes that have been utilized both in reidentification and forensics.</p><p>It is not a coincidence that the reidentification literature often uses the word “fingerprint” — this body of work has generalized the notion of a fingerprint beyond physical attributes to a variety of other characteristics. Just like physical fingerprints, there are good uses and bad, but regardless, finding generalized fingerprints is a contribution to human knowledge. A fundamental question is how much information (i.e., uniqueness) there is in each of these types of attributes or characteristics. Reidentification research is gradually helping answer this question, but much remains unknown.</p><p>It is not only people that are fingerprintable — so are various physical devices. A wonderful set of (unrelated) research papers has shown that many types of devices, objects, and software systems, even supposedly identical ones, are have unique fingerprints: <a href=\"http://33bits.org/2011/09/13/everything-has-a-fingerprint-the-case-of-blank-paper/\">blank paper</a>, <a href=\"http://33bits.org/2011/09/19/digital-camera-fingerprinting/\">digital cameras</a>, <a href=\"http://33bits.org/2011/10/04/fingerprinting-of-rfid-tags-and-high-tech-stalking/\">RFID tags</a>, <a href=\"http://33bits.org/2011/10/11/everything-has-a-fingerprint-%e2%80%94-dont-forget-scanners-and-printers/\">scanners and printers</a>, and <a href=\"https://panopticlick.eff.org/\">web browsers</a>, among others. The techniques are similar to reidentification algorithms, and once again straddle security-enhancing and privacy-infringing applications.</p><p>Even more generally, reidentification algorithms are classification algorithms for the case when the number of classes is very large. Classification algorithms categorize observed data into one of several classes, i.e., categories. They are at the core of machine learning, but typical machine-learning applications rarely need to consider more than several hundred classes. Thus, reidentification science is helping develop our knowledge of how best to extend classification algorithms as the number of classes increases.</p><p>Moving on, research on reidentification and other types of “leakage” of information reveals a problem with the way data-mining contests are run. Most commonly, some elements of a dataset are withheld, and contest participants are required to predict these unknown values. Reidentification allows contestants to bypass the prediction process altogether by simply “looking up” the true values in the original data! For an example and more elaborate explanation, see <a href=\"http://33bits.org/2011/03/09/link-prediction-by-de-anonymization-how-we-won-the-kaggle-social-network-challenge/\">this post</a> on how my collaborators and I won the Kaggle social network challenge. Demonstrations of information leakage have spurred <a href=\"http://www.cs.umb.edu/~ding/history/470_670_fall_2011/papers/cs670_Tran_PreferredPaper_LeakingInDataMining.pdf\">research</a> on how to design contests without such flaws.</p><p>If reidentification can cause leakage and make things messy, it can also clean things up. In a general form, reidentification is about connecting common entities across two different databases. Quite often in real-world datasets there is no unique identifier, or it is missing or erroneous. Just about every programmer who does interesting things with data has dealt with this problem at some point. In the research world, William Winkler of the U.S. Census Bureau has authored a <a href=\"https://www.census.gov/srd/papers/pdf/rrs2006-02.pdf\">survey of “record linkage”</a>, covering well over a hundred papers. I’m not saying that the high-powered machinery of reidentification is necessary here, but the principles are certainly useful.</p><p>In my brief life as an entrepreneur, I utilized just such an algorithm for the back-end of the web application that my co-founders and I built. The task in question was to link a (musical) artist profile from last.fm to the corresponding Wikipedia article based on discography information (linking by name alone fails in any number of interesting ways.) On another occasion, for the <a href=\"http://feedworld.net/toc/\">theory of computing blog aggregator</a> that I run, I wrote code to link authors of papers uploaded to <a href=\"http://arxiv.org/\">arXiv</a> to their <a href=\"http://www.informatik.uni-trier.de/~ley/db/\">DBLP</a> profiles based on the list of coauthors.</p><p>There is more, but I’ll stop here. The point is that these algorithms are <em>everywhere</em>.</p><p>If the algorithms are the key, why perform demonstrations of privacy failures? To put it simply, algorithms can’t be studied in a vacuum; we need concrete cases to test how well they work. But it’s more complicated than that. First, as I mentioned earlier, keeping the privacy conversation intellectually honest is one of my motivations, and these demonstrations help. Second, in the majority of cases, my collaborators and I have chosen to examine pairs of datasets that were <em>already public</em>, and so our work <em>did not</em> uncover the identities of previously anonymous subjects, but merely helped to establish that this <em>could</em> happen in other instances of “anonymized” data sharing.</p><p>Third, and I consider this quite unfortunate, reidentification results are taken much more seriously if researchers do uncover identities, which naturally gives us an incentive to do so. I’ve seen this in my own work — the <a href=\"http://33bits.org/about/netflix-paper-home-page/\">Netflix paper</a> is the most straightforward and arguably the least scientifically interesting reidentification result that I’ve co-authored, and yet it received by far the most attention, all because it was carried out on an actual dataset published by a company rather than demonstrated hypothetically.</p><p>My primary focus on the fundamental research aspect of reidentification guides my work in an important way. There are many, many potential targets for reidentification — despite all the research, data holders often (<a href=\"http://33bits.org/2012/12/17/new-developments-in-deanonymization/\">rationally</a>) act like nothing has changed and continue to make data releases with <a href=\"http://www.cs.utexas.edu/~shmat/shmat_cacm10.pdf\">“PII”</a> removed. So which dataset should I pick to work on?</p><p>Focusing on the algorithms makes it a lot easier. One of my criteria for picking a reidentification question to work on is that <em>it must lead to a new algorithm</em>. I’m not at all saying that all reidentification researchers should do this, but for me it’s a good way to maximize the impact I can hope for from my research, while minimizing controversies about the privacy of the subjects in the datasets I study.</p><p>I hope this post has given you some insight into my goals, motivations, and research outputs, and an appreciation of the fact that there is more to reidentification algorithms than their application to breaching privacy. It will be useful to keep this fact in the back of our minds as we continue the conversation on the ethics of reidentification.</p><p><em>Thanks to <a href=\"http://www.cs.utexas.edu/~shmat/\">Vitaly Shmatikov</a> for reviewing a draft.</em></p><p>To stay on top of future posts, <a href=\"http://33bits.org/feed/\">subscribe</a> to the RSS feed or follow me on <a href=\"https://twitter.com/random_walker\">Twitter</a> or <a href=\"https://plus.google.com/u/0/110908828231461227679\">Google+</a>.</p><br /><a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/gocomments/33bits.wordpress.com/1116/\"><img alt=\" \" border=\"0\" src=\"http://feeds.wordpress.com/1.0/comments/33bits.wordpress.com/1116/\" /></a><img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&blog=5017838&post=1116&subd=33bits&ref=&feed=1\" width=\"1\" height=\"1\" />" "http://33bits.org/2013/05/27/reidentification-as-basic-science/" (20899 27298) new 5 nil nil ((title nil "Reidentification as Basic Science") (link nil "http://33bits.org/2013/05/27/reidentification-as-basic-science/") (comments nil "http://33bits.org/2013/05/27/reidentification-as-basic-science/#comments") (pubDate nil "Mon, 27 May 2013 14:16:02 +0000") (dc:creator nil "Arvind Narayanan") (category nil "Uncategorized") (category nil "de-anonymization") (category nil "ethics") (category nil "re-identification") (guid ((isPermaLink . "false")) "http://33bits.org/?p=1116") (description nil "This essay originally appeared on the Bill of Health blog as part of a conversation on the law, ethics and science of reidentification demonstrations. What really drives reidentification researchers? Do we publish these demonstrations to alert individuals to privacy risks? To shame companies? For personal glory? If our goal is to improve privacy, are we doing it in [&#8230;]<img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&#038;blog=5017838&#038;post=1116&#038;subd=33bits&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />") (content:encoded nil "<p><em>This essay <a href=\"http://blogs.law.harvard.edu/billofhealth/2013/05/26/reidentification-as-basic-science/\">originally appeared</a> on the <a href=\"http://blogs.law.harvard.edu/billofhealth\">Bill of Health blog</a> as part of a conversation on the law, ethics and science of reidentification demonstrations.</em></p><p>What <em>really</em> drives reidentification researchers? Do we publish these demonstrations to alert individuals to privacy risks? To shame companies? For personal glory? If our goal is to improve privacy, are we doing it in the best way possible?</p><p>In this post I’d like to discuss my own motivations as a reidentification researcher, without speaking for anyone else. Certainly I care about improving privacy outcomes, in the sense of making sure that companies, governments and others don’t get away with mathematically unsound promises about the privacy of consumers’ data. But there is a quite different goal I care about at least as much: <strong><em>reidentification algorithms</em></strong>. These algorithms are my primary object of study, and so I see reidentification research partly as basic science.</p><p>Let me elaborate on why reidentification algorithms are interesting and important. First, they yield fundamental insights about people — our interests, preferences, behavior, and connections — as reflected in the datasets collected about us. Second, as is the case with most basic science, these algorithms turn out to have a variety of applications other than reidentification, both for good and bad. Let us consider some of these.</p><p>First and foremost, reidentification algorithms are directly applicable in digital forensics and intelligence. Analyzing the <a href=\"http://www.americanscientist.org/issues/pub/connecting-the-dots\">structure of a terrorist network</a> (say, based on surveillance of movement patterns and meetings) to assign identities to nodes is technically very similar to <a href=\"http://33bits.org/2009/03/19/de-anonymizing-social-networks/\">social network deanonymization</a>. A reidentification researcher that I know who is a U.S. citizen tells me he has been contacted more than once by intelligence agencies to apply his expertise to their data.</p><p>Homer et al’s work on <a href=\"http://www.plosgenetics.org/article/info%3Adoi%2F10.1371%2Fjournal.pgen.1000167\">identifying individuals in DNA mixtures</a> is another great example of how forensics algorithms are inextricably linked to privacy-infringing applications. In addition to DNA and network structure, <a href=\"http://33bits.org/2012/02/20/is-writing-style-sufficient-to-deanonymize-material-posted-online/\">writing style</a> and <a href=\"http://www.nature.com/srep/2013/130325/srep01376/full/srep01376.html\">location trails</a> are other attributes that have been utilized both in reidentification and forensics.</p><p>It is not a coincidence that the reidentification literature often uses the word “fingerprint” — this body of work has generalized the notion of a fingerprint beyond physical attributes to a variety of other characteristics. Just like physical fingerprints, there are good uses and bad, but regardless, finding generalized fingerprints is a contribution to human knowledge. A fundamental question is how much information (i.e., uniqueness) there is in each of these types of attributes or characteristics. Reidentification research is gradually helping answer this question, but much remains unknown.</p><p>It is not only people that are fingerprintable — so are various physical devices. A wonderful set of (unrelated) research papers has shown that many types of devices, objects, and software systems, even supposedly identical ones, are have unique fingerprints: <a href=\"http://33bits.org/2011/09/13/everything-has-a-fingerprint-the-case-of-blank-paper/\">blank paper</a>, <a href=\"http://33bits.org/2011/09/19/digital-camera-fingerprinting/\">digital cameras</a>, <a href=\"http://33bits.org/2011/10/04/fingerprinting-of-rfid-tags-and-high-tech-stalking/\">RFID tags</a>, <a href=\"http://33bits.org/2011/10/11/everything-has-a-fingerprint-%e2%80%94-dont-forget-scanners-and-printers/\">scanners and printers</a>, and <a href=\"https://panopticlick.eff.org/\">web browsers</a>, among others. The techniques are similar to reidentification algorithms, and once again straddle security-enhancing and privacy-infringing applications.</p><p>Even more generally, reidentification algorithms are classification algorithms for the case when the number of classes is very large. Classification algorithms categorize observed data into one of several classes, i.e., categories. They are at the core of machine learning, but typical machine-learning applications rarely need to consider more than several hundred classes. Thus, reidentification science is helping develop our knowledge of how best to extend classification algorithms as the number of classes increases.</p><p>Moving on, research on reidentification and other types of “leakage” of information reveals a problem with the way data-mining contests are run. Most commonly, some elements of a dataset are withheld, and contest participants are required to predict these unknown values. Reidentification allows contestants to bypass the prediction process altogether by simply “looking up” the true values in the original data! For an example and more elaborate explanation, see <a href=\"http://33bits.org/2011/03/09/link-prediction-by-de-anonymization-how-we-won-the-kaggle-social-network-challenge/\">this post</a> on how my collaborators and I won the Kaggle social network challenge. Demonstrations of information leakage have spurred <a href=\"http://www.cs.umb.edu/~ding/history/470_670_fall_2011/papers/cs670_Tran_PreferredPaper_LeakingInDataMining.pdf\">research</a> on how to design contests without such flaws.</p><p>If reidentification can cause leakage and make things messy, it can also clean things up. In a general form, reidentification is about connecting common entities across two different databases. Quite often in real-world datasets there is no unique identifier, or it is missing or erroneous. Just about every programmer who does interesting things with data has dealt with this problem at some point. In the research world, William Winkler of the U.S. Census Bureau has authored a <a href=\"https://www.census.gov/srd/papers/pdf/rrs2006-02.pdf\">survey of “record linkage”</a>, covering well over a hundred papers. I’m not saying that the high-powered machinery of reidentification is necessary here, but the principles are certainly useful.</p><p>In my brief life as an entrepreneur, I utilized just such an algorithm for the back-end of the web application that my co-founders and I built. The task in question was to link a (musical) artist profile from last.fm to the corresponding Wikipedia article based on discography information (linking by name alone fails in any number of interesting ways.) On another occasion, for the <a href=\"http://feedworld.net/toc/\">theory of computing blog aggregator</a> that I run, I wrote code to link authors of papers uploaded to <a href=\"http://arxiv.org/\">arXiv</a> to their <a href=\"http://www.informatik.uni-trier.de/~ley/db/\">DBLP</a> profiles based on the list of coauthors.</p><p>There is more, but I’ll stop here. The point is that these algorithms are <em>everywhere</em>.</p><p>If the algorithms are the key, why perform demonstrations of privacy failures? To put it simply, algorithms can’t be studied in a vacuum; we need concrete cases to test how well they work. But it’s more complicated than that. First, as I mentioned earlier, keeping the privacy conversation intellectually honest is one of my motivations, and these demonstrations help. Second, in the majority of cases, my collaborators and I have chosen to examine pairs of datasets that were <em>already public</em>, and so our work <em>did not</em> uncover the identities of previously anonymous subjects, but merely helped to establish that this <em>could</em> happen in other instances of “anonymized” data sharing.</p><p>Third, and I consider this quite unfortunate, reidentification results are taken much more seriously if researchers do uncover identities, which naturally gives us an incentive to do so. I’ve seen this in my own work — the <a href=\"http://33bits.org/about/netflix-paper-home-page/\">Netflix paper</a> is the most straightforward and arguably the least scientifically interesting reidentification result that I’ve co-authored, and yet it received by far the most attention, all because it was carried out on an actual dataset published by a company rather than demonstrated hypothetically.</p><p>My primary focus on the fundamental research aspect of reidentification guides my work in an important way. There are many, many potential targets for reidentification — despite all the research, data holders often (<a href=\"http://33bits.org/2012/12/17/new-developments-in-deanonymization/\">rationally</a>) act like nothing has changed and continue to make data releases with <a href=\"http://www.cs.utexas.edu/~shmat/shmat_cacm10.pdf\">“PII”</a> removed. So which dataset should I pick to work on?</p><p>Focusing on the algorithms makes it a lot easier. One of my criteria for picking a reidentification question to work on is that <em>it must lead to a new algorithm</em>. I’m not at all saying that all reidentification researchers should do this, but for me it’s a good way to maximize the impact I can hope for from my research, while minimizing controversies about the privacy of the subjects in the datasets I study.</p><p>I hope this post has given you some insight into my goals, motivations, and research outputs, and an appreciation of the fact that there is more to reidentification algorithms than their application to breaching privacy. It will be useful to keep this fact in the back of our minds as we continue the conversation on the ethics of reidentification.</p><p><em>Thanks to <a href=\"http://www.cs.utexas.edu/~shmat/\">Vitaly Shmatikov</a> for reviewing a draft.</em></p><p>To stay on top of future posts, <a href=\"http://33bits.org/feed/\">subscribe</a> to the RSS feed or follow me on <a href=\"https://twitter.com/random_walker\">Twitter</a> or <a href=\"https://plus.google.com/u/0/110908828231461227679\">Google+</a>.</p><br /><a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/gocomments/33bits.wordpress.com/1116/\"><img alt=\" \" border=\"0\" src=\"http://feeds.wordpress.com/1.0/comments/33bits.wordpress.com/1116/\" /></a><img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&#038;blog=5017838&#038;post=1116&#038;subd=33bits&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />") (wfw:commentRss nil "http://33bits.org/2013/05/27/reidentification-as-basic-science/feed/") (slash:comments nil "0") (media:content ((url . "http://1.gravatar.com/avatar/aa438b63ff1e9b75693aeabbeddae5eb?s=96&d=identicon&r=G") (medium . "image")) (media:title ((type . "html")) "randomwalker")))) ("Privacy technologies course roundup: Wiki, student projects, HotPETs" "<p>In earlier posts about the privacy technologies course I taught at Princeton during Fall 2012, I described how I <a href=\"http://33bits.org/2013/04/11/how-i-utilized-expectation-failure-to-refute-privacy-myths/\">refuted privacy myths</a>, and presented an <a href=\"http://33bits.org/2013/04/16/privacy-technologies-an-annotated-syllabus/\">annotated syllabus</a>. In this concluding post I will offer some additional tidbits about the course.</p><p><strong>Wiki.</strong> I referred to a Wiki a few times in my earlier post, and you might wonder what that was about. The course included an online Wiki discussion component, and this was in fact the centerpiece. Students were required to participate in the online discussion of the day’s readings before coming to class. The in-class discussion would use the Wiki discussion as a starting point.</p><p dir=\"ltr\">The advantages of this approach are: 1. it gives the instructor a great degree of control in shaping the discussion of each paper, 2. the instructor can more closely monitor individual students’ progress 3. class discussion can focus on particularly tricky and/or contentious points, instead of rehashing the obvious.</p><p><strong>Student projects.</strong> Students picked a variety of final projects for the class, and on the whole exceeded my expectations. Here are two very different projects, in brief.</p><p>Nora Taranto, a History of Science major, wrote a policy paper about the privacy implications of the shift to electronic medical records. Nora writes:</p><blockquote><p>I wrote a paper about the privacy implications of patient-care institutions (in the United States) using electronic medical record (EMR) systems more and more frequently.  This topic had particular relevance given the huge number of privacy breaches that occurred in 2012 alone.  Meanwhile, there is a simultaneous criticism coming from care providers about the usability of such EMR systems.  As such, many different communities—in the information privacy sphere, in the medical community, in the general public, etc.—have many different things to say.  But, given the several privacy breaches that occurred within a couple of weeks in April 2012 and together implicated over a million individuals, concerns have been raised in particular about how secure EMR systems are.  These concerns are especially worrisome given the federal government’s push for their adoption nationwide beginning in 2009 when the American Recovery and Reinvestment Act granting funds to hospitals explicitly for the purpose of EMR implementation.</p><p>So I looked into the benefits and costs of such systems, with a particular slant towards the privacy benefits/costs.  Overall, these systems <i>do </i>have a number of protective mechanisms at their disposal, some preventative and others reactive.  While these protective barriers are all necessary, they are not sufficient to guarantee the patient his or her privacy rights in the modern day.  These protective mechanisms—authentication schemes, encryption, and data logs/anomaly-detection—need to be expanded and further developed to provide an adequate amount of protection for personal health information.  While the government is, at the moment, encouraging the adoption of EMR systems for maximal penetration, medical institutions ought to use caution in considering which systems to implement and ought to hold themselves to a higher standard.  Moreover, greater regulatory oversight of EMR systems on the market would help institutions maintain this cautious approach.</p></blockquote><p>Abu Saparov, Ajay Roopakalu, and Raﬁ Shamim, also undergraduates, designed an implemented an alternative to centralized key distribution. They write:</p><blockquote><p>Our project for the course was to create and implement a decentralized public key distribution protocol and show how it could be used. One of the initial goals of our project was to experience first-hand some of the things that made the design of a usable and useful privacy application so hard. Early on in the process, we decided to try to build some type of application that used cryptography to enhance the privacy of communication with friends. Some of the reasons that we chose this general topic were the fact that all of us had experience with network programming and that we thought some of the things that cryptography can achieve are uniquely cool. We were also somewhat motivated by the prospect of using our application to talk with each other and our other friends after we graduate. We eventually gravitated towards two ideas: (1) a completely peer-to-peer chat system that is encrypted from end-to-end, and (2) a “dumb” social network that allows users to share posts that only their friends (and not the server) can see. During the semester, our focus shifted to designing and implementing the underlying key distribution mechanism upon which these two systems could be built.</p><p>When we began to flesh out the designs for our two ideas, we realized that the act of retrieving a friend’s public cryptographic keys was the first challenge to solve. Certificate authorities are the most common way to obtain public keys, but require a large degree of trust to be placed in a small number of authorities. Web of Trust is another option, and is completely decentralized, but often proves difficult in practice because of the need for manual key signing. We decided to make our own decentralized protocol that exposes an easily usable API for clients to use in order to obtain public keys. Our protocol defines an overlay network that features regular nodes, as well as supernodes that are able to prove their trustworthiness, although the details of this are controllable through a policy delegate. The idea is for supernodes to share the task of remembering and verifying public keys through a majority vote of neighboring supernodes. Users running other nodes can ask the supernodes for a friend’s public key. In order to trick someone, an adversary would have to control over half of the supernodes from which a user requested a key. Our decision to go with an overlay network created a variety of issues such as synchronizing information between supernodes, being able to detect and report malicious supernodes, and getting new nodes incorporated into the network. These and the countless other design problems we faced definitely allowed us to appreciate the difficulty of writing a privacy application, but unfortunately, we were not fully able to test every element of our protocol and its implementation. After creating the protocol, we implemented small, bare-bones applications for our initial ideas of peer-to-peer chat and an encrypted social network.</p></blockquote><p>Master’s students Chris Eubank, <a href=\"http://www.cs.princeton.edu/~melara/\">Marcela Melara</a>, and <a href=\"http://www.cs.princeton.edu/~diegop/\">Diego Perez-Botero</a> did a project on mobile web tracking which, with some further work, turned into a <a href=\"http://w2spconf.com/2013/papers/s2p2.pdf\">research paper</a> that Chris will speak about at <a href=\"http://w2spconf.com/2013/\">W2SP</a> tomorrow.</p><p>Finally, I’m happy to say that I will be discussing the syllabus and my experiences teaching this class at <a href=\"http://petsymposium.org/2013/hotpets.php\">HotPETs</a> this year, in Bloomington, IN, in July.</p><p>To stay on top of future posts, <a href=\"http://33bits.org/feed/\">subscribe</a> to the RSS feed or follow me on <a href=\"https://twitter.com/random_walker\">Twitter</a> or <a href=\"https://plus.google.com/u/0/110908828231461227679\">Google+</a>.</p><br /><a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/gocomments/33bits.wordpress.com/1113/\"><img alt=\" \" border=\"0\" src=\"http://feeds.wordpress.com/1.0/comments/33bits.wordpress.com/1113/\" /></a><img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&blog=5017838&post=1113&subd=33bits&ref=&feed=1\" width=\"1\" height=\"1\" />" "http://33bits.org/2013/05/23/privacy-technologies-course-roundup-wiki-student-projects-hotpets/" (20894 38079) new 6 nil nil ((title nil "Privacy technologies course roundup: Wiki, student projects, HotPETs") (link nil "http://33bits.org/2013/05/23/privacy-technologies-course-roundup-wiki-student-projects-hotpets/") (comments nil "http://33bits.org/2013/05/23/privacy-technologies-course-roundup-wiki-student-projects-hotpets/#comments") (pubDate nil "Thu, 23 May 2013 22:14:23 +0000") (dc:creator nil "Arvind Narayanan") (category nil "Uncategorized") (category nil "princeton") (category nil "privacy") (category nil "teaching") (guid ((isPermaLink . "false")) "http://33bits.org/?p=1113") (description nil "In earlier posts about the privacy technologies course I taught at Princeton during Fall 2012, I described how I refuted privacy myths, and presented an annotated syllabus. In this concluding post I will offer some additional tidbits about the course. Wiki. I referred to a Wiki a few times in my earlier post, and you [&#8230;]<img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&#038;blog=5017838&#038;post=1113&#038;subd=33bits&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />") (content:encoded nil "<p>In earlier posts about the privacy technologies course I taught at Princeton during Fall 2012, I described how I <a href=\"http://33bits.org/2013/04/11/how-i-utilized-expectation-failure-to-refute-privacy-myths/\">refuted privacy myths</a>, and presented an <a href=\"http://33bits.org/2013/04/16/privacy-technologies-an-annotated-syllabus/\">annotated syllabus</a>. In this concluding post I will offer some additional tidbits about the course.</p><p><strong>Wiki.</strong> I referred to a Wiki a few times in my earlier post, and you might wonder what that was about. The course included an online Wiki discussion component, and this was in fact the centerpiece. Students were required to participate in the online discussion of the day’s readings before coming to class. The in-class discussion would use the Wiki discussion as a starting point.</p><p dir=\"ltr\">The advantages of this approach are: 1. it gives the instructor a great degree of control in shaping the discussion of each paper, 2. the instructor can more closely monitor individual students’ progress 3. class discussion can focus on particularly tricky and/or contentious points, instead of rehashing the obvious.</p><p><strong>Student projects.</strong> Students picked a variety of final projects for the class, and on the whole exceeded my expectations. Here are two very different projects, in brief.</p><p>Nora Taranto, a History of Science major, wrote a policy paper about the privacy implications of the shift to electronic medical records. Nora writes:</p><blockquote><p>I wrote a paper about the privacy implications of patient-care institutions (in the United States) using electronic medical record (EMR) systems more and more frequently.  This topic had particular relevance given the huge number of privacy breaches that occurred in 2012 alone.  Meanwhile, there is a simultaneous criticism coming from care providers about the usability of such EMR systems.  As such, many different communities—in the information privacy sphere, in the medical community, in the general public, etc.—have many different things to say.  But, given the several privacy breaches that occurred within a couple of weeks in April 2012 and together implicated over a million individuals, concerns have been raised in particular about how secure EMR systems are.  These concerns are especially worrisome given the federal government’s push for their adoption nationwide beginning in 2009 when the American Recovery and Reinvestment Act granting funds to hospitals explicitly for the purpose of EMR implementation.</p><p>So I looked into the benefits and costs of such systems, with a particular slant towards the privacy benefits/costs.  Overall, these systems <i>do </i>have a number of protective mechanisms at their disposal, some preventative and others reactive.  While these protective barriers are all necessary, they are not sufficient to guarantee the patient his or her privacy rights in the modern day.  These protective mechanisms—authentication schemes, encryption, and data logs/anomaly-detection—need to be expanded and further developed to provide an adequate amount of protection for personal health information.  While the government is, at the moment, encouraging the adoption of EMR systems for maximal penetration, medical institutions ought to use caution in considering which systems to implement and ought to hold themselves to a higher standard.  Moreover, greater regulatory oversight of EMR systems on the market would help institutions maintain this cautious approach.</p></blockquote><p>Abu Saparov, Ajay Roopakalu, and Raﬁ Shamim, also undergraduates, designed an implemented an alternative to centralized key distribution. They write:</p><blockquote><p>Our project for the course was to create and implement a decentralized public key distribution protocol and show how it could be used. One of the initial goals of our project was to experience first-hand some of the things that made the design of a usable and useful privacy application so hard. Early on in the process, we decided to try to build some type of application that used cryptography to enhance the privacy of communication with friends. Some of the reasons that we chose this general topic were the fact that all of us had experience with network programming and that we thought some of the things that cryptography can achieve are uniquely cool. We were also somewhat motivated by the prospect of using our application to talk with each other and our other friends after we graduate. We eventually gravitated towards two ideas: (1) a completely peer-to-peer chat system that is encrypted from end-to-end, and (2) a &#8220;dumb&#8221; social network that allows users to share posts that only their friends (and not the server) can see. During the semester, our focus shifted to designing and implementing the underlying key distribution mechanism upon which these two systems could be built.</p><p>When we began to flesh out the designs for our two ideas, we realized that the act of retrieving a friend&#8217;s public cryptographic keys was the first challenge to solve. Certificate authorities are the most common way to obtain public keys, but require a large degree of trust to be placed in a small number of authorities. Web of Trust is another option, and is completely decentralized, but often proves difficult in practice because of the need for manual key signing. We decided to make our own decentralized protocol that exposes an easily usable API for clients to use in order to obtain public keys. Our protocol defines an overlay network that features regular nodes, as well as supernodes that are able to prove their trustworthiness, although the details of this are controllable through a policy delegate. The idea is for supernodes to share the task of remembering and verifying public keys through a majority vote of neighboring supernodes. Users running other nodes can ask the supernodes for a friend&#8217;s public key. In order to trick someone, an adversary would have to control over half of the supernodes from which a user requested a key. Our decision to go with an overlay network created a variety of issues such as synchronizing information between supernodes, being able to detect and report malicious supernodes, and getting new nodes incorporated into the network. These and the countless other design problems we faced definitely allowed us to appreciate the difficulty of writing a privacy application, but unfortunately, we were not fully able to test every element of our protocol and its implementation. After creating the protocol, we implemented small, bare-bones applications for our initial ideas of peer-to-peer chat and an encrypted social network.</p></blockquote><p>Master&#8217;s students Chris Eubank, <a href=\"http://www.cs.princeton.edu/~melara/\">Marcela Melara</a>, and <a href=\"http://www.cs.princeton.edu/~diegop/\">Diego Perez-Botero</a> did a project on mobile web tracking which, with some further work, turned into a <a href=\"http://w2spconf.com/2013/papers/s2p2.pdf\">research paper</a> that Chris will speak about at <a href=\"http://w2spconf.com/2013/\">W2SP</a> tomorrow.</p><p>Finally, I&#8217;m happy to say that I will be discussing the syllabus and my experiences teaching this class at <a href=\"http://petsymposium.org/2013/hotpets.php\">HotPETs</a> this year, in Bloomington, IN, in July.</p><p>To stay on top of future posts, <a href=\"http://33bits.org/feed/\">subscribe</a> to the RSS feed or follow me on <a href=\"https://twitter.com/random_walker\">Twitter</a> or <a href=\"https://plus.google.com/u/0/110908828231461227679\">Google+</a>.</p><br /><a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/gocomments/33bits.wordpress.com/1113/\"><img alt=\" \" border=\"0\" src=\"http://feeds.wordpress.com/1.0/comments/33bits.wordpress.com/1113/\" /></a><img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&#038;blog=5017838&#038;post=1113&#038;subd=33bits&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />") (wfw:commentRss nil "http://33bits.org/2013/05/23/privacy-technologies-course-roundup-wiki-student-projects-hotpets/feed/") (slash:comments nil "1") (media:content ((url . "http://1.gravatar.com/avatar/aa438b63ff1e9b75693aeabbeddae5eb?s=96&d=identicon&r=G") (medium . "image")) (media:title ((type . "html")) "randomwalker")))) ("What Happened to the Crypto Dream? Now in a new and improved paper form!" "<p dir=\"ltr\">Last October I gave a talk titled “<a href=\"https://citp.princeton.edu/event/arvind-narayanan/\">What Happened to the Crypto Dream?</a>” where I looked at why crypto seems to have done little for personal privacy. The reaction from the audience (physical and online) was quite encouraging — not that everyone agreed, but they seemed to find it thought provoking — and several people asked me if I’d turn it into a paper. So when Prof. Alessandro Acquisti invited me to contribute an essay to the “On the Horizon” column in IEEE S&amp;P magazine, I jumped at the chance, and suggested this topic.</p><p dir=\"ltr\">Thanks to some fantastic feedback from colleagues and many improvements to the prose by the editors, I’m happy with how the essay has turned out. Here it is in two parts: <strong><a href=\"http://randomwalker.info/publications/crypto-dream-part1.pdf\">Part 1</a></strong>, <strong><a href=\"http://randomwalker.info/publications/crypto-dream-part2.pdf\">Part 2</a></strong>.</p><p dir=\"ltr\">While I’m not saying anything earth shaking, I do make a somewhat nuanced argument — I distinguish between “crypto for security” and “crypto for privacy,” and further subdivide the latter into a spectrum between what I call “Cypherpunk Crypto” and “Pragmatic Crypto.” I identify different practical impediments that apply to those two flavors (in the latter case, a complex of related factors), and lay out a few avenues for action that can help privacy-enhancing crypto move in a direction more relevant to practice.</p><p>I’m aware that this is a contentious topic, especially since some people feel that the time is ripe for a resurgence of the cypherpunk vision. I’m happy to hear your reactions.</p><p>To stay on top of future posts, <a href=\"http://33bits.org/feed/\">subscribe</a> to the RSS feed or follow me on <a href=\"https://twitter.com/random_walker\">Twitter</a> or <a href=\"https://plus.google.com/u/0/110908828231461227679\">Google+</a>.</p><br /><a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/gocomments/33bits.wordpress.com/1110/\"><img alt=\" \" border=\"0\" src=\"http://feeds.wordpress.com/1.0/comments/33bits.wordpress.com/1110/\" /></a><img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&blog=5017838&post=1110&subd=33bits&ref=&feed=1\" width=\"1\" height=\"1\" />" "http://33bits.org/2013/04/29/what-happened-to-the-crypto-dream-now-in-a-new-and-improved-paper-form/" (20862 53981) new 7 nil nil ((title nil "What Happened to the Crypto Dream? Now in a new and improved paper form!") (link nil "http://33bits.org/2013/04/29/what-happened-to-the-crypto-dream-now-in-a-new-and-improved-paper-form/") (comments nil "http://33bits.org/2013/04/29/what-happened-to-the-crypto-dream-now-in-a-new-and-improved-paper-form/#comments") (pubDate nil "Mon, 29 Apr 2013 20:06:53 +0000") (dc:creator nil "Arvind Narayanan") (category nil "Uncategorized") (category nil "cryptography") (category nil "cypherpunk") (category nil "economics") (category nil "privacy") (guid ((isPermaLink . "false")) "http://33bits.org/?p=1110") (description nil "Last October I gave a talk titled “What Happened to the Crypto Dream?” where I looked at why crypto seems to have done little for personal privacy. The reaction from the audience (physical and online) was quite encouraging — not that everyone agreed, but they seemed to find it thought provoking — and several people [&#8230;]<img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&#038;blog=5017838&#038;post=1110&#038;subd=33bits&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />") (content:encoded nil "<p dir=\"ltr\">Last October I gave a talk titled “<a href=\"https://citp.princeton.edu/event/arvind-narayanan/\">What Happened to the Crypto Dream?</a>” where I looked at why crypto seems to have done little for personal privacy. The reaction from the audience (physical and online) was quite encouraging — not that everyone agreed, but they seemed to find it thought provoking — and several people asked me if I’d turn it into a paper. So when Prof. Alessandro Acquisti invited me to contribute an essay to the “On the Horizon” column in IEEE S&amp;P magazine, I jumped at the chance, and suggested this topic.</p><p dir=\"ltr\">Thanks to some fantastic feedback from colleagues and many improvements to the prose by the editors, I’m happy with how the essay has turned out. Here it is in two parts: <strong><a href=\"http://randomwalker.info/publications/crypto-dream-part1.pdf\">Part 1</a></strong>, <strong><a href=\"http://randomwalker.info/publications/crypto-dream-part2.pdf\">Part 2</a></strong>.</p><p dir=\"ltr\">While I’m not saying anything earth shaking, I do make a somewhat nuanced argument — I distinguish between “crypto for security” and “crypto for privacy,” and further subdivide the latter into a spectrum between what I call “Cypherpunk Crypto” and “Pragmatic Crypto.” I identify different practical impediments that apply to those two flavors (in the latter case, a complex of related factors), and lay out a few avenues for action that can help privacy-enhancing crypto move in a direction more relevant to practice.</p><p>I’m aware that this is a contentious topic, especially since some people feel that the time is ripe for a resurgence of the cypherpunk vision. I’m happy to hear your reactions.</p><p>To stay on top of future posts, <a href=\"http://33bits.org/feed/\">subscribe</a> to the RSS feed or follow me on <a href=\"https://twitter.com/random_walker\">Twitter</a> or <a href=\"https://plus.google.com/u/0/110908828231461227679\">Google+</a>.</p><br /><a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/gocomments/33bits.wordpress.com/1110/\"><img alt=\" \" border=\"0\" src=\"http://feeds.wordpress.com/1.0/comments/33bits.wordpress.com/1110/\" /></a><img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&#038;blog=5017838&#038;post=1110&#038;subd=33bits&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />") (wfw:commentRss nil "http://33bits.org/2013/04/29/what-happened-to-the-crypto-dream-now-in-a-new-and-improved-paper-form/feed/") (slash:comments nil "0") (media:content ((url . "http://1.gravatar.com/avatar/aa438b63ff1e9b75693aeabbeddae5eb?s=96&d=identicon&r=G") (medium . "image")) (media:title ((type . "html")) "randomwalker")))) ("Privacy technologies: An annotated syllabus" "<p>Last semester I taught a <span class=\"c7\"><a class=\"c5\" href=\"http://randomwalker.info/teaching/fall-2012-privacy-technologies/\">course</a></span> on privacy technologies here at Princeton. Earlier I discussed how I <span class=\"c7\"><a class=\"c5\" href=\"http://33bits.org/2013/04/11/how-i-utilized-expectation-failure-to-refute-privacy-myths/\">refuted privacy myths</a></span> that students brought into class. In this post I’d like to discuss the contents of the course. I hope it will be useful to other instructors who are interested in teaching this topic as well as for students undertaking self-study of privacy technologies. Beware: this post is quite <span class=\"c6\">long</span>.</p><p class=\"c0\">What should be taught in a class on privacy technologies? Before we answer that, let’s take a step back and ask, <strong><span class=\"c10\">how does one go about figuring out what should be taught in any class?</span></strong></p><p class=\"c0\">I’ve seen two approaches. The traditional, default, overwhelmingly common approach is to think of it in terms of “covering content” without much consideration to what students are getting out of it. The content that’s deemed relevant is often determined by what the fashionable research areas happen to be, or historical accident, or some combination thereof.</p><p class=\"c0\">A contrasting approach, promoted by authors like <span class=\"c7\"><a class=\"c5\" href=\"http://www.amazon.com/What-Best-College-Teachers-Do/dp/0674013255\">Bain</a></span>, applies a laser focus on skills that students will acquire and how they will apply them later in life. On teaching orientation day at Princeton, our instructor, who clearly subscribed to this approach, had each professor describe what students would do in the class they are teaching, then wrote down only the verbs from these descriptions. The point was that our thinking had to be centered around skills that students would take home.</p><p class=\"c0\">I prefer a middle ground. It should be apparent from my description of the traditional approach above that I’m not a fan. On the other hand, I have to wonder what skills our teaching coach would have suggested for a course on cosmology — avoiding falling into black holes? Alright, I’m exaggerating to make a point. The verbs in question are words like “synthesize” and “evaluate,” so there would be no particular difficulty in applying them to cosmology. But my point is that in a cosmology course, I’m not sure the instructor should start from these verbs.</p><p class=\"c0\">Sometimes we want students to be exposed to knowledge primarily because it is beautiful, and being able to perceive that beauty inspires us, instills us with a love of further learning, and I dare say satisfies a fundamental need. To me a lot of the crypto “magic” that goes into privacy technologies falls into that category (not that it doesn’t have practical applications).</p><p class=\"c0\">With that caveat, however, I agree with the emphasis on skills and life impact. I thought of my students primarily as developers of privacy technologies (and more generally, of technological systems that incorporate privacy considerations), but also as users and scholars of privacy technologies.</p><p class=\"c0\">I organized the course into sections, a short introductory section followed by five sections that alternated in the level of math/technical depth. Every time we studied a technology, we also discussed its social/economic/political aspects. I had a great deal of discretion in guiding where the conversation around the papers went by giving them questions/prompts on the class Wiki. Let us now jump in. The italicized text is from the <a href=\"http://randomwalker.info/teaching/fall-2012-privacy-technologies/\">course page</a>, the rest is my annotation.</p><p class=\"c0\"><strong><em><span class=\"c2 c10\">0. </span><span class=\"c2 c10\">Intro</span></em></strong></p><p class=\"c0\"><em><span class=\"c2\">Goals of this section: Why are we here? Who cares about privacy? What might the future look like?</span></em></p><ul><li class=\"c4 c0\"><em><span class=\"c2\">Dan Solove. </span><span class=\"c8 c14 c6\"><a class=\"c5\" href=\"http://chronicle.com/article/Why-Privacy-Matters-Even-if/127461/\">Why Privacy Matters Even if You Have ‘Nothing to Hide’</a></span><span class=\"c2\"> (Chronicle)</span></em></li><li class=\"c4 c0\"><em><span class=\"c2\">David Brin. </span><span class=\"c8 c14 c6\"><a class=\"c5\" href=\"http://www.wired.com/wired/archive/4.12/fftransparent_pr.html\">The Transparent Society</a></span><span class=\"c2\"> (WIRED, circa 1996, later expanded into a book)</span></em></li></ul><p class=\"c0\">In addition to helping flesh out the foundational assumptions of this course that I discussed in the <a href=\"http://33bits.org/2013/04/11/how-i-utilized-expectation-failure-to-refute-privacy-myths/\">previous post</a>, pairing these opposing views with each other helped make the point that there are few absolutes in this class, that privacy scholars may disagree with each other, and that the instructor doesn’t necessarily agree with the viewpoints in the assigned reading, much less expects students to.</p><p class=\"c0\"><em><strong><span class=\"c2 c10\">1. </span><span class=\"c2 c10\">Cryptography: power and limitations</span></strong></em></p><p class=\"c9 c0\"><em><span class=\"c6\">Goals. Travel back in time to the 80s and early 90s, understand the often-euphoric vision that many crypto pioneers and hobbyists had for the impact it would have. Understand how cryptographic building blocks were thought to be able to support this restructuring of society. Reason about why it didn’t happen.</span></em></p><p class=\"c9 c0\"><em><span class=\"c6\">Understand the motivations and mathematical underpinnings of the modern research on privacy-preserving computations. Experiment with various encryption tools, discover usability problems and other limitations of crypto.</span></em></p><ul><li class=\"c4 c0\"><em><span class=\"c2\">David Chaum. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.chaum.com/articles/Security_Wthout_Identification.htm\">Security without Identification: Card Computers to make Big Brother Obsolete</a></span><span class=\"c2\"> (1985)</span></em></li><li class=\"c4 c0\"><em><span class=\"c2\">Steven Levy. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.wired.com/wired/archive/1.02/crypto.rebels_pr.html\">Crypto Rebels</a></span><span class=\"c2\"> (WIRED, 1993; later a </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.amazon.com/Crypto-Rebels-Government-Privacy-Digital/dp/0140244328/\">2001 book</a></span><span class=\"c2\">)</span></em></li><li class=\"c4 c0\"><em><span class=\"c2\">Eric Hughes. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.activism.net/cypherpunk/manifesto.html\">A cypherpunk’s manifesto.</a></span><span class=\"c2\"> (short essay, 1993.)</span></em></li></ul><p class=\"c0 c11\">I think the Chaum paper is a phenomenal and underutilized resource for teaching. My goal was to really immerse students in an alternate reality where the legal underpinnings of commerce were replaced by cryptography, much as Chaum envisioned (and even going beyond that). I created a couple of e-commerce scenarios for Wiki discussion and had them reason about how various functions would be accomplished.</p><p class=\"c0 c11\">My own views on this topic are set forth in this <a href=\"https://citp.princeton.edu/event/arvind-narayanan/\">talk</a> (now a paper; coming soon). In general I aimed to shield students from my viewpoints, and saw my role as helping them discover (and be able to defend) their own. At least in this instance I succeeded. Some students took the position that the cypherpunk dream is just around the corner.</p><ul><li><em>The ‘Garbled Circuit Protocol’ (Yao’s theorem on secure two-party computation) and its implications (lecture)</em></li></ul><p class=\"c0\">This is one of the topics that sadly suffers from a lack of good expository material, so I instead lectured on it.</p><ul><li class=\"c4 c0\"><em><span class=\"c2\">Alma Whitten and Doug Tygar. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.gaudior.net/alma/johnny.pdf\">Why Johnny Can’t Encrypt: A Usability Evaluation of PGP 5.0</a></span></em></li><li class=\"c4 c0\"><em><span class=\"c2\">Nikita Borisov, Ian Goldberg, Eric Brewer. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.cypherpunks.ca/otr/otr-wpes.pdf\">Off-the-Record Communication, or, Why Not To Use PGP</a></span></em></li><li class=\"c4 c0\"><em><span class=\"c2\">Thomas Ptacek. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.matasano.com/articles/javascript-cryptography/\">Javascript Cryptography Considered Harmful</a></span></em></li></ul><p class=\"c0\">One of the exercises here was to install and use various crypto tools and rediscover the usability problems. The difficulties were even worse than I’d anticipated.</p><p class=\"c0\"><em><strong><span class=\"c2 c10\">2. Data collection and data mining, economics of personal data, behavioral economics of privacy</span></strong></em></p><p class=\"c0\"><em><span class=\"c6\">Goals. Jump forward in time to the present day and immerse ourselves in the world of ubiquitous data collection and surveillance. Discover what kinds of data collection and data mining are going on, and why. Discuss how and why the conversation has shifted from Government surveillance to data collection by private companies in the last 20 years.</span></em></p><p class=\"c9 c0\"><em><span class=\"c2\">Theme: first-party data collection.</span></em></p><ul><li><em><span class=\"c2\">New York Times. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.nytimes.com/2012/02/19/magazine/shopping-habits.html\">How Companies Learn Your Secrets</a></span></em></li><li><em><span class=\"c2\">Andrew Odlyzko. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.dtc.umn.edu/~odlyzko/doc/privacy.economics.pdf\">Privacy, Economics, and Price Discrimination on the Internet</a></span></em></li></ul><p class=\"c9 c0\"><em><span class=\"c2\">Theme: third-party data collection.</span></em></p><ul><li><em><span class=\"c2\">Julia Angwin. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://online.wsj.com/article/SB10001424052748703940904575395073512989404.html\">The Web’s New Gold Mine: Your Secrets</a></span><span class=\"c2\"> (First in the Wall Street Journal’s What They Know series)</span></em></li><li><em><span class=\"c2\">Jonathan R. Mayer and John C. Mitchell. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"https://www.stanford.edu/~jmayer/papers/trackingsurvey12.pdf\">Third-Party Web Tracking: Policy and Technology</a></span></em></li></ul><p class=\"c9 c0\"><em><span class=\"c2\">Theme: why companies act the way they do.</span></em></p><ul><li><em><span class=\"c2\">Joseph Bonneau and Sören Preibusch. The Privacy Jungle: </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://preibusch.de/publications/Bonneau_Preibusch__Privacy_Jungle__2009-05-26.pdf\">On the Market for Data Protection in Social Networks</a></span></em></li><li><em><span class=\"c2\">Bruce Schneier. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.wired.com/politics/security/commentary/securitymatters/2007/04/securitymatters_0419\">How Security Companies Sucker Us With Lemons</a></span><span class=\"c2\"> (WIRED)</span></em></li></ul><p class=\"c9 c0\"><em><span class=\"c2\">Theme: why people act the way they do.</span></em></p><ul><li><em><span class=\"c2\">Alessandro Acquisti and Jens Grossklags. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.heinz.cmu.edu/~acquisti/papers/Acquisti-Grossklags-Chapter-Etrics.pdf\">What Can Behavioral Economics Teach Us About Privacy?</a></span></em></li><li><em><span class=\"c2\">Alessandro Acquisti. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.heinz.cmu.edu/~acquisti/papers/privacy-gratification.pdf\">Privacy in Electronic Commerce and the Economics of Immediate Gratification</a></span></em></li></ul><p class=\"c0\">This section is rather self-explanatory. After the math-y flavor of the first section, this one has a good amount of economics, behavioral economics, and policy. One of the thought exercises was to project current trends into the future and imagine what ubiquitous tracking might lead to in five or ten years.</p><p class=\"c0\"><em><strong><span class=\"c2 c10\">3. </span><span class=\"c2 c10\">Anonymity and De-anonymization</span></strong></em></p><p class=\"c0 c9\"><em><span class=\"c2\">Important note: communications anonymity (e.g., Tor) and data anonymity/de-anonymization (e.g., identifying people in digital databases) are technically very different, but we will discuss them together because they raise some of the same ethical questions. Also, Bitcoin lies somewhere in between the two.</span></em></p><ul><li><em><span class=\"c2\">Roger Dingledine, Nick Mathewson, Paul Syverson. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"https://svn.torproject.org/svn/projects/design-paper/tor-design.pdf\">Tor: The Second-Generation Onion Router</a></span></em></li></ul><ul><li><em><span class=\"c2\">Satoshi Nakamoto. Bitcoin: </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://bitcoin.org/bitcoin.pdf\">A Peer-to-Peer Electronic Cash System</a></span></em></li></ul><p class=\"c0\">Tor and Bitcoin (especially the latter) were the hardest but also the most rewarding parts of the class, both for them and for me. Together they took up 4 classes. Bitcoin is extremely challenging to teach because it is technically intricate, the ecosystem is rapidly changing, and a lot of the information is in random blog/forum posts.</p><p class=\"c0\">In a way, I was betting on Bitcoin by deciding to teach it — if it had died with a whimper, their knowledge of it would be much less relevant. In general I think instructors should choose to make these such bets more often; most curricula are very conservative. I’m glad I did.</p><ul><li><em><span class=\"c2\">Nils Homer at al. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.plosgenetics.org/article/info%3Adoi%2F10.1371%2Fjournal.pgen.1000167\">Resolving Individuals Contributing Trace Amounts of DNA to Highly Complex Mixtures Using High-Density SNP Genotyping Microarrays</a></span></em></li><li><em><span class=\"c2\">[Optional] Arvind Narayanan, Elaine Shi, Benjamin I. P. Rubinstein. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://arxiv.org/pdf/1102.4374v1.pdf\">Link Prediction by De-anonymization: How We Won the Kaggle Social Network Challenge</a></span></em></li></ul><p class=\"c0\">It was a challenge to figure out which deanonymization paper to assign. I went with the DNA one because I wanted them to see that deanonymization isn’t a fact about data, but a fact about the world. Another thing I liked about this paper is that they’d have to extract the not-too-complex statistical methodology in this paper from the bioinformatics discussion in which it is embedded. This didn’t go as well as I’d hoped.</p><p class=\"c0\">I’ve co-authored a few deanonymization papers, but they’re not very well written and/or are poorly suited for pedagogical purposes. The Kaggle paper is one exception, which I made optional.</p><ul><li><em><span class=\"c2\">Paul Ohm. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1450006\">Broken Promises of Privacy: Responding to the Surprising Failure of Anonymization</a></span></em></li><li><em><span class=\"c2\">[Optional] Jane Yakowitz Bambauer. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1789749\">Tragedy of the Data Commons</a></span></em></li></ul><p class=\"c0\">This is another pair of papers with opposing views. Since the latter paper is optional, knowing that most of them wouldn’t have read it, I used the Wiki prompts to raise many of the issues that the author raises.</p><p class=\"c0\"><em><strong><span class=\"c2 c10\">4. </span><span class=\"c2 c10\">Lightweight Privacy Technologies and New Approaches to Information Privacy</span></strong></em></p><p class=\"c0\"><span class=\"c12\">While cryptography is the mechanism of choice for cypherpunk privacy and anonymity tools like Tor, it is too heavy a weapon in other contexts like social networking. In the latter context, it’s not so much users deploying privacy tools to protect themselves against all-powerful adversaries but rather a service provider attempting to cater to a more nuanced understanding of privacy that users bring to the system. </span><span class=\"c12\">The goal of this section is to consider a diverse spectrum of ideas applicable to this latter scenario that have been proposed in recent years in the fields of CS, HCI, law, and more. The technologies here are “lightweight” in comparison to cryptographic tools like Tor.</span></p><ul><li><em><span class=\"c2\">Scott Lederer, Jason Hong et al. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://repository.cmu.edu/cgi/viewcontent.cgi?article=1077&amp;context=hcii\">Personal Privacy through Understanding and Action: Five Pitfalls for Designers</a></span></em></li><li><em><span class=\"c2\">Franziska Roesner et al. </span><span class=\"c6 c8\"><a class=\"c5\" href=\"http://research.microsoft.com/apps/pubs/?id=152495\">User-Driven Access Control: Rethinking Permission Granting in Modern Operating Systems</a></span></em></li></ul><ul><li><em><span class=\"c2\">Fred Stutzman and Woodrow Hartzog. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://fredstutzman.com/papers/CSCW2012W_Stutzman.pdf\">Obscurity by Design: An Approach to Building Privacy into Social Media</a></span></em></li><li><em><span class=\"c2\">Woodrow Hartzog and Fred Stutzman. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1597745\">The Case for Online Obscurity</a></span></em></li></ul><ul><li class=\"c4 c0\"><em><span class=\"c2\">Jerry Kang et al. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.ntia.doc.gov/files/ntia/comments/101214614-0614-01/attachments/kang,%20shilton,%20estrin,%20burke,%20hansen,%20self-surveillance%20privacy%20v12.pdf\">Self-surveillance Privacy</a></span></em></li><li class=\"c4 c0\"><em><span class=\"c2\">[Optional] Ryan Calo. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1790144\">Against Notice Skepticism In Privacy (And Elsewhere)</a></span></em></li></ul><ul><li><em><span class=\"c2\">Helen Nissenbaum. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.amacad.org/publications/daedalus/11_fall_nissenbaum.pdf\">A Contextual Approach to Privacy Online</a></span></em></li></ul><p class=\"c0\"><em><strong><span class=\"c2 c10\">5. Purely technological approaches revisited</span></strong></em></p><p class=\"c0\"><span class=\"c12\">This final section doesn’t have a coherent theme (and I admitted as much in class). My goal with the first two papers was to contrast a privacy problem which seems amenable to a purely or primarily technological formulation and solution (statistical queries over databases of sensitive personal information) with one where such attempts have been less successful (the decentralized, own-your-data approach to social networking and e-commerce). </span></p><ul><li><em>Differential Privacy. (Lecture)</em><ul><li><em><span class=\"c2\">Cynthia Dwork. </span><span class=\"c8 c14 c6\"><a class=\"c5\" href=\"http://research.microsoft.com/pubs/64346/dwork.pdf\">Differential Privacy</a></span><span class=\"c6 c13\">.</span></em></li></ul></li></ul><p class=\"c0\">Differential privacy is another topic that is sorely lacking in expository material, especially from the point of view of students who’ve never done crypto before. So this was again a lecture.</p><ul><li><em><span class=\"c2\">Arvind Narayanan et al. </span><span class=\"c8 c14 c6\"><a class=\"c5\" href=\"http://randomwalker.info/publications/critical-look-at-decentralization-v1.pdf\">A Critical Look at Decentralized Personal Data Architectures</a></span></em></li></ul><ul><li><em><span class=\"c2\">John Perry Barlow </span><span class=\"c8 c14 c6\"><a class=\"c5\" href=\"https://projects.eff.org/~barlow/Declaration-Final.html\">A Declaration of the Independence of Cyberspace</a></span><span class=\"c2\"> (short essay, 1996)</span></em></li><li><em><span class=\"c2\">James Grimmelmann. </span><span class=\"c8 c6 c14\"><a class=\"c5\" href=\"http://illinoislawreview.org/wp-content/ilr-content/articles/2012/2/Grimmelmann.pdf\">Sealand, HavenCo, and the Rule of Law</a></span></em></li></ul><p class=\"c0\">These two essays aren’t directly related to privacy. One of the recurring threads in this course is the debate between purely technological and legal or other approaches to privacy; the theme here is to generalize it to a context broader than privacy. The Barlow essay asserts the exceptionalism of Cyberspace as an unregulable medium, whereas the Grimmelmann paper provides a much more nuanced view of the relationship between the law and new technological frontiers.</p><p class=\"c0\"><strong><span class=\"c10\">I’m making available the entire set of Wiki discussion prompts for the class</span></strong><b id=\"internal-source-marker_0.6116034584119916\">(<a href=\"http://randomwalker.info/teaching/fall-2012-privacy-technologies/discussion-prompts.html\">HTML</a>/<a href=\"http://randomwalker.info/teaching/fall-2012-privacy-technologies/discussion-prompts.pdf\">PDF</a>).</b> I consider this integral to the syllabus, for it shapes the discussion very significantly. I really hope other instructors and students find this useful as a teaching/study guide. For reference, each set of prompts (one set per class) took me about three hours to write on average.</p><p class=\"c0\">There are many more things I want to share about this class: the major take-home ideas, the rationale for the Wiki discussion format, the feedback I got from students, a description of a couple of student projects, some thoughts on the sociology of different communities studying privacy and how that impacted the class, and finally, links to similar courses that are being taught elsewhere. I’ll probably close this series with a round-up post including as many of the above topics as I can.</p><p class=\"c0\">To stay on top of future posts, <a href=\"http://33bits.org/feed/\">subscribe</a> to the RSS feed or follow me on <a href=\"https://twitter.com/random_walker\">Twitter</a> or <a href=\"https://plus.google.com/u/0/110908828231461227679\">Google+</a>.</p><br /><a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/gocomments/33bits.wordpress.com/1105/\"><img alt=\" \" border=\"0\" src=\"http://feeds.wordpress.com/1.0/comments/33bits.wordpress.com/1105/\" /></a><img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&blog=5017838&post=1105&subd=33bits&ref=&feed=1\" width=\"1\" height=\"1\" />" "http://33bits.org/2013/04/16/privacy-technologies-an-annotated-syllabus/" (20845 15857) new 8 nil nil ((title nil "Privacy technologies: An annotated syllabus") (link nil "http://33bits.org/2013/04/16/privacy-technologies-an-annotated-syllabus/") (comments nil "http://33bits.org/2013/04/16/privacy-technologies-an-annotated-syllabus/#comments") (pubDate nil "Tue, 16 Apr 2013 12:02:57 +0000") (dc:creator nil "Arvind Narayanan") (category nil "Uncategorized") (category nil "princeton") (category nil "privacy") (category nil "teaching") (guid ((isPermaLink . "false")) "http://33bits.org/?p=1105") (description nil "Last semester I taught a course on privacy technologies here at Princeton. Earlier I discussed how I refuted privacy myths that students brought into class. In this post I’d like to discuss the contents of the course. I hope it will be useful to other instructors who are interested in teaching this topic as well [&#8230;]<img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&#038;blog=5017838&#038;post=1105&#038;subd=33bits&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />") (content:encoded nil "<p>Last semester I taught a <span class=\"c7\"><a class=\"c5\" href=\"http://randomwalker.info/teaching/fall-2012-privacy-technologies/\">course</a></span> on privacy technologies here at Princeton. Earlier I discussed how I <span class=\"c7\"><a class=\"c5\" href=\"http://33bits.org/2013/04/11/how-i-utilized-expectation-failure-to-refute-privacy-myths/\">refuted privacy myths</a></span> that students brought into class. In this post I’d like to discuss the contents of the course. I hope it will be useful to other instructors who are interested in teaching this topic as well as for students undertaking self-study of privacy technologies. Beware: this post is quite <span class=\"c6\">long</span>.</p><p class=\"c0\">What should be taught in a class on privacy technologies? Before we answer that, let’s take a step back and ask, <strong><span class=\"c10\">how does one go about figuring out what should be taught in any class?</span></strong></p><p class=\"c0\">I’ve seen two approaches. The traditional, default, overwhelmingly common approach is to think of it in terms of “covering content” without much consideration to what students are getting out of it. The content that’s deemed relevant is often determined by what the fashionable research areas happen to be, or historical accident, or some combination thereof.</p><p class=\"c0\">A contrasting approach, promoted by authors like <span class=\"c7\"><a class=\"c5\" href=\"http://www.amazon.com/What-Best-College-Teachers-Do/dp/0674013255\">Bain</a></span>, applies a laser focus on skills that students will acquire and how they will apply them later in life. On teaching orientation day at Princeton, our instructor, who clearly subscribed to this approach, had each professor describe what students would do in the class they are teaching, then wrote down only the verbs from these descriptions. The point was that our thinking had to be centered around skills that students would take home.</p><p class=\"c0\">I prefer a middle ground. It should be apparent from my description of the traditional approach above that I’m not a fan. On the other hand, I have to wonder what skills our teaching coach would have suggested for a course on cosmology — avoiding falling into black holes? Alright, I’m exaggerating to make a point. The verbs in question are words like “synthesize” and “evaluate,” so there would be no particular difficulty in applying them to cosmology. But my point is that in a cosmology course, I’m not sure the instructor should start from these verbs.</p><p class=\"c0\">Sometimes we want students to be exposed to knowledge primarily because it is beautiful, and being able to perceive that beauty inspires us, instills us with a love of further learning, and I dare say satisfies a fundamental need. To me a lot of the crypto “magic” that goes into privacy technologies falls into that category (not that it doesn&#8217;t have practical applications).</p><p class=\"c0\">With that caveat, however, I agree with the emphasis on skills and life impact. I thought of my students primarily as developers of privacy technologies (and more generally, of technological systems that incorporate privacy considerations), but also as users and scholars of privacy technologies.</p><p class=\"c0\">I organized the course into sections, a short introductory section followed by five sections that alternated in the level of math/technical depth. Every time we studied a technology, we also discussed its social/economic/political aspects. I had a great deal of discretion in guiding where the conversation around the papers went by giving them questions/prompts on the class Wiki. Let us now jump in. The italicized text is from the <a href=\"http://randomwalker.info/teaching/fall-2012-privacy-technologies/\">course page</a>, the rest is my annotation.</p><p class=\"c0\"><strong><em><span class=\"c2 c10\">0. </span><span class=\"c2 c10\">Intro</span></em></strong></p><p class=\"c0\"><em><span class=\"c2\">Goals of this section: Why are we here? Who cares about privacy? What might the future look like?</span></em></p><ul><li class=\"c4 c0\"><em><span class=\"c2\">Dan Solove. </span><span class=\"c8 c14 c6\"><a class=\"c5\" href=\"http://chronicle.com/article/Why-Privacy-Matters-Even-if/127461/\">Why Privacy Matters Even if You Have &#8216;Nothing to Hide’</a></span><span class=\"c2\"> (Chronicle)</span></em></li><li class=\"c4 c0\"><em><span class=\"c2\">David Brin. </span><span class=\"c8 c14 c6\"><a class=\"c5\" href=\"http://www.wired.com/wired/archive/4.12/fftransparent_pr.html\">The Transparent Society</a></span><span class=\"c2\"> (WIRED, circa 1996, later expanded into a book)</span></em></li></ul><p class=\"c0\">In addition to helping flesh out the foundational assumptions of this course that I discussed in the <a href=\"http://33bits.org/2013/04/11/how-i-utilized-expectation-failure-to-refute-privacy-myths/\">previous post</a>, pairing these opposing views with each other helped make the point that there are few absolutes in this class, that privacy scholars may disagree with each other, and that the instructor doesn’t necessarily agree with the viewpoints in the assigned reading, much less expects students to.</p><p class=\"c0\"><em><strong><span class=\"c2 c10\">1. </span><span class=\"c2 c10\">Cryptography: power and limitations</span></strong></em></p><p class=\"c9 c0\"><em><span class=\"c6\">Goals. Travel back in time to the 80s and early 90s, understand the often-euphoric vision that many crypto pioneers and hobbyists had for the impact it would have. Understand how cryptographic building blocks were thought to be able to support this restructuring of society. Reason about why it didn&#8217;t happen.</span></em></p><p class=\"c9 c0\"><em><span class=\"c6\">Understand the motivations and mathematical underpinnings of the modern research on privacy-preserving computations. Experiment with various encryption tools, discover usability problems and other limitations of crypto.</span></em></p><ul><li class=\"c4 c0\"><em><span class=\"c2\">David Chaum. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.chaum.com/articles/Security_Wthout_Identification.htm\">Security without Identification: Card Computers to make Big Brother Obsolete</a></span><span class=\"c2\"> (1985)</span></em></li><li class=\"c4 c0\"><em><span class=\"c2\">Steven Levy. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.wired.com/wired/archive/1.02/crypto.rebels_pr.html\">Crypto Rebels</a></span><span class=\"c2\"> (WIRED, 1993; later a </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.amazon.com/Crypto-Rebels-Government-Privacy-Digital/dp/0140244328/\">2001 book</a></span><span class=\"c2\">)</span></em></li><li class=\"c4 c0\"><em><span class=\"c2\">Eric Hughes. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.activism.net/cypherpunk/manifesto.html\">A cypherpunk&#8217;s manifesto.</a></span><span class=\"c2\"> (short essay, 1993.)</span></em></li></ul><p class=\"c0 c11\">I think the Chaum paper is a phenomenal and underutilized resource for teaching. My goal was to really immerse students in an alternate reality where the legal underpinnings of commerce were replaced by cryptography, much as Chaum envisioned (and even going beyond that). I created a couple of e-commerce scenarios for Wiki discussion and had them reason about how various functions would be accomplished.</p><p class=\"c0 c11\">My own views on this topic are set forth in this <a href=\"https://citp.princeton.edu/event/arvind-narayanan/\">talk</a> (now a paper; coming soon). In general I aimed to shield students from my viewpoints, and saw my role as helping them discover (and be able to defend) their own. At least in this instance I succeeded. Some students took the position that the cypherpunk dream is just around the corner.</p><ul><li><em>The ‘Garbled Circuit Protocol’ (Yao&#8217;s theorem on secure two-party computation) and its implications (lecture)</em></li></ul><p class=\"c0\">This is one of the topics that sadly suffers from a lack of good expository material, so I instead lectured on it.</p><ul><li class=\"c4 c0\"><em><span class=\"c2\">Alma Whitten and Doug Tygar. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.gaudior.net/alma/johnny.pdf\">Why Johnny Can’t Encrypt: A Usability Evaluation of PGP 5.0</a></span></em></li><li class=\"c4 c0\"><em><span class=\"c2\">Nikita Borisov, Ian Goldberg, Eric Brewer. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.cypherpunks.ca/otr/otr-wpes.pdf\">Off-the-Record Communication, or, Why Not To Use PGP</a></span></em></li><li class=\"c4 c0\"><em><span class=\"c2\">Thomas Ptacek. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.matasano.com/articles/javascript-cryptography/\">Javascript Cryptography Considered Harmful</a></span></em></li></ul><p class=\"c0\">One of the exercises here was to install and use various crypto tools and rediscover the usability problems. The difficulties were even worse than I’d anticipated.</p><p class=\"c0\"><em><strong><span class=\"c2 c10\">2. Data collection and data mining, economics of personal data, behavioral economics of privacy</span></strong></em></p><p class=\"c0\"><em><span class=\"c6\">Goals. Jump forward in time to the present day and immerse ourselves in the world of ubiquitous data collection and surveillance. Discover what kinds of data collection and data mining are going on, and why. Discuss how and why the conversation has shifted from Government surveillance to data collection by private companies in the last 20 years.</span></em></p><p class=\"c9 c0\"><em><span class=\"c2\">Theme: first-party data collection.</span></em></p><ul><li><em><span class=\"c2\">New York Times. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.nytimes.com/2012/02/19/magazine/shopping-habits.html\">How Companies Learn Your Secrets</a></span></em></li><li><em><span class=\"c2\">Andrew Odlyzko. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.dtc.umn.edu/~odlyzko/doc/privacy.economics.pdf\">Privacy, Economics, and Price Discrimination on the Internet</a></span></em></li></ul><p class=\"c9 c0\"><em><span class=\"c2\">Theme: third-party data collection.</span></em></p><ul><li><em><span class=\"c2\">Julia Angwin. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://online.wsj.com/article/SB10001424052748703940904575395073512989404.html\">The Web&#8217;s New Gold Mine: Your Secrets</a></span><span class=\"c2\"> (First in the Wall Street Journal’s What They Know series)</span></em></li><li><em><span class=\"c2\">Jonathan R. Mayer and John C. Mitchell. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"https://www.stanford.edu/~jmayer/papers/trackingsurvey12.pdf\">Third-Party Web Tracking: Policy and Technology</a></span></em></li></ul><p class=\"c9 c0\"><em><span class=\"c2\">Theme: why companies act the way they do.</span></em></p><ul><li><em><span class=\"c2\">Joseph Bonneau and Sören Preibusch. The Privacy Jungle: </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://preibusch.de/publications/Bonneau_Preibusch__Privacy_Jungle__2009-05-26.pdf\">On the Market for Data Protection in Social Networks</a></span></em></li><li><em><span class=\"c2\">Bruce Schneier. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.wired.com/politics/security/commentary/securitymatters/2007/04/securitymatters_0419\">How Security Companies Sucker Us With Lemons</a></span><span class=\"c2\"> (WIRED)</span></em></li></ul><p class=\"c9 c0\"><em><span class=\"c2\">Theme: why people act the way they do.</span></em></p><ul><li><em><span class=\"c2\">Alessandro Acquisti and Jens Grossklags. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.heinz.cmu.edu/~acquisti/papers/Acquisti-Grossklags-Chapter-Etrics.pdf\">What Can Behavioral Economics Teach Us About Privacy?</a></span></em></li><li><em><span class=\"c2\">Alessandro Acquisti. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.heinz.cmu.edu/~acquisti/papers/privacy-gratification.pdf\">Privacy in Electronic Commerce and the Economics of Immediate Gratification</a></span></em></li></ul><p class=\"c0\">This section is rather self-explanatory. After the math-y flavor of the first section, this one has a good amount of economics, behavioral economics, and policy. One of the thought exercises was to project current trends into the future and imagine what ubiquitous tracking might lead to in five or ten years.</p><p class=\"c0\"><em><strong><span class=\"c2 c10\">3. </span><span class=\"c2 c10\">Anonymity and De-anonymization</span></strong></em></p><p class=\"c0 c9\"><em><span class=\"c2\">Important note: communications anonymity (e.g., Tor) and data anonymity/de-anonymization (e.g., identifying people in digital databases) are technically very different, but we will discuss them together because they raise some of the same ethical questions. Also, Bitcoin lies somewhere in between the two.</span></em></p><ul><li><em><span class=\"c2\">Roger Dingledine, Nick Mathewson, Paul Syverson. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"https://svn.torproject.org/svn/projects/design-paper/tor-design.pdf\">Tor: The Second-Generation Onion Router</a></span></em></li></ul><ul><li><em><span class=\"c2\">Satoshi Nakamoto. Bitcoin: </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://bitcoin.org/bitcoin.pdf\">A Peer-to-Peer Electronic Cash System</a></span></em></li></ul><p class=\"c0\">Tor and Bitcoin (especially the latter) were the hardest but also the most rewarding parts of the class, both for them and for me. Together they took up 4 classes. Bitcoin is extremely challenging to teach because it is technically intricate, the ecosystem is rapidly changing, and a lot of the information is in random blog/forum posts.</p><p class=\"c0\">In a way, I was betting on Bitcoin by deciding to teach it — if it had died with a whimper, their knowledge of it would be much less relevant. In general I think instructors should choose to make these such bets more often; most curricula are very conservative. I’m glad I did.</p><ul><li><em><span class=\"c2\">Nils Homer at al. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.plosgenetics.org/article/info%3Adoi%2F10.1371%2Fjournal.pgen.1000167\">Resolving Individuals Contributing Trace Amounts of DNA to Highly Complex Mixtures Using High-Density SNP Genotyping Microarrays</a></span></em></li><li><em><span class=\"c2\">[Optional] Arvind Narayanan, Elaine Shi, Benjamin I. P. Rubinstein. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://arxiv.org/pdf/1102.4374v1.pdf\">Link Prediction by De-anonymization: How We Won the Kaggle Social Network Challenge</a></span></em></li></ul><p class=\"c0\">It was a challenge to figure out which deanonymization paper to assign. I went with the DNA one because I wanted them to see that deanonymization isn&#8217;t a fact about data, but a fact about the world. Another thing I liked about this paper is that they’d have to extract the not-too-complex statistical methodology in this paper from the bioinformatics discussion in which it is embedded. This didn&#8217;t go as well as I’d hoped.</p><p class=\"c0\">I’ve co-authored a few deanonymization papers, but they’re not very well written and/or are poorly suited for pedagogical purposes. The Kaggle paper is one exception, which I made optional.</p><ul><li><em><span class=\"c2\">Paul Ohm. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1450006\">Broken Promises of Privacy: Responding to the Surprising Failure of Anonymization</a></span></em></li><li><em><span class=\"c2\">[Optional] Jane Yakowitz Bambauer. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1789749\">Tragedy of the Data Commons</a></span></em></li></ul><p class=\"c0\">This is another pair of papers with opposing views. Since the latter paper is optional, knowing that most of them wouldn&#8217;t have read it, I used the Wiki prompts to raise many of the issues that the author raises.</p><p class=\"c0\"><em><strong><span class=\"c2 c10\">4. </span><span class=\"c2 c10\">Lightweight Privacy Technologies and New Approaches to Information Privacy</span></strong></em></p><p class=\"c0\"><span class=\"c12\">While cryptography is the mechanism of choice for cypherpunk privacy and anonymity tools like Tor, it is too heavy a weapon in other contexts like social networking. In the latter context, it’s not so much users deploying privacy tools to protect themselves against all-powerful adversaries but rather a service provider attempting to cater to a more nuanced understanding of privacy that users bring to the system. </span><span class=\"c12\">The goal of this section is to consider a diverse spectrum of ideas applicable to this latter scenario that have been proposed in recent years in the fields of CS, HCI, law, and more. The technologies here are “lightweight” in comparison to cryptographic tools like Tor.</span></p><ul><li><em><span class=\"c2\">Scott Lederer, Jason Hong et al. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://repository.cmu.edu/cgi/viewcontent.cgi?article=1077&amp;context=hcii\">Personal Privacy through Understanding and Action: Five Pitfalls for Designers</a></span></em></li><li><em><span class=\"c2\">Franziska Roesner et al. </span><span class=\"c6 c8\"><a class=\"c5\" href=\"http://research.microsoft.com/apps/pubs/?id=152495\">User-Driven Access Control: Rethinking Permission Granting in Modern Operating Systems</a></span></em></li></ul><ul><li><em><span class=\"c2\">Fred Stutzman and Woodrow Hartzog. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://fredstutzman.com/papers/CSCW2012W_Stutzman.pdf\">Obscurity by Design: An Approach to Building Privacy into Social Media</a></span></em></li><li><em><span class=\"c2\">Woodrow Hartzog and Fred Stutzman. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1597745\">The Case for Online Obscurity</a></span></em></li></ul><ul><li class=\"c4 c0\"><em><span class=\"c2\">Jerry Kang et al. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.ntia.doc.gov/files/ntia/comments/101214614-0614-01/attachments/kang,%20shilton,%20estrin,%20burke,%20hansen,%20self-surveillance%20privacy%20v12.pdf\">Self-surveillance Privacy</a></span></em></li><li class=\"c4 c0\"><em><span class=\"c2\">[Optional] Ryan Calo. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1790144\">Against Notice Skepticism In Privacy (And Elsewhere)</a></span></em></li></ul><ul><li><em><span class=\"c2\">Helen Nissenbaum. </span><span class=\"c8 c6\"><a class=\"c5\" href=\"http://www.amacad.org/publications/daedalus/11_fall_nissenbaum.pdf\">A Contextual Approach to Privacy Online</a></span></em></li></ul><p class=\"c0\"><em><strong><span class=\"c2 c10\">5. Purely technological approaches revisited</span></strong></em></p><p class=\"c0\"><span class=\"c12\">This final section doesn’t have a coherent theme (and I admitted as much in class). My goal with the first two papers was to contrast a privacy problem which seems amenable to a purely or primarily technological formulation and solution (statistical queries over databases of sensitive personal information) with one where such attempts have been less successful (the decentralized, own-your-data approach to social networking and e-commerce). </span></p><ul><li><em>Differential Privacy. (Lecture)</em><ul><li><em><span class=\"c2\">Cynthia Dwork. </span><span class=\"c8 c14 c6\"><a class=\"c5\" href=\"http://research.microsoft.com/pubs/64346/dwork.pdf\">Differential Privacy</a></span><span class=\"c6 c13\">.</span></em></li></ul></li></ul><p class=\"c0\">Differential privacy is another topic that is sorely lacking in expository material, especially from the point of view of students who’ve never done crypto before. So this was again a lecture.</p><ul><li><em><span class=\"c2\">Arvind Narayanan et al. </span><span class=\"c8 c14 c6\"><a class=\"c5\" href=\"http://randomwalker.info/publications/critical-look-at-decentralization-v1.pdf\">A Critical Look at Decentralized Personal Data Architectures</a></span></em></li></ul><ul><li><em><span class=\"c2\">John Perry Barlow </span><span class=\"c8 c14 c6\"><a class=\"c5\" href=\"https://projects.eff.org/~barlow/Declaration-Final.html\">A Declaration of the Independence of Cyberspace</a></span><span class=\"c2\"> (short essay, 1996)</span></em></li><li><em><span class=\"c2\">James Grimmelmann. </span><span class=\"c8 c6 c14\"><a class=\"c5\" href=\"http://illinoislawreview.org/wp-content/ilr-content/articles/2012/2/Grimmelmann.pdf\">Sealand, HavenCo, and the Rule of Law</a></span></em></li></ul><p class=\"c0\">These two essays aren’t directly related to privacy. One of the recurring threads in this course is the debate between purely technological and legal or other approaches to privacy; the theme here is to generalize it to a context broader than privacy. The Barlow essay asserts the exceptionalism of Cyberspace as an unregulable medium, whereas the Grimmelmann paper provides a much more nuanced view of the relationship between the law and new technological frontiers.</p><p class=\"c0\"><strong><span class=\"c10\">I’m making available the entire set of Wiki discussion prompts for the class</span></strong><b id=\"internal-source-marker_0.6116034584119916\">(<a href=\"http://randomwalker.info/teaching/fall-2012-privacy-technologies/discussion-prompts.html\">HTML</a>/<a href=\"http://randomwalker.info/teaching/fall-2012-privacy-technologies/discussion-prompts.pdf\">PDF</a>).</b> I consider this integral to the syllabus, for it shapes the discussion very significantly. I really hope other instructors and students find this useful as a teaching/study guide. For reference, each set of prompts (one set per class) took me about three hours to write on average.</p><p class=\"c0\">There are many more things I want to share about this class: the major take-home ideas, the rationale for the Wiki discussion format, the feedback I got from students, a description of a couple of student projects, some thoughts on the sociology of different communities studying privacy and how that impacted the class, and finally, links to similar courses that are being taught elsewhere. I’ll probably close this series with a round-up post including as many of the above topics as I can.</p><p class=\"c0\">To stay on top of future posts, <a href=\"http://33bits.org/feed/\">subscribe</a> to the RSS feed or follow me on <a href=\"https://twitter.com/random_walker\">Twitter</a> or <a href=\"https://plus.google.com/u/0/110908828231461227679\">Google+</a>.</p><br /><a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/gocomments/33bits.wordpress.com/1105/\"><img alt=\" \" border=\"0\" src=\"http://feeds.wordpress.com/1.0/comments/33bits.wordpress.com/1105/\" /></a><img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&#038;blog=5017838&#038;post=1105&#038;subd=33bits&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />") (wfw:commentRss nil "http://33bits.org/2013/04/16/privacy-technologies-an-annotated-syllabus/feed/") (slash:comments nil "2") (media:content ((url . "http://1.gravatar.com/avatar/aa438b63ff1e9b75693aeabbeddae5eb?s=96&d=identicon&r=G") (medium . "image")) (media:title ((type . "html")) "randomwalker")))) ("How I utilized “expectation failure” to refute privacy myths" "<p dir=\"ltr\">Last semester I taught a course on <a href=\"http://randomwalker.info/teaching/fall-2012-privacy-technologies/\">privacy technologies</a>. Since it was a seminar, the class was a small, self-selected group of very motivated students. Based on the feedback, it seems to have been a success; it was certainly quite personally gratifying for me. This is the first in a series of posts on what I learnt from teaching this course. In this post I will discuss some major misconceptions about privacy, how to refute them, and why it is important to do this right at the beginning of the course.</p><p><strong>Privacy’s primary pitfalls</strong></p><p>Instructors are often confronted with breaking down faulty mental models that students bring into class before actual learning can happen. This is especially true of the topic at hand. Luckily, misconceptions about privacy are so pervasive in the media and among the general public that it wasn’t too hard to identify the most common ones before the start of the course. And it didn’t take much class discussion to confirm that my students weren’t somehow exempt from these beliefs.</p><p>One cluster of myths is about the supposed lack of importance of privacy. 1. “There is no privacy in the digital age.” This is the most common and perhaps the most grotesquely fallacious of the misconceptions; more on this below. 2. “No one cares about privacy any more” (variant: young people don’t care about privacy.) 3. “If you haven’t done anything wrong you have <a href=\"https://chronicle.com/article/Why-Privacy-Matters-Even-if/127461/\">nothing to hide</a>.”</p><p>A second cluster of fallacious beliefs is very common among computer scientists and comes from the tendency to reduce everything to a black-and-white technical problem. In this view, privacy maps directly to access control and cryptography is the main technical mechanism for achieving privacy. It’s a view in which the world is full of <a href=\"http://33bits.org/2010/11/08/adversarial-thinking-considered-harmful-sometimes/\">adversaries</a> and there is no room for <a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1597745\">obscurity</a> or nontechnical ways of improving privacy.</p><p><strong>The first step in learning is to unlearn</strong></p><p dir=\"ltr\">Why is it important to spend time confronting faulty mental models? Why not simply teach the “right” ones? In my case, there was a particularly acute reason — to the extent that students believe that privacy is dead and that learning about privacy technologies is unimportant, they are not going to be invested in the class, which would be really bad. But even in the case of misconceptions that don’t lead to students doubting the fundamental premise of the class, there is a surprising reason why unlearning is important.</p><p dir=\"ltr\">A <a href=\"http://rmcfadden.wikispaces.com/file/view/bain_what_do_they_know_about_how_we_learn2.pdf\">famous experiment</a> in the ’80s (I really <em>really</em> recommend reading the linked text) demonstrated what we now know about the ineffectiveness of the “information transmission” model of teaching. The researchers interviewed students after any of four introductory physics courses, and determined that they hadn’t actually learned what had been taught, such as Newton’s laws of motion; instead they just learned to pass the tests. When the researchers sat down with students to find out why, here’s what they found:<b><b> </b></b></p><p dir=\"ltr\"><em>What they heard astonished them: many of the students still refused to give up their mistaken ideas about motion. Instead, they argued that the experiment they had just witnessed did not exactly apply to the law of motion in question; it was a special case, or it didn’t quite fit the mistaken theory or law that they held as true.</em></p><p>A special case! Ha. What’s going on here? Well, learning new facts is easy. On the other hand, updating mental models is so cognitively expensive that we go to absurd lengths to avoid doing so. The societal-scale analog of this extreme reluctance is well-illustrated by the history of science — we patched the Ptolemaic model of the Universe, with the Earth at the center, for over a millennium before we were forced to accept that the Copernican system fit observations better.</p><p><strong>The instructor’s arsenal </strong></p><p dir=\"ltr\">The good news is that the instructor can utilize many effective strategies that fall under the umbrella of <a href=\"https://en.wikipedia.org/wiki/Active_learning\">active learning</a>. Ken Bain’s excellent <a href=\"http://www.amazon.com/What-Best-College-Teachers-Do/dp/0674013255/\">book</a> (which the preceding text describing the experiment is from) lays out a pattern in which the instructor creates an <a href=\"http://www.julianhermida.com/workshop2expect.htm\">expectation failure</a>, a situation in which existing mental models of reality will lead to faulty expectations. One of the prerequisites for this to work, according to the book, is to get students to care.</p><p dir=\"ltr\">Bain argues that expectation failure, done right, can be so powerful that students might need <em>emotional support</em> to cope. Fortunately, this wasn’t necessary in my class, but I have no doubt of it based on my personal experiences. For instance, back when I was in high school, learning how the Internet actually worked and realizing that my intuitions about the network had to be discarded entirely was such a disturbing experience that I remember my feelings to this day.<b><b> </b></b></p><p dir=\"ltr\">Let’s look at an example of expectation failure in my privacy class. To refute the “privacy is dying” myth, I found it useful to talk about Fifty Shades of Grey — specifically, why it succeeded even though publishers initially passed on it. One answer <a href=\"http://observer.com/2013/01/doubleday-to-publish-hardcover-fifty-shades-of-grey-trilogy/\">seems to be</a> that since it was first self-published as an e-book, it allowed readers to be discreet and avoid the stigma associated with the genre. (But following its runaway success in that form, the stigma disappeared, and it was released in paper form and flew off the shelves.)</p><p dir=\"ltr\">The relative privacy of e-books from prying strangers is one of the many ways in which digital technology affords <a href=\"http://33bits.org/2011/06/08/the-many-ways-in-which-the-internet-has-given-us-more-privacy/\">more privacy</a> for specific activities. Confronting students with an observed phenomenon whose explanation involves a fact that seems starkly contrary to the popular narrative creates an expectation failure. Telling personal stories about how technology has either improved or eroded privacy, and eliciting such stories from students, gets them to care. Once this has been accomplished, it’s productive to get into a nuanced discussion of how to reconcile the two views with each other, different meanings of privacy (e.g., <a href=\"http://www.guardian.co.uk/books/2012/aug/31/readers-privacy-under-threat\">tracking of reading habits</a>), how the Internet has affected each, and how society is adjusting to the changing technological landscape.</p><p dir=\"ltr\">I’m quite new to teaching — this is only my second semester at Princeton — but it’s been exciting to internalize the fact that learning is something that can be studied scientifically and teaching is an activity that can vary dramatically in effectiveness. I’m looking forward to getting better at it and experimenting with different methods. In the next post I will share some thoughts on the content of my course and what I tried to get students to take home from it.</p><p dir=\"ltr\"><em>Thanks to Josh Hug for reviewing a draft</em>.</p><p dir=\"ltr\">To stay on top of future posts, <a href=\"http://33bits.org/feed/\">subscribe</a> to the RSS feed or follow me on <a href=\"https://twitter.com/random_walker\">Twitter</a> or <a href=\"https://plus.google.com/u/0/110908828231461227679\">Google+</a>.</p><br /><a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/gocomments/33bits.wordpress.com/1101/\"><img alt=\" \" border=\"0\" src=\"http://feeds.wordpress.com/1.0/comments/33bits.wordpress.com/1101/\" /></a><img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&blog=5017838&post=1101&subd=33bits&ref=&feed=1\" width=\"1\" height=\"1\" />" "http://33bits.org/2013/04/11/how-i-utilized-expectation-failure-to-refute-privacy-myths/" (20838 45450) new 9 nil nil ((title nil "How I utilized “expectation failure” to refute privacy myths") (link nil "http://33bits.org/2013/04/11/how-i-utilized-expectation-failure-to-refute-privacy-myths/") (comments nil "http://33bits.org/2013/04/11/how-i-utilized-expectation-failure-to-refute-privacy-myths/#comments") (pubDate nil "Thu, 11 Apr 2013 12:50:18 +0000") (dc:creator nil "Arvind Narayanan") (category nil "Uncategorized") (category nil "princeton") (category nil "privacy") (category nil "teaching") (guid ((isPermaLink . "false")) "http://33bits.org/?p=1101") (description nil "Last semester I taught a course on privacy technologies. Since it was a seminar, the class was a small, self-selected group of very motivated students. Based on the feedback, it seems to have been a success; it was certainly quite personally gratifying for me. This is the first in a series of posts on what [&#8230;]<img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&#038;blog=5017838&#038;post=1101&#038;subd=33bits&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />") (content:encoded nil "<p dir=\"ltr\">Last semester I taught a course on <a href=\"http://randomwalker.info/teaching/fall-2012-privacy-technologies/\">privacy technologies</a>. Since it was a seminar, the class was a small, self-selected group of very motivated students. Based on the feedback, it seems to have been a success; it was certainly quite personally gratifying for me. This is the first in a series of posts on what I learnt from teaching this course. In this post I will discuss some major misconceptions about privacy, how to refute them, and why it is important to do this right at the beginning of the course.</p><p><strong>Privacy’s primary pitfalls</strong></p><p>Instructors are often confronted with breaking down faulty mental models that students bring into class before actual learning can happen. This is especially true of the topic at hand. Luckily, misconceptions about privacy are so pervasive in the media and among the general public that it wasn&#8217;t too hard to identify the most common ones before the start of the course. And it didn&#8217;t take much class discussion to confirm that my students weren&#8217;t somehow exempt from these beliefs.</p><p>One cluster of myths is about the supposed lack of importance of privacy. 1. “There is no privacy in the digital age.” This is the most common and perhaps the most grotesquely fallacious of the misconceptions; more on this below. 2. “No one cares about privacy any more” (variant: young people don’t care about privacy.) 3. “If you haven’t done anything wrong you have <a href=\"https://chronicle.com/article/Why-Privacy-Matters-Even-if/127461/\">nothing to hide</a>.”</p><p>A second cluster of fallacious beliefs is very common among computer scientists and comes from the tendency to reduce everything to a black-and-white technical problem. In this view, privacy maps directly to access control and cryptography is the main technical mechanism for achieving privacy. It’s a view in which the world is full of <a href=\"http://33bits.org/2010/11/08/adversarial-thinking-considered-harmful-sometimes/\">adversaries</a> and there is no room for <a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1597745\">obscurity</a> or nontechnical ways of improving privacy.</p><p><strong>The first step in learning is to unlearn</strong></p><p dir=\"ltr\">Why is it important to spend time confronting faulty mental models? Why not simply teach the “right” ones? In my case, there was a particularly acute reason — to the extent that students believe that privacy is dead and that learning about privacy technologies is unimportant, they are not going to be invested in the class, which would be really bad. But even in the case of misconceptions that don’t lead to students doubting the fundamental premise of the class, there is a surprising reason why unlearning is important.</p><p dir=\"ltr\">A <a href=\"http://rmcfadden.wikispaces.com/file/view/bain_what_do_they_know_about_how_we_learn2.pdf\">famous experiment</a> in the &#8217;80s (I really <em>really</em> recommend reading the linked text) demonstrated what we now know about the ineffectiveness of the “information transmission” model of teaching. The researchers interviewed students after any of four introductory physics courses, and determined that they hadn&#8217;t actually learned what had been taught, such as Newton’s laws of motion; instead they just learned to pass the tests. When the researchers sat down with students to find out why, here’s what they found:<b><b> </b></b></p><p dir=\"ltr\"><em>What they heard astonished them: many of the students still refused to give up their mistaken ideas about motion. Instead, they argued that the experiment they had just witnessed did not exactly apply to the law of motion in question; it was a special case, or it didn&#8217;t quite fit the mistaken theory or law that they held as true.</em></p><p>A special case! Ha. What’s going on here? Well, learning new facts is easy. On the other hand, updating mental models is so cognitively expensive that we go to absurd lengths to avoid doing so. The societal-scale analog of this extreme reluctance is well-illustrated by the history of science — we patched the Ptolemaic model of the Universe, with the Earth at the center, for over a millennium before we were forced to accept that the Copernican system fit observations better.</p><p><strong>The instructor’s arsenal </strong></p><p dir=\"ltr\">The good news is that the instructor can utilize many effective strategies that fall under the umbrella of <a href=\"https://en.wikipedia.org/wiki/Active_learning\">active learning</a>. Ken Bain’s excellent <a href=\"http://www.amazon.com/What-Best-College-Teachers-Do/dp/0674013255/\">book</a> (which the preceding text describing the experiment is from) lays out a pattern in which the instructor creates an <a href=\"http://www.julianhermida.com/workshop2expect.htm\">expectation failure</a>, a situation in which existing mental models of reality will lead to faulty expectations. One of the prerequisites for this to work, according to the book, is to get students to care.</p><p dir=\"ltr\">Bain argues that expectation failure, done right, can be so powerful that students might need <em>emotional support</em> to cope. Fortunately, this wasn&#8217;t necessary in my class, but I have no doubt of it based on my personal experiences. For instance, back when I was in high school, learning how the Internet actually worked and realizing that my intuitions about the network had to be discarded entirely was such a disturbing experience that I remember my feelings to this day.<b><b> </b></b></p><p dir=\"ltr\">Let’s look at an example of expectation failure in my privacy class. To refute the “privacy is dying” myth, I found it useful to talk about Fifty Shades of Grey — specifically, why it succeeded even though publishers initially passed on it. One answer <a href=\"http://observer.com/2013/01/doubleday-to-publish-hardcover-fifty-shades-of-grey-trilogy/\">seems to be</a> that since it was first self-published as an e-book, it allowed readers to be discreet and avoid the stigma associated with the genre. (But following its runaway success in that form, the stigma disappeared, and it was released in paper form and flew off the shelves.)</p><p dir=\"ltr\">The relative privacy of e-books from prying strangers is one of the many ways in which digital technology affords <a href=\"http://33bits.org/2011/06/08/the-many-ways-in-which-the-internet-has-given-us-more-privacy/\">more privacy</a> for specific activities. Confronting students with an observed phenomenon whose explanation involves a fact that seems starkly contrary to the popular narrative creates an expectation failure. Telling personal stories about how technology has either improved or eroded privacy, and eliciting such stories from students, gets them to care. Once this has been accomplished, it’s productive to get into a nuanced discussion of how to reconcile the two views with each other, different meanings of privacy (e.g., <a href=\"http://www.guardian.co.uk/books/2012/aug/31/readers-privacy-under-threat\">tracking of reading habits</a>), how the Internet has affected each, and how society is adjusting to the changing technological landscape.</p><p dir=\"ltr\">I’m quite new to teaching — this is only my second semester at Princeton — but it’s been exciting to internalize the fact that learning is something that can be studied scientifically and teaching is an activity that can vary dramatically in effectiveness. I’m looking forward to getting better at it and experimenting with different methods. In the next post I will share some thoughts on the content of my course and what I tried to get students to take home from it.</p><p dir=\"ltr\"><em>Thanks to Josh Hug for reviewing a draft</em>.</p><p dir=\"ltr\">To stay on top of future posts, <a href=\"http://33bits.org/feed/\">subscribe</a> to the RSS feed or follow me on <a href=\"https://twitter.com/random_walker\">Twitter</a> or <a href=\"https://plus.google.com/u/0/110908828231461227679\">Google+</a>.</p><br /><a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/gocomments/33bits.wordpress.com/1101/\"><img alt=\" \" border=\"0\" src=\"http://feeds.wordpress.com/1.0/comments/33bits.wordpress.com/1101/\" /></a><img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&#038;blog=5017838&#038;post=1101&#038;subd=33bits&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />") (wfw:commentRss nil "http://33bits.org/2013/04/11/how-i-utilized-expectation-failure-to-refute-privacy-myths/feed/") (slash:comments nil "0") (media:content ((url . "http://1.gravatar.com/avatar/aa438b63ff1e9b75693aeabbeddae5eb?s=96&d=identicon&r=G") (medium . "image")) (media:title ((type . "html")) "randomwalker")))) ("Unlikely Outcomes? A Distributed Discussion on Decentralized Personal Data Architectures" "<p dir=\"ltr\">In recent years there has been a mushrooming of decentralized social networks, personal data stores and other such alternatives to the current paradigm of centralized services. In the academic paper <a href=\"http://randomwalker.info/publications/critical-look-at-decentralization-v1.pdf\">A Critical Look at Decentralized Personal Data Architectures</a> last year, my coauthors and I challenged the feasibility and desirability of these alternatives (I also gave a <a href=\"https://www.youtube.com/watch?v=8gvjwgGJuHA\">talk</a> about this work). Based on the feedback, we realized it would be useful to explicate some of our assumptions and implicit viewpoints, add context to our work, clarify some points that were unclear, and engage with our critics on some of the more contentious claims.</p><p dir=\"ltr\">We found the perfect opportunity to do this via an invitation from <a href=\"http://networkcultures.org/wpmu/portal/publication/unlike-us-reader-social-media-monopolies-and-their-alternatives/\">Unlike Us Reader</a>, produced by the <a href=\"http://networkcultures.org/\">Institute of Network Cultures</a> — it’s a magazine run by a humanities-oriented group of people, with a long-standing interest in digital culture, but they also attract some politically oriented developers. The <a href=\"http://networkcultures.org/wpmu/unlikeus/\">Unlike Us conference</a>, from which this edited volume stems, is also very interesting. [1]</p><p dir=\"ltr\">Three of the five original authors — Solon, Vincent and I — teamed up with the inimitable <a href=\"http://homes.esat.kuleuven.be/~sguerses/\">Seda Gürses</a> for an <strong><a href=\"http://randomwalker.info/publications/unlike-us.pdf\">interview-style conversation (PDF)</a></strong>. Seda is unique among privacy researchers — one of her interests is to understand and reconcile the often maddeningly divergent viewpoints of the different communities that study privacy, so she was the ideal person to play the role of interlocutor. Seda solicited feedback from about two dozen people in the hobbyist, activist and academic communities, and synthesized the responses into major themes. Then the three of us took turns responding to the prompts, which Solon, with Seda’s help, organized into a coherent whole. A majority of the commenters consented to making their feedback public, and Seda has collected the discussion into an <a href=\"http://networkcultures.org/wpmu/unlikeus/resources/articles/appendix/\">online appendix</a>.</p><p dir=\"ltr\">This was an unusual opportunity, and I’m grateful to everyone who made it happen, particularly Seda and Solon who put in an immense amount of work. My participation was very enjoyable. Research proceeds at such a pace that we rarely have the opportunity to look back and cogitate about the process; when we do, we’re often surprised by what we find. For example, here’s something I noted with amusement in one of my responses:</p><blockquote><p dir=\"ltr\">My interest in decentralized social networking apparently dates to 2009, as I just discovered by digging through my archives. I’d signed up to give a talk on pitfalls of social networking privacy at a <a href=\"https://crypto.stanford.edu/socialnetsec/\">Stanford workshop</a>, and while preparing for it I discovered the rich academic literature and the various hobbyist efforts in the decentralized model. My slides from that talk seem to anticipate several of the points we made about decentralized social networking in the paper (albeit in bullet-point form), along with the conclusion that they were “unlikely to disrupt walled gardens.” Funnily enough, I’d completely forgotten about having given this talk when we were writing the paper.</p></blockquote><p dir=\"ltr\">I would recommend reading this text as a companion to our original paper. Read it for extra context and clarifications, a discussion of controversial points, and as a way of stimulating thinking about the future prospects of alternative architectures. It may also be an interesting read as an example of how people writing an article together can have different views, and as a bit of a behind-the-scenes look at the research process.</p><p>[1] In particular, the <a href=\"http://networkcultures.org/wpmu/unlikeus/3-amsterdam/program/\">latest edition</a> of the conference that just concluded had a panel titled “Are you distributed? The Federated Web Show” moderated by Seda, with Vincent as one of the participants. It touched upon many of the same themes as our work.</p><p>To stay on top of future posts, <a href=\"http://33bits.org/feed/\">subscribe</a> to the RSS feed or follow me on <a href=\"https://twitter.com/random_walker\">Twitter</a> or <a href=\"https://plus.google.com/u/0/110908828231461227679\">Google+</a>.</p><br /><a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/gocomments/33bits.wordpress.com/1098/\"><img alt=\" \" border=\"0\" src=\"http://feeds.wordpress.com/1.0/comments/33bits.wordpress.com/1098/\" /></a><img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&blog=5017838&post=1098&subd=33bits&ref=&feed=1\" width=\"1\" height=\"1\" />" "http://33bits.org/2013/03/27/unlikely-outcomes-a-distributed-discussion-on-decentralized-personal-data-architectures/" (20819 5091) new 10 nil nil ((title nil "Unlikely Outcomes? A Distributed Discussion on Decentralized Personal Data Architectures") (link nil "http://33bits.org/2013/03/27/unlikely-outcomes-a-distributed-discussion-on-decentralized-personal-data-architectures/") (comments nil "http://33bits.org/2013/03/27/unlikely-outcomes-a-distributed-discussion-on-decentralized-personal-data-architectures/#comments") (pubDate nil "Wed, 27 Mar 2013 15:44:35 +0000") (dc:creator nil "Arvind Narayanan") (category nil "Uncategorized") (category nil "conference") (category nil "distributed social networks") (category nil "economics") (category nil "personal data stores") (category nil "policy") (category nil "privacy") (category nil "web") (guid ((isPermaLink . "false")) "http://33bits.org/?p=1098") (description nil "In recent years there has been a mushrooming of decentralized social networks, personal data stores and other such alternatives to the current paradigm of centralized services. In the academic paper A Critical Look at Decentralized Personal Data Architectures last year, my coauthors and I challenged the feasibility and desirability of these alternatives (I also gave [&#8230;]<img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&#038;blog=5017838&#038;post=1098&#038;subd=33bits&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />") (content:encoded nil "<p dir=\"ltr\">In recent years there has been a mushrooming of decentralized social networks, personal data stores and other such alternatives to the current paradigm of centralized services. In the academic paper <a href=\"http://randomwalker.info/publications/critical-look-at-decentralization-v1.pdf\">A Critical Look at Decentralized Personal Data Architectures</a> last year, my coauthors and I challenged the feasibility and desirability of these alternatives (I also gave a <a href=\"https://www.youtube.com/watch?v=8gvjwgGJuHA\">talk</a> about this work). Based on the feedback, we realized it would be useful to explicate some of our assumptions and implicit viewpoints, add context to our work, clarify some points that were unclear, and engage with our critics on some of the more contentious claims.</p><p dir=\"ltr\">We found the perfect opportunity to do this via an invitation from <a href=\"http://networkcultures.org/wpmu/portal/publication/unlike-us-reader-social-media-monopolies-and-their-alternatives/\">Unlike Us Reader</a>, produced by the <a href=\"http://networkcultures.org/\">Institute of Network Cultures</a> — it’s a magazine run by a humanities-oriented group of people, with a long-standing interest in digital culture, but they also attract some politically oriented developers. The <a href=\"http://networkcultures.org/wpmu/unlikeus/\">Unlike Us conference</a>, from which this edited volume stems, is also very interesting. [1]</p><p dir=\"ltr\">Three of the five original authors — Solon, Vincent and I — teamed up with the inimitable <a href=\"http://homes.esat.kuleuven.be/~sguerses/\">Seda Gürses</a> for an <strong><a href=\"http://randomwalker.info/publications/unlike-us.pdf\">interview-style conversation (PDF)</a></strong>. Seda is unique among privacy researchers — one of her interests is to understand and reconcile the often maddeningly divergent viewpoints of the different communities that study privacy, so she was the ideal person to play the role of interlocutor. Seda solicited feedback from about two dozen people in the hobbyist, activist and academic communities, and synthesized the responses into major themes. Then the three of us took turns responding to the prompts, which Solon, with Seda’s help, organized into a coherent whole. A majority of the commenters consented to making their feedback public, and Seda has collected the discussion into an <a href=\"http://networkcultures.org/wpmu/unlikeus/resources/articles/appendix/\">online appendix</a>.</p><p dir=\"ltr\">This was an unusual opportunity, and I’m grateful to everyone who made it happen, particularly Seda and Solon who put in an immense amount of work. My participation was very enjoyable. Research proceeds at such a pace that we rarely have the opportunity to look back and cogitate about the process; when we do, we’re often surprised by what we find. For example, here’s something I noted with amusement in one of my responses:</p><blockquote><p dir=\"ltr\">My interest in decentralized social networking apparently dates to 2009, as I just discovered by digging through my archives. I’d signed up to give a talk on pitfalls of social networking privacy at a <a href=\"https://crypto.stanford.edu/socialnetsec/\">Stanford workshop</a>, and while preparing for it I discovered the rich academic literature and the various hobbyist efforts in the decentralized model. My slides from that talk seem to anticipate several of the points we made about decentralized social networking in the paper (albeit in bullet-point form), along with the conclusion that they were “unlikely to disrupt walled gardens.” Funnily enough, I’d completely forgotten about having given this talk when we were writing the paper.</p></blockquote><p dir=\"ltr\">I would recommend reading this text as a companion to our original paper. Read it for extra context and clarifications, a discussion of controversial points, and as a way of stimulating thinking about the future prospects of alternative architectures. It may also be an interesting read as an example of how people writing an article together can have different views, and as a bit of a behind-the-scenes look at the research process.</p><p>[1] In particular, the <a href=\"http://networkcultures.org/wpmu/unlikeus/3-amsterdam/program/\">latest edition</a> of the conference that just concluded had a panel titled “Are you distributed? The Federated Web Show” moderated by Seda, with Vincent as one of the participants. It touched upon many of the same themes as our work.</p><p>To stay on top of future posts, <a href=\"http://33bits.org/feed/\">subscribe</a> to the RSS feed or follow me on <a href=\"https://twitter.com/random_walker\">Twitter</a> or <a href=\"https://plus.google.com/u/0/110908828231461227679\">Google+</a>.</p><br /><a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/gocomments/33bits.wordpress.com/1098/\"><img alt=\" \" border=\"0\" src=\"http://feeds.wordpress.com/1.0/comments/33bits.wordpress.com/1098/\" /></a><img alt=\" \" border=\"0\" src=\"http://stats.wordpress.com/b.gif?host=33bits.org&#038;blog=5017838&#038;post=1098&#038;subd=33bits&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />") (wfw:commentRss nil "http://33bits.org/2013/03/27/unlikely-outcomes-a-distributed-discussion-on-decentralized-personal-data-architectures/feed/") (slash:comments nil "1") (media:content ((url . "http://1.gravatar.com/avatar/aa438b63ff1e9b75693aeabbeddae5eb?s=96&d=identicon&r=G") (medium . "image")) (media:title ((type . "html")) "randomwalker")))))