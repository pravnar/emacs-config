;; -*- coding: utf-8 -*-
(("All Things Distributed" nil nil (21326 44205 117821 920000) feed 0 nil nil ((title nil "All Things Distributed") (link ((href . "http://www.allthingsdistributed.com/atom.xml") (rel . "self"))) (link ((href . "http://www.allthingsdistributed.com/"))) (updated nil "2014-03-04T21:26:38-08:00") (id nil "http://www.allthingsdistributed.com/") (author nil (name nil "Werner Vogels") (email nil "werner@allthingsdistributed.com")) (entry nil (title nil "Customer Centricity at Amazon Web Services") (link ((href . "http://www.allthingsdistributed.com/2014/02/customer-centricity-at-aws.html"))) (updated nil "2014-02-04T07:00:00Z") (id nil "http://www.allthingsdistributed.com/2014/02/customer-centricity-at-aws") (content ((type . "html")) "<p>In the <a href=\"http://phx.corporate-ir.net/External.File?item=UGFyZW50SUQ9MTc5ODc4fENoaWxkSUQ9LTF8VHlwZT0z&amp;t=1\">2013 Amazon Shareholder letter</a>, Jeff Bezos spent time explaining the decision to pursue a customer-centric way in our business.</p>

<blockquote><p><em>As regular readers of this letter will know, our energy at Amazon comes from the desire to impress customers rather than the zeal to best competitors. We don’t take a view on which of these approaches is more likely to maximize business success. There are pros and cons to both and many examples of highly successful competitor-focused companies. We do work to pay attention to competitors and be inspired by them, but it is a fact that the customer-centric way is at this point a defining element of our culture.</em></p></blockquote>

<p>AWS has built a reputation over the years for the breadth and depth of our services and the pace of our innovation with 280 features released in 2013.  One area we don’t spend a lot of time discussing is the significant investments we’ve made in building a World Class Customer Service and Technical Support function.  These are the people working behind the scenes helping customers fully leverage all of AWS’s capabilities when running their infrastructure on AWS.  We launched <a href=\"http://aws.amazon.com/premiumsupport/\">AWS Support</a> in 2009 and since the launch the mission has remained constant: to help customers of all sizes and technical abilities to successfully utilize the products and features provided by AWS.</p>

<p>Customers are frequently surprised to hear we have a Support organization that not only helps customers via email, phone, chat or web cases, but also builds innovative software to deliver better customer experiences. In recent years, this team has released technology such as Support for Health Checks, AWS Trusted Advisor, Support API’s, Trusted Advisor API’s, and many more.  One customer facing feature Jeff highlighted in the Shareholder letter was <a href=\"https://aws.amazon.com/premiumsupport/trustedadvisor/\">AWS Trusted Advisor</a> which is a tool that our support organization built to move support from reactive help to proactive, preventative help.</p>

<blockquote><p><em>I can keep going – Kindle Fire’s FreeTime, our customer service Andon Cord, Amazon MP3’s AutoRip – but will finish up with a very clear example of internally driven motivation: Amazon Web Services. In 2012,AWS announced 159 new features and services. We’ve reduced AWS prices 27 times since launching 7 years ago, added enterprise service support enhancements, and created innovative tools to help customers be more efficient. AWS Trusted Advisor monitors customer configurations, compares them to known best practices, and then notifies customers where opportunities exist to improve performance, enhance security, or save money. Yes, we are actively telling customers they’re paying us more than they need to. In the last 90 days, customers have saved millions of dollars through Trusted Advisor, and the service is only getting started. All of this progress comes in the context of AWS being the widely recognized leader in its area – a situation where you might worry that external motivation could fail. On the other hand, internal motivation – the drive to get the customer to say “Wow” – keeps the pace of innovation fast.</em></p></blockquote>

<p>We’ve always focused on getting highly skilled support engineers with all hires requiring the same technical certification process (Tech Bar Raisers) as any of our developers building services.  Over the years, we have scaled the AWS Support organization to meet customer need from a team with heavy Linux Sys Admin with strong Networking skills in one location to a large global team, located in 17 locations around the world with Windows Sys Admins, Networking Engineers, DBAs, Security Specialists, Developers, and many more specializations.  In 2013, we spent a lot of time developing sophisticated internal tools that make supporting our customers more efficient including intelligent skills based case routing tools that provide in-depth technical information to engineers that help address customer needs.  Our customers tell us that the service is 78% better than it was 3 years ago.</p>

<p>Our customers can feel confident that AWS will work every day to deliver World Class Support for our customers.  I wanted to share a new video with you where our customers discuss this critical behind the scenes function in a little more detail. After watching, I believe that you will have a better perspective on our mission, our support options, and the benefits that our customers derive from their use of AWS Support:</p>

<iframe width=\"640\" height=\"360\" src=\"//www.youtube.com/embed/Ar3Q-cJehyg\" frameborder=\"0\" allowfullscreen></iframe>

")) (entry nil (title nil "Updated Lampson's Hints for Computer Systems Design") (link ((href . "http://www.allthingsdistributed.com/2013/12/updated-hints.html"))) (updated nil "2013-12-23T20:00:00Z") (id nil "http://www.allthingsdistributed.com/2013/12/updated-hints") (content ((type . "html")) "<p>This year I have not been able to publish many back-to-basics readings, so I will not close the year with a recap of those. Instead I have a video of a wonderful presentation by <a href=\"http://research.microsoft.com/en-us/um/people/blampson/\">Butler Lampson</a> where he talks about the learnings of the past decades that helped him to update his excellent 1983 \"<a href=\"http://research.microsoft.com/en-us/um/people/blampson/33-hints/WebPage.html\">Hints for computer system design</a>\".</p>

<p>The presentation was part of the <a href=\"http://www.heidelberg-laureate-forum.org/\">Heidelberg Laureate Forum</a> helt in September of this year. At the Forum many of the Abel, Fields and Turing Laureates held presentations. Our most famous computer scientists like Fernando Carbato, Stephen Cook,  Edward Feigenbaum, Juris Hartmanis, John Hopcroft, Alan Kay, Vinton Cerf, etc. were all at the Forum. You can find a list of selected video presentation <a href=\"http://www.heidelberg-laureate-forum.org/event_2013/\">here</a></p>

<p>For me the highight was Butler's <a href=\"http://www.heidelberg-laureate-forum.org/blog/video/lecture-friday-september-27-butler-w-lampson/\">presentation</a> on Hints and Principles for Computer Science Design. I include it here as it is absolutely worth watching.</p>

<iframe width=\"650\" height=\"487\" frameborder=\"0\" scrolling=\"auto\" marginheight=\"0\" marginwidth=\"0\" src=\"http://hits.mediasite.com/mediasite/Play/0bc53975278d41209e3aa847e867b54c1d\"></iframe>

")) (entry nil (title nil "Taking DynamoDB beyond Key-Value: Now with Faster, More Flexible, More Powerful Query Capabilities") (link ((href . "http://www.allthingsdistributed.com/2013/12/dynamodb-global-secondary-indexes.html"))) (updated nil "2013-12-12T08:00:00Z") (id nil "http://www.allthingsdistributed.com/2013/12/dynamodb-global-secondary-indexes") (content ((type . "html")) "<p>We launched <a href=\"http://aws.amazon.com/dynamodb\">DynamoDB</a> last year to address the need for a cloud database that provides seamless scalability, irrespective of whether you are doing ten transactions or ten million transactions, while providing rock solid durability and availability. Our vision from the day we conceived DynamoDB was to fulfil this need without limiting the query functionality that people have come to expect from a database. However, we also knew that building a distributed database that has unlimited scale and maintains predictably high performance while providing rich and flexible query capabilities, is one of the hardest problems in database development, and will take a lot of effort and invention from our team of distributed database engineers to solve. So when we launched in January 2012, we provided simple query functionality that used hash primary keys or composite primary keys (hash + range). Since then, we have been working on adding flexible querying. You saw the first iteration in April 2013 with the launch of <a href=\"http://aws.typepad.com/aws/2013/04/local-secondary-indexes-for-amazon-dynamodb.html\">Local Secondary Indexes</a> (LSI). Today, I am thrilled to announce a fundamental expansion of the query capabilities of DynamoDB with the launch of <em>Global Secondary Indexes</em> (GSI). This new capability allows indexing any attribute (column) of a DynamoDB table and performing high-performance queries at any table scale.</p>

<p><strong>Going beyond Key-Value</strong></p>

<p>Advanced Key-value data stores such as DynamoDB achieve high scalability on loosely coupled clusters by using the primary key as the partitioning key to distribute data across nodes. Even though the resulting query functionality may appear more limiting than a relational database on a cursory examination, it works exceedingly well for a wide range of applications as evident from DynamoDB's rapid growth and adoption by customers like Electronic Arts, Scopley, HasOffers, SmugMug, AdRoll, Dropcam, Digg and by many teams at Amazon.com (Cloud Drive, Retail). DynamoDB continues to be embraced for workloads in Gaming, Ad-tech, Mobile, Web Apps, and other segments where scale and performance are critical. At Amazon.com, we increasingly default to DynamoDB instead of using relational databases when we don’t need complex query, table join and transaction capabilities, as it offers a more available, more scalable and ultimately a lower cost solution.</p>

<p>For non-primary key access in advanced key-value stores, a user has to resort to either maintaining a separate table or some form of scatter-gather query across partitions. Both these options are less than ideal. For instance, maintaining a separate table for indexes forces users to maintain consistency between the primary key table and the index tables. On the other hand, with a scatter gather query, as the dataset grows, the query must be scattered more and more resulting in poor performance over time. DynamoDB's new Global Secondary Indexes remove this fundamental restriction by allowing \"scaled out\" indexes without ever requiring any book-keeping on behalf of the developer. Now you can run queries on any item attributes (columns) in your DynamoDB table. Moreover, a GSI's performance is designed to meet DynamoDB's single digit millisecond latency - you can add items to a Users table for a gaming app with tens of millions of users with UserId as the primary key, but retrieve them based on their home city, with no reduction in query performance.</p>

<p><strong>DynamoDB Refresher</strong></p>

<p>DynamoDB stores information as database tables, which are collections of individual items. Each item is a collection of data attributes. The items are analogous to rows in a spreadsheet, and the attributes are analogous to columns. Each item is uniquely identified by a primary key, which is composed of its first two attributes, called the hash and range. DynamoDB queries refer to the hash and range attributes of items you’d like to access. These query capabilities so far have been based on the default primary index and optional local secondary indexes of a DynamoDB table:</p>

<ul>
<li><em>Primary Index</em>: Customers can choose from two types of keys for primary index querying: Simple Hash Keys and Composite Hash Key / Range Keys. Simple Hash Key gives DynamoDB the Distributed Hash Table abstraction. The key is hashed over the different partitions to optimize workload distribution. For more background on this please read <a href=\"http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf\">the original Dynamo paper</a>. Composite Hash Key with Range Key allows the developer to create a primary key that is the composite of two attributes, a “hash attribute” and a “range attribute.” When querying against a composite key, the hash attribute needs to be uniquely matched but a range operation can be specified for the range attribute: e.g. all orders from Werner in the past 24 hours, or all games played by an individual player in the past 24 hours.</li>
<li><em>Local Secondary Index</em>: Local Secondary Indexes allow the developer to create indexes on non-primary key attributes and quickly retrieve records within a hash partition (i.e., items that share the same hash value in their primary key): e.g. if there is a DynamoDB table with PlayerName as the hash key and GameStartTime as the range key, you can use local secondary indexes to run efficient queries on other attributes like “Score.” Query “Show me John’s all-time top 5 scores” will return results automatically ordered by score.</li>
</ul>


<p><strong>What are Global Secondary Indexes?</strong></p>

<p>Global secondary indexes allow you to efficiently query over the whole DynamoDB table, not just within a partition as local secondary indexes, using any attributes (columns), even as the DynamoDB table horizontally scales to accommodate your needs. Let’s walk through another gaming example. Consider a table named GameScores that keeps track of users and scores for a mobile gaming application. Each item in GameScores is identified by a hash key (UserId) and a range key (GameTitle). The following diagram shows how the items in the table would be organized. (Not all of the attributes are shown)</p>

<p><img src=\"/images/gsi1.png\"/ width=\"650\"></p>

<p>Now suppose that you wanted to write a leaderboard application to display top scores for each game. A query that specified the key attributes (UserId and GameTitle) would be very efficient; however, if the application needed to retrieve data from GameScores based on GameTitle only, it would need to use a Scan operation. As more items are added to the table, scans of all the data would become slow and inefficient, making it difficult to answer questions such as</p>

<ul>
<li>What is the top score ever recorded for the game \"Meteor Blasters\"?</li>
<li>Which user had the highest score for \"Galaxy Invaders\"?</li>
<li>What was the highest ratio of wins vs. losses?</li>
</ul>


<p>To speed up queries on non-key attributes, you can specify global secondary indexes. For example, you could create a global secondary index named GameTitleIndex, with a hash key of GameTitle and a range key of TopScore. Since the table's primary key attributes are always projected into an index, the UserId attribute is also present. The following diagram shows what GameTitleIndex index would look like:</p>

<p><img src=\"/images/gsi2.png\"/></p>

<p>Now you can query GameTitleIndex and easily obtain the scores for \"Meteor Blasters\". The results are ordered by the range key, TopScore.</p>

<p><strong>Efficient Queries</strong></p>

<p>Traditionally, databases have been scaled as a whole –tables and indexes together. While this may appear simple, it masked the underlying complexity of varying needs for different types of queries and consequently different indexes, which resulted in wasted resources. With global secondary indexes in DynamoDB, you can now have many indexes and tune their capacity independently. These indexes also provide query/cost flexibility, allowing a custom level of clustering to be defined per index.  Developers can specify which attributes should be “projected” to the secondary index, allowing faster access to often-accessed data, while avoiding extra read/write costs for other attributes.</p>

<p><strong>Start with DynamoDB</strong></p>

<p>The enhanced query flexibility that global and local secondary indexes provide means DynamoDB can support an even broader range of workloads. When designing a new application that will operate in the AWS cloud, first take a look at DynamoDB when selecting a database. If you don’t need the table join capabilities of relational databases, you will be better served from a cost, availability and performance standpoint by using DynamoDB. If you need support for transactions, use the recently released <a href=\"http://aws.typepad.com/aws/2013/07/dynamodb-transaction-library.html\">transaction library</a>. You can also use GSI features with <a href=\"http://aws.typepad.com/aws/2013/09/dynamodb-local-for-desktop-development.html\">DynamoDB Local</a> for offline development of your application. As your application becomes popular and goes from being used by thousands of users to millions or even tens of millions of users, you will not have to worry about the typical performance or availability bottlenecks applications face from relational databases that require application re-architecture. You can simply dial up the provisioned throughput that your app needs from DynamoDB and we will take care of the rest without any impact on the performance of your app.</p>

<p><a href=\"http://www.dropcam.com\">Dropcam</a> tells us that they adopted DynamoDB for seamless scalability and performance as they continue to innovate on their cloud based monitoring platform which has grown to become one of the largest video platforms on the internet today. With GSIs, they do not have to choose between scalability and query flexibility and instead can get both out of their database. <a href=\"http://www.guerrilla-games.com/\">Guerrilla Games</a>, the developer of Killzone Shadow Fall uses DynamoDB for online multiplayer leaderboards and game settings. They will be leveraging GSIs to add more features and increase database performance. Also, <a href=\"http://www.bizo.com\">Bizo</a>, a B2B digital marketing platform, uses DynamoDB for audience targeting. GSIs will enable lookups using evolving criterion across multiple datasets.</p>

<p>These are just a few examples where GSIs can help and I am looking forward to our customers building scalable businesses with DynamoDB. I want application writers to focus on their business logic, leaving the heavy-lifting of maintaining consistency across look-up attributes to DynamoDB. To learn more see <a href=\"http://aws.typepad.com/aws/2013/12/now-available-global-secondary-indexes-for-amazon-dynamodb.html\">Jeff Barr’s blog</a> and the <a href=\"http://aws.amazon.com/documentation/dynamodb/\">DynamoDB developer guide</a>.</p>
")) (entry nil (title nil "Expanding the Cloud: Enabling Globally Distributed Applications and Disaster Recovery") (link ((href . "http://www.allthingsdistributed.com/2013/11/rds-cross-region-replicas.html"))) (updated nil "2013-11-26T14:00:00Z") (id nil "http://www.allthingsdistributed.com/2013/11/rds-cross-region-replicas") (content ((type . "html")) "<p>As I discussed in my <a href=\"https://www.youtube.com/watch?v=Waq8Y6s1Cjs#t=2486\">re:Invent keynote</a> earlier this month, I am now happy to announce the immediate availability of <a href=\"http://aws.amazon.com/rds/mysql/#Read_Replica\">Amazon RDS Cross Region Read Replicas</a>, which is another important enhancement for our customers using or planning to use multiple AWS Regions to deploy their applications. Cross Region Read Replicas are available for MySQL 5.6 and enable you to maintain a nearly up-to-date copy of your master database in a different AWS Region. In case of a regional disaster, you can simply promote your read replica in a different region to a master and point your application to it to resume operations. Cross Region Read Replicas also enable you to serve read traffic for your global customer base from regions that are nearest to them.</p>

<p>About 5 years ago, I <a href=\"http://www.allthingsdistributed.com/2008/03/on_the_road_to_highly_availabl.html\">introduced</a> you to AWS Availability Zones, which are distinct locations within a Region that are engineered to be insulated from failures in other Availability Zones and provide inexpensive, low latency network connectivity to other Availability Zones in the same region. Availability Zones have since become the foundational elements for AWS customers to create a new generation of highly available distributed applications in the cloud that are designed to be fault tolerant from the get go. We also made it easy for customers to leverage multiple Availability Zones to architect the various layers of their applications with a few clicks on the AWS Management Console with services such as <a href=\"http://aws.amazon.com/elasticloadbalancing/\">Amazon Elastic Load Balancing</a>, <a href=\"http://aws.amazon.com/rds/\">Amazon RDS</a> and <a href=\"http://aws.amazon.com/dynamodb/\">Amazon DynamoDB</a>. In addition, Amazon S3 redundantly stores data in multiple facilities and is designed for 99.999999999% durability and 99.99% availability of objects over a given year. Our SLAs offer even more confidence to customers running applications across multiple Availability Zones. Amazon RDS offers a monthly uptime percentage <a href=\"http://aws.amazon.com/rds-sla\">SLA</a> of 99.95% per Multi-AZ database instance. Amazon EC2 and EBS offer a monthly uptime percentage <a href=\"http://aws.amazon.com/ec2-sla/\">SLA</a> of 99.95% for instances running across multiple Availability Zones.</p>

<p>As AWS expanded to 9 distinct AWS Regions and 25 Availability Zones across the world during the last few years, many of our customers started to leverage multiple AWS Regions to further enhance the reliability of their applications for disaster recovery. For example, when a disastrous earthquake hit Japan in March 2011, many customers in Japan came to AWS to take advantage of the multiple Availability Zones. In addition, they also backed up their data from the AWS Tokyo Region to AWS Singapore Region as an additional measure for business continuity. In a similar scenario here in the United States, Milind Borate, the CTO of Druva, an enterprise backup company using AWS told me that after hurricane Sandy, he got an enormous amount of interest from his customers in the North Eastern US region to replicate their data to other parts of the US for Disaster Recovery.</p>

<p>Up until AWS and the Cloud, reliable Disaster Recovery had largely remained cost prohibitive for most companies excepting for large enterprises. It traditionally involved the expense and headaches associated with procuring new co-location space, negotiating pricing with a new vendor, adding racks, setting up network links and encryption, taking backups, initiating a transfer and monitoring it until  the operation complete. While the infrastructure costs for basic disaster recovery could have been very high, the associated system and database administration costs could be just as much or more. Despite incurring these costs, given the complexity, customers could have found themselves in a situation where the restoration process does not meet their recovery time objective and/or recovery point objective. AWS provides several easy to use and cost effective building blocks to make disaster recovery very accessible to customers. Using the S3 copy functionality, you can copy the objects/files that are used by your application from one AWS Region to another. You can use the <a href=\"http://aws.typepad.com/aws/2013/03/ec2-ami-copy-between-regions.html\">EC2 AMI copy</a> functionality to make your server images available in multiple AWS Regions. In the last 12 months, we launched <a href=\"http://aws.typepad.com/aws/2012/12/ebs-snapshot-copy.html\">EBS Snapshot Copy</a>, <a href=\"http://aws.typepad.com/aws/2013/10/cross-region-snapshot-copy-for-amazon-rds.html\">RDS Snapshot Copy</a>, <a href=\"http://aws.typepad.com/aws/2013/09/copy-dynamodb-data-between-regions-using-the-aws-data-pipeline.html\">DynamoDB Data Copy</a> and <a href=\"http://aws.typepad.com/aws/2013/11/automated-cross-region-snapshot-copy-for-amazon-redshift.html\">Redshift Snapshot Copy</a>, all of which help you to easily restore the full stack of your application environments in a different AWS Region for disaster recovery. Amazon RDS Cross Region Read Replica is another important enhancement for supporting these disaster recovery scenarios.</p>

<p>We have heard from Joel Callaway from Zoopla, a property listing and house prices website in UK that attracts over 20 million visits per month, that they are using the RDS Snapshot Copy feature to easily transfer hundreds of GB of their RDS databases from the US East Region to the EU West (Dublin) Region every week using a few simple API calls. Joel told us that prior to using this feature it used to take them several days and manual steps to set up a similar disaster recovery process. Joel also told us that he is looking forward to using Cross Region Read Replicas to further enhance their disaster recovery objectives.</p>

<p>AWS customers come from over 190 countries and a lot of them in turn have global customers. Cross Region Read Replicas also make it even easier for our global customers to scale database deployments to meet the performance demands of high-traffic, globally disperse applications.  This feature enables our customers to better serve read-heavy traffic from an AWS Region closer to their end users to provide a faster response time. Medidata delivers cloud-based clinical trial solutions using AWS that enable physicians to look up patient records quickly and avoid prescribing treatments that might counteract the patient’s clinical trial regimen. Isaac Wong, VP of Platform Architecture with Medidata, told us that their clinical trial platform is global in scope and the ability to move data closer to the doctors and nurses participating in a trial anywhere in the world through Cross Region Read Replicas enables them to shorten read latencies and allows their health professionals to serve their patients better.  Isaac also told us that using Cross Region Replication features of RDS, he is able to ensure that life critical services of their platform are not affected by regional disruption. These are great examples of how many of our customers are very easily and cost effectively able to implement disaster recovery solutions as well as design globally scalable web applications using AWS.</p>

<p>Note that building a reliable disaster recovery solution entails that every component of your application architecture, be it a web server, load balancer, application, cache or database server, is able to meet the recovery point and time objectives you have for your business. If you are going to take advantage of Cross Region Read Replicas of RDS, make sure to monitor the replication status through <a href=\"http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Events.html\">DB Event Notifications</a> and the Replica Lag metric through <a href=\"http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Monitoring.html\">CloudWatch</a> to ensure that your read replica is always available and keeping up. Refer to the <a href=\"http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReadRepl.html#USER_ReadRepl.XRgn\">Cross Region Read Replica section</a> of the Amazon RDS User Guide to learn more.</p>
")) (entry nil (title nil "AWS re:Invent 2013") (link ((href . "http://www.allthingsdistributed.com/2013/11/aws-reinvent-2103.html"))) (updated nil "2013-11-13T07:00:00Z") (id nil "http://www.allthingsdistributed.com/2013/11/aws-reinvent-2103") (content ((type . "html")) "<p><img src=\"/images/reinvent2013.jpg\"/ width=\"650\"></p>

<p>Today we are kicking off <a href=\"http://reinvent.awsevents.com/\">AWS re:Invent 2013</a>. Over the course of the next three days, we will host more than 200 sessions, training bootcamps, and hands on labs taught by expert AWS staff as well as dozens of our customers.</p>

<p>This year’s conference kicks off with a keynote address by AWS Senior Vice President Andy Jassy, followed by my keynote on Thursday morning.  Tune in to hear the latest from AWS and our customers.</p>

<p>If you’re not already here in Vegas with us, you can sign up to watch the keynotes on live stream <a href=\"http://reinvent.awsevents.com/\">here</a>.</p>

<p>Outside of the keynotes, there are an incredible number of sessions offering a tailored experience whether you are a developer, startup, executive, partner, or other. You can see the full session catalog <a href=\"https://portal.reinvent.awsevents.com/connect/search.ww\">here</a>. I’m impressed by the scale and technical depth of what’s offered to attendees.</p>

<p>After my keynote on Thursday I will host two fireside chat sessions with cloud innovators and industry influencers:</p>

<p><a href=\"https://portal.reinvent.awsevents.com/connect/search.ww#loadSearch-searchPhrase=spot203&amp;searchType=session&amp;tc=0&amp;sortBy=abbreviationSort&amp;p=\">First</a>, I’ll talk with three technical startup founders</p>

<ul>
<li>Eliot Horowitz from <a href=\"http://www.mongodb.com/\">MongoDB</a></li>
<li>Jeff Lawson from <a href=\"http://www.twillio.com/\">Twilio</a></li>
<li>Valentino Volonghi from <a href=\"http://www.techstars.com/\">Adroll</a></li>
</ul>


<p> In the <a href=\"https://portal.reinvent.awsevents.com/connect/search.ww#loadSearch-searchPhrase=spot203&amp;searchType=session&amp;tc=0&amp;sortBy=abbreviationSort&amp;p=\">second session</a> I will talk with three startup influencers</p>

<ul>
<li>David Cohen from <a href=\"http://www.techstars.com/\">Techstars</a></li>
<li>Ash Fontana from <a href=\"http://angel.co\">AngelList</a></li>
<li>Albert Wenger from <a href=\"http://www.usv.com/\">Union Square Ventures</a></li>
</ul>


<p>  I will follow those two sessions with <a href=\"https://portal.reinvent.awsevents.com/connect/search.ww#loadSearch-searchPhrase=spot101&amp;searchType=session&amp;tc=0&amp;sortBy=abbreviationSort&amp;p=\">Startup Launches</a>, where five companies will either launch their business or a significant feature entirely built on AWS. It will be a busy, fun, and informative afternoon!</p>

<p>Look forward to seeing you around the conference.</p>
")) (entry nil (title nil "Simplifying Mobile App Data Management with DynamoDB's Fine-Grained Access Control") (link ((href . "http://www.allthingsdistributed.com/2013/10/mobile-app-data-management-dynamodb.html"))) (updated nil "2013-10-30T09:00:00Z") (id nil "http://www.allthingsdistributed.com/2013/10/mobile-app-data-management-dynamodb") (content ((type . "html")) "<p>Speed of development, scalability, and simplicity of management are among the critical needs of mobile developers. With the proliferation of mobile devices and users, and small agile teams that are tasked with building successful mobile apps that can grow from 100 users to 1 million users in a few days, scalability of the underlying infrastructure and simplicity of management are more important than ever. We created <a href=\"http://aws.amazon.com/dynamodb/\">DynamoDB</a> to make it easy to set up and scale databases so that developers can focus on building great apps without worrying about the muck of managing the database infrastructure. As I have <a href=\"http://www.allthingsdistributed.com/2013/09/dynamodb-geospatial.html\">mentioned previously</a>, companies like <a href=\"https://www.crittercism.com/\">Crittercism</a> and <a href=\"http://dropcam.com\">Dropcam</a> have already built exciting mobile businesses leveraging DynamoDB. Today, we are further simplifying mobile app development with our newest DynamoDB feature, Fine-Grained Access Control, which gives you the ability to directly and securely access mobile application data in DynamoDB.</p>

<p>One of the pieces of a mobile infrastructure that developers have to build and maintain is the fleet of proxy servers that authorize requests coming from millions of mobile devices. This proxy tier allows vetted requests to continue to DynamoDB and then filters responses so the user only receives permitted items and attributes. So, if I am building a mobile gaming app, I must run a proxy fleet that ensures “johndoe@gmail.com” only retrieves his game state and nothing else. While <a href=\"http://aws.typepad.com/aws/2013/05/aws-iam-now-supports-amazon-facebook-and-google-identity-federation.html\">Web Identity Federation</a>, which we introduced a few months back, allowed using public identity providers such as Login with <a href=\"http://login.amazon.com/\">Amazon</a>, <a href=\"https://developers.facebook.com/docs/facebook-login/\">Facebook</a>, or <a href=\"https://developers.google.com/+/\">Google</a> for authentication, it still required a developer to build and deploy a proxy layer in front of DynamoDB for this type of authorization</p>

<p>With Fine-Grained Access Control, we solve this problem by enabling you to author access policies that include conditions that describe additional levels of filtering and control. This eliminates the need for the proxy layer, simplifies the application stack, and results in cost savings. Using access control this way involves a setup phase of authenticating the user (step 1) and obtaining IAM credentials (step 2). After these steps, the mobile app may directly perform permitted operations on DynamoDB (step 3).</p>

<p><img src=\"/images/fgac-dynamodb.png\"/ width=\"650\"></p>

<p>With today’s launch, apps running on mobile devices can send workloads to a DynamoDB table, row, or even a column without going through an intervening proxy layer. For instance, the developer of a mobile app will use Fine-Grained Access Control to restrict the synchronization of user data (e.g. Game history) across the many devices the user has the app installed on. This capability allows apps running on mobile devices to modify only rows belonging to a specific user. Also, by consolidating users’ data in a DynamoDB table, you can obtain real-time insights over the user base, at large scale, without going through expensive joins and batch approaches such as scatter / gather.</p>

<p>To get started, please see the <a href=\"http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/FGAC_DDB.html\">Fine-Grained Access Control documentation</a> and <a href=\"http://aws.typepad.com/aws/2013/10/fine-grained-access-control-for-amazon-dynamodb.html\">Jeff Barr’s blog</a>.</p>
")) (entry nil (title nil "Back-to-Basics Weekend Reading - U-Net: A User-Level Network Interface") (link ((href . "http://www.allthingsdistributed.com/2013/10/unet-user-level-network-interface.html"))) (updated nil "2013-10-25T11:00:00Z") (id nil "http://www.allthingsdistributed.com/2013/10/unet-user-level-network-interface") (content ((type . "html")) "<p><img src=\"/images/kochin.jpg\"/ width=\"650\"></p>

<p>Many of you know <a href=\"http://www.rightscale.com/blog/users/thorsten-von-eicken\">Thorsten von Eicken</a> as the founder of <a href=\"http://www.rightscale.com\">Rightscale</a>, the company that has helped numerous organizations find their way onto AWS. In what seems almost a previous life by now Thorsten was one of the top young professors in Distributed Systems and I had the great pleasure of working with him at Cornell in the early 90's. What set Thorsten aside from so many other system research academics was his desire to build practical, working systems, a path that I followed as well.</p>

<p>In the back to basics readings this week I am re-reading a paper from 1995 about the work that I did together with Thorsten on solving the problem of end-to-end low-latency communication on high-speed networks. The problem we were facing in those days was than many new high-speed network technologies, such as ATM, became available for standard workstations but that the operating systems were not able to deliver those capabilities to its applications. Throughput was often acceptable but individual message latency was as bad as over regular ethernet, a problem that <a href=\"http://research.microsoft.com/en-us/people/thekkath/\">Chandu Tekkath</a> had described earlier in \"<a href=\"http://www.thekkath.org/Documents/lowlatency.pdf\">Limits to Low-Latency Communication on High-Speed Networks</a>\"</p>

<p>The lack of low-latency made that distributed systems (e.g. database replication, fault tolerance protocols) could not benefit from these advances at the network level. The research to unlock these capabilities led to an architecture called <a href=\"http://www.cs.cornell.edu/tve/u-net/\">U-Net</a>. What set U-Net aside from other research was that it was first and foremost and engineering effort as we set out to build a system that actually had to function in production. Many of those engineering experiences found their way back into the paper. U-Net also heavily influenced what later became the Virtual Network Architecture industry standard.</p>

<p>The work on U-Net was continued by <a href=\"http://www.mdw.la/\">Matt Welsh</a> who built among other things a version that could be used for <a href=\"http://www.eecs.harvard.edu/~mdw/proj/old/unet/\">fast-ethernet on regular PCs</a> and one that could <a href=\"http://www.eecs.harvard.edu/~mdw/proj/old/unet-sle/\">safely integrate into type-safe environments</a> such as the JVM.</p>

<p><a href=\"http://www.allthingsdistributed.com/files/u-net.pdf\"><em>U-Net: A User-Level Network Interface for Parallel and Distributed Computing</em></a>, Anindya Basu, Vineet Buch, Werner Vogels, Thorsten von Eicken. Proceedings of the 15th ACM Symposium on Operating Systems Principles (SOSP), Copper Mountain, Colorado, December 3-6, 1995</p>
")) (entry nil (title nil "AWS Activate – Supporting Startups on AWS") (link ((href . "http://www.allthingsdistributed.com/2013/10/aws-activate.html"))) (updated nil "2013-10-10T00:30:00Z") (id nil "http://www.allthingsdistributed.com/2013/10/aws-activate") (content ((type . "html")) "<p><img src=\"/images/activate2.png\"/ align=\"right\" vspace=\"0\" hspace=\"0\" width=\"270\">
I am very excited to announce <a href=\"https://aws.amazon.com/activate/\">AWS Activate</a>, a program designed to provide startups with the resources they need to build applications on AWS.</p>

<p>Startups will forever be a very important customer segment of AWS. They were among our first customers and along the way some amazing businesses have been built by these startups, many of which running for 100% on AWS. Startups operate in a world of high uncertainty and limited capital, so an elastic and on-demand infrastructure at low and variable cost aligns very naturally with their needs. By reducing the cost of failure and democratizing access to infrastructure, the cloud has enabled more startups to build, experiment, and scale.</p>

<p>When we launched AWS the original mission was</p>

<blockquote><p><em>To enable businesses and developers to use web services to build scalable sophisticated applications</em></p></blockquote>

<p>We’re continually amazed at the incredible sophisticated applications that these startups have built on top of our foundational services. That includes the startups that have become household names –
<a href=\"http://instagram.com\">Instagram</a>,
<a href=\"http://www.spotify.com\">Spotify</a>,
<a href=\"http://www.pinterest.com\">Pinterest</a>,
<a href=\"http://www.dropbox.com\">Dropbox</a>,
<a href=\"http://www.etsy.com\">Etsy</a>,
<a href=\"http://www.airbnb.com\">AirBnB</a>,
<a href=\"http://www.shazam.com\">Shazam</a>
 – as well as incredibly successful companies that you might not yet have heard of, such as
<a href=\"http://www.twilio.com\">Twilio</a>,
<a href=\"http://www.viki.com\">Viki</a>,
<a href=\"http://www.redbus.in\">Redbus</a>,
<a href=\"http://www.floorplanner.com\">Floorplanner</a>
and <a href=\"http://www.tellybug.com\">Tellybug</a>,
and many more. We’re proud to have helped all startups achieve their goals.</p>

<p>As I’ve traveled this past year for AWS Summits I’ve met startups in countries all over the world building apps for every imaginable use case. What’s exciting to me is infrastructure is no longer a bottleneck to innovation. The democratization of infrastructure means that an internet startup in Bangalore or Sao Paulo or Manila has access to the same compute power as Amazon.com; the same durability as Dropbox; the same scalability as Airbnb; the same global footprint as Netflix. The result is we’re beginning to see more and more startups grow up in more places.</p>

<p>We’re excited to be a part of this global momentum in the startup ecosystem. The challenge now is to support and assist an increasing number of startups across the world.</p>

<p>To that end, today we’re pleased to announce <a href=\"https://aws.amazon.com/activate/\">AWS Activate</a>, a new program for startups. AWS Activate is designed to provide startups with the resources they need to build applications on AWS. It includes access to web-based AWS Training courses, to help startups become familiar and proficient with AWS services; an AWS Support period, to provide expert guidance when a startup might need it; and in some cases AWS Promotional Credit. AWS Activate also allows startups to leverage the unique and robust ecosystem that has grown around AWS, both in terms of the developer community and third-party software vendors. The new Startup Forum will give startups a place to find and share tips and lessons learned – there are already posts from customers like Coursera as well as best practice guidance from AWS Solutions Architects. In addition, AWS Activate will include discounts on software that many startups find useful. Included already are exclusive offers from Opscode (for automation), AlertLogic (for security), and SOASTA (for testing).</p>

<p>The best part is – it’s free to join.  You can learn more and sign up at <a href=\"https://aws.amazon.com/activate/\">AWS Activate</a>.</p>
")) (entry nil (title nil "Back-to-Basics Weekend Reading - Tor: The Second-Generation Onion Router") (link ((href . "http://www.allthingsdistributed.com/2013/10/tor-second-generation-onion-router.html"))) (updated nil "2013-10-04T14:30:00Z") (id nil "http://www.allthingsdistributed.com/2013/10/tor-second-generation-onion-router") (content ((type . "html")) "<p><img src=\"/images/lux.jpg\"/ width=\"650\"></p>

<p>The anonymity routing network <a href=\"http://en.wikipedia.org/wiki/Tor_(anonymity_network)\">Tor</a> is frequently in the news these days, which makes it a good case to read up on the fascinating technologies behind it. Tor stands for The Onion Router as its technology is based on the <a href=\"http://en.wikipedia.org/wiki/Onion_Routing\">onion routing</a> principles. These principles were first described by Goldschlag, et al., from the Naval Research Lab, in their 1996 paper on Hiding Routing Information. Almost immediately work started on addressing a number of omissions in the original work in what became known as the second-generation onion router. Tor is the implementation of such a second generation router and has a number of fascinating features. The paper describing Tor is also very interesting from a practitioners point of view as it deals with the system complexities of implementing the router at scale.</p>

<p><a href=\"http://www.onion-router.net/Publications/IH-1996.pdf\"><em>Hiding Routing Information</em></a>, David M. Goldschlag, Michael G. Reed, and Paul F. Syverson, in the proceeding of the Workshop on Information Hiding, Cambridge, UK, May, 1996.</p>

<p><a href=\"http://www.onion-router.net/Publications/tor-design.pdf\"><em>Tor: The Second-Generation Onion Router</em></a>, Roger Dingledine, Nick Mathewson and Paul Syverson, in Proceedings of the 13th USENIX Security Symposium, August 2004</p>
")) (entry nil (title nil "Back-to-Basics Weekend Reading - A Decomposition Storage Model") (link ((href . "http://www.allthingsdistributed.com/2013/09/column-oriented-databases.html"))) (updated nil "2013-09-20T17:30:00Z") (id nil "http://www.allthingsdistributed.com/2013/09/column-oriented-databases") (content ((type . "html")) "<p><img src=\"/images/sin-garden.jpg\"/ width=\"650\"></p>

<p>Traditionally records in a database were stored as such: the data in a row was stored together for easy and fast retrieval. Not everybody agreed that the \"N-ary Storage Model\" (NSM) was the best approach for all workloads but it stayed dominant until hardware constraints, especially on caches, forced the community to revisit some of the alternatives. Combined with the rise of data warehouse workloads, where there is often significant redundancy in the values stored in columns, and  database models based on column oriented storage took off. The first practical modern implementation is probably <a href=\"http://db.csail.mit.edu/projects/cstore/vldb.pdf\">C-Store by Stonebraker, et al.</a> in 2005. There is a great tutorial by <a href=\"http://www.cs.yale.edu/homes/dna/talks/Column_Store_Tutorial_VLDB09.pdf\">Harizopoulos, Abadi and Boncz from VLDB 2009</a> that takes you through the history, trade-off's and the state of the art. Many of the modern high-performance data warehouses such as <a href=\"http://aws.amazon.com/redshift\">Amazon Redshift</a> are based on column stores.</p>

<p>But the groundwork for Column Oriented Databases was laid in 1985 when George Copeland and Setrag Koshafian questioned the NSM with their seminal paper on a \"Decomposition Storage Model\" (DSM). From the abstract:</p>

<blockquote><p><em>There seems to be a general consensus among
the database community that the n-ary approach is
better This conclusion is usually based on a
consideration of only one or two dimensions of a
database system The purpose of this report is not
to claim that decomposition is better Instead, we
claim that the consensus opinion is not well
founded and that neither is clearly better until a
closer analysis is made along the many dimensions
of a database system The purpose of this report
is to move further in both scope and depth toward
such an analysis We examine such dimensions as
simplicity, generality, storage requirements,
update performance and retrieval performance</em></p></blockquote>

<p><a href=\"http://www3.in.tum.de/teaching/ws0506/MMDBMS/download/decomposition-storage-model.pdf\"><em>A Decomposition Storage Model</em></a>, George P. Copeland and Setrag N. Khoshafian, in the Proceedings of the 1985 SIGMOD International Conference on Management of Data</p>
")) (entry nil (title nil "Dutch Enterprises and The Cloud") (link ((href . "http://www.allthingsdistributed.com/2013/09/dutch-enterprise-and-the-cloud.html"))) (updated nil "2013-09-06T00:00:00Z") (id nil "http://www.allthingsdistributed.com/2013/09/dutch-enterprise-and-the-cloud") (content ((type . "html")) "<p><img src=\"/images/ams.jpg\"/ width=\"650\"></p>

<p>This spring I travelled through Europe for the AWS Global Summit series.
In my many conversations with customers, and with the media, I
encountered surprise and excitement about the extent that European
enterprises have already been using the Amazon Web Services for some
time. Whether it is large telecommunications manufactures like <a href=\"http://nsn.com/\">Nokia
Siemens Networks</a> running their real-time data analytics for network
operators on AWS, or a luxury hotel chain like <a href=\"http://www.kempinski.com/\">Kempinski</a> moving their
core IT functions to AWS such that they can get out of the IT business,
or a major newspaper corporation like <a href=\"http://news.co.uk/\">News International</a>, who plan to
have 75% of their infrastructure running on AWS within 3 years to
improve their agility, European enterprises have been moving to the
cloud for some time to become more agile and competitive.</p>

<p>Europe is a continent with much diversity and for each country there are
great AWS customer examples to tell.  Given that I am originally from
the Netherlands I have, of course, a special interest in how Dutch
companies are using our cloud services.  </p>

<p>For many young Dutch businesses AWS is the platform of choice such that
they can grow unconstrained, targeting a global customer base, in the
most cost-effective manner possible. There is long list of success
stories:
<a href=\"http://WeTransfer.com\">WeTransfer</a>,
<a href=\"http://Floorplanner.com\">Floorplanner</a>,
<a href=\"http://Mobypicture.com\">Mobypicture</a>,
<a href=\"http://Albumprinter.nl\">Albumprinter</a>,
<a href=\"http://wercker.com\">Wercker</a>,
<a href=\"http://c9.io\">Cloud9</a>,
<a href=\"http://www.silkapp.com/\">Silk</a>,
<a href=\"https://www.layar.com/\">Layar</a>,
<a href=\"https://yourkarma.com/\">Karma</a>,
<a href=\"http://wakoopa.com\">Wakoopa</a>,
<a href=\"http://peecho.com\">Peecho</a>,
<a href=\"http://foodzy.com\">Foodzy</a>
<a href=\"http://usabila.com\">Usabila</a>
and many, many more.</p></p>

<p>But it is not just Dutch entrepreneurs who build their business in the
cloud, also traditional Dutch enterprises are moving to the cloud to
improve their agility and cost-effectiveness. Here are some great
examples from different industries each with unique use cases.</p>

<ul>
<li><p><strong>Royal Dutch Shell</strong> – is one of the world’s largest companies. In
addition to its goal of reducing energy costs, Shell needed to be more
agile in deploying IT services and planning for user demand. To reach
those goals, Shell in 2010 began using AWS.  Shell leverages sensors to
find oil in wells formerly thought to have run dry or in places where
previous exploration indicated there was no oil. These sensors create
massive amounts of geological data. Shell's IT shop has to figure out
how to drive costs down, effectively manage the giant files and make it
profitable for the company to deploy these sensors.   Shell leverages
AWS for big data analytics to help achieve these goals. Shell's
scientists, especially the geophysicists and drilling engineers,
frequently use cloud computing to run models. They provision compute
capacity themselves, run their models and then return the cloud compute
capacity, getting charged only for what they used. Shell says that two
hundred and 300 project teams could be up and running in a day versus
the weeks it would take them prior to AWS.</p></li>
<li><p><strong>Unilever</strong> – Unilever R&amp;D program intended to accelerate the company’s
scientific progress through improved access to global information. Due
to the exponential growth of the biology and informatics fields,
Unilever needs to maintain this new program within a highly-scalable
environment that supports parallel computation and heavy data storage
demands. It makes use of the Eagle Genomics platform running on AWS,
resulting in that Unilever’s digital data program now processes genetic
sequences twenty times faster—without incurring higher compute costs. In
addition, its robust architecture supports ten times as many scientists,
all working simultaneously. This genetics R&amp;D is crucial for Unliver to
develop new products faster; for example comparing a healthy mouth with
one with gingivitis - by identifying the shared genes amongst these two
can be very helpful in developing the next generation of toothpaste.</p></li>
<li><p><strong>Essent</strong> – supplies customers in the Benelux region with gas,
electricity, heat and energy services. Essent has moved to the cloud to
take advantage of the low, pay-as you-go, cost model and also the
flexibility and scalability the cloud provides. Essent currently hosts
all of their public facing websites and customer self-service portals in
the AWS cloud. By offloading the task of managing infrastructure to AWS
Essent is able to spend more time on innovating on behalf of their
customers to help them in their energy usage. The company has used AWS
to build an IT innovation zone, based upon open source products, which
is being used to launch new innovations for customers like E-Mobility
and E-thermostat products with a very fast time-to-market.</p></li>
<li><p><strong>Tom Tom – </strong>Founded in 1991, TomTom is a leading provider of
navigation and location-based products and services. In 2012 Tom Tom
launched a new Location Based Services (LBS) platform to give app
developers easy access to its mapping content to be able to incorporate
rich location based data into their applications. When Tom Tom launched
the LBS platform they wanted the ability to reach millions of developers
all around the world without having them invest a lot of capital upfront
in hardware and building expensive data centers so turned to the cloud.
Using cloud computing as the underlying technology to run the LBS
platform Tom Tom is able to provide developers with on-demand content
that will enable them to build location based applications for fleet
management, route planning, traffic management or spatial analytics. </p></li>
<li><p><strong>Ohpen</strong> – The Dutch banking regulator, De Nederlandsche Bank (DNB),
has cleared the path for Dutch financial institutions to make use of
AWS.  Dutch firm Ohpen has already moved to take advantage of the ruling
by choosing AWS to host its core banking platform in an on-demand,
software-as-a-service environment. According to Chris Zadeh, the CEO of
Ohpen,  large Dutch banks are already moving their entire retail banking
platforms to the cloud using Ohpen core banking technology running on
top of AWS.</p></li>
</ul>


<p>These are just some of the public enterprise references from the
Netherlands, but from personal conversations I know that in almost
industry vertical Dutch companies are moving ahead rapidly to ensure
that they can keep up with the global competition. Dutch enterprises
from Media &amp; Advertising, Financial Services, Energy, Transportation and
Shipping, Life Sciences and Healthcare are experiencing the
transformative nature of Cloud Computing; how IT can be enabler of
innovation and greatly improve agility with traditional organizations.</p>

<p>I have picked the Netherlands as the obvious example, but the Dutch are
not an exception; I can tell similar stories for almost all European
countries. Enterprises in Europe are rapidly embracing cloud computing
to continue to compete globally, and at AWS we are proud to help them
achieve their goals.</p>

<p>On September 26 there is an AWS Summit in the Beurs van Berlage in
Amsterdam for those from the Benelux interested in hearing how customers
are making use of AWS and hearing the details about the AWS business and
technologies. You can find more details and registration information at <a href=\"http://aws.amazon.com/aws-summit-benelux-2013/amsterdam/\">http://aws.amazon.com/aws-summit-benelux-2013/amsterdam/</a> </p>
")) (entry nil (title nil "DynamoDB for Location Data: Geospatial querying on DynamoDB datasets") (link ((href . "http://www.allthingsdistributed.com/2013/09/dynamodb-geospatial.html"))) (updated nil "2013-09-05T14:30:00Z") (id nil "http://www.allthingsdistributed.com/2013/09/dynamodb-geospatial") (content ((type . "html")) "<p>Over the past few years, two important trends that have been disrupting the database industry are mobile applications and big data.  The explosive growth in mobile devices and mobile apps is generating a huge amount of data, which has fueled the demand for big data services and for high scale databases. Meanwhile, mobile app developers have shown that they care a lot about getting to market quickly, the ability to easily scale their app from 100 users to 1 million users on day 1, and the extreme low latency database performance that is crucial to ensure a great end-user experience. These factors have made DynamoDB a compelling database for mobile developers, who happen to be among the biggest adopters of this technology. For example, <a href=\"https://www.crittercism.com/\">Crittercism</a>, a mobile application performance management company, uses DynamoDB to monitor the performance and stability of mobile apps on over 600 million devices with billions of daily transactions.</p>

<p>“We picked DynamoDB because it supports the scale we require\" said <a href=\"https://twitter.com/robkwok\">Robert Kwok</a>, CTO of Crittercism. \"Our business is growing rapidly, and DynamoDB allows us to immediately scale up to support sudden increases in our workload. Switching to DynamoDB also reduced our costs by an order of magnitude and eliminated engineering efforts that used to come with growing our database layer.\"</p>

<p>Similarly, <a href=\"http://www.earthnetworks.com/\">Earth Networks</a> uses DynamoDB to power its lightning alert system, which gives millions of users real time access to live streaming lightning data, while <a href=\"https://www.dropcam.com/\">Dropcam</a> uses DynamoDB to power its cloud based monitoring system which has become one of the biggest video streaming platforms in the world. These innovative developers chose DynamoDB because it allows them to scale seamlessly without compromising on performance or cost.</p>

<p>The blooming mobile industry has made location data ubiquitous and offers mobile developers opportunities to build a whole new breed of novel mobile applications. Many mobile apps have features that help customers find nearby points of interest (e.g. “Find the closest coffee shop”), access location-specific offers, and find friends in your vicinity. Today, we are launching a geospatial indexing library that helps our customers build location-aware features by executing geospatial queries on their datasets in DynamoDB.  With this library, you can:</p>

<ul>
<li>Efficiently store points of interest (POIs) and run exploration spatial queries</li>
<li>Calculate great circle distances and perform spherical math. For example, “find points of interest near me”.</li>
</ul>


<p>We put together a sample application that shows the power of the library we are launching today. For more details on this library, which you can <a href=\"https://github.com/awslabs/dynamodb-geo\">find on github</a>, please take a look at <a href=\"http://aws.typepad.com/aws/2013/09/new-geo-library-for-dynamodb-.html\">Jeff Barr’s blog</a>.</p>
")) (entry nil (title nil "Expanding the Cloud: More memory, more caching and more performance for your data	") (link ((href . "http://www.allthingsdistributed.com/2013/09/amazon-elasticache-redis.html"))) (updated nil "2013-09-03T18:00:00Z") (id nil "http://www.allthingsdistributed.com/2013/09/amazon-elasticache-redis") (content ((type . "html")) "<p>Today, we added two important choices for customers running high performance apps in the cloud: support for <a href=\"http://redis.io/\">Redis</a> in <a href=\"http://aws.amazon.com/elasticache\">Amazon ElastiCache</a> and a new high memory database instance (db.cr1.8xlarge) for <a href=\"http://aws.amazon.com/rds\">Amazon RDS</a>.</p>

<p>As we prepared to launch these features, I was struck not only by the range of services we provide to enable customers to run fully managed, scalable, high performance database workloads, including <a href=\"http://aws.amazon.com/rds\">Amazon RDS</a>, <a href=\"http://aws.amazon.com/dynamodb\">Amazon DynamoDB</a>, <a href=\"http://aws.amazon.com/redshift\">Amazon Redshift</a> and <a href=\"http://aws.amazon.com/elasticache\">Amazon ElastiCache</a>, but also by the pace at which these services are evolving and improving. Since you now have lots of choices to address your high performance database needs, I decided to write this blog to help you select the most appropriate services for your workload using lessons I have learnt by scaling the infrastructure for Amazon.com.</p>

<p>Choosing your database architecture may be the most critical decision you’ll make and has a disproportionate impact on the performance, scalability, and availability of your app. Get it right and your application will seamlessly scale from hundreds to tens of millions of users without difficulty, while remaining performant and available. Get it wrong and you’re looking at sleepless nights, struggling to keep up with growth and fighting to keep your app available while you rewrite critical portions of your code. Since databases are complex and have so much impact on our customers’ apps, from day 1 we have believed in delivering managed services and taking on the burden of provisioning, configuring, securing, backing up and restoring databases to enable our customers to focus on what they do best, which is to develop awesome apps for their users.</p>

<p>No single database architecture or solution can meet all of Amazon.com’s or our customers’ needs. For example, even within relational databases, some of the 3rd party apps we use at Amazon are only certified to run using Oracle databases whereas others use MySQL databases. Certain parts of our architecture used to run on relational databases but we just couldn’t scale them fast enough to meet the demands of our fast growing online retail business, particularly during the holiday shopping seasons. We endured significant disruptions to our retail infrastructure in early 2000s and had to invent a new category of databases like <a href=\"http://www.allthingsdistributed.com/2007/10/amazons_dynamo.html\">Dynamo</a> that has come to be known as NoSQL. Since we moved these parts of our architecture to <a href=\"http://aws.amazon.com/dynamodb\">DynamoDB</a> we can’t imagine doing it any other way because we don’t know of another solution that can seamlessly scale to our transaction rates while maintaining our stringent 100% availability demands. While we use DynamoDB extensively, we also have relational databases in other parts of our stack and they are equally critical.</p>

<p>AWS offers its customers a choice of different database services, each optimized for different workloads. <strong>DynamoDB</strong> is for customers who want high availability, predictable performance and scalability and we limit some relational functionality to achieve these critical requirements. <strong>Amazon RDS</strong>, with support for MySQL, SQL Server and Oracle databases, is for customers with apps where relational database features and support for a specific brand of database are critical. We offer high availability options called <a href=\"http://aws.amazon.com/rds/multi-az/\">Amazon RDS Multi-AZ</a> and commit to an availability SLA of 99.95%. We allow customers to provision the number of input and output operations (IOPS) they require by using Amazon RDS with Provisioned IOPS. <strong>Amazon ElastiCache</strong> is a fully managed, in-memory caching service for customers to optimize the latency, performance and cost of their read workloads. For our customers who need scalable datawarehouse we offer <strong>Amazon Redshift</strong>, a fast, fully managed, petabyte-scale data warehouse service that makes it simple and cost-effective to efficiently analyze all your data using your existing business intelligence tools.</p>

<p>Today, we are further expanding the choices available for designing and developing highly scalable and high performance apps. In a relational database, the memory working set size is critical for database performance. As the amount of data stored increases constantly, the amount of memory needed also goes up. To address this, we are adding support for a new memory-optimized instance to Amazon RDS. The db.cr1.8xlarge has 88 ECUs, 244GB of memory, high-bandwidth network, and the ability to deliver up to 20,000 IOPS for MySQL 5.6, an increase of 60 percent over the prior 12,500 IOPS limit for MySQL. This is an ideal instance for high-performance relational workloads.</p>

<p>Similar to how we offer multiple engines in Amazon RDS, starting today, we are supporting <a href=\"http://redis.io/\">Redis</a> as a new engine choice in Amazon ElastiCache, in addition to Memcached. I’ve seen Redis grow rapidly over the years and while some customers use it as a primary datastore, its main benefit is to augment your database tier to utilize data structures such as sorted sets and lists that are not readily available in traditional databases. Customers tell us that they love the ease of use and capabilities of Redis, but have been asking us to help simplify its management. Amazon ElastiCache for Redis provides the full capabilities of Redis and is designed to enable your existing libraries, applications and tools for Redis to just work. Amazon ElastiCache supports creation of Redis read replicas across availability zones and automatically detects and replaces failed read replicas. Integration with <a href=\"http://aws.amazon.com/cloudwatch/\">Amazon CloudWatch</a> gives customers visibility into key performance metrics, further simplifying system management.</p>

<p>Many developers tell us that they want to rely on AWS to manage their databases so that they can spend their effort on building apps. For example, Scopely has built their gaming platform with DynamoDB as their primary datastore, while using Amazon RDS where they need complex query support. For features that need data structures like sorted sets (e.g., leaderboards) they have been using Redis. With the launch of Redis in ElastiCache, <a href=\"http://scopely.com\">Scopely</a> is planning to move its self-managed Redis to Amazon ElastiCache to obtain the added benefits of monitoring and management without having to change its existing Redis toolchain. Similarly, <a href=\"http://gu3.co.jp/en/\">gumi</a>, one of the top game developers in Japan, uses Redis extensively in their platform for real-time leaderboard tracking in addition to their usage of RDS Multi AZ and DynamoDB. gumi used to manage a large Redis fleet and is excited to begin moving away from the undifferentiated heavy lifting of self-managing Redis by adopting ElastiCache Redis.</p>

<p>There are many customers like Scopely and gumi who believe they should “use the best tool for the specific use case”, but selecting the right database architecture can be challenging. To simplify the selection process, I recommend a simple rule of thumb: For critical workloads which need to be highly available, at any scale, I generally recommend DynamoDB as it offers seamless scalability, predictable performance and high availability at low cost without any operational overhead. For workloads that need complex querying, transactions or specific relational features, I recommend Amazon RDS. It provides customers with familiar MySQL, Microsoft SQL Server or Oracle database engines while simplifying the monitoring and management of complex RDBMSs. You can augment your database tier with a caching layer using Amazon ElastiCache to lower read costs and reduce read latency using Memcached and now Redis, especially if you need those advanced data structures that are not typically provided by your database tier. You can analyze all of your data stored in DynamoDB or RDS using Amazon Redshift, a fully managed petabyte-scale data warehouse service that delivers increased query performance when analyzing virtually any size dataset for a tenth the cost of most traditional data warehousing solutions.</p>

<p>We believe in providing customers with building blocks that allow them to construct the apps they need and I’m excited to see what they’re going to do with the new options we’re announcing today.</p>

<p>To learn more about Amazon RDS and the new instance type, you can visit <a href=\"http://aws.amazon.com/rds\">http://aws.amazon.com/rds</a></p>

<p>To learn more about ElastiCache Redis, please refer to <a href=\"http://aws.typepad.com/aws/2013/09/amazon-elasticache-now-with-a-dash-of-redis.html\">Jeff Barr’s blog</a> and visit <a href=\"http://aws.amazon.com/elasticache\">http://aws.amazon.com/elasticache</a></p>
")) (entry nil (title nil "Back-to-Basics Weekend Reading - An Introduction to Spatial Database Systems") (link ((href . "http://www.allthingsdistributed.com/2013/08/spatial-databases.html"))) (updated nil "2013-08-30T17:30:00Z") (id nil "http://www.allthingsdistributed.com/2013/08/spatial-databases") (content ((type . "html")) "<p><img src=\"/images/cochin.jpg\"/ width=\"650\"></p>

<p>Storing and querying datasets that contain objects in a geometric space have always required special treatment. The choice of data structures and query algorithms can easily make the different between a query that runs in seconds or in days. Much of the fundamental work has been done in the late eighties and early nineties, for examples around topological relations (disjoint, meet, equal, overlap, contains, etc.), direction relations (north, north-east, etc.) and distance relations (far, near), and also with respect to spatial data structures (<a href=\"http://wv.ly/18rn6kd\">a great survey</a> by Hanan Samet).</p>

<p>With location becoming a more important attribute to many modern datasets a solid understanding of the tradeoffs is important. In 1994 Ralf Güting wrote an overview of the state of the art for a regular databases audience in a special issue on Spatial Database Systems of the VLDB Journal. It is an extensive but relatively easy read and gives a great introduction to the back-to-basics of Spatial Database Systems.</p>

<p><a href=\"http://wv.ly/18rnNtJ\"><em>An Introduction to Spatial Database Systems</em></a>, Ralf Hartmut Güting, The International Journal on Very Large Data Bases - Special Issues on Spatial Database Systems, Volume 3 Issue 4, October 1994, Pages 357-399</p>
")) (entry nil (title nil "Back-to-the-Future Weekend Reading - Distributed GraphLab: A Framework for Machine Learning and Data Mining in the Cloud") (link ((href . "http://www.allthingsdistributed.com/2013/08/graphlab-distributed-machine-learning.html"))) (updated nil "2013-08-23T12:00:00Z") (id nil "http://www.allthingsdistributed.com/2013/08/graphlab-distributed-machine-learning") (content ((type . "html")) "<p><img src=\"/images/taipei.jpg\"/ width=\"650\"></p>

<p>The intense travels around the world in the spring have kept me from keeping up on the historical reading that I would like to do, as such there have not been that many suggesting for the back-to-basics reading list. The fall is going be not that much different but I will make an effort to get back into a reading habit.</p>

<p>I want to kick off the fall readings not with an historical paper but with two that detail <a href=\"http://graphlab.org/\">GraphLab</a>, an excellent framework for high performance machine learning that originally has been built by the <a href=\"http://www.cs.washington.edu/people/faculty/guestrin/\">Carlos Guestrin</a> (Carlos is now the Amazon Professor of Machine Learning at UW). GraphLab has been used to build several different data mining and graph processing toolkits and applications. The research in the papers has been performed on Amazon EC2. Instructions for running your own GraphLab Cluster on EC2 can be found <a href=\"http://graphlab.org/tutorials-2/graphlab-on-ec2-cluster-quick-start/#\">here</a></p>

<p><a href=\"http://wv.ly/188LwyK\"><em>Distributed GraphLab: A Framework for Machine Learning and Data Mining in the Cloud</em></a>, Yucheng Low, Joseph Gonzalez, Aapo Kyrola, Danny Bickson, Carlos Guestrin and Joseph M. Hellerstein, Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 8, pp. 716-727 (2012)</p>

<p><a href=\"http://wv.ly/188Mg6W\"><em>PowerGraph: Distributed Graph-Parallel Computation on Natural Graphs</em></a>, Joseph Gonzalez, Yucheng Low, Haijie Gu, Danny Bickson and Carlos Guestrin, Proceedings of the 10th USENIX conference on Operating Systems Design and Implementation, 2012</p>
")) (entry nil (title nil "Making Mobile App Development Easier with Cross Platform Mobile Push") (link ((href . "http://www.allthingsdistributed.com/2013/08/amazon-sns-mobile-push.html"))) (updated nil "2013-08-13T05:30:00Z") (id nil "http://www.allthingsdistributed.com/2013/08/amazon-sns-mobile-push") (content ((type . "html")) "<p>This year as I hosted AWS Summits in 12 different cities around the world, I met thousands of developers who are building powerful new applications for smartphones, tablets and other connected devices, all running mobile cloud backends on AWS.</p>

<p>These developers want to engage their users with timely, dynamic content even when the users haven’t opened their mobile apps.  For example, baseball fans want to know as soon as their favorite team player hits a home run, so they can watch a video replay and catch the rest of the game. The rising proliferation of cheap and powerful sensors means not only apps but smart devices want to communicate important information.  For example, your new car could warn you on your mobile phone when the door is not fully closed, so you can return to lock it properly.</p>

<p>Developers address these use cases with push notifications, which are short messages pushed from a backend server to a specific application on an end user's mobile device.  Push offers similar user experiences to SMS, but with enhanced functionality and at a fraction of the cost.</p>

<p>While we have made it easy to build great mobile apps with AWS that use on-demand, scalable and reliable building blocks like EC2, DynamoDB, SQS and many others, supporting push notifications at large scale remains incredibly complicated for our customers.  Amazon, Apple, and Google each maintains a free relay service that delivers notifications via persistent connections to devices running the platforms they own.  Supporting millions of users on multiple mobile platforms means integrating with each of these platform-specific relay services, thus introducing operational complexity and cost for our customers.</p>

<p>Customers tell us that virtually all use cases for push notifications require an intermediary application to manage security tokens, queue outgoing messages, and abstract platform-specific APIs. Developers have told us that they build and maintain their own intermediary relay applications, even though they find the process of operating these intermediary relay applications to be painful and error prone.  Building these proxy or relay services to be reliable and scalable so that you can push millions of notifications a day is difficult and our customers want us to make it easier.</p>

<p><strong>Announcing Amazon SNS with Mobile Push</strong></p>

<p>Today, we are enhancing <a href=\"http://aws.amazon.com/sns/\">Amazon Simple Notification Service (SNS)</a> with Mobile Push to meet this customer request and support cross platform, device agnostic push notifications to iOS, Android and Kindle mobile devices natively within AWS.  SNS Mobile Push alleviates the need to build and operate one’s own intermediary service, and enables developers to push once, deliver anywhere.  This reduces the cost and complexity for developers, as they do not have to integrate and maintain different versions of the same push software for multiple mobile platforms.  Instead, SNS Mobile Push enables notifications to be delivered directly to everyone who wants to receive them – regardless of which mobile, desktop or connected device they happen to be using.</p>

<p>Developers tell us that managing push notifications at large scale distracts them from building great apps.  In some cases, this work is complex enough that it actually limits what the developers are willing to offer to their customers.  For example, <a href=\"http://www.crittercism.com\">Crittercism</a> tells us that delivering timely push notifications became so burdensome as they grew to touch 600 million devices, that they chose to stop offering push notifications in the past.  They are now able to offer push notifications to their customers again using Amazon SNS and can notify tens of millions of users in a matter of seconds about critical app performance issues.</p>

<p>We chose to enhance Amazon SNS instead of building a separate mobile notification service because Amazon SNS was designed from day 1 to support multiple protocols and delivery methods (Email, SMS, SQS, HTTP etc.) and already operates at a massive scale delivering billions of notifications every day over these delivery methods.</p>

<p>By leveraging the scale of AWS and the existing SNS technology, we are able to offer the same cost effective prices for Mobile Push that we offer for Amazon SNS. Customers can send their first million notifications per month for free and then pay only for what they use beyond that, at $1.00 per million push notifications ($0.50 per million publishes and $0.50 per million push deliveries).  They can use Mobile Push to target unique messages to individual devices, or broadcast identical messages to multiple devices at once.</p>

<p>Customers tell us SNS Mobile Push offers lower costs and operational burden, in addition to powerful scale and speed.  For instance, <a href=\"http://www.earthnetworks.com/\">Earth Networks</a> used to build and manage its own push infrastructure but has now migrated to SNS Mobile Push because Amazon SNS Mobile Push is less expensive than the self-managed service they used to operate.</p>

<p>To get started right away for free with Amazon SNS Mobile Push, visit <a href=\"http://aws.amazon.com/sns\">http://aws.amazon.com/sns</a>.  For more information, please see the <a href=\"http://aws.amazon.com/documentation/sns/\">Amazon SNS documentation</a>, including a getting started guide and reference apps for each mobile platform.</p>
")) (entry nil (title nil "Feeling the Customer Love for AWS") (link ((href . "http://www.allthingsdistributed.com/2013/07/Astro-loves-AWS.html"))) (updated nil "2013-07-19T11:00:00Z") (id nil "http://www.allthingsdistributed.com/2013/07/Astro-loves-AWS") (content ((type . "html")) "<p>We work hard to meet our customer's expectations and to continue to innovate on their behalf. This week at the Singapore AWS Summit we were fortunate that our customers Astro Radio from Kuala Lumpur were willing to join us on stage. Jayaram Gopinath Nagaraj and Kavitha Doraimaickam gave a truly electrifying presentation about how AWS has transformed their radio stations. They also brought with them a video that showed their appreciation on how we enable them to innovate. It's humbling and fun at the same time.</p>

<iframe src=\"http://player.vimeo.com/video/70622714\" width=\"650\" height=\"365\" frameborder=\"0\" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>



")) (entry nil (title nil "AWS re:Invent 2013") (link ((href . "http://www.allthingsdistributed.com/2013/07/aws-reinvent-2013.html"))) (updated nil "2013-07-17T17:00:00Z") (id nil "http://www.allthingsdistributed.com/2013/07/aws-reinvent-2013") (content ((type . "html")) "<p><img src=\"/images/reinvent2012.jpg\"/ width=\"650\"></p>

<p>The <a href=\"http://reinvent.awsevents.com\">AWS re:Invent</a> user conference <a href=\"http://reinvent.awsevents.com/recap.html\">last year</a> in Las Vegas was by many described as the best technology conference they had been to in a long time. We had worked hard to give you great keynote sessions as well as deep technical content by AWS engineers, partners and customers.</p>

<p>This year we will again work hard to create a conference that will exceed your expectations of a conference that is unique in its high quality content and engagement.You can choose from 175+ sessions, training bootcamps, hands-on labs, and hackathons to gain deeper skills and knowledge of the AWS Cloud. Bring your entire executive and technical teams and walk away with the skills and knowledge to refine your cloud strategy, improve developer productivity, increase application performance and security, and reduce infrastructure costs.</p>

<p>The registration for AWS re:Invent is now open at <a href=\"https://reinvent.awsevents.com/?sc_ichannel=SM&amp;sc_iplace=wernerblog_text_link&amp;sc_icampaigntype=event&amp;sc_icampaign=sm_reinvent2013_register_now&amp;sc_icountry=US&amp;TRK=SM_reinvent2013_wernerblog_text_link_reg\">this site</a>. Sign up before it is too late...</p>

<p>As a taste of what re:Invent is like here is the fireside chat I did last year with Jeff Bezos:</p>

<iframe width=\"640\" height=\"360\" src=\"//www.youtube.com/embed/O4MtQGRIIuA?rel=0\" frameborder=\"0\" allowfullscreen></iframe>



")) (entry nil (title nil "Exerting Fine Grain Control Over Your Cloud Resources") (link ((href . "http://www.allthingsdistributed.com/2013/07/ec2-rds-resource-permissions.html"))) (updated nil "2013-07-07T18:30:00Z") (id nil "http://www.allthingsdistributed.com/2013/07/ec2-rds-resource-permissions") (content ((type . "html")) "<p>I am thrilled that now both Amazon EC2 and Amazon RDS support resource-level permissions. As customers move increasing amounts of compute and database workloads over to AWS, they have expressed an increased desire for finer grain control over their underlying resources. You can now use these new features to define the permissions your AWS IAM users (and applications) have to perform actions on specific or groups of Amazon EC2 and Amazon RDS resources.</p>

<p>You can apply user-defined tags to your EC2 and RDS resources to help organize resources according to whatever schema is most relevant for a particular organization – be it an application stack, an organization unit, a cost center, or any other schema that might be appropriate. These user-defined tags can already be used to generate detailed chargeback reports that provide a view into the costs associated with these resources.  And now these user-defined tags can also be used to create AWS IAM policies to define which users have permissions to use the resources that have certain tags associated with them.</p>

<p>For example, you can mandate that only Senior Database Administrators in your company can modify  “production” Amazon RDS DB instances. You do this by first tagging the relevant Amazon RDS DB instance resources as “production” instances, then creating an AWS IAM policy that permits the modify action on these “production” instances, and finally assigning the AWS IAM policy to your group of AWS IAM users who are Senior Database Administrators.</p>

<p>Additionally, you can set policies such as the following:</p>

<ul>
<li>Only certain users can terminate “production” EC2 or RDS instances</li>
<li>Only certain EBS volumes can be attached or detached from certain EC2 instances</li>
<li>Users can only stop or terminate EC2 instances that are tagged with their username</li>
<li>Only certain users can create larger RDS instances (e.g. M2.4Xlarge)</li>
<li>Only certain database engines, parameter groups and security groups can be used by users when they create RDS DB instances</li>
<li>Only certain users can create RDS instances that are Multi-AZ and PIOPs enabled</li>
</ul>


<p>Because AWS provides customers with fundamental infrastructure building blocks, there are a wide range of additional policy scenarios that you can support using tools like IAM, tags, and resource-level permission.  And our development teams are already hard at work on the next wave of features to extend our support for setting and managing resource-level permissions, so expect even more tools to help control your AWS resources soon.</p>
")) (entry nil (title nil "Back-to-Basics Weekend Reading - Auctions and bidding: A guide for computer scientists") (link ((href . "http://www.allthingsdistributed.com/2013/06/auctions-and-bidding.html"))) (updated nil "2013-06-08T18:00:00Z") (id nil "http://www.allthingsdistributed.com/2013/06/auctions-and-bidding") (content ((type . "html")) "<p><img src=\"/images/auckland.jpg\"/ width=\"650\"></p>

<p>I have just returned from the AWS Summits in New Zealand and Japan, which were both very well attended and, according to the feedback, very successful. While I was in New Zealand I had great discussion with the folks from <a href=\"http://www.trademe.co.nz/\">Trade Me</a>, the auction site which according to some counts for 70% of all NZ internet traffic. This resulted in some deep technical conversations later, over beer, with some colleagues and customers about the principles behinds different auction and bidding styles. I noticed that my basic knowledge there was rather rusty and I have decided to use this weekend to go a bit more in-depth in the various styles and techniques. An ideal paper for this is the survey by Parsons, Rodriquez-Aguilar and Klein, as it writing style brings economists and computer scientists together.</p>

<blockquote><p><em>There is a veritable menagerie of auctions — single dimensional, multi-dimensional, single sided, double sided, ﬁrst price, second price, English, Dutch, Japanese, sealed bid — and these have been extensively discussed and analysed in the economics literature. The main purpose of this paper is to survey this literature from a computer science perspective, primarily from the viewpoint of computer scientists who are interested in learning about auction theory, and to provide pointers into the economics literature for those who want a deeper technical understanding. In addition, since auctions are an increasingly important topic in computer science, we also look at work on auctions from the computer science literature. Overall, our aim is to identifying what both these bodies of work these tell us about creating electronic auctions.</em></p></blockquote>

<p><a href=\"http://wv.ly/19Tn3RZ\"><em>Auctions and bidding: A guide for computer scientists</em></a>, Simon Parsons, Juan A. Rodriguez-Aguilar and Mark Klein, ACM Computing Surveys (CSUR), Volume 43 Issue 2, January 2011</p>
")))) ("Customer Centricity at Amazon Web Services" "<p>In the <a href=\"http://phx.corporate-ir.net/External.File?item=UGFyZW50SUQ9MTc5ODc4fENoaWxkSUQ9LTF8VHlwZT0z&amp;t=1\">2013 Amazon Shareholder letter</a>, Jeff Bezos spent time explaining the decision to pursue a customer-centric way in our business.</p>
<blockquote><p><em>As regular readers of this letter will know, our energy at Amazon comes from the desire to impress customers rather than the zeal to best competitors. We don’t take a view on which of these approaches is more likely to maximize business success. There are pros and cons to both and many examples of highly successful competitor-focused companies. We do work to pay attention to competitors and be inspired by them, but it is a fact that the customer-centric way is at this point a defining element of our culture.</em></p></blockquote>
<p>AWS has built a reputation over the years for the breadth and depth of our services and the pace of our innovation with 280 features released in 2013.  One area we don’t spend a lot of time discussing is the significant investments we’ve made in building a World Class Customer Service and Technical Support function.  These are the people working behind the scenes helping customers fully leverage all of AWS’s capabilities when running their infrastructure on AWS.  We launched <a href=\"http://aws.amazon.com/premiumsupport/\">AWS Support</a> in 2009 and since the launch the mission has remained constant: to help customers of all sizes and technical abilities to successfully utilize the products and features provided by AWS.</p>
<p>Customers are frequently surprised to hear we have a Support organization that not only helps customers via email, phone, chat or web cases, but also builds innovative software to deliver better customer experiences. In recent years, this team has released technology such as Support for Health Checks, AWS Trusted Advisor, Support API’s, Trusted Advisor API’s, and many more.  One customer facing feature Jeff highlighted in the Shareholder letter was <a href=\"https://aws.amazon.com/premiumsupport/trustedadvisor/\">AWS Trusted Advisor</a> which is a tool that our support organization built to move support from reactive help to proactive, preventative help.</p>
<blockquote><p><em>I can keep going – Kindle Fire’s FreeTime, our customer service Andon Cord, Amazon MP3’s AutoRip – but will finish up with a very clear example of internally driven motivation: Amazon Web Services. In 2012,AWS announced 159 new features and services. We’ve reduced AWS prices 27 times since launching 7 years ago, added enterprise service support enhancements, and created innovative tools to help customers be more efficient. AWS Trusted Advisor monitors customer configurations, compares them to known best practices, and then notifies customers where opportunities exist to improve performance, enhance security, or save money. Yes, we are actively telling customers they’re paying us more than they need to. In the last 90 days, customers have saved millions of dollars through Trusted Advisor, and the service is only getting started. All of this progress comes in the context of AWS being the widely recognized leader in its area – a situation where you might worry that external motivation could fail. On the other hand, internal motivation – the drive to get the customer to say “Wow” – keeps the pace of innovation fast.</em></p></blockquote>
<p>We’ve always focused on getting highly skilled support engineers with all hires requiring the same technical certification process (Tech Bar Raisers) as any of our developers building services.  Over the years, we have scaled the AWS Support organization to meet customer need from a team with heavy Linux Sys Admin with strong Networking skills in one location to a large global team, located in 17 locations around the world with Windows Sys Admins, Networking Engineers, DBAs, Security Specialists, Developers, and many more specializations.  In 2013, we spent a lot of time developing sophisticated internal tools that make supporting our customers more efficient including intelligent skills based case routing tools that provide in-depth technical information to engineers that help address customer needs.  Our customers tell us that the service is 78% better than it was 3 years ago.</p>
<p>Our customers can feel confident that AWS will work every day to deliver World Class Support for our customers.  I wanted to share a new video with you where our customers discuss this critical behind the scenes function in a little more detail. After watching, I believe that you will have a better perspective on our mission, our support options, and the benefits that our customers derive from their use of AWS Support:</p>
<iframe width=\"640\" height=\"360\" src=\"//www.youtube.com/embed/Ar3Q-cJehyg\" frameborder=\"0\" allowfullscreen></iframe>" "http://www.allthingsdistributed.com/2014/02/customer-centricity-at-aws.html" (21232 36848) old 1 nil nil ((title nil "Customer Centricity at Amazon Web Services") (link ((href . "http://www.allthingsdistributed.com/2014/02/customer-centricity-at-aws.html"))) (updated nil "2014-02-04T07:00:00Z") (id nil "http://www.allthingsdistributed.com/2014/02/customer-centricity-at-aws") (content ((type . "html")) "<p>In the <a href=\"http://phx.corporate-ir.net/External.File?item=UGFyZW50SUQ9MTc5ODc4fENoaWxkSUQ9LTF8VHlwZT0z&amp;t=1\">2013 Amazon Shareholder letter</a>, Jeff Bezos spent time explaining the decision to pursue a customer-centric way in our business.</p>

<blockquote><p><em>As regular readers of this letter will know, our energy at Amazon comes from the desire to impress customers rather than the zeal to best competitors. We don’t take a view on which of these approaches is more likely to maximize business success. There are pros and cons to both and many examples of highly successful competitor-focused companies. We do work to pay attention to competitors and be inspired by them, but it is a fact that the customer-centric way is at this point a defining element of our culture.</em></p></blockquote>

<p>AWS has built a reputation over the years for the breadth and depth of our services and the pace of our innovation with 280 features released in 2013.  One area we don’t spend a lot of time discussing is the significant investments we’ve made in building a World Class Customer Service and Technical Support function.  These are the people working behind the scenes helping customers fully leverage all of AWS’s capabilities when running their infrastructure on AWS.  We launched <a href=\"http://aws.amazon.com/premiumsupport/\">AWS Support</a> in 2009 and since the launch the mission has remained constant: to help customers of all sizes and technical abilities to successfully utilize the products and features provided by AWS.</p>

<p>Customers are frequently surprised to hear we have a Support organization that not only helps customers via email, phone, chat or web cases, but also builds innovative software to deliver better customer experiences. In recent years, this team has released technology such as Support for Health Checks, AWS Trusted Advisor, Support API’s, Trusted Advisor API’s, and many more.  One customer facing feature Jeff highlighted in the Shareholder letter was <a href=\"https://aws.amazon.com/premiumsupport/trustedadvisor/\">AWS Trusted Advisor</a> which is a tool that our support organization built to move support from reactive help to proactive, preventative help.</p>

<blockquote><p><em>I can keep going – Kindle Fire’s FreeTime, our customer service Andon Cord, Amazon MP3’s AutoRip – but will finish up with a very clear example of internally driven motivation: Amazon Web Services. In 2012,AWS announced 159 new features and services. We’ve reduced AWS prices 27 times since launching 7 years ago, added enterprise service support enhancements, and created innovative tools to help customers be more efficient. AWS Trusted Advisor monitors customer configurations, compares them to known best practices, and then notifies customers where opportunities exist to improve performance, enhance security, or save money. Yes, we are actively telling customers they’re paying us more than they need to. In the last 90 days, customers have saved millions of dollars through Trusted Advisor, and the service is only getting started. All of this progress comes in the context of AWS being the widely recognized leader in its area – a situation where you might worry that external motivation could fail. On the other hand, internal motivation – the drive to get the customer to say “Wow” – keeps the pace of innovation fast.</em></p></blockquote>

<p>We’ve always focused on getting highly skilled support engineers with all hires requiring the same technical certification process (Tech Bar Raisers) as any of our developers building services.  Over the years, we have scaled the AWS Support organization to meet customer need from a team with heavy Linux Sys Admin with strong Networking skills in one location to a large global team, located in 17 locations around the world with Windows Sys Admins, Networking Engineers, DBAs, Security Specialists, Developers, and many more specializations.  In 2013, we spent a lot of time developing sophisticated internal tools that make supporting our customers more efficient including intelligent skills based case routing tools that provide in-depth technical information to engineers that help address customer needs.  Our customers tell us that the service is 78% better than it was 3 years ago.</p>

<p>Our customers can feel confident that AWS will work every day to deliver World Class Support for our customers.  I wanted to share a new video with you where our customers discuss this critical behind the scenes function in a little more detail. After watching, I believe that you will have a better perspective on our mission, our support options, and the benefits that our customers derive from their use of AWS Support:</p>

<iframe width=\"640\" height=\"360\" src=\"//www.youtube.com/embed/Ar3Q-cJehyg\" frameborder=\"0\" allowfullscreen></iframe>

"))) ("Updated Lampson's Hints for Computer Systems Design" "<p>This year I have not been able to publish many back-to-basics readings, so I will not close the year with a recap of those. Instead I have a video of a wonderful presentation by <a href=\"http://research.microsoft.com/en-us/um/people/blampson/\">Butler Lampson</a> where he talks about the learnings of the past decades that helped him to update his excellent 1983 \"<a href=\"http://research.microsoft.com/en-us/um/people/blampson/33-hints/WebPage.html\">Hints for computer system design</a>\".</p>
<p>The presentation was part of the <a href=\"http://www.heidelberg-laureate-forum.org/\">Heidelberg Laureate Forum</a> helt in September of this year. At the Forum many of the Abel, Fields and Turing Laureates held presentations. Our most famous computer scientists like Fernando Carbato, Stephen Cook,  Edward Feigenbaum, Juris Hartmanis, John Hopcroft, Alan Kay, Vinton Cerf, etc. were all at the Forum. You can find a list of selected video presentation <a href=\"http://www.heidelberg-laureate-forum.org/event_2013/\">here</a></p>
<p>For me the highight was Butler's <a href=\"http://www.heidelberg-laureate-forum.org/blog/video/lecture-friday-september-27-butler-w-lampson/\">presentation</a> on Hints and Principles for Computer Science Design. I include it here as it is absolutely worth watching.</p>
<iframe width=\"650\" height=\"487\" frameborder=\"0\" scrolling=\"auto\" marginheight=\"0\" marginwidth=\"0\" src=\"http://hits.mediasite.com/mediasite/Play/0bc53975278d41209e3aa847e867b54c1d\"></iframe>" "http://www.allthingsdistributed.com/2013/12/updated-hints.html" (21176 38464) old 2 nil nil ((title nil "Updated Lampson's Hints for Computer Systems Design") (link ((href . "http://www.allthingsdistributed.com/2013/12/updated-hints.html"))) (updated nil "2013-12-23T20:00:00Z") (id nil "http://www.allthingsdistributed.com/2013/12/updated-hints") (content ((type . "html")) "<p>This year I have not been able to publish many back-to-basics readings, so I will not close the year with a recap of those. Instead I have a video of a wonderful presentation by <a href=\"http://research.microsoft.com/en-us/um/people/blampson/\">Butler Lampson</a> where he talks about the learnings of the past decades that helped him to update his excellent 1983 \"<a href=\"http://research.microsoft.com/en-us/um/people/blampson/33-hints/WebPage.html\">Hints for computer system design</a>\".</p>

<p>The presentation was part of the <a href=\"http://www.heidelberg-laureate-forum.org/\">Heidelberg Laureate Forum</a> helt in September of this year. At the Forum many of the Abel, Fields and Turing Laureates held presentations. Our most famous computer scientists like Fernando Carbato, Stephen Cook,  Edward Feigenbaum, Juris Hartmanis, John Hopcroft, Alan Kay, Vinton Cerf, etc. were all at the Forum. You can find a list of selected video presentation <a href=\"http://www.heidelberg-laureate-forum.org/event_2013/\">here</a></p>

<p>For me the highight was Butler's <a href=\"http://www.heidelberg-laureate-forum.org/blog/video/lecture-friday-september-27-butler-w-lampson/\">presentation</a> on Hints and Principles for Computer Science Design. I include it here as it is absolutely worth watching.</p>

<iframe width=\"650\" height=\"487\" frameborder=\"0\" scrolling=\"auto\" marginheight=\"0\" marginwidth=\"0\" src=\"http://hits.mediasite.com/mediasite/Play/0bc53975278d41209e3aa847e867b54c1d\"></iframe>

"))) ("Taking DynamoDB beyond Key-Value: Now with Faster, More Flexible, More Powerful Query Capabilities" "<p>We launched <a href=\"http://aws.amazon.com/dynamodb\">DynamoDB</a> last year to address the need for a cloud database that provides seamless scalability, irrespective of whether you are doing ten transactions or ten million transactions, while providing rock solid durability and availability. Our vision from the day we conceived DynamoDB was to fulfil this need without limiting the query functionality that people have come to expect from a database. However, we also knew that building a distributed database that has unlimited scale and maintains predictably high performance while providing rich and flexible query capabilities, is one of the hardest problems in database development, and will take a lot of effort and invention from our team of distributed database engineers to solve. So when we launched in January 2012, we provided simple query functionality that used hash primary keys or composite primary keys (hash + range). Since then, we have been working on adding flexible querying. You saw the first iteration in April 2013 with the launch of <a href=\"http://aws.typepad.com/aws/2013/04/local-secondary-indexes-for-amazon-dynamodb.html\">Local Secondary Indexes</a> (LSI). Today, I am thrilled to announce a fundamental expansion of the query capabilities of DynamoDB with the launch of <em>Global Secondary Indexes</em> (GSI). This new capability allows indexing any attribute (column) of a DynamoDB table and performing high-performance queries at any table scale.</p>
<p><strong>Going beyond Key-Value</strong></p>
<p>Advanced Key-value data stores such as DynamoDB achieve high scalability on loosely coupled clusters by using the primary key as the partitioning key to distribute data across nodes. Even though the resulting query functionality may appear more limiting than a relational database on a cursory examination, it works exceedingly well for a wide range of applications as evident from DynamoDB's rapid growth and adoption by customers like Electronic Arts, Scopley, HasOffers, SmugMug, AdRoll, Dropcam, Digg and by many teams at Amazon.com (Cloud Drive, Retail). DynamoDB continues to be embraced for workloads in Gaming, Ad-tech, Mobile, Web Apps, and other segments where scale and performance are critical. At Amazon.com, we increasingly default to DynamoDB instead of using relational databases when we don’t need complex query, table join and transaction capabilities, as it offers a more available, more scalable and ultimately a lower cost solution.</p>
<p>For non-primary key access in advanced key-value stores, a user has to resort to either maintaining a separate table or some form of scatter-gather query across partitions. Both these options are less than ideal. For instance, maintaining a separate table for indexes forces users to maintain consistency between the primary key table and the index tables. On the other hand, with a scatter gather query, as the dataset grows, the query must be scattered more and more resulting in poor performance over time. DynamoDB's new Global Secondary Indexes remove this fundamental restriction by allowing \"scaled out\" indexes without ever requiring any book-keeping on behalf of the developer. Now you can run queries on any item attributes (columns) in your DynamoDB table. Moreover, a GSI's performance is designed to meet DynamoDB's single digit millisecond latency - you can add items to a Users table for a gaming app with tens of millions of users with UserId as the primary key, but retrieve them based on their home city, with no reduction in query performance.</p>
<p><strong>DynamoDB Refresher</strong></p>
<p>DynamoDB stores information as database tables, which are collections of individual items. Each item is a collection of data attributes. The items are analogous to rows in a spreadsheet, and the attributes are analogous to columns. Each item is uniquely identified by a primary key, which is composed of its first two attributes, called the hash and range. DynamoDB queries refer to the hash and range attributes of items you’d like to access. These query capabilities so far have been based on the default primary index and optional local secondary indexes of a DynamoDB table:</p>
<ul>
<li><em>Primary Index</em>: Customers can choose from two types of keys for primary index querying: Simple Hash Keys and Composite Hash Key / Range Keys. Simple Hash Key gives DynamoDB the Distributed Hash Table abstraction. The key is hashed over the different partitions to optimize workload distribution. For more background on this please read <a href=\"http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf\">the original Dynamo paper</a>. Composite Hash Key with Range Key allows the developer to create a primary key that is the composite of two attributes, a “hash attribute” and a “range attribute.” When querying against a composite key, the hash attribute needs to be uniquely matched but a range operation can be specified for the range attribute: e.g. all orders from Werner in the past 24 hours, or all games played by an individual player in the past 24 hours.</li>
<li><em>Local Secondary Index</em>: Local Secondary Indexes allow the developer to create indexes on non-primary key attributes and quickly retrieve records within a hash partition (i.e., items that share the same hash value in their primary key): e.g. if there is a DynamoDB table with PlayerName as the hash key and GameStartTime as the range key, you can use local secondary indexes to run efficient queries on other attributes like “Score.” Query “Show me John’s all-time top 5 scores” will return results automatically ordered by score.</li>
</ul>
<p><strong>What are Global Secondary Indexes?</strong></p>
<p>Global secondary indexes allow you to efficiently query over the whole DynamoDB table, not just within a partition as local secondary indexes, using any attributes (columns), even as the DynamoDB table horizontally scales to accommodate your needs. Let’s walk through another gaming example. Consider a table named GameScores that keeps track of users and scores for a mobile gaming application. Each item in GameScores is identified by a hash key (UserId) and a range key (GameTitle). The following diagram shows how the items in the table would be organized. (Not all of the attributes are shown)</p>
<p><img src=\"/images/gsi1.png\"/ width=\"650\"></p>
<p>Now suppose that you wanted to write a leaderboard application to display top scores for each game. A query that specified the key attributes (UserId and GameTitle) would be very efficient; however, if the application needed to retrieve data from GameScores based on GameTitle only, it would need to use a Scan operation. As more items are added to the table, scans of all the data would become slow and inefficient, making it difficult to answer questions such as</p>
<ul>
<li>What is the top score ever recorded for the game \"Meteor Blasters\"?</li>
<li>Which user had the highest score for \"Galaxy Invaders\"?</li>
<li>What was the highest ratio of wins vs. losses?</li>
</ul>
<p>To speed up queries on non-key attributes, you can specify global secondary indexes. For example, you could create a global secondary index named GameTitleIndex, with a hash key of GameTitle and a range key of TopScore. Since the table's primary key attributes are always projected into an index, the UserId attribute is also present. The following diagram shows what GameTitleIndex index would look like:</p>
<p><img src=\"/images/gsi2.png\"/></p>
<p>Now you can query GameTitleIndex and easily obtain the scores for \"Meteor Blasters\". The results are ordered by the range key, TopScore.</p>
<p><strong>Efficient Queries</strong></p>
<p>Traditionally, databases have been scaled as a whole –tables and indexes together. While this may appear simple, it masked the underlying complexity of varying needs for different types of queries and consequently different indexes, which resulted in wasted resources. With global secondary indexes in DynamoDB, you can now have many indexes and tune their capacity independently. These indexes also provide query/cost flexibility, allowing a custom level of clustering to be defined per index.  Developers can specify which attributes should be “projected” to the secondary index, allowing faster access to often-accessed data, while avoiding extra read/write costs for other attributes.</p>
<p><strong>Start with DynamoDB</strong></p>
<p>The enhanced query flexibility that global and local secondary indexes provide means DynamoDB can support an even broader range of workloads. When designing a new application that will operate in the AWS cloud, first take a look at DynamoDB when selecting a database. If you don’t need the table join capabilities of relational databases, you will be better served from a cost, availability and performance standpoint by using DynamoDB. If you need support for transactions, use the recently released <a href=\"http://aws.typepad.com/aws/2013/07/dynamodb-transaction-library.html\">transaction library</a>. You can also use GSI features with <a href=\"http://aws.typepad.com/aws/2013/09/dynamodb-local-for-desktop-development.html\">DynamoDB Local</a> for offline development of your application. As your application becomes popular and goes from being used by thousands of users to millions or even tens of millions of users, you will not have to worry about the typical performance or availability bottlenecks applications face from relational databases that require application re-architecture. You can simply dial up the provisioned throughput that your app needs from DynamoDB and we will take care of the rest without any impact on the performance of your app.</p>
<p><a href=\"http://www.dropcam.com\">Dropcam</a> tells us that they adopted DynamoDB for seamless scalability and performance as they continue to innovate on their cloud based monitoring platform which has grown to become one of the largest video platforms on the internet today. With GSIs, they do not have to choose between scalability and query flexibility and instead can get both out of their database. <a href=\"http://www.guerrilla-games.com/\">Guerrilla Games</a>, the developer of Killzone Shadow Fall uses DynamoDB for online multiplayer leaderboards and game settings. They will be leveraging GSIs to add more features and increase database performance. Also, <a href=\"http://www.bizo.com\">Bizo</a>, a B2B digital marketing platform, uses DynamoDB for audience targeting. GSIs will enable lookups using evolving criterion across multiple datasets.</p>
<p>These are just a few examples where GSIs can help and I am looking forward to our customers building scalable businesses with DynamoDB. I want application writers to focus on their business logic, leaving the heavy-lifting of maintaining consistency across look-up attributes to DynamoDB. To learn more see <a href=\"http://aws.typepad.com/aws/2013/12/now-available-global-secondary-indexes-for-amazon-dynamodb.html\">Jeff Barr’s blog</a> and the <a href=\"http://aws.amazon.com/documentation/dynamodb/\">DynamoDB developer guide</a>.</p>" "http://www.allthingsdistributed.com/2013/12/dynamodb-global-secondary-indexes.html" (21161 27904) old 3 nil nil ((title nil "Taking DynamoDB beyond Key-Value: Now with Faster, More Flexible, More Powerful Query Capabilities") (link ((href . "http://www.allthingsdistributed.com/2013/12/dynamodb-global-secondary-indexes.html"))) (updated nil "2013-12-12T08:00:00Z") (id nil "http://www.allthingsdistributed.com/2013/12/dynamodb-global-secondary-indexes") (content ((type . "html")) "<p>We launched <a href=\"http://aws.amazon.com/dynamodb\">DynamoDB</a> last year to address the need for a cloud database that provides seamless scalability, irrespective of whether you are doing ten transactions or ten million transactions, while providing rock solid durability and availability. Our vision from the day we conceived DynamoDB was to fulfil this need without limiting the query functionality that people have come to expect from a database. However, we also knew that building a distributed database that has unlimited scale and maintains predictably high performance while providing rich and flexible query capabilities, is one of the hardest problems in database development, and will take a lot of effort and invention from our team of distributed database engineers to solve. So when we launched in January 2012, we provided simple query functionality that used hash primary keys or composite primary keys (hash + range). Since then, we have been working on adding flexible querying. You saw the first iteration in April 2013 with the launch of <a href=\"http://aws.typepad.com/aws/2013/04/local-secondary-indexes-for-amazon-dynamodb.html\">Local Secondary Indexes</a> (LSI). Today, I am thrilled to announce a fundamental expansion of the query capabilities of DynamoDB with the launch of <em>Global Secondary Indexes</em> (GSI). This new capability allows indexing any attribute (column) of a DynamoDB table and performing high-performance queries at any table scale.</p>

<p><strong>Going beyond Key-Value</strong></p>

<p>Advanced Key-value data stores such as DynamoDB achieve high scalability on loosely coupled clusters by using the primary key as the partitioning key to distribute data across nodes. Even though the resulting query functionality may appear more limiting than a relational database on a cursory examination, it works exceedingly well for a wide range of applications as evident from DynamoDB's rapid growth and adoption by customers like Electronic Arts, Scopley, HasOffers, SmugMug, AdRoll, Dropcam, Digg and by many teams at Amazon.com (Cloud Drive, Retail). DynamoDB continues to be embraced for workloads in Gaming, Ad-tech, Mobile, Web Apps, and other segments where scale and performance are critical. At Amazon.com, we increasingly default to DynamoDB instead of using relational databases when we don’t need complex query, table join and transaction capabilities, as it offers a more available, more scalable and ultimately a lower cost solution.</p>

<p>For non-primary key access in advanced key-value stores, a user has to resort to either maintaining a separate table or some form of scatter-gather query across partitions. Both these options are less than ideal. For instance, maintaining a separate table for indexes forces users to maintain consistency between the primary key table and the index tables. On the other hand, with a scatter gather query, as the dataset grows, the query must be scattered more and more resulting in poor performance over time. DynamoDB's new Global Secondary Indexes remove this fundamental restriction by allowing \"scaled out\" indexes without ever requiring any book-keeping on behalf of the developer. Now you can run queries on any item attributes (columns) in your DynamoDB table. Moreover, a GSI's performance is designed to meet DynamoDB's single digit millisecond latency - you can add items to a Users table for a gaming app with tens of millions of users with UserId as the primary key, but retrieve them based on their home city, with no reduction in query performance.</p>

<p><strong>DynamoDB Refresher</strong></p>

<p>DynamoDB stores information as database tables, which are collections of individual items. Each item is a collection of data attributes. The items are analogous to rows in a spreadsheet, and the attributes are analogous to columns. Each item is uniquely identified by a primary key, which is composed of its first two attributes, called the hash and range. DynamoDB queries refer to the hash and range attributes of items you’d like to access. These query capabilities so far have been based on the default primary index and optional local secondary indexes of a DynamoDB table:</p>

<ul>
<li><em>Primary Index</em>: Customers can choose from two types of keys for primary index querying: Simple Hash Keys and Composite Hash Key / Range Keys. Simple Hash Key gives DynamoDB the Distributed Hash Table abstraction. The key is hashed over the different partitions to optimize workload distribution. For more background on this please read <a href=\"http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf\">the original Dynamo paper</a>. Composite Hash Key with Range Key allows the developer to create a primary key that is the composite of two attributes, a “hash attribute” and a “range attribute.” When querying against a composite key, the hash attribute needs to be uniquely matched but a range operation can be specified for the range attribute: e.g. all orders from Werner in the past 24 hours, or all games played by an individual player in the past 24 hours.</li>
<li><em>Local Secondary Index</em>: Local Secondary Indexes allow the developer to create indexes on non-primary key attributes and quickly retrieve records within a hash partition (i.e., items that share the same hash value in their primary key): e.g. if there is a DynamoDB table with PlayerName as the hash key and GameStartTime as the range key, you can use local secondary indexes to run efficient queries on other attributes like “Score.” Query “Show me John’s all-time top 5 scores” will return results automatically ordered by score.</li>
</ul>


<p><strong>What are Global Secondary Indexes?</strong></p>

<p>Global secondary indexes allow you to efficiently query over the whole DynamoDB table, not just within a partition as local secondary indexes, using any attributes (columns), even as the DynamoDB table horizontally scales to accommodate your needs. Let’s walk through another gaming example. Consider a table named GameScores that keeps track of users and scores for a mobile gaming application. Each item in GameScores is identified by a hash key (UserId) and a range key (GameTitle). The following diagram shows how the items in the table would be organized. (Not all of the attributes are shown)</p>

<p><img src=\"/images/gsi1.png\"/ width=\"650\"></p>

<p>Now suppose that you wanted to write a leaderboard application to display top scores for each game. A query that specified the key attributes (UserId and GameTitle) would be very efficient; however, if the application needed to retrieve data from GameScores based on GameTitle only, it would need to use a Scan operation. As more items are added to the table, scans of all the data would become slow and inefficient, making it difficult to answer questions such as</p>

<ul>
<li>What is the top score ever recorded for the game \"Meteor Blasters\"?</li>
<li>Which user had the highest score for \"Galaxy Invaders\"?</li>
<li>What was the highest ratio of wins vs. losses?</li>
</ul>


<p>To speed up queries on non-key attributes, you can specify global secondary indexes. For example, you could create a global secondary index named GameTitleIndex, with a hash key of GameTitle and a range key of TopScore. Since the table's primary key attributes are always projected into an index, the UserId attribute is also present. The following diagram shows what GameTitleIndex index would look like:</p>

<p><img src=\"/images/gsi2.png\"/></p>

<p>Now you can query GameTitleIndex and easily obtain the scores for \"Meteor Blasters\". The results are ordered by the range key, TopScore.</p>

<p><strong>Efficient Queries</strong></p>

<p>Traditionally, databases have been scaled as a whole –tables and indexes together. While this may appear simple, it masked the underlying complexity of varying needs for different types of queries and consequently different indexes, which resulted in wasted resources. With global secondary indexes in DynamoDB, you can now have many indexes and tune their capacity independently. These indexes also provide query/cost flexibility, allowing a custom level of clustering to be defined per index.  Developers can specify which attributes should be “projected” to the secondary index, allowing faster access to often-accessed data, while avoiding extra read/write costs for other attributes.</p>

<p><strong>Start with DynamoDB</strong></p>

<p>The enhanced query flexibility that global and local secondary indexes provide means DynamoDB can support an even broader range of workloads. When designing a new application that will operate in the AWS cloud, first take a look at DynamoDB when selecting a database. If you don’t need the table join capabilities of relational databases, you will be better served from a cost, availability and performance standpoint by using DynamoDB. If you need support for transactions, use the recently released <a href=\"http://aws.typepad.com/aws/2013/07/dynamodb-transaction-library.html\">transaction library</a>. You can also use GSI features with <a href=\"http://aws.typepad.com/aws/2013/09/dynamodb-local-for-desktop-development.html\">DynamoDB Local</a> for offline development of your application. As your application becomes popular and goes from being used by thousands of users to millions or even tens of millions of users, you will not have to worry about the typical performance or availability bottlenecks applications face from relational databases that require application re-architecture. You can simply dial up the provisioned throughput that your app needs from DynamoDB and we will take care of the rest without any impact on the performance of your app.</p>

<p><a href=\"http://www.dropcam.com\">Dropcam</a> tells us that they adopted DynamoDB for seamless scalability and performance as they continue to innovate on their cloud based monitoring platform which has grown to become one of the largest video platforms on the internet today. With GSIs, they do not have to choose between scalability and query flexibility and instead can get both out of their database. <a href=\"http://www.guerrilla-games.com/\">Guerrilla Games</a>, the developer of Killzone Shadow Fall uses DynamoDB for online multiplayer leaderboards and game settings. They will be leveraging GSIs to add more features and increase database performance. Also, <a href=\"http://www.bizo.com\">Bizo</a>, a B2B digital marketing platform, uses DynamoDB for audience targeting. GSIs will enable lookups using evolving criterion across multiple datasets.</p>

<p>These are just a few examples where GSIs can help and I am looking forward to our customers building scalable businesses with DynamoDB. I want application writers to focus on their business logic, leaving the heavy-lifting of maintaining consistency across look-up attributes to DynamoDB. To learn more see <a href=\"http://aws.typepad.com/aws/2013/12/now-available-global-secondary-indexes-for-amazon-dynamodb.html\">Jeff Barr’s blog</a> and the <a href=\"http://aws.amazon.com/documentation/dynamodb/\">DynamoDB developer guide</a>.</p>
"))) ("Expanding the Cloud: Enabling Globally Distributed Applications and Disaster Recovery" "<p>As I discussed in my <a href=\"https://www.youtube.com/watch?v=Waq8Y6s1Cjs#t=2486\">re:Invent keynote</a> earlier this month, I am now happy to announce the immediate availability of <a href=\"http://aws.amazon.com/rds/mysql/#Read_Replica\">Amazon RDS Cross Region Read Replicas</a>, which is another important enhancement for our customers using or planning to use multiple AWS Regions to deploy their applications. Cross Region Read Replicas are available for MySQL 5.6 and enable you to maintain a nearly up-to-date copy of your master database in a different AWS Region. In case of a regional disaster, you can simply promote your read replica in a different region to a master and point your application to it to resume operations. Cross Region Read Replicas also enable you to serve read traffic for your global customer base from regions that are nearest to them.</p>
<p>About 5 years ago, I <a href=\"http://www.allthingsdistributed.com/2008/03/on_the_road_to_highly_availabl.html\">introduced</a> you to AWS Availability Zones, which are distinct locations within a Region that are engineered to be insulated from failures in other Availability Zones and provide inexpensive, low latency network connectivity to other Availability Zones in the same region. Availability Zones have since become the foundational elements for AWS customers to create a new generation of highly available distributed applications in the cloud that are designed to be fault tolerant from the get go. We also made it easy for customers to leverage multiple Availability Zones to architect the various layers of their applications with a few clicks on the AWS Management Console with services such as <a href=\"http://aws.amazon.com/elasticloadbalancing/\">Amazon Elastic Load Balancing</a>, <a href=\"http://aws.amazon.com/rds/\">Amazon RDS</a> and <a href=\"http://aws.amazon.com/dynamodb/\">Amazon DynamoDB</a>. In addition, Amazon S3 redundantly stores data in multiple facilities and is designed for 99.999999999% durability and 99.99% availability of objects over a given year. Our SLAs offer even more confidence to customers running applications across multiple Availability Zones. Amazon RDS offers a monthly uptime percentage <a href=\"http://aws.amazon.com/rds-sla\">SLA</a> of 99.95% per Multi-AZ database instance. Amazon EC2 and EBS offer a monthly uptime percentage <a href=\"http://aws.amazon.com/ec2-sla/\">SLA</a> of 99.95% for instances running across multiple Availability Zones.</p>
<p>As AWS expanded to 9 distinct AWS Regions and 25 Availability Zones across the world during the last few years, many of our customers started to leverage multiple AWS Regions to further enhance the reliability of their applications for disaster recovery. For example, when a disastrous earthquake hit Japan in March 2011, many customers in Japan came to AWS to take advantage of the multiple Availability Zones. In addition, they also backed up their data from the AWS Tokyo Region to AWS Singapore Region as an additional measure for business continuity. In a similar scenario here in the United States, Milind Borate, the CTO of Druva, an enterprise backup company using AWS told me that after hurricane Sandy, he got an enormous amount of interest from his customers in the North Eastern US region to replicate their data to other parts of the US for Disaster Recovery.</p>
<p>Up until AWS and the Cloud, reliable Disaster Recovery had largely remained cost prohibitive for most companies excepting for large enterprises. It traditionally involved the expense and headaches associated with procuring new co-location space, negotiating pricing with a new vendor, adding racks, setting up network links and encryption, taking backups, initiating a transfer and monitoring it until  the operation complete. While the infrastructure costs for basic disaster recovery could have been very high, the associated system and database administration costs could be just as much or more. Despite incurring these costs, given the complexity, customers could have found themselves in a situation where the restoration process does not meet their recovery time objective and/or recovery point objective. AWS provides several easy to use and cost effective building blocks to make disaster recovery very accessible to customers. Using the S3 copy functionality, you can copy the objects/files that are used by your application from one AWS Region to another. You can use the <a href=\"http://aws.typepad.com/aws/2013/03/ec2-ami-copy-between-regions.html\">EC2 AMI copy</a> functionality to make your server images available in multiple AWS Regions. In the last 12 months, we launched <a href=\"http://aws.typepad.com/aws/2012/12/ebs-snapshot-copy.html\">EBS Snapshot Copy</a>, <a href=\"http://aws.typepad.com/aws/2013/10/cross-region-snapshot-copy-for-amazon-rds.html\">RDS Snapshot Copy</a>, <a href=\"http://aws.typepad.com/aws/2013/09/copy-dynamodb-data-between-regions-using-the-aws-data-pipeline.html\">DynamoDB Data Copy</a> and <a href=\"http://aws.typepad.com/aws/2013/11/automated-cross-region-snapshot-copy-for-amazon-redshift.html\">Redshift Snapshot Copy</a>, all of which help you to easily restore the full stack of your application environments in a different AWS Region for disaster recovery. Amazon RDS Cross Region Read Replica is another important enhancement for supporting these disaster recovery scenarios.</p>
<p>We have heard from Joel Callaway from Zoopla, a property listing and house prices website in UK that attracts over 20 million visits per month, that they are using the RDS Snapshot Copy feature to easily transfer hundreds of GB of their RDS databases from the US East Region to the EU West (Dublin) Region every week using a few simple API calls. Joel told us that prior to using this feature it used to take them several days and manual steps to set up a similar disaster recovery process. Joel also told us that he is looking forward to using Cross Region Read Replicas to further enhance their disaster recovery objectives.</p>
<p>AWS customers come from over 190 countries and a lot of them in turn have global customers. Cross Region Read Replicas also make it even easier for our global customers to scale database deployments to meet the performance demands of high-traffic, globally disperse applications.  This feature enables our customers to better serve read-heavy traffic from an AWS Region closer to their end users to provide a faster response time. Medidata delivers cloud-based clinical trial solutions using AWS that enable physicians to look up patient records quickly and avoid prescribing treatments that might counteract the patient’s clinical trial regimen. Isaac Wong, VP of Platform Architecture with Medidata, told us that their clinical trial platform is global in scope and the ability to move data closer to the doctors and nurses participating in a trial anywhere in the world through Cross Region Read Replicas enables them to shorten read latencies and allows their health professionals to serve their patients better.  Isaac also told us that using Cross Region Replication features of RDS, he is able to ensure that life critical services of their platform are not affected by regional disruption. These are great examples of how many of our customers are very easily and cost effectively able to implement disaster recovery solutions as well as design globally scalable web applications using AWS.</p>
<p>Note that building a reliable disaster recovery solution entails that every component of your application architecture, be it a web server, load balancer, application, cache or database server, is able to meet the recovery point and time objectives you have for your business. If you are going to take advantage of Cross Region Read Replicas of RDS, make sure to monitor the replication status through <a href=\"http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Events.html\">DB Event Notifications</a> and the Replica Lag metric through <a href=\"http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Monitoring.html\">CloudWatch</a> to ensure that your read replica is always available and keeping up. Refer to the <a href=\"http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReadRepl.html#USER_ReadRepl.XRgn\">Cross Region Read Replica section</a> of the Amazon RDS User Guide to learn more.</p>" "http://www.allthingsdistributed.com/2013/11/rds-cross-region-replicas.html" (21140 43360) old 4 nil nil ((title nil "Expanding the Cloud: Enabling Globally Distributed Applications and Disaster Recovery") (link ((href . "http://www.allthingsdistributed.com/2013/11/rds-cross-region-replicas.html"))) (updated nil "2013-11-26T14:00:00Z") (id nil "http://www.allthingsdistributed.com/2013/11/rds-cross-region-replicas") (content ((type . "html")) "<p>As I discussed in my <a href=\"https://www.youtube.com/watch?v=Waq8Y6s1Cjs#t=2486\">re:Invent keynote</a> earlier this month, I am now happy to announce the immediate availability of <a href=\"http://aws.amazon.com/rds/mysql/#Read_Replica\">Amazon RDS Cross Region Read Replicas</a>, which is another important enhancement for our customers using or planning to use multiple AWS Regions to deploy their applications. Cross Region Read Replicas are available for MySQL 5.6 and enable you to maintain a nearly up-to-date copy of your master database in a different AWS Region. In case of a regional disaster, you can simply promote your read replica in a different region to a master and point your application to it to resume operations. Cross Region Read Replicas also enable you to serve read traffic for your global customer base from regions that are nearest to them.</p>

<p>About 5 years ago, I <a href=\"http://www.allthingsdistributed.com/2008/03/on_the_road_to_highly_availabl.html\">introduced</a> you to AWS Availability Zones, which are distinct locations within a Region that are engineered to be insulated from failures in other Availability Zones and provide inexpensive, low latency network connectivity to other Availability Zones in the same region. Availability Zones have since become the foundational elements for AWS customers to create a new generation of highly available distributed applications in the cloud that are designed to be fault tolerant from the get go. We also made it easy for customers to leverage multiple Availability Zones to architect the various layers of their applications with a few clicks on the AWS Management Console with services such as <a href=\"http://aws.amazon.com/elasticloadbalancing/\">Amazon Elastic Load Balancing</a>, <a href=\"http://aws.amazon.com/rds/\">Amazon RDS</a> and <a href=\"http://aws.amazon.com/dynamodb/\">Amazon DynamoDB</a>. In addition, Amazon S3 redundantly stores data in multiple facilities and is designed for 99.999999999% durability and 99.99% availability of objects over a given year. Our SLAs offer even more confidence to customers running applications across multiple Availability Zones. Amazon RDS offers a monthly uptime percentage <a href=\"http://aws.amazon.com/rds-sla\">SLA</a> of 99.95% per Multi-AZ database instance. Amazon EC2 and EBS offer a monthly uptime percentage <a href=\"http://aws.amazon.com/ec2-sla/\">SLA</a> of 99.95% for instances running across multiple Availability Zones.</p>

<p>As AWS expanded to 9 distinct AWS Regions and 25 Availability Zones across the world during the last few years, many of our customers started to leverage multiple AWS Regions to further enhance the reliability of their applications for disaster recovery. For example, when a disastrous earthquake hit Japan in March 2011, many customers in Japan came to AWS to take advantage of the multiple Availability Zones. In addition, they also backed up their data from the AWS Tokyo Region to AWS Singapore Region as an additional measure for business continuity. In a similar scenario here in the United States, Milind Borate, the CTO of Druva, an enterprise backup company using AWS told me that after hurricane Sandy, he got an enormous amount of interest from his customers in the North Eastern US region to replicate their data to other parts of the US for Disaster Recovery.</p>

<p>Up until AWS and the Cloud, reliable Disaster Recovery had largely remained cost prohibitive for most companies excepting for large enterprises. It traditionally involved the expense and headaches associated with procuring new co-location space, negotiating pricing with a new vendor, adding racks, setting up network links and encryption, taking backups, initiating a transfer and monitoring it until  the operation complete. While the infrastructure costs for basic disaster recovery could have been very high, the associated system and database administration costs could be just as much or more. Despite incurring these costs, given the complexity, customers could have found themselves in a situation where the restoration process does not meet their recovery time objective and/or recovery point objective. AWS provides several easy to use and cost effective building blocks to make disaster recovery very accessible to customers. Using the S3 copy functionality, you can copy the objects/files that are used by your application from one AWS Region to another. You can use the <a href=\"http://aws.typepad.com/aws/2013/03/ec2-ami-copy-between-regions.html\">EC2 AMI copy</a> functionality to make your server images available in multiple AWS Regions. In the last 12 months, we launched <a href=\"http://aws.typepad.com/aws/2012/12/ebs-snapshot-copy.html\">EBS Snapshot Copy</a>, <a href=\"http://aws.typepad.com/aws/2013/10/cross-region-snapshot-copy-for-amazon-rds.html\">RDS Snapshot Copy</a>, <a href=\"http://aws.typepad.com/aws/2013/09/copy-dynamodb-data-between-regions-using-the-aws-data-pipeline.html\">DynamoDB Data Copy</a> and <a href=\"http://aws.typepad.com/aws/2013/11/automated-cross-region-snapshot-copy-for-amazon-redshift.html\">Redshift Snapshot Copy</a>, all of which help you to easily restore the full stack of your application environments in a different AWS Region for disaster recovery. Amazon RDS Cross Region Read Replica is another important enhancement for supporting these disaster recovery scenarios.</p>

<p>We have heard from Joel Callaway from Zoopla, a property listing and house prices website in UK that attracts over 20 million visits per month, that they are using the RDS Snapshot Copy feature to easily transfer hundreds of GB of their RDS databases from the US East Region to the EU West (Dublin) Region every week using a few simple API calls. Joel told us that prior to using this feature it used to take them several days and manual steps to set up a similar disaster recovery process. Joel also told us that he is looking forward to using Cross Region Read Replicas to further enhance their disaster recovery objectives.</p>

<p>AWS customers come from over 190 countries and a lot of them in turn have global customers. Cross Region Read Replicas also make it even easier for our global customers to scale database deployments to meet the performance demands of high-traffic, globally disperse applications.  This feature enables our customers to better serve read-heavy traffic from an AWS Region closer to their end users to provide a faster response time. Medidata delivers cloud-based clinical trial solutions using AWS that enable physicians to look up patient records quickly and avoid prescribing treatments that might counteract the patient’s clinical trial regimen. Isaac Wong, VP of Platform Architecture with Medidata, told us that their clinical trial platform is global in scope and the ability to move data closer to the doctors and nurses participating in a trial anywhere in the world through Cross Region Read Replicas enables them to shorten read latencies and allows their health professionals to serve their patients better.  Isaac also told us that using Cross Region Replication features of RDS, he is able to ensure that life critical services of their platform are not affected by regional disruption. These are great examples of how many of our customers are very easily and cost effectively able to implement disaster recovery solutions as well as design globally scalable web applications using AWS.</p>

<p>Note that building a reliable disaster recovery solution entails that every component of your application architecture, be it a web server, load balancer, application, cache or database server, is able to meet the recovery point and time objectives you have for your business. If you are going to take advantage of Cross Region Read Replicas of RDS, make sure to monitor the replication status through <a href=\"http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Events.html\">DB Event Notifications</a> and the Replica Lag metric through <a href=\"http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Monitoring.html\">CloudWatch</a> to ensure that your read replica is always available and keeping up. Refer to the <a href=\"http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReadRepl.html#USER_ReadRepl.XRgn\">Cross Region Read Replica section</a> of the Amazon RDS User Guide to learn more.</p>
"))) ("AWS re:Invent 2013" "<p><img src=\"/images/reinvent2013.jpg\"/ width=\"650\"></p>
<p>Today we are kicking off <a href=\"http://reinvent.awsevents.com/\">AWS re:Invent 2013</a>. Over the course of the next three days, we will host more than 200 sessions, training bootcamps, and hands on labs taught by expert AWS staff as well as dozens of our customers.</p>
<p>This year’s conference kicks off with a keynote address by AWS Senior Vice President Andy Jassy, followed by my keynote on Thursday morning.  Tune in to hear the latest from AWS and our customers.</p>
<p>If you’re not already here in Vegas with us, you can sign up to watch the keynotes on live stream <a href=\"http://reinvent.awsevents.com/\">here</a>.</p>
<p>Outside of the keynotes, there are an incredible number of sessions offering a tailored experience whether you are a developer, startup, executive, partner, or other. You can see the full session catalog <a href=\"https://portal.reinvent.awsevents.com/connect/search.ww\">here</a>. I’m impressed by the scale and technical depth of what’s offered to attendees.</p>
<p>After my keynote on Thursday I will host two fireside chat sessions with cloud innovators and industry influencers:</p>
<p><a href=\"https://portal.reinvent.awsevents.com/connect/search.ww#loadSearch-searchPhrase=spot203&amp;searchType=session&amp;tc=0&amp;sortBy=abbreviationSort&amp;p=\">First</a>, I’ll talk with three technical startup founders</p>
<ul>
<li>Eliot Horowitz from <a href=\"http://www.mongodb.com/\">MongoDB</a></li>
<li>Jeff Lawson from <a href=\"http://www.twillio.com/\">Twilio</a></li>
<li>Valentino Volonghi from <a href=\"http://www.techstars.com/\">Adroll</a></li>
</ul>
<p> In the <a href=\"https://portal.reinvent.awsevents.com/connect/search.ww#loadSearch-searchPhrase=spot203&amp;searchType=session&amp;tc=0&amp;sortBy=abbreviationSort&amp;p=\">second session</a> I will talk with three startup influencers</p>
<ul>
<li>David Cohen from <a href=\"http://www.techstars.com/\">Techstars</a></li>
<li>Ash Fontana from <a href=\"http://angel.co\">AngelList</a></li>
<li>Albert Wenger from <a href=\"http://www.usv.com/\">Union Square Ventures</a></li>
</ul>
<p>  I will follow those two sessions with <a href=\"https://portal.reinvent.awsevents.com/connect/search.ww#loadSearch-searchPhrase=spot101&amp;searchType=session&amp;tc=0&amp;sortBy=abbreviationSort&amp;p=\">Startup Launches</a>, where five companies will either launch their business or a significant feature entirely built on AWS. It will be a busy, fun, and informative afternoon!</p>
<p>Look forward to seeing you around the conference.</p>" "http://www.allthingsdistributed.com/2013/11/aws-reinvent-2103.html" (21123 9072) old 5 nil nil ((title nil "AWS re:Invent 2013") (link ((href . "http://www.allthingsdistributed.com/2013/11/aws-reinvent-2103.html"))) (updated nil "2013-11-13T07:00:00Z") (id nil "http://www.allthingsdistributed.com/2013/11/aws-reinvent-2103") (content ((type . "html")) "<p><img src=\"/images/reinvent2013.jpg\"/ width=\"650\"></p>

<p>Today we are kicking off <a href=\"http://reinvent.awsevents.com/\">AWS re:Invent 2013</a>. Over the course of the next three days, we will host more than 200 sessions, training bootcamps, and hands on labs taught by expert AWS staff as well as dozens of our customers.</p>

<p>This year’s conference kicks off with a keynote address by AWS Senior Vice President Andy Jassy, followed by my keynote on Thursday morning.  Tune in to hear the latest from AWS and our customers.</p>

<p>If you’re not already here in Vegas with us, you can sign up to watch the keynotes on live stream <a href=\"http://reinvent.awsevents.com/\">here</a>.</p>

<p>Outside of the keynotes, there are an incredible number of sessions offering a tailored experience whether you are a developer, startup, executive, partner, or other. You can see the full session catalog <a href=\"https://portal.reinvent.awsevents.com/connect/search.ww\">here</a>. I’m impressed by the scale and technical depth of what’s offered to attendees.</p>

<p>After my keynote on Thursday I will host two fireside chat sessions with cloud innovators and industry influencers:</p>

<p><a href=\"https://portal.reinvent.awsevents.com/connect/search.ww#loadSearch-searchPhrase=spot203&amp;searchType=session&amp;tc=0&amp;sortBy=abbreviationSort&amp;p=\">First</a>, I’ll talk with three technical startup founders</p>

<ul>
<li>Eliot Horowitz from <a href=\"http://www.mongodb.com/\">MongoDB</a></li>
<li>Jeff Lawson from <a href=\"http://www.twillio.com/\">Twilio</a></li>
<li>Valentino Volonghi from <a href=\"http://www.techstars.com/\">Adroll</a></li>
</ul>


<p> In the <a href=\"https://portal.reinvent.awsevents.com/connect/search.ww#loadSearch-searchPhrase=spot203&amp;searchType=session&amp;tc=0&amp;sortBy=abbreviationSort&amp;p=\">second session</a> I will talk with three startup influencers</p>

<ul>
<li>David Cohen from <a href=\"http://www.techstars.com/\">Techstars</a></li>
<li>Ash Fontana from <a href=\"http://angel.co\">AngelList</a></li>
<li>Albert Wenger from <a href=\"http://www.usv.com/\">Union Square Ventures</a></li>
</ul>


<p>  I will follow those two sessions with <a href=\"https://portal.reinvent.awsevents.com/connect/search.ww#loadSearch-searchPhrase=spot101&amp;searchType=session&amp;tc=0&amp;sortBy=abbreviationSort&amp;p=\">Startup Launches</a>, where five companies will either launch their business or a significant feature entirely built on AWS. It will be a busy, fun, and informative afternoon!</p>

<p>Look forward to seeing you around the conference.</p>
"))) ("Simplifying Mobile App Data Management with DynamoDB's Fine-Grained Access Control" "<p>Speed of development, scalability, and simplicity of management are among the critical needs of mobile developers. With the proliferation of mobile devices and users, and small agile teams that are tasked with building successful mobile apps that can grow from 100 users to 1 million users in a few days, scalability of the underlying infrastructure and simplicity of management are more important than ever. We created <a href=\"http://aws.amazon.com/dynamodb/\">DynamoDB</a> to make it easy to set up and scale databases so that developers can focus on building great apps without worrying about the muck of managing the database infrastructure. As I have <a href=\"http://www.allthingsdistributed.com/2013/09/dynamodb-geospatial.html\">mentioned previously</a>, companies like <a href=\"https://www.crittercism.com/\">Crittercism</a> and <a href=\"http://dropcam.com\">Dropcam</a> have already built exciting mobile businesses leveraging DynamoDB. Today, we are further simplifying mobile app development with our newest DynamoDB feature, Fine-Grained Access Control, which gives you the ability to directly and securely access mobile application data in DynamoDB.</p>
<p>One of the pieces of a mobile infrastructure that developers have to build and maintain is the fleet of proxy servers that authorize requests coming from millions of mobile devices. This proxy tier allows vetted requests to continue to DynamoDB and then filters responses so the user only receives permitted items and attributes. So, if I am building a mobile gaming app, I must run a proxy fleet that ensures “johndoe@gmail.com” only retrieves his game state and nothing else. While <a href=\"http://aws.typepad.com/aws/2013/05/aws-iam-now-supports-amazon-facebook-and-google-identity-federation.html\">Web Identity Federation</a>, which we introduced a few months back, allowed using public identity providers such as Login with <a href=\"http://login.amazon.com/\">Amazon</a>, <a href=\"https://developers.facebook.com/docs/facebook-login/\">Facebook</a>, or <a href=\"https://developers.google.com/+/\">Google</a> for authentication, it still required a developer to build and deploy a proxy layer in front of DynamoDB for this type of authorization</p>
<p>With Fine-Grained Access Control, we solve this problem by enabling you to author access policies that include conditions that describe additional levels of filtering and control. This eliminates the need for the proxy layer, simplifies the application stack, and results in cost savings. Using access control this way involves a setup phase of authenticating the user (step 1) and obtaining IAM credentials (step 2). After these steps, the mobile app may directly perform permitted operations on DynamoDB (step 3).</p>
<p><img src=\"/images/fgac-dynamodb.png\"/ width=\"650\"></p>
<p>With today’s launch, apps running on mobile devices can send workloads to a DynamoDB table, row, or even a column without going through an intervening proxy layer. For instance, the developer of a mobile app will use Fine-Grained Access Control to restrict the synchronization of user data (e.g. Game history) across the many devices the user has the app installed on. This capability allows apps running on mobile devices to modify only rows belonging to a specific user. Also, by consolidating users’ data in a DynamoDB table, you can obtain real-time insights over the user base, at large scale, without going through expensive joins and batch approaches such as scatter / gather.</p>
<p>To get started, please see the <a href=\"http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/FGAC_DDB.html\">Fine-Grained Access Control documentation</a> and <a href=\"http://aws.typepad.com/aws/2013/10/fine-grained-access-control-for-amazon-dynamodb.html\">Jeff Barr’s blog</a>.</p>" "http://www.allthingsdistributed.com/2013/10/mobile-app-data-management-dynamodb.html" (21104 51856) old 6 nil nil ((title nil "Simplifying Mobile App Data Management with DynamoDB's Fine-Grained Access Control") (link ((href . "http://www.allthingsdistributed.com/2013/10/mobile-app-data-management-dynamodb.html"))) (updated nil "2013-10-30T09:00:00Z") (id nil "http://www.allthingsdistributed.com/2013/10/mobile-app-data-management-dynamodb") (content ((type . "html")) "<p>Speed of development, scalability, and simplicity of management are among the critical needs of mobile developers. With the proliferation of mobile devices and users, and small agile teams that are tasked with building successful mobile apps that can grow from 100 users to 1 million users in a few days, scalability of the underlying infrastructure and simplicity of management are more important than ever. We created <a href=\"http://aws.amazon.com/dynamodb/\">DynamoDB</a> to make it easy to set up and scale databases so that developers can focus on building great apps without worrying about the muck of managing the database infrastructure. As I have <a href=\"http://www.allthingsdistributed.com/2013/09/dynamodb-geospatial.html\">mentioned previously</a>, companies like <a href=\"https://www.crittercism.com/\">Crittercism</a> and <a href=\"http://dropcam.com\">Dropcam</a> have already built exciting mobile businesses leveraging DynamoDB. Today, we are further simplifying mobile app development with our newest DynamoDB feature, Fine-Grained Access Control, which gives you the ability to directly and securely access mobile application data in DynamoDB.</p>

<p>One of the pieces of a mobile infrastructure that developers have to build and maintain is the fleet of proxy servers that authorize requests coming from millions of mobile devices. This proxy tier allows vetted requests to continue to DynamoDB and then filters responses so the user only receives permitted items and attributes. So, if I am building a mobile gaming app, I must run a proxy fleet that ensures “johndoe@gmail.com” only retrieves his game state and nothing else. While <a href=\"http://aws.typepad.com/aws/2013/05/aws-iam-now-supports-amazon-facebook-and-google-identity-federation.html\">Web Identity Federation</a>, which we introduced a few months back, allowed using public identity providers such as Login with <a href=\"http://login.amazon.com/\">Amazon</a>, <a href=\"https://developers.facebook.com/docs/facebook-login/\">Facebook</a>, or <a href=\"https://developers.google.com/+/\">Google</a> for authentication, it still required a developer to build and deploy a proxy layer in front of DynamoDB for this type of authorization</p>

<p>With Fine-Grained Access Control, we solve this problem by enabling you to author access policies that include conditions that describe additional levels of filtering and control. This eliminates the need for the proxy layer, simplifies the application stack, and results in cost savings. Using access control this way involves a setup phase of authenticating the user (step 1) and obtaining IAM credentials (step 2). After these steps, the mobile app may directly perform permitted operations on DynamoDB (step 3).</p>

<p><img src=\"/images/fgac-dynamodb.png\"/ width=\"650\"></p>

<p>With today’s launch, apps running on mobile devices can send workloads to a DynamoDB table, row, or even a column without going through an intervening proxy layer. For instance, the developer of a mobile app will use Fine-Grained Access Control to restrict the synchronization of user data (e.g. Game history) across the many devices the user has the app installed on. This capability allows apps running on mobile devices to modify only rows belonging to a specific user. Also, by consolidating users’ data in a DynamoDB table, you can obtain real-time insights over the user base, at large scale, without going through expensive joins and batch approaches such as scatter / gather.</p>

<p>To get started, please see the <a href=\"http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/FGAC_DDB.html\">Fine-Grained Access Control documentation</a> and <a href=\"http://aws.typepad.com/aws/2013/10/fine-grained-access-control-for-amazon-dynamodb.html\">Jeff Barr’s blog</a>.</p>
"))) ("Back-to-Basics Weekend Reading - U-Net: A User-Level Network Interface" "<p><img src=\"/images/kochin.jpg\"/ width=\"650\"></p>
<p>Many of you know <a href=\"http://www.rightscale.com/blog/users/thorsten-von-eicken\">Thorsten von Eicken</a> as the founder of <a href=\"http://www.rightscale.com\">Rightscale</a>, the company that has helped numerous organizations find their way onto AWS. In what seems almost a previous life by now Thorsten was one of the top young professors in Distributed Systems and I had the great pleasure of working with him at Cornell in the early 90's. What set Thorsten aside from so many other system research academics was his desire to build practical, working systems, a path that I followed as well.</p>
<p>In the back to basics readings this week I am re-reading a paper from 1995 about the work that I did together with Thorsten on solving the problem of end-to-end low-latency communication on high-speed networks. The problem we were facing in those days was than many new high-speed network technologies, such as ATM, became available for standard workstations but that the operating systems were not able to deliver those capabilities to its applications. Throughput was often acceptable but individual message latency was as bad as over regular ethernet, a problem that <a href=\"http://research.microsoft.com/en-us/people/thekkath/\">Chandu Tekkath</a> had described earlier in \"<a href=\"http://www.thekkath.org/Documents/lowlatency.pdf\">Limits to Low-Latency Communication on High-Speed Networks</a>\"</p>
<p>The lack of low-latency made that distributed systems (e.g. database replication, fault tolerance protocols) could not benefit from these advances at the network level. The research to unlock these capabilities led to an architecture called <a href=\"http://www.cs.cornell.edu/tve/u-net/\">U-Net</a>. What set U-Net aside from other research was that it was first and foremost and engineering effort as we set out to build a system that actually had to function in production. Many of those engineering experiences found their way back into the paper. U-Net also heavily influenced what later became the Virtual Network Architecture industry standard.</p>
<p>The work on U-Net was continued by <a href=\"http://www.mdw.la/\">Matt Welsh</a> who built among other things a version that could be used for <a href=\"http://www.eecs.harvard.edu/~mdw/proj/old/unet/\">fast-ethernet on regular PCs</a> and one that could <a href=\"http://www.eecs.harvard.edu/~mdw/proj/old/unet-sle/\">safely integrate into type-safe environments</a> such as the JVM.</p>
<p><a href=\"http://www.allthingsdistributed.com/files/u-net.pdf\"><em>U-Net: A User-Level Network Interface for Parallel and Distributed Computing</em></a>, Anindya Basu, Vineet Buch, Werner Vogels, Thorsten von Eicken. Proceedings of the 15th ACM Symposium on Operating Systems Principles (SOSP), Copper Mountain, Colorado, December 3-6, 1995</p>" "http://www.allthingsdistributed.com/2013/10/unet-user-level-network-interface.html" (21098 20272) old 7 nil nil ((title nil "Back-to-Basics Weekend Reading - U-Net: A User-Level Network Interface") (link ((href . "http://www.allthingsdistributed.com/2013/10/unet-user-level-network-interface.html"))) (updated nil "2013-10-25T11:00:00Z") (id nil "http://www.allthingsdistributed.com/2013/10/unet-user-level-network-interface") (content ((type . "html")) "<p><img src=\"/images/kochin.jpg\"/ width=\"650\"></p>

<p>Many of you know <a href=\"http://www.rightscale.com/blog/users/thorsten-von-eicken\">Thorsten von Eicken</a> as the founder of <a href=\"http://www.rightscale.com\">Rightscale</a>, the company that has helped numerous organizations find their way onto AWS. In what seems almost a previous life by now Thorsten was one of the top young professors in Distributed Systems and I had the great pleasure of working with him at Cornell in the early 90's. What set Thorsten aside from so many other system research academics was his desire to build practical, working systems, a path that I followed as well.</p>

<p>In the back to basics readings this week I am re-reading a paper from 1995 about the work that I did together with Thorsten on solving the problem of end-to-end low-latency communication on high-speed networks. The problem we were facing in those days was than many new high-speed network technologies, such as ATM, became available for standard workstations but that the operating systems were not able to deliver those capabilities to its applications. Throughput was often acceptable but individual message latency was as bad as over regular ethernet, a problem that <a href=\"http://research.microsoft.com/en-us/people/thekkath/\">Chandu Tekkath</a> had described earlier in \"<a href=\"http://www.thekkath.org/Documents/lowlatency.pdf\">Limits to Low-Latency Communication on High-Speed Networks</a>\"</p>

<p>The lack of low-latency made that distributed systems (e.g. database replication, fault tolerance protocols) could not benefit from these advances at the network level. The research to unlock these capabilities led to an architecture called <a href=\"http://www.cs.cornell.edu/tve/u-net/\">U-Net</a>. What set U-Net aside from other research was that it was first and foremost and engineering effort as we set out to build a system that actually had to function in production. Many of those engineering experiences found their way back into the paper. U-Net also heavily influenced what later became the Virtual Network Architecture industry standard.</p>

<p>The work on U-Net was continued by <a href=\"http://www.mdw.la/\">Matt Welsh</a> who built among other things a version that could be used for <a href=\"http://www.eecs.harvard.edu/~mdw/proj/old/unet/\">fast-ethernet on regular PCs</a> and one that could <a href=\"http://www.eecs.harvard.edu/~mdw/proj/old/unet-sle/\">safely integrate into type-safe environments</a> such as the JVM.</p>

<p><a href=\"http://www.allthingsdistributed.com/files/u-net.pdf\"><em>U-Net: A User-Level Network Interface for Parallel and Distributed Computing</em></a>, Anindya Basu, Vineet Buch, Werner Vogels, Thorsten von Eicken. Proceedings of the 15th ACM Symposium on Operating Systems Principles (SOSP), Copper Mountain, Colorado, December 3-6, 1995</p>
"))) ("AWS Activate – Supporting Startups on AWS" "<p><img src=\"/images/activate2.png\"/ align=\"right\" vspace=\"0\" hspace=\"0\" width=\"270\">
I am very excited to announce <a href=\"https://aws.amazon.com/activate/\">AWS Activate</a>, a program designed to provide startups with the resources they need to build applications on AWS.</p>
<p>Startups will forever be a very important customer segment of AWS. They were among our first customers and along the way some amazing businesses have been built by these startups, many of which running for 100% on AWS. Startups operate in a world of high uncertainty and limited capital, so an elastic and on-demand infrastructure at low and variable cost aligns very naturally with their needs. By reducing the cost of failure and democratizing access to infrastructure, the cloud has enabled more startups to build, experiment, and scale.</p>
<p>When we launched AWS the original mission was</p>
<blockquote><p><em>To enable businesses and developers to use web services to build scalable sophisticated applications</em></p></blockquote>
<p>We’re continually amazed at the incredible sophisticated applications that these startups have built on top of our foundational services. That includes the startups that have become household names –
<a href=\"http://instagram.com\">Instagram</a>,
<a href=\"http://www.spotify.com\">Spotify</a>,
<a href=\"http://www.pinterest.com\">Pinterest</a>,
<a href=\"http://www.dropbox.com\">Dropbox</a>,
<a href=\"http://www.etsy.com\">Etsy</a>,
<a href=\"http://www.airbnb.com\">AirBnB</a>,
<a href=\"http://www.shazam.com\">Shazam</a>
– as well as incredibly successful companies that you might not yet have heard of, such as
<a href=\"http://www.twilio.com\">Twilio</a>,
<a href=\"http://www.viki.com\">Viki</a>,
<a href=\"http://www.redbus.in\">Redbus</a>,
<a href=\"http://www.floorplanner.com\">Floorplanner</a>
and <a href=\"http://www.tellybug.com\">Tellybug</a>,
and many more. We’re proud to have helped all startups achieve their goals.</p>
<p>As I’ve traveled this past year for AWS Summits I’ve met startups in countries all over the world building apps for every imaginable use case. What’s exciting to me is infrastructure is no longer a bottleneck to innovation. The democratization of infrastructure means that an internet startup in Bangalore or Sao Paulo or Manila has access to the same compute power as Amazon.com; the same durability as Dropbox; the same scalability as Airbnb; the same global footprint as Netflix. The result is we’re beginning to see more and more startups grow up in more places.</p>
<p>We’re excited to be a part of this global momentum in the startup ecosystem. The challenge now is to support and assist an increasing number of startups across the world.</p>
<p>To that end, today we’re pleased to announce <a href=\"https://aws.amazon.com/activate/\">AWS Activate</a>, a new program for startups. AWS Activate is designed to provide startups with the resources they need to build applications on AWS. It includes access to web-based AWS Training courses, to help startups become familiar and proficient with AWS services; an AWS Support period, to provide expert guidance when a startup might need it; and in some cases AWS Promotional Credit. AWS Activate also allows startups to leverage the unique and robust ecosystem that has grown around AWS, both in terms of the developer community and third-party software vendors. The new Startup Forum will give startups a place to find and share tips and lessons learned – there are already posts from customers like Coursera as well as best practice guidance from AWS Solutions Architects. In addition, AWS Activate will include discounts on software that many startups find useful. Included already are exclusive offers from Opscode (for automation), AlertLogic (for security), and SOASTA (for testing).</p>
<p>The best part is – it’s free to join.  You can learn more and sign up at <a href=\"https://aws.amazon.com/activate/\">AWS Activate</a>.</p>" "http://www.allthingsdistributed.com/2013/10/aws-activate.html" (21077 62728) old 8 nil nil ((title nil "AWS Activate – Supporting Startups on AWS") (link ((href . "http://www.allthingsdistributed.com/2013/10/aws-activate.html"))) (updated nil "2013-10-10T00:30:00Z") (id nil "http://www.allthingsdistributed.com/2013/10/aws-activate") (content ((type . "html")) "<p><img src=\"/images/activate2.png\"/ align=\"right\" vspace=\"0\" hspace=\"0\" width=\"270\">
I am very excited to announce <a href=\"https://aws.amazon.com/activate/\">AWS Activate</a>, a program designed to provide startups with the resources they need to build applications on AWS.</p>

<p>Startups will forever be a very important customer segment of AWS. They were among our first customers and along the way some amazing businesses have been built by these startups, many of which running for 100% on AWS. Startups operate in a world of high uncertainty and limited capital, so an elastic and on-demand infrastructure at low and variable cost aligns very naturally with their needs. By reducing the cost of failure and democratizing access to infrastructure, the cloud has enabled more startups to build, experiment, and scale.</p>

<p>When we launched AWS the original mission was</p>

<blockquote><p><em>To enable businesses and developers to use web services to build scalable sophisticated applications</em></p></blockquote>

<p>We’re continually amazed at the incredible sophisticated applications that these startups have built on top of our foundational services. That includes the startups that have become household names –
<a href=\"http://instagram.com\">Instagram</a>,
<a href=\"http://www.spotify.com\">Spotify</a>,
<a href=\"http://www.pinterest.com\">Pinterest</a>,
<a href=\"http://www.dropbox.com\">Dropbox</a>,
<a href=\"http://www.etsy.com\">Etsy</a>,
<a href=\"http://www.airbnb.com\">AirBnB</a>,
<a href=\"http://www.shazam.com\">Shazam</a>
 – as well as incredibly successful companies that you might not yet have heard of, such as
<a href=\"http://www.twilio.com\">Twilio</a>,
<a href=\"http://www.viki.com\">Viki</a>,
<a href=\"http://www.redbus.in\">Redbus</a>,
<a href=\"http://www.floorplanner.com\">Floorplanner</a>
and <a href=\"http://www.tellybug.com\">Tellybug</a>,
and many more. We’re proud to have helped all startups achieve their goals.</p>

<p>As I’ve traveled this past year for AWS Summits I’ve met startups in countries all over the world building apps for every imaginable use case. What’s exciting to me is infrastructure is no longer a bottleneck to innovation. The democratization of infrastructure means that an internet startup in Bangalore or Sao Paulo or Manila has access to the same compute power as Amazon.com; the same durability as Dropbox; the same scalability as Airbnb; the same global footprint as Netflix. The result is we’re beginning to see more and more startups grow up in more places.</p>

<p>We’re excited to be a part of this global momentum in the startup ecosystem. The challenge now is to support and assist an increasing number of startups across the world.</p>

<p>To that end, today we’re pleased to announce <a href=\"https://aws.amazon.com/activate/\">AWS Activate</a>, a new program for startups. AWS Activate is designed to provide startups with the resources they need to build applications on AWS. It includes access to web-based AWS Training courses, to help startups become familiar and proficient with AWS services; an AWS Support period, to provide expert guidance when a startup might need it; and in some cases AWS Promotional Credit. AWS Activate also allows startups to leverage the unique and robust ecosystem that has grown around AWS, both in terms of the developer community and third-party software vendors. The new Startup Forum will give startups a place to find and share tips and lessons learned – there are already posts from customers like Coursera as well as best practice guidance from AWS Solutions Architects. In addition, AWS Activate will include discounts on software that many startups find useful. Included already are exclusive offers from Opscode (for automation), AlertLogic (for security), and SOASTA (for testing).</p>

<p>The best part is – it’s free to join.  You can learn more and sign up at <a href=\"https://aws.amazon.com/activate/\">AWS Activate</a>.</p>
"))) ("Back-to-Basics Weekend Reading - Tor: The Second-Generation Onion Router" "<p><img src=\"/images/lux.jpg\"/ width=\"650\"></p>
<p>The anonymity routing network <a href=\"http://en.wikipedia.org/wiki/Tor_(anonymity_network)\">Tor</a> is frequently in the news these days, which makes it a good case to read up on the fascinating technologies behind it. Tor stands for The Onion Router as its technology is based on the <a href=\"http://en.wikipedia.org/wiki/Onion_Routing\">onion routing</a> principles. These principles were first described by Goldschlag, et al., from the Naval Research Lab, in their 1996 paper on Hiding Routing Information. Almost immediately work started on addressing a number of omissions in the original work in what became known as the second-generation onion router. Tor is the implementation of such a second generation router and has a number of fascinating features. The paper describing Tor is also very interesting from a practitioners point of view as it deals with the system complexities of implementing the router at scale.</p>
<p><a href=\"http://www.onion-router.net/Publications/IH-1996.pdf\"><em>Hiding Routing Information</em></a>, David M. Goldschlag, Michael G. Reed, and Paul F. Syverson, in the proceeding of the Workshop on Information Hiding, Cambridge, UK, May, 1996.</p>
<p><a href=\"http://www.onion-router.net/Publications/tor-design.pdf\"><em>Tor: The Second-Generation Onion Router</em></a>, Roger Dingledine, Nick Mathewson and Paul Syverson, in Proceedings of the 13th USENIX Security Symposium, August 2004</p>" "http://www.allthingsdistributed.com/2013/10/tor-second-generation-onion-router.html" (21070 53480) old 9 nil nil ((title nil "Back-to-Basics Weekend Reading - Tor: The Second-Generation Onion Router") (link ((href . "http://www.allthingsdistributed.com/2013/10/tor-second-generation-onion-router.html"))) (updated nil "2013-10-04T14:30:00Z") (id nil "http://www.allthingsdistributed.com/2013/10/tor-second-generation-onion-router") (content ((type . "html")) "<p><img src=\"/images/lux.jpg\"/ width=\"650\"></p>

<p>The anonymity routing network <a href=\"http://en.wikipedia.org/wiki/Tor_(anonymity_network)\">Tor</a> is frequently in the news these days, which makes it a good case to read up on the fascinating technologies behind it. Tor stands for The Onion Router as its technology is based on the <a href=\"http://en.wikipedia.org/wiki/Onion_Routing\">onion routing</a> principles. These principles were first described by Goldschlag, et al., from the Naval Research Lab, in their 1996 paper on Hiding Routing Information. Almost immediately work started on addressing a number of omissions in the original work in what became known as the second-generation onion router. Tor is the implementation of such a second generation router and has a number of fascinating features. The paper describing Tor is also very interesting from a practitioners point of view as it deals with the system complexities of implementing the router at scale.</p>

<p><a href=\"http://www.onion-router.net/Publications/IH-1996.pdf\"><em>Hiding Routing Information</em></a>, David M. Goldschlag, Michael G. Reed, and Paul F. Syverson, in the proceeding of the Workshop on Information Hiding, Cambridge, UK, May, 1996.</p>

<p><a href=\"http://www.onion-router.net/Publications/tor-design.pdf\"><em>Tor: The Second-Generation Onion Router</em></a>, Roger Dingledine, Nick Mathewson and Paul Syverson, in Proceedings of the 13th USENIX Security Symposium, August 2004</p>
"))) ("Back-to-Basics Weekend Reading - A Decomposition Storage Model" "<p><img src=\"/images/sin-garden.jpg\"/ width=\"650\"></p>
<p>Traditionally records in a database were stored as such: the data in a row was stored together for easy and fast retrieval. Not everybody agreed that the \"N-ary Storage Model\" (NSM) was the best approach for all workloads but it stayed dominant until hardware constraints, especially on caches, forced the community to revisit some of the alternatives. Combined with the rise of data warehouse workloads, where there is often significant redundancy in the values stored in columns, and  database models based on column oriented storage took off. The first practical modern implementation is probably <a href=\"http://db.csail.mit.edu/projects/cstore/vldb.pdf\">C-Store by Stonebraker, et al.</a> in 2005. There is a great tutorial by <a href=\"http://www.cs.yale.edu/homes/dna/talks/Column_Store_Tutorial_VLDB09.pdf\">Harizopoulos, Abadi and Boncz from VLDB 2009</a> that takes you through the history, trade-off's and the state of the art. Many of the modern high-performance data warehouses such as <a href=\"http://aws.amazon.com/redshift\">Amazon Redshift</a> are based on column stores.</p>
<p>But the groundwork for Column Oriented Databases was laid in 1985 when George Copeland and Setrag Koshafian questioned the NSM with their seminal paper on a \"Decomposition Storage Model\" (DSM). From the abstract:</p>
<blockquote><p><em>There seems to be a general consensus among
the database community that the n-ary approach is
better This conclusion is usually based on a
consideration of only one or two dimensions of a
database system The purpose of this report is not
to claim that decomposition is better Instead, we
claim that the consensus opinion is not well
founded and that neither is clearly better until a
closer analysis is made along the many dimensions
of a database system The purpose of this report
is to move further in both scope and depth toward
such an analysis We examine such dimensions as
simplicity, generality, storage requirements,
update performance and retrieval performance</em></p></blockquote>
<p><a href=\"http://www3.in.tum.de/teaching/ws0506/MMDBMS/download/decomposition-storage-model.pdf\"><em>A Decomposition Storage Model</em></a>, George P. Copeland and Setrag N. Khoshafian, in the Proceedings of the 1985 SIGMOD International Conference on Management of Data</p>" "http://www.allthingsdistributed.com/2013/09/column-oriented-databases.html" (21052 34328) old 10 nil nil ((title nil "Back-to-Basics Weekend Reading - A Decomposition Storage Model") (link ((href . "http://www.allthingsdistributed.com/2013/09/column-oriented-databases.html"))) (updated nil "2013-09-20T17:30:00Z") (id nil "http://www.allthingsdistributed.com/2013/09/column-oriented-databases") (content ((type . "html")) "<p><img src=\"/images/sin-garden.jpg\"/ width=\"650\"></p>

<p>Traditionally records in a database were stored as such: the data in a row was stored together for easy and fast retrieval. Not everybody agreed that the \"N-ary Storage Model\" (NSM) was the best approach for all workloads but it stayed dominant until hardware constraints, especially on caches, forced the community to revisit some of the alternatives. Combined with the rise of data warehouse workloads, where there is often significant redundancy in the values stored in columns, and  database models based on column oriented storage took off. The first practical modern implementation is probably <a href=\"http://db.csail.mit.edu/projects/cstore/vldb.pdf\">C-Store by Stonebraker, et al.</a> in 2005. There is a great tutorial by <a href=\"http://www.cs.yale.edu/homes/dna/talks/Column_Store_Tutorial_VLDB09.pdf\">Harizopoulos, Abadi and Boncz from VLDB 2009</a> that takes you through the history, trade-off's and the state of the art. Many of the modern high-performance data warehouses such as <a href=\"http://aws.amazon.com/redshift\">Amazon Redshift</a> are based on column stores.</p>

<p>But the groundwork for Column Oriented Databases was laid in 1985 when George Copeland and Setrag Koshafian questioned the NSM with their seminal paper on a \"Decomposition Storage Model\" (DSM). From the abstract:</p>

<blockquote><p><em>There seems to be a general consensus among
the database community that the n-ary approach is
better This conclusion is usually based on a
consideration of only one or two dimensions of a
database system The purpose of this report is not
to claim that decomposition is better Instead, we
claim that the consensus opinion is not well
founded and that neither is clearly better until a
closer analysis is made along the many dimensions
of a database system The purpose of this report
is to move further in both scope and depth toward
such an analysis We examine such dimensions as
simplicity, generality, storage requirements,
update performance and retrieval performance</em></p></blockquote>

<p><a href=\"http://www3.in.tum.de/teaching/ws0506/MMDBMS/download/decomposition-storage-model.pdf\"><em>A Decomposition Storage Model</em></a>, George P. Copeland and Setrag N. Khoshafian, in the Proceedings of the 1985 SIGMOD International Conference on Management of Data</p>
"))) ("Dutch Enterprises and The Cloud" "<p><img src=\"/images/ams.jpg\"/ width=\"650\"></p>
<p>This spring I travelled through Europe for the AWS Global Summit series.
In my many conversations with customers, and with the media, I
encountered surprise and excitement about the extent that European
enterprises have already been using the Amazon Web Services for some
time. Whether it is large telecommunications manufactures like <a href=\"http://nsn.com/\">Nokia
Siemens Networks</a> running their real-time data analytics for network
operators on AWS, or a luxury hotel chain like <a href=\"http://www.kempinski.com/\">Kempinski</a> moving their
core IT functions to AWS such that they can get out of the IT business,
or a major newspaper corporation like <a href=\"http://news.co.uk/\">News International</a>, who plan to
have 75% of their infrastructure running on AWS within 3 years to
improve their agility, European enterprises have been moving to the
cloud for some time to become more agile and competitive.</p>
<p>Europe is a continent with much diversity and for each country there are
great AWS customer examples to tell.  Given that I am originally from
the Netherlands I have, of course, a special interest in how Dutch
companies are using our cloud services.  </p>
<p>For many young Dutch businesses AWS is the platform of choice such that
they can grow unconstrained, targeting a global customer base, in the
most cost-effective manner possible. There is long list of success
stories:
<a href=\"http://WeTransfer.com\">WeTransfer</a>,
<a href=\"http://Floorplanner.com\">Floorplanner</a>,
<a href=\"http://Mobypicture.com\">Mobypicture</a>,
<a href=\"http://Albumprinter.nl\">Albumprinter</a>,
<a href=\"http://wercker.com\">Wercker</a>,
<a href=\"http://c9.io\">Cloud9</a>,
<a href=\"http://www.silkapp.com/\">Silk</a>,
<a href=\"https://www.layar.com/\">Layar</a>,
<a href=\"https://yourkarma.com/\">Karma</a>,
<a href=\"http://wakoopa.com\">Wakoopa</a>,
<a href=\"http://peecho.com\">Peecho</a>,
<a href=\"http://foodzy.com\">Foodzy</a>
<a href=\"http://usabila.com\">Usabila</a>
and many, many more.</p></p>
<p>But it is not just Dutch entrepreneurs who build their business in the
cloud, also traditional Dutch enterprises are moving to the cloud to
improve their agility and cost-effectiveness. Here are some great
examples from different industries each with unique use cases.</p>
<ul>
<li><p><strong>Royal Dutch Shell</strong> – is one of the world’s largest companies. In
addition to its goal of reducing energy costs, Shell needed to be more
agile in deploying IT services and planning for user demand. To reach
those goals, Shell in 2010 began using AWS.  Shell leverages sensors to
find oil in wells formerly thought to have run dry or in places where
previous exploration indicated there was no oil. These sensors create
massive amounts of geological data. Shell's IT shop has to figure out
how to drive costs down, effectively manage the giant files and make it
profitable for the company to deploy these sensors.   Shell leverages
AWS for big data analytics to help achieve these goals. Shell's
scientists, especially the geophysicists and drilling engineers,
frequently use cloud computing to run models. They provision compute
capacity themselves, run their models and then return the cloud compute
capacity, getting charged only for what they used. Shell says that two
hundred and 300 project teams could be up and running in a day versus
the weeks it would take them prior to AWS.</p></li>
<li><p><strong>Unilever</strong> – Unilever R&amp;D program intended to accelerate the company’s
scientific progress through improved access to global information. Due
to the exponential growth of the biology and informatics fields,
Unilever needs to maintain this new program within a highly-scalable
environment that supports parallel computation and heavy data storage
demands. It makes use of the Eagle Genomics platform running on AWS,
resulting in that Unilever’s digital data program now processes genetic
sequences twenty times faster—without incurring higher compute costs. In
addition, its robust architecture supports ten times as many scientists,
all working simultaneously. This genetics R&amp;D is crucial for Unliver to
develop new products faster; for example comparing a healthy mouth with
one with gingivitis - by identifying the shared genes amongst these two
can be very helpful in developing the next generation of toothpaste.</p></li>
<li><p><strong>Essent</strong> – supplies customers in the Benelux region with gas,
electricity, heat and energy services. Essent has moved to the cloud to
take advantage of the low, pay-as you-go, cost model and also the
flexibility and scalability the cloud provides. Essent currently hosts
all of their public facing websites and customer self-service portals in
the AWS cloud. By offloading the task of managing infrastructure to AWS
Essent is able to spend more time on innovating on behalf of their
customers to help them in their energy usage. The company has used AWS
to build an IT innovation zone, based upon open source products, which
is being used to launch new innovations for customers like E-Mobility
and E-thermostat products with a very fast time-to-market.</p></li>
<li><p><strong>Tom Tom – </strong>Founded in 1991, TomTom is a leading provider of
navigation and location-based products and services. In 2012 Tom Tom
launched a new Location Based Services (LBS) platform to give app
developers easy access to its mapping content to be able to incorporate
rich location based data into their applications. When Tom Tom launched
the LBS platform they wanted the ability to reach millions of developers
all around the world without having them invest a lot of capital upfront
in hardware and building expensive data centers so turned to the cloud.
Using cloud computing as the underlying technology to run the LBS
platform Tom Tom is able to provide developers with on-demand content
that will enable them to build location based applications for fleet
management, route planning, traffic management or spatial analytics. </p></li>
<li><p><strong>Ohpen</strong> – The Dutch banking regulator, De Nederlandsche Bank (DNB),
has cleared the path for Dutch financial institutions to make use of
AWS.  Dutch firm Ohpen has already moved to take advantage of the ruling
by choosing AWS to host its core banking platform in an on-demand,
software-as-a-service environment. According to Chris Zadeh, the CEO of
Ohpen,  large Dutch banks are already moving their entire retail banking
platforms to the cloud using Ohpen core banking technology running on
top of AWS.</p></li>
</ul>
<p>These are just some of the public enterprise references from the
Netherlands, but from personal conversations I know that in almost
industry vertical Dutch companies are moving ahead rapidly to ensure
that they can keep up with the global competition. Dutch enterprises
from Media &amp; Advertising, Financial Services, Energy, Transportation and
Shipping, Life Sciences and Healthcare are experiencing the
transformative nature of Cloud Computing; how IT can be enabler of
innovation and greatly improve agility with traditional organizations.</p>
<p>I have picked the Netherlands as the obvious example, but the Dutch are
not an exception; I can tell similar stories for almost all European
countries. Enterprises in Europe are rapidly embracing cloud computing
to continue to compete globally, and at AWS we are proud to help them
achieve their goals.</p>
<p>On September 26 there is an AWS Summit in the Beurs van Berlage in
Amsterdam for those from the Benelux interested in hearing how customers
are making use of AWS and hearing the details about the AWS business and
technologies. You can find more details and registration information at <a href=\"http://aws.amazon.com/aws-summit-benelux-2013/amsterdam/\">http://aws.amazon.com/aws-summit-benelux-2013/amsterdam/</a> </p>" "http://www.allthingsdistributed.com/2013/09/dutch-enterprise-and-the-cloud.html" (21033 6912) old 11 nil nil ((title nil "Dutch Enterprises and The Cloud") (link ((href . "http://www.allthingsdistributed.com/2013/09/dutch-enterprise-and-the-cloud.html"))) (updated nil "2013-09-06T00:00:00Z") (id nil "http://www.allthingsdistributed.com/2013/09/dutch-enterprise-and-the-cloud") (content ((type . "html")) "<p><img src=\"/images/ams.jpg\"/ width=\"650\"></p>

<p>This spring I travelled through Europe for the AWS Global Summit series.
In my many conversations with customers, and with the media, I
encountered surprise and excitement about the extent that European
enterprises have already been using the Amazon Web Services for some
time. Whether it is large telecommunications manufactures like <a href=\"http://nsn.com/\">Nokia
Siemens Networks</a> running their real-time data analytics for network
operators on AWS, or a luxury hotel chain like <a href=\"http://www.kempinski.com/\">Kempinski</a> moving their
core IT functions to AWS such that they can get out of the IT business,
or a major newspaper corporation like <a href=\"http://news.co.uk/\">News International</a>, who plan to
have 75% of their infrastructure running on AWS within 3 years to
improve their agility, European enterprises have been moving to the
cloud for some time to become more agile and competitive.</p>

<p>Europe is a continent with much diversity and for each country there are
great AWS customer examples to tell.  Given that I am originally from
the Netherlands I have, of course, a special interest in how Dutch
companies are using our cloud services.  </p>

<p>For many young Dutch businesses AWS is the platform of choice such that
they can grow unconstrained, targeting a global customer base, in the
most cost-effective manner possible. There is long list of success
stories:
<a href=\"http://WeTransfer.com\">WeTransfer</a>,
<a href=\"http://Floorplanner.com\">Floorplanner</a>,
<a href=\"http://Mobypicture.com\">Mobypicture</a>,
<a href=\"http://Albumprinter.nl\">Albumprinter</a>,
<a href=\"http://wercker.com\">Wercker</a>,
<a href=\"http://c9.io\">Cloud9</a>,
<a href=\"http://www.silkapp.com/\">Silk</a>,
<a href=\"https://www.layar.com/\">Layar</a>,
<a href=\"https://yourkarma.com/\">Karma</a>,
<a href=\"http://wakoopa.com\">Wakoopa</a>,
<a href=\"http://peecho.com\">Peecho</a>,
<a href=\"http://foodzy.com\">Foodzy</a>
<a href=\"http://usabila.com\">Usabila</a>
and many, many more.</p></p>

<p>But it is not just Dutch entrepreneurs who build their business in the
cloud, also traditional Dutch enterprises are moving to the cloud to
improve their agility and cost-effectiveness. Here are some great
examples from different industries each with unique use cases.</p>

<ul>
<li><p><strong>Royal Dutch Shell</strong> – is one of the world’s largest companies. In
addition to its goal of reducing energy costs, Shell needed to be more
agile in deploying IT services and planning for user demand. To reach
those goals, Shell in 2010 began using AWS.  Shell leverages sensors to
find oil in wells formerly thought to have run dry or in places where
previous exploration indicated there was no oil. These sensors create
massive amounts of geological data. Shell's IT shop has to figure out
how to drive costs down, effectively manage the giant files and make it
profitable for the company to deploy these sensors.   Shell leverages
AWS for big data analytics to help achieve these goals. Shell's
scientists, especially the geophysicists and drilling engineers,
frequently use cloud computing to run models. They provision compute
capacity themselves, run their models and then return the cloud compute
capacity, getting charged only for what they used. Shell says that two
hundred and 300 project teams could be up and running in a day versus
the weeks it would take them prior to AWS.</p></li>
<li><p><strong>Unilever</strong> – Unilever R&amp;D program intended to accelerate the company’s
scientific progress through improved access to global information. Due
to the exponential growth of the biology and informatics fields,
Unilever needs to maintain this new program within a highly-scalable
environment that supports parallel computation and heavy data storage
demands. It makes use of the Eagle Genomics platform running on AWS,
resulting in that Unilever’s digital data program now processes genetic
sequences twenty times faster—without incurring higher compute costs. In
addition, its robust architecture supports ten times as many scientists,
all working simultaneously. This genetics R&amp;D is crucial for Unliver to
develop new products faster; for example comparing a healthy mouth with
one with gingivitis - by identifying the shared genes amongst these two
can be very helpful in developing the next generation of toothpaste.</p></li>
<li><p><strong>Essent</strong> – supplies customers in the Benelux region with gas,
electricity, heat and energy services. Essent has moved to the cloud to
take advantage of the low, pay-as you-go, cost model and also the
flexibility and scalability the cloud provides. Essent currently hosts
all of their public facing websites and customer self-service portals in
the AWS cloud. By offloading the task of managing infrastructure to AWS
Essent is able to spend more time on innovating on behalf of their
customers to help them in their energy usage. The company has used AWS
to build an IT innovation zone, based upon open source products, which
is being used to launch new innovations for customers like E-Mobility
and E-thermostat products with a very fast time-to-market.</p></li>
<li><p><strong>Tom Tom – </strong>Founded in 1991, TomTom is a leading provider of
navigation and location-based products and services. In 2012 Tom Tom
launched a new Location Based Services (LBS) platform to give app
developers easy access to its mapping content to be able to incorporate
rich location based data into their applications. When Tom Tom launched
the LBS platform they wanted the ability to reach millions of developers
all around the world without having them invest a lot of capital upfront
in hardware and building expensive data centers so turned to the cloud.
Using cloud computing as the underlying technology to run the LBS
platform Tom Tom is able to provide developers with on-demand content
that will enable them to build location based applications for fleet
management, route planning, traffic management or spatial analytics. </p></li>
<li><p><strong>Ohpen</strong> – The Dutch banking regulator, De Nederlandsche Bank (DNB),
has cleared the path for Dutch financial institutions to make use of
AWS.  Dutch firm Ohpen has already moved to take advantage of the ruling
by choosing AWS to host its core banking platform in an on-demand,
software-as-a-service environment. According to Chris Zadeh, the CEO of
Ohpen,  large Dutch banks are already moving their entire retail banking
platforms to the cloud using Ohpen core banking technology running on
top of AWS.</p></li>
</ul>


<p>These are just some of the public enterprise references from the
Netherlands, but from personal conversations I know that in almost
industry vertical Dutch companies are moving ahead rapidly to ensure
that they can keep up with the global competition. Dutch enterprises
from Media &amp; Advertising, Financial Services, Energy, Transportation and
Shipping, Life Sciences and Healthcare are experiencing the
transformative nature of Cloud Computing; how IT can be enabler of
innovation and greatly improve agility with traditional organizations.</p>

<p>I have picked the Netherlands as the obvious example, but the Dutch are
not an exception; I can tell similar stories for almost all European
countries. Enterprises in Europe are rapidly embracing cloud computing
to continue to compete globally, and at AWS we are proud to help them
achieve their goals.</p>

<p>On September 26 there is an AWS Summit in the Beurs van Berlage in
Amsterdam for those from the Benelux interested in hearing how customers
are making use of AWS and hearing the details about the AWS business and
technologies. You can find more details and registration information at <a href=\"http://aws.amazon.com/aws-summit-benelux-2013/amsterdam/\">http://aws.amazon.com/aws-summit-benelux-2013/amsterdam/</a> </p>
"))) ("DynamoDB for Location Data: Geospatial querying on DynamoDB datasets" "<p>Over the past few years, two important trends that have been disrupting the database industry are mobile applications and big data.  The explosive growth in mobile devices and mobile apps is generating a huge amount of data, which has fueled the demand for big data services and for high scale databases. Meanwhile, mobile app developers have shown that they care a lot about getting to market quickly, the ability to easily scale their app from 100 users to 1 million users on day 1, and the extreme low latency database performance that is crucial to ensure a great end-user experience. These factors have made DynamoDB a compelling database for mobile developers, who happen to be among the biggest adopters of this technology. For example, <a href=\"https://www.crittercism.com/\">Crittercism</a>, a mobile application performance management company, uses DynamoDB to monitor the performance and stability of mobile apps on over 600 million devices with billions of daily transactions.</p>
<p>“We picked DynamoDB because it supports the scale we require\" said <a href=\"https://twitter.com/robkwok\">Robert Kwok</a>, CTO of Crittercism. \"Our business is growing rapidly, and DynamoDB allows us to immediately scale up to support sudden increases in our workload. Switching to DynamoDB also reduced our costs by an order of magnitude and eliminated engineering efforts that used to come with growing our database layer.\"</p>
<p>Similarly, <a href=\"http://www.earthnetworks.com/\">Earth Networks</a> uses DynamoDB to power its lightning alert system, which gives millions of users real time access to live streaming lightning data, while <a href=\"https://www.dropcam.com/\">Dropcam</a> uses DynamoDB to power its cloud based monitoring system which has become one of the biggest video streaming platforms in the world. These innovative developers chose DynamoDB because it allows them to scale seamlessly without compromising on performance or cost.</p>
<p>The blooming mobile industry has made location data ubiquitous and offers mobile developers opportunities to build a whole new breed of novel mobile applications. Many mobile apps have features that help customers find nearby points of interest (e.g. “Find the closest coffee shop”), access location-specific offers, and find friends in your vicinity. Today, we are launching a geospatial indexing library that helps our customers build location-aware features by executing geospatial queries on their datasets in DynamoDB.  With this library, you can:</p>
<ul>
<li>Efficiently store points of interest (POIs) and run exploration spatial queries</li>
<li>Calculate great circle distances and perform spherical math. For example, “find points of interest near me”.</li>
</ul>
<p>We put together a sample application that shows the power of the library we are launching today. For more details on this library, which you can <a href=\"https://github.com/awslabs/dynamodb-geo\">find on github</a>, please take a look at <a href=\"http://aws.typepad.com/aws/2013/09/new-geo-library-for-dynamodb-.html\">Jeff Barr’s blog</a>.</p>" "http://www.allthingsdistributed.com/2013/09/dynamodb-geospatial.html" (21032 38248) old 12 nil nil ((title nil "DynamoDB for Location Data: Geospatial querying on DynamoDB datasets") (link ((href . "http://www.allthingsdistributed.com/2013/09/dynamodb-geospatial.html"))) (updated nil "2013-09-05T14:30:00Z") (id nil "http://www.allthingsdistributed.com/2013/09/dynamodb-geospatial") (content ((type . "html")) "<p>Over the past few years, two important trends that have been disrupting the database industry are mobile applications and big data.  The explosive growth in mobile devices and mobile apps is generating a huge amount of data, which has fueled the demand for big data services and for high scale databases. Meanwhile, mobile app developers have shown that they care a lot about getting to market quickly, the ability to easily scale their app from 100 users to 1 million users on day 1, and the extreme low latency database performance that is crucial to ensure a great end-user experience. These factors have made DynamoDB a compelling database for mobile developers, who happen to be among the biggest adopters of this technology. For example, <a href=\"https://www.crittercism.com/\">Crittercism</a>, a mobile application performance management company, uses DynamoDB to monitor the performance and stability of mobile apps on over 600 million devices with billions of daily transactions.</p>

<p>“We picked DynamoDB because it supports the scale we require\" said <a href=\"https://twitter.com/robkwok\">Robert Kwok</a>, CTO of Crittercism. \"Our business is growing rapidly, and DynamoDB allows us to immediately scale up to support sudden increases in our workload. Switching to DynamoDB also reduced our costs by an order of magnitude and eliminated engineering efforts that used to come with growing our database layer.\"</p>

<p>Similarly, <a href=\"http://www.earthnetworks.com/\">Earth Networks</a> uses DynamoDB to power its lightning alert system, which gives millions of users real time access to live streaming lightning data, while <a href=\"https://www.dropcam.com/\">Dropcam</a> uses DynamoDB to power its cloud based monitoring system which has become one of the biggest video streaming platforms in the world. These innovative developers chose DynamoDB because it allows them to scale seamlessly without compromising on performance or cost.</p>

<p>The blooming mobile industry has made location data ubiquitous and offers mobile developers opportunities to build a whole new breed of novel mobile applications. Many mobile apps have features that help customers find nearby points of interest (e.g. “Find the closest coffee shop”), access location-specific offers, and find friends in your vicinity. Today, we are launching a geospatial indexing library that helps our customers build location-aware features by executing geospatial queries on their datasets in DynamoDB.  With this library, you can:</p>

<ul>
<li>Efficiently store points of interest (POIs) and run exploration spatial queries</li>
<li>Calculate great circle distances and perform spherical math. For example, “find points of interest near me”.</li>
</ul>


<p>We put together a sample application that shows the power of the library we are launching today. For more details on this library, which you can <a href=\"https://github.com/awslabs/dynamodb-geo\">find on github</a>, please take a look at <a href=\"http://aws.typepad.com/aws/2013/09/new-geo-library-for-dynamodb-.html\">Jeff Barr’s blog</a>.</p>
"))) ("Expanding the Cloud: More memory, more caching and more performance for your data" "<p>Today, we added two important choices for customers running high performance apps in the cloud: support for <a href=\"http://redis.io/\">Redis</a> in <a href=\"http://aws.amazon.com/elasticache\">Amazon ElastiCache</a> and a new high memory database instance (db.cr1.8xlarge) for <a href=\"http://aws.amazon.com/rds\">Amazon RDS</a>.</p>
<p>As we prepared to launch these features, I was struck not only by the range of services we provide to enable customers to run fully managed, scalable, high performance database workloads, including <a href=\"http://aws.amazon.com/rds\">Amazon RDS</a>, <a href=\"http://aws.amazon.com/dynamodb\">Amazon DynamoDB</a>, <a href=\"http://aws.amazon.com/redshift\">Amazon Redshift</a> and <a href=\"http://aws.amazon.com/elasticache\">Amazon ElastiCache</a>, but also by the pace at which these services are evolving and improving. Since you now have lots of choices to address your high performance database needs, I decided to write this blog to help you select the most appropriate services for your workload using lessons I have learnt by scaling the infrastructure for Amazon.com.</p>
<p>Choosing your database architecture may be the most critical decision you’ll make and has a disproportionate impact on the performance, scalability, and availability of your app. Get it right and your application will seamlessly scale from hundreds to tens of millions of users without difficulty, while remaining performant and available. Get it wrong and you’re looking at sleepless nights, struggling to keep up with growth and fighting to keep your app available while you rewrite critical portions of your code. Since databases are complex and have so much impact on our customers’ apps, from day 1 we have believed in delivering managed services and taking on the burden of provisioning, configuring, securing, backing up and restoring databases to enable our customers to focus on what they do best, which is to develop awesome apps for their users.</p>
<p>No single database architecture or solution can meet all of Amazon.com’s or our customers’ needs. For example, even within relational databases, some of the 3rd party apps we use at Amazon are only certified to run using Oracle databases whereas others use MySQL databases. Certain parts of our architecture used to run on relational databases but we just couldn’t scale them fast enough to meet the demands of our fast growing online retail business, particularly during the holiday shopping seasons. We endured significant disruptions to our retail infrastructure in early 2000s and had to invent a new category of databases like <a href=\"http://www.allthingsdistributed.com/2007/10/amazons_dynamo.html\">Dynamo</a> that has come to be known as NoSQL. Since we moved these parts of our architecture to <a href=\"http://aws.amazon.com/dynamodb\">DynamoDB</a> we can’t imagine doing it any other way because we don’t know of another solution that can seamlessly scale to our transaction rates while maintaining our stringent 100% availability demands. While we use DynamoDB extensively, we also have relational databases in other parts of our stack and they are equally critical.</p>
<p>AWS offers its customers a choice of different database services, each optimized for different workloads. <strong>DynamoDB</strong> is for customers who want high availability, predictable performance and scalability and we limit some relational functionality to achieve these critical requirements. <strong>Amazon RDS</strong>, with support for MySQL, SQL Server and Oracle databases, is for customers with apps where relational database features and support for a specific brand of database are critical. We offer high availability options called <a href=\"http://aws.amazon.com/rds/multi-az/\">Amazon RDS Multi-AZ</a> and commit to an availability SLA of 99.95%. We allow customers to provision the number of input and output operations (IOPS) they require by using Amazon RDS with Provisioned IOPS. <strong>Amazon ElastiCache</strong> is a fully managed, in-memory caching service for customers to optimize the latency, performance and cost of their read workloads. For our customers who need scalable datawarehouse we offer <strong>Amazon Redshift</strong>, a fast, fully managed, petabyte-scale data warehouse service that makes it simple and cost-effective to efficiently analyze all your data using your existing business intelligence tools.</p>
<p>Today, we are further expanding the choices available for designing and developing highly scalable and high performance apps. In a relational database, the memory working set size is critical for database performance. As the amount of data stored increases constantly, the amount of memory needed also goes up. To address this, we are adding support for a new memory-optimized instance to Amazon RDS. The db.cr1.8xlarge has 88 ECUs, 244GB of memory, high-bandwidth network, and the ability to deliver up to 20,000 IOPS for MySQL 5.6, an increase of 60 percent over the prior 12,500 IOPS limit for MySQL. This is an ideal instance for high-performance relational workloads.</p>
<p>Similar to how we offer multiple engines in Amazon RDS, starting today, we are supporting <a href=\"http://redis.io/\">Redis</a> as a new engine choice in Amazon ElastiCache, in addition to Memcached. I’ve seen Redis grow rapidly over the years and while some customers use it as a primary datastore, its main benefit is to augment your database tier to utilize data structures such as sorted sets and lists that are not readily available in traditional databases. Customers tell us that they love the ease of use and capabilities of Redis, but have been asking us to help simplify its management. Amazon ElastiCache for Redis provides the full capabilities of Redis and is designed to enable your existing libraries, applications and tools for Redis to just work. Amazon ElastiCache supports creation of Redis read replicas across availability zones and automatically detects and replaces failed read replicas. Integration with <a href=\"http://aws.amazon.com/cloudwatch/\">Amazon CloudWatch</a> gives customers visibility into key performance metrics, further simplifying system management.</p>
<p>Many developers tell us that they want to rely on AWS to manage their databases so that they can spend their effort on building apps. For example, Scopely has built their gaming platform with DynamoDB as their primary datastore, while using Amazon RDS where they need complex query support. For features that need data structures like sorted sets (e.g., leaderboards) they have been using Redis. With the launch of Redis in ElastiCache, <a href=\"http://scopely.com\">Scopely</a> is planning to move its self-managed Redis to Amazon ElastiCache to obtain the added benefits of monitoring and management without having to change its existing Redis toolchain. Similarly, <a href=\"http://gu3.co.jp/en/\">gumi</a>, one of the top game developers in Japan, uses Redis extensively in their platform for real-time leaderboard tracking in addition to their usage of RDS Multi AZ and DynamoDB. gumi used to manage a large Redis fleet and is excited to begin moving away from the undifferentiated heavy lifting of self-managing Redis by adopting ElastiCache Redis.</p>
<p>There are many customers like Scopely and gumi who believe they should “use the best tool for the specific use case”, but selecting the right database architecture can be challenging. To simplify the selection process, I recommend a simple rule of thumb: For critical workloads which need to be highly available, at any scale, I generally recommend DynamoDB as it offers seamless scalability, predictable performance and high availability at low cost without any operational overhead. For workloads that need complex querying, transactions or specific relational features, I recommend Amazon RDS. It provides customers with familiar MySQL, Microsoft SQL Server or Oracle database engines while simplifying the monitoring and management of complex RDBMSs. You can augment your database tier with a caching layer using Amazon ElastiCache to lower read costs and reduce read latency using Memcached and now Redis, especially if you need those advanced data structures that are not typically provided by your database tier. You can analyze all of your data stored in DynamoDB or RDS using Amazon Redshift, a fully managed petabyte-scale data warehouse service that delivers increased query performance when analyzing virtually any size dataset for a tenth the cost of most traditional data warehousing solutions.</p>
<p>We believe in providing customers with building blocks that allow them to construct the apps they need and I’m excited to see what they’re going to do with the new options we’re announcing today.</p>
<p>To learn more about Amazon RDS and the new instance type, you can visit <a href=\"http://aws.amazon.com/rds\">http://aws.amazon.com/rds</a></p>
<p>To learn more about ElastiCache Redis, please refer to <a href=\"http://aws.typepad.com/aws/2013/09/amazon-elasticache-now-with-a-dash-of-redis.html\">Jeff Barr’s blog</a> and visit <a href=\"http://aws.amazon.com/elasticache\">http://aws.amazon.com/elasticache</a></p>" "http://www.allthingsdistributed.com/2013/09/amazon-elasticache-redis.html" (21030 9120) old 13 nil nil ((title nil "Expanding the Cloud: More memory, more caching and more performance for your data	") (link ((href . "http://www.allthingsdistributed.com/2013/09/amazon-elasticache-redis.html"))) (updated nil "2013-09-03T18:00:00Z") (id nil "http://www.allthingsdistributed.com/2013/09/amazon-elasticache-redis") (content ((type . "html")) "<p>Today, we added two important choices for customers running high performance apps in the cloud: support for <a href=\"http://redis.io/\">Redis</a> in <a href=\"http://aws.amazon.com/elasticache\">Amazon ElastiCache</a> and a new high memory database instance (db.cr1.8xlarge) for <a href=\"http://aws.amazon.com/rds\">Amazon RDS</a>.</p>

<p>As we prepared to launch these features, I was struck not only by the range of services we provide to enable customers to run fully managed, scalable, high performance database workloads, including <a href=\"http://aws.amazon.com/rds\">Amazon RDS</a>, <a href=\"http://aws.amazon.com/dynamodb\">Amazon DynamoDB</a>, <a href=\"http://aws.amazon.com/redshift\">Amazon Redshift</a> and <a href=\"http://aws.amazon.com/elasticache\">Amazon ElastiCache</a>, but also by the pace at which these services are evolving and improving. Since you now have lots of choices to address your high performance database needs, I decided to write this blog to help you select the most appropriate services for your workload using lessons I have learnt by scaling the infrastructure for Amazon.com.</p>

<p>Choosing your database architecture may be the most critical decision you’ll make and has a disproportionate impact on the performance, scalability, and availability of your app. Get it right and your application will seamlessly scale from hundreds to tens of millions of users without difficulty, while remaining performant and available. Get it wrong and you’re looking at sleepless nights, struggling to keep up with growth and fighting to keep your app available while you rewrite critical portions of your code. Since databases are complex and have so much impact on our customers’ apps, from day 1 we have believed in delivering managed services and taking on the burden of provisioning, configuring, securing, backing up and restoring databases to enable our customers to focus on what they do best, which is to develop awesome apps for their users.</p>

<p>No single database architecture or solution can meet all of Amazon.com’s or our customers’ needs. For example, even within relational databases, some of the 3rd party apps we use at Amazon are only certified to run using Oracle databases whereas others use MySQL databases. Certain parts of our architecture used to run on relational databases but we just couldn’t scale them fast enough to meet the demands of our fast growing online retail business, particularly during the holiday shopping seasons. We endured significant disruptions to our retail infrastructure in early 2000s and had to invent a new category of databases like <a href=\"http://www.allthingsdistributed.com/2007/10/amazons_dynamo.html\">Dynamo</a> that has come to be known as NoSQL. Since we moved these parts of our architecture to <a href=\"http://aws.amazon.com/dynamodb\">DynamoDB</a> we can’t imagine doing it any other way because we don’t know of another solution that can seamlessly scale to our transaction rates while maintaining our stringent 100% availability demands. While we use DynamoDB extensively, we also have relational databases in other parts of our stack and they are equally critical.</p>

<p>AWS offers its customers a choice of different database services, each optimized for different workloads. <strong>DynamoDB</strong> is for customers who want high availability, predictable performance and scalability and we limit some relational functionality to achieve these critical requirements. <strong>Amazon RDS</strong>, with support for MySQL, SQL Server and Oracle databases, is for customers with apps where relational database features and support for a specific brand of database are critical. We offer high availability options called <a href=\"http://aws.amazon.com/rds/multi-az/\">Amazon RDS Multi-AZ</a> and commit to an availability SLA of 99.95%. We allow customers to provision the number of input and output operations (IOPS) they require by using Amazon RDS with Provisioned IOPS. <strong>Amazon ElastiCache</strong> is a fully managed, in-memory caching service for customers to optimize the latency, performance and cost of their read workloads. For our customers who need scalable datawarehouse we offer <strong>Amazon Redshift</strong>, a fast, fully managed, petabyte-scale data warehouse service that makes it simple and cost-effective to efficiently analyze all your data using your existing business intelligence tools.</p>

<p>Today, we are further expanding the choices available for designing and developing highly scalable and high performance apps. In a relational database, the memory working set size is critical for database performance. As the amount of data stored increases constantly, the amount of memory needed also goes up. To address this, we are adding support for a new memory-optimized instance to Amazon RDS. The db.cr1.8xlarge has 88 ECUs, 244GB of memory, high-bandwidth network, and the ability to deliver up to 20,000 IOPS for MySQL 5.6, an increase of 60 percent over the prior 12,500 IOPS limit for MySQL. This is an ideal instance for high-performance relational workloads.</p>

<p>Similar to how we offer multiple engines in Amazon RDS, starting today, we are supporting <a href=\"http://redis.io/\">Redis</a> as a new engine choice in Amazon ElastiCache, in addition to Memcached. I’ve seen Redis grow rapidly over the years and while some customers use it as a primary datastore, its main benefit is to augment your database tier to utilize data structures such as sorted sets and lists that are not readily available in traditional databases. Customers tell us that they love the ease of use and capabilities of Redis, but have been asking us to help simplify its management. Amazon ElastiCache for Redis provides the full capabilities of Redis and is designed to enable your existing libraries, applications and tools for Redis to just work. Amazon ElastiCache supports creation of Redis read replicas across availability zones and automatically detects and replaces failed read replicas. Integration with <a href=\"http://aws.amazon.com/cloudwatch/\">Amazon CloudWatch</a> gives customers visibility into key performance metrics, further simplifying system management.</p>

<p>Many developers tell us that they want to rely on AWS to manage their databases so that they can spend their effort on building apps. For example, Scopely has built their gaming platform with DynamoDB as their primary datastore, while using Amazon RDS where they need complex query support. For features that need data structures like sorted sets (e.g., leaderboards) they have been using Redis. With the launch of Redis in ElastiCache, <a href=\"http://scopely.com\">Scopely</a> is planning to move its self-managed Redis to Amazon ElastiCache to obtain the added benefits of monitoring and management without having to change its existing Redis toolchain. Similarly, <a href=\"http://gu3.co.jp/en/\">gumi</a>, one of the top game developers in Japan, uses Redis extensively in their platform for real-time leaderboard tracking in addition to their usage of RDS Multi AZ and DynamoDB. gumi used to manage a large Redis fleet and is excited to begin moving away from the undifferentiated heavy lifting of self-managing Redis by adopting ElastiCache Redis.</p>

<p>There are many customers like Scopely and gumi who believe they should “use the best tool for the specific use case”, but selecting the right database architecture can be challenging. To simplify the selection process, I recommend a simple rule of thumb: For critical workloads which need to be highly available, at any scale, I generally recommend DynamoDB as it offers seamless scalability, predictable performance and high availability at low cost without any operational overhead. For workloads that need complex querying, transactions or specific relational features, I recommend Amazon RDS. It provides customers with familiar MySQL, Microsoft SQL Server or Oracle database engines while simplifying the monitoring and management of complex RDBMSs. You can augment your database tier with a caching layer using Amazon ElastiCache to lower read costs and reduce read latency using Memcached and now Redis, especially if you need those advanced data structures that are not typically provided by your database tier. You can analyze all of your data stored in DynamoDB or RDS using Amazon Redshift, a fully managed petabyte-scale data warehouse service that delivers increased query performance when analyzing virtually any size dataset for a tenth the cost of most traditional data warehousing solutions.</p>

<p>We believe in providing customers with building blocks that allow them to construct the apps they need and I’m excited to see what they’re going to do with the new options we’re announcing today.</p>

<p>To learn more about Amazon RDS and the new instance type, you can visit <a href=\"http://aws.amazon.com/rds\">http://aws.amazon.com/rds</a></p>

<p>To learn more about ElastiCache Redis, please refer to <a href=\"http://aws.typepad.com/aws/2013/09/amazon-elasticache-now-with-a-dash-of-redis.html\">Jeff Barr’s blog</a> and visit <a href=\"http://aws.amazon.com/elasticache\">http://aws.amazon.com/elasticache</a></p>
"))) ("Back-to-Basics Weekend Reading - An Introduction to Spatial Database Systems" "<p><img src=\"/images/cochin.jpg\"/ width=\"650\"></p>
<p>Storing and querying datasets that contain objects in a geometric space have always required special treatment. The choice of data structures and query algorithms can easily make the different between a query that runs in seconds or in days. Much of the fundamental work has been done in the late eighties and early nineties, for examples around topological relations (disjoint, meet, equal, overlap, contains, etc.), direction relations (north, north-east, etc.) and distance relations (far, near), and also with respect to spatial data structures (<a href=\"http://wv.ly/18rn6kd\">a great survey</a> by Hanan Samet).</p>
<p>With location becoming a more important attribute to many modern datasets a solid understanding of the tradeoffs is important. In 1994 Ralf Güting wrote an overview of the state of the art for a regular databases audience in a special issue on Spatial Database Systems of the VLDB Journal. It is an extensive but relatively easy read and gives a great introduction to the back-to-basics of Spatial Database Systems.</p>
<p><a href=\"http://wv.ly/18rnNtJ\"><em>An Introduction to Spatial Database Systems</em></a>, Ralf Hartmut Güting, The International Journal on Very Large Data Bases - Special Issues on Spatial Database Systems, Volume 3 Issue 4, October 1994, Pages 357-399</p>" "http://www.allthingsdistributed.com/2013/08/spatial-databases.html" (21024 54936) old 14 nil nil ((title nil "Back-to-Basics Weekend Reading - An Introduction to Spatial Database Systems") (link ((href . "http://www.allthingsdistributed.com/2013/08/spatial-databases.html"))) (updated nil "2013-08-30T17:30:00Z") (id nil "http://www.allthingsdistributed.com/2013/08/spatial-databases") (content ((type . "html")) "<p><img src=\"/images/cochin.jpg\"/ width=\"650\"></p>

<p>Storing and querying datasets that contain objects in a geometric space have always required special treatment. The choice of data structures and query algorithms can easily make the different between a query that runs in seconds or in days. Much of the fundamental work has been done in the late eighties and early nineties, for examples around topological relations (disjoint, meet, equal, overlap, contains, etc.), direction relations (north, north-east, etc.) and distance relations (far, near), and also with respect to spatial data structures (<a href=\"http://wv.ly/18rn6kd\">a great survey</a> by Hanan Samet).</p>

<p>With location becoming a more important attribute to many modern datasets a solid understanding of the tradeoffs is important. In 1994 Ralf Güting wrote an overview of the state of the art for a regular databases audience in a special issue on Spatial Database Systems of the VLDB Journal. It is an extensive but relatively easy read and gives a great introduction to the back-to-basics of Spatial Database Systems.</p>

<p><a href=\"http://wv.ly/18rnNtJ\"><em>An Introduction to Spatial Database Systems</em></a>, Ralf Hartmut Güting, The International Journal on Very Large Data Bases - Special Issues on Spatial Database Systems, Volume 3 Issue 4, October 1994, Pages 357-399</p>
"))) ("Back-to-the-Future Weekend Reading - Distributed GraphLab: A Framework for Machine Learning and Data Mining in the Cloud" "<p><img src=\"/images/taipei.jpg\"/ width=\"650\"></p>
<p>The intense travels around the world in the spring have kept me from keeping up on the historical reading that I would like to do, as such there have not been that many suggesting for the back-to-basics reading list. The fall is going be not that much different but I will make an effort to get back into a reading habit.</p>
<p>I want to kick off the fall readings not with an historical paper but with two that detail <a href=\"http://graphlab.org/\">GraphLab</a>, an excellent framework for high performance machine learning that originally has been built by the <a href=\"http://www.cs.washington.edu/people/faculty/guestrin/\">Carlos Guestrin</a> (Carlos is now the Amazon Professor of Machine Learning at UW). GraphLab has been used to build several different data mining and graph processing toolkits and applications. The research in the papers has been performed on Amazon EC2. Instructions for running your own GraphLab Cluster on EC2 can be found <a href=\"http://graphlab.org/tutorials-2/graphlab-on-ec2-cluster-quick-start/#\">here</a></p>
<p><a href=\"http://wv.ly/188LwyK\"><em>Distributed GraphLab: A Framework for Machine Learning and Data Mining in the Cloud</em></a>, Yucheng Low, Joseph Gonzalez, Aapo Kyrola, Danny Bickson, Carlos Guestrin and Joseph M. Hellerstein, Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 8, pp. 716-727 (2012)</p>
<p><a href=\"http://wv.ly/188Mg6W\"><em>PowerGraph: Distributed Graph-Parallel Computation on Natural Graphs</em></a>, Joseph Gonzalez, Yucheng Low, Haijie Gu, Danny Bickson and Carlos Guestrin, Proceedings of the 10th USENIX conference on Operating Systems Design and Implementation, 2012</p>" "http://www.allthingsdistributed.com/2013/08/graphlab-distributed-machine-learning.html" (21015 20160) old 15 nil nil ((title nil "Back-to-the-Future Weekend Reading - Distributed GraphLab: A Framework for Machine Learning and Data Mining in the Cloud") (link ((href . "http://www.allthingsdistributed.com/2013/08/graphlab-distributed-machine-learning.html"))) (updated nil "2013-08-23T12:00:00Z") (id nil "http://www.allthingsdistributed.com/2013/08/graphlab-distributed-machine-learning") (content ((type . "html")) "<p><img src=\"/images/taipei.jpg\"/ width=\"650\"></p>

<p>The intense travels around the world in the spring have kept me from keeping up on the historical reading that I would like to do, as such there have not been that many suggesting for the back-to-basics reading list. The fall is going be not that much different but I will make an effort to get back into a reading habit.</p>

<p>I want to kick off the fall readings not with an historical paper but with two that detail <a href=\"http://graphlab.org/\">GraphLab</a>, an excellent framework for high performance machine learning that originally has been built by the <a href=\"http://www.cs.washington.edu/people/faculty/guestrin/\">Carlos Guestrin</a> (Carlos is now the Amazon Professor of Machine Learning at UW). GraphLab has been used to build several different data mining and graph processing toolkits and applications. The research in the papers has been performed on Amazon EC2. Instructions for running your own GraphLab Cluster on EC2 can be found <a href=\"http://graphlab.org/tutorials-2/graphlab-on-ec2-cluster-quick-start/#\">here</a></p>

<p><a href=\"http://wv.ly/188LwyK\"><em>Distributed GraphLab: A Framework for Machine Learning and Data Mining in the Cloud</em></a>, Yucheng Low, Joseph Gonzalez, Aapo Kyrola, Danny Bickson, Carlos Guestrin and Joseph M. Hellerstein, Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 8, pp. 716-727 (2012)</p>

<p><a href=\"http://wv.ly/188Mg6W\"><em>PowerGraph: Distributed Graph-Parallel Computation on Natural Graphs</em></a>, Joseph Gonzalez, Yucheng Low, Haijie Gu, Danny Bickson and Carlos Guestrin, Proceedings of the 10th USENIX conference on Operating Systems Design and Implementation, 2012</p>
"))) ("Making Mobile App Development Easier with Cross Platform Mobile Push" "<p>This year as I hosted AWS Summits in 12 different cities around the world, I met thousands of developers who are building powerful new applications for smartphones, tablets and other connected devices, all running mobile cloud backends on AWS.</p>
<p>These developers want to engage their users with timely, dynamic content even when the users haven’t opened their mobile apps.  For example, baseball fans want to know as soon as their favorite team player hits a home run, so they can watch a video replay and catch the rest of the game. The rising proliferation of cheap and powerful sensors means not only apps but smart devices want to communicate important information.  For example, your new car could warn you on your mobile phone when the door is not fully closed, so you can return to lock it properly.</p>
<p>Developers address these use cases with push notifications, which are short messages pushed from a backend server to a specific application on an end user's mobile device.  Push offers similar user experiences to SMS, but with enhanced functionality and at a fraction of the cost.</p>
<p>While we have made it easy to build great mobile apps with AWS that use on-demand, scalable and reliable building blocks like EC2, DynamoDB, SQS and many others, supporting push notifications at large scale remains incredibly complicated for our customers.  Amazon, Apple, and Google each maintains a free relay service that delivers notifications via persistent connections to devices running the platforms they own.  Supporting millions of users on multiple mobile platforms means integrating with each of these platform-specific relay services, thus introducing operational complexity and cost for our customers.</p>
<p>Customers tell us that virtually all use cases for push notifications require an intermediary application to manage security tokens, queue outgoing messages, and abstract platform-specific APIs. Developers have told us that they build and maintain their own intermediary relay applications, even though they find the process of operating these intermediary relay applications to be painful and error prone.  Building these proxy or relay services to be reliable and scalable so that you can push millions of notifications a day is difficult and our customers want us to make it easier.</p>
<p><strong>Announcing Amazon SNS with Mobile Push</strong></p>
<p>Today, we are enhancing <a href=\"http://aws.amazon.com/sns/\">Amazon Simple Notification Service (SNS)</a> with Mobile Push to meet this customer request and support cross platform, device agnostic push notifications to iOS, Android and Kindle mobile devices natively within AWS.  SNS Mobile Push alleviates the need to build and operate one’s own intermediary service, and enables developers to push once, deliver anywhere.  This reduces the cost and complexity for developers, as they do not have to integrate and maintain different versions of the same push software for multiple mobile platforms.  Instead, SNS Mobile Push enables notifications to be delivered directly to everyone who wants to receive them – regardless of which mobile, desktop or connected device they happen to be using.</p>
<p>Developers tell us that managing push notifications at large scale distracts them from building great apps.  In some cases, this work is complex enough that it actually limits what the developers are willing to offer to their customers.  For example, <a href=\"http://www.crittercism.com\">Crittercism</a> tells us that delivering timely push notifications became so burdensome as they grew to touch 600 million devices, that they chose to stop offering push notifications in the past.  They are now able to offer push notifications to their customers again using Amazon SNS and can notify tens of millions of users in a matter of seconds about critical app performance issues.</p>
<p>We chose to enhance Amazon SNS instead of building a separate mobile notification service because Amazon SNS was designed from day 1 to support multiple protocols and delivery methods (Email, SMS, SQS, HTTP etc.) and already operates at a massive scale delivering billions of notifications every day over these delivery methods.</p>
<p>By leveraging the scale of AWS and the existing SNS technology, we are able to offer the same cost effective prices for Mobile Push that we offer for Amazon SNS. Customers can send their first million notifications per month for free and then pay only for what they use beyond that, at $1.00 per million push notifications ($0.50 per million publishes and $0.50 per million push deliveries).  They can use Mobile Push to target unique messages to individual devices, or broadcast identical messages to multiple devices at once.</p>
<p>Customers tell us SNS Mobile Push offers lower costs and operational burden, in addition to powerful scale and speed.  For instance, <a href=\"http://www.earthnetworks.com/\">Earth Networks</a> used to build and manage its own push infrastructure but has now migrated to SNS Mobile Push because Amazon SNS Mobile Push is less expensive than the self-managed service they used to operate.</p>
<p>To get started right away for free with Amazon SNS Mobile Push, visit <a href=\"http://aws.amazon.com/sns\">http://aws.amazon.com/sns</a>.  For more information, please see the <a href=\"http://aws.amazon.com/documentation/sns/\">Amazon SNS documentation</a>, including a getting started guide and reference apps for each mobile platform.</p>" "http://www.allthingsdistributed.com/2013/08/amazon-sns-mobile-push.html" (21001 50264) old 16 nil nil ((title nil "Making Mobile App Development Easier with Cross Platform Mobile Push") (link ((href . "http://www.allthingsdistributed.com/2013/08/amazon-sns-mobile-push.html"))) (updated nil "2013-08-13T05:30:00Z") (id nil "http://www.allthingsdistributed.com/2013/08/amazon-sns-mobile-push") (content ((type . "html")) "<p>This year as I hosted AWS Summits in 12 different cities around the world, I met thousands of developers who are building powerful new applications for smartphones, tablets and other connected devices, all running mobile cloud backends on AWS.</p>

<p>These developers want to engage their users with timely, dynamic content even when the users haven’t opened their mobile apps.  For example, baseball fans want to know as soon as their favorite team player hits a home run, so they can watch a video replay and catch the rest of the game. The rising proliferation of cheap and powerful sensors means not only apps but smart devices want to communicate important information.  For example, your new car could warn you on your mobile phone when the door is not fully closed, so you can return to lock it properly.</p>

<p>Developers address these use cases with push notifications, which are short messages pushed from a backend server to a specific application on an end user's mobile device.  Push offers similar user experiences to SMS, but with enhanced functionality and at a fraction of the cost.</p>

<p>While we have made it easy to build great mobile apps with AWS that use on-demand, scalable and reliable building blocks like EC2, DynamoDB, SQS and many others, supporting push notifications at large scale remains incredibly complicated for our customers.  Amazon, Apple, and Google each maintains a free relay service that delivers notifications via persistent connections to devices running the platforms they own.  Supporting millions of users on multiple mobile platforms means integrating with each of these platform-specific relay services, thus introducing operational complexity and cost for our customers.</p>

<p>Customers tell us that virtually all use cases for push notifications require an intermediary application to manage security tokens, queue outgoing messages, and abstract platform-specific APIs. Developers have told us that they build and maintain their own intermediary relay applications, even though they find the process of operating these intermediary relay applications to be painful and error prone.  Building these proxy or relay services to be reliable and scalable so that you can push millions of notifications a day is difficult and our customers want us to make it easier.</p>

<p><strong>Announcing Amazon SNS with Mobile Push</strong></p>

<p>Today, we are enhancing <a href=\"http://aws.amazon.com/sns/\">Amazon Simple Notification Service (SNS)</a> with Mobile Push to meet this customer request and support cross platform, device agnostic push notifications to iOS, Android and Kindle mobile devices natively within AWS.  SNS Mobile Push alleviates the need to build and operate one’s own intermediary service, and enables developers to push once, deliver anywhere.  This reduces the cost and complexity for developers, as they do not have to integrate and maintain different versions of the same push software for multiple mobile platforms.  Instead, SNS Mobile Push enables notifications to be delivered directly to everyone who wants to receive them – regardless of which mobile, desktop or connected device they happen to be using.</p>

<p>Developers tell us that managing push notifications at large scale distracts them from building great apps.  In some cases, this work is complex enough that it actually limits what the developers are willing to offer to their customers.  For example, <a href=\"http://www.crittercism.com\">Crittercism</a> tells us that delivering timely push notifications became so burdensome as they grew to touch 600 million devices, that they chose to stop offering push notifications in the past.  They are now able to offer push notifications to their customers again using Amazon SNS and can notify tens of millions of users in a matter of seconds about critical app performance issues.</p>

<p>We chose to enhance Amazon SNS instead of building a separate mobile notification service because Amazon SNS was designed from day 1 to support multiple protocols and delivery methods (Email, SMS, SQS, HTTP etc.) and already operates at a massive scale delivering billions of notifications every day over these delivery methods.</p>

<p>By leveraging the scale of AWS and the existing SNS technology, we are able to offer the same cost effective prices for Mobile Push that we offer for Amazon SNS. Customers can send their first million notifications per month for free and then pay only for what they use beyond that, at $1.00 per million push notifications ($0.50 per million publishes and $0.50 per million push deliveries).  They can use Mobile Push to target unique messages to individual devices, or broadcast identical messages to multiple devices at once.</p>

<p>Customers tell us SNS Mobile Push offers lower costs and operational burden, in addition to powerful scale and speed.  For instance, <a href=\"http://www.earthnetworks.com/\">Earth Networks</a> used to build and manage its own push infrastructure but has now migrated to SNS Mobile Push because Amazon SNS Mobile Push is less expensive than the self-managed service they used to operate.</p>

<p>To get started right away for free with Amazon SNS Mobile Push, visit <a href=\"http://aws.amazon.com/sns\">http://aws.amazon.com/sns</a>.  For more information, please see the <a href=\"http://aws.amazon.com/documentation/sns/\">Amazon SNS documentation</a>, including a getting started guide and reference apps for each mobile platform.</p>
"))) ("Feeling the Customer Love for AWS" "<p>We work hard to meet our customer's expectations and to continue to innovate on their behalf. This week at the Singapore AWS Summit we were fortunate that our customers Astro Radio from Kuala Lumpur were willing to join us on stage. Jayaram Gopinath Nagaraj and Kavitha Doraimaickam gave a truly electrifying presentation about how AWS has transformed their radio stations. They also brought with them a video that showed their appreciation on how we enable them to innovate. It's humbling and fun at the same time.</p>
<iframe src=\"http://player.vimeo.com/video/70622714\" width=\"650\" height=\"365\" frameborder=\"0\" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>" "http://www.allthingsdistributed.com/2013/07/Astro-loves-AWS.html" (20969 7216) old 17 nil nil ((title nil "Feeling the Customer Love for AWS") (link ((href . "http://www.allthingsdistributed.com/2013/07/Astro-loves-AWS.html"))) (updated nil "2013-07-19T11:00:00Z") (id nil "http://www.allthingsdistributed.com/2013/07/Astro-loves-AWS") (content ((type . "html")) "<p>We work hard to meet our customer's expectations and to continue to innovate on their behalf. This week at the Singapore AWS Summit we were fortunate that our customers Astro Radio from Kuala Lumpur were willing to join us on stage. Jayaram Gopinath Nagaraj and Kavitha Doraimaickam gave a truly electrifying presentation about how AWS has transformed their radio stations. They also brought with them a video that showed their appreciation on how we enable them to innovate. It's humbling and fun at the same time.</p>

<iframe src=\"http://player.vimeo.com/video/70622714\" width=\"650\" height=\"365\" frameborder=\"0\" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>



"))) ("AWS re:Invent 2013" "<p><img src=\"/images/reinvent2012.jpg\"/ width=\"650\"></p>
<p>The <a href=\"http://reinvent.awsevents.com\">AWS re:Invent</a> user conference <a href=\"http://reinvent.awsevents.com/recap.html\">last year</a> in Las Vegas was by many described as the best technology conference they had been to in a long time. We had worked hard to give you great keynote sessions as well as deep technical content by AWS engineers, partners and customers.</p>
<p>This year we will again work hard to create a conference that will exceed your expectations of a conference that is unique in its high quality content and engagement.You can choose from 175+ sessions, training bootcamps, hands-on labs, and hackathons to gain deeper skills and knowledge of the AWS Cloud. Bring your entire executive and technical teams and walk away with the skills and knowledge to refine your cloud strategy, improve developer productivity, increase application performance and security, and reduce infrastructure costs.</p>
<p>The registration for AWS re:Invent is now open at <a href=\"https://reinvent.awsevents.com/?sc_ichannel=SM&amp;sc_iplace=wernerblog_text_link&amp;sc_icampaigntype=event&amp;sc_icampaign=sm_reinvent2013_register_now&amp;sc_icountry=US&amp;TRK=SM_reinvent2013_wernerblog_text_link_reg\">this site</a>. Sign up before it is too late...</p>
<p>As a taste of what re:Invent is like here is the fireside chat I did last year with Jeff Bezos:</p>
<iframe width=\"640\" height=\"360\" src=\"//www.youtube.com/embed/O4MtQGRIIuA?rel=0\" frameborder=\"0\" allowfullscreen></iframe>" "http://www.allthingsdistributed.com/2013/07/aws-reinvent-2013.html" (20966 52624) old 18 nil nil ((title nil "AWS re:Invent 2013") (link ((href . "http://www.allthingsdistributed.com/2013/07/aws-reinvent-2013.html"))) (updated nil "2013-07-17T17:00:00Z") (id nil "http://www.allthingsdistributed.com/2013/07/aws-reinvent-2013") (content ((type . "html")) "<p><img src=\"/images/reinvent2012.jpg\"/ width=\"650\"></p>

<p>The <a href=\"http://reinvent.awsevents.com\">AWS re:Invent</a> user conference <a href=\"http://reinvent.awsevents.com/recap.html\">last year</a> in Las Vegas was by many described as the best technology conference they had been to in a long time. We had worked hard to give you great keynote sessions as well as deep technical content by AWS engineers, partners and customers.</p>

<p>This year we will again work hard to create a conference that will exceed your expectations of a conference that is unique in its high quality content and engagement.You can choose from 175+ sessions, training bootcamps, hands-on labs, and hackathons to gain deeper skills and knowledge of the AWS Cloud. Bring your entire executive and technical teams and walk away with the skills and knowledge to refine your cloud strategy, improve developer productivity, increase application performance and security, and reduce infrastructure costs.</p>

<p>The registration for AWS re:Invent is now open at <a href=\"https://reinvent.awsevents.com/?sc_ichannel=SM&amp;sc_iplace=wernerblog_text_link&amp;sc_icampaigntype=event&amp;sc_icampaign=sm_reinvent2013_register_now&amp;sc_icountry=US&amp;TRK=SM_reinvent2013_wernerblog_text_link_reg\">this site</a>. Sign up before it is too late...</p>

<p>As a taste of what re:Invent is like here is the fireside chat I did last year with Jeff Bezos:</p>

<iframe width=\"640\" height=\"360\" src=\"//www.youtube.com/embed/O4MtQGRIIuA?rel=0\" frameborder=\"0\" allowfullscreen></iframe>



"))) ("Exerting Fine Grain Control Over Your Cloud Resources" "<p>I am thrilled that now both Amazon EC2 and Amazon RDS support resource-level permissions. As customers move increasing amounts of compute and database workloads over to AWS, they have expressed an increased desire for finer grain control over their underlying resources. You can now use these new features to define the permissions your AWS IAM users (and applications) have to perform actions on specific or groups of Amazon EC2 and Amazon RDS resources.</p>
<p>You can apply user-defined tags to your EC2 and RDS resources to help organize resources according to whatever schema is most relevant for a particular organization – be it an application stack, an organization unit, a cost center, or any other schema that might be appropriate. These user-defined tags can already be used to generate detailed chargeback reports that provide a view into the costs associated with these resources.  And now these user-defined tags can also be used to create AWS IAM policies to define which users have permissions to use the resources that have certain tags associated with them.</p>
<p>For example, you can mandate that only Senior Database Administrators in your company can modify  “production” Amazon RDS DB instances. You do this by first tagging the relevant Amazon RDS DB instance resources as “production” instances, then creating an AWS IAM policy that permits the modify action on these “production” instances, and finally assigning the AWS IAM policy to your group of AWS IAM users who are Senior Database Administrators.</p>
<p>Additionally, you can set policies such as the following:</p>
<ul>
<li>Only certain users can terminate “production” EC2 or RDS instances</li>
<li>Only certain EBS volumes can be attached or detached from certain EC2 instances</li>
<li>Users can only stop or terminate EC2 instances that are tagged with their username</li>
<li>Only certain users can create larger RDS instances (e.g. M2.4Xlarge)</li>
<li>Only certain database engines, parameter groups and security groups can be used by users when they create RDS DB instances</li>
<li>Only certain users can create RDS instances that are Multi-AZ and PIOPs enabled</li>
</ul>
<p>Because AWS provides customers with fundamental infrastructure building blocks, there are a wide range of additional policy scenarios that you can support using tools like IAM, tags, and resource-level permission.  And our development teams are already hard at work on the next wave of features to extend our support for setting and managing resource-level permissions, so expect even more tools to help control your AWS resources soon.</p>" "http://www.allthingsdistributed.com/2013/07/ec2-rds-resource-permissions.html" (20953 45992) old 19 nil nil ((title nil "Exerting Fine Grain Control Over Your Cloud Resources") (link ((href . "http://www.allthingsdistributed.com/2013/07/ec2-rds-resource-permissions.html"))) (updated nil "2013-07-07T18:30:00Z") (id nil "http://www.allthingsdistributed.com/2013/07/ec2-rds-resource-permissions") (content ((type . "html")) "<p>I am thrilled that now both Amazon EC2 and Amazon RDS support resource-level permissions. As customers move increasing amounts of compute and database workloads over to AWS, they have expressed an increased desire for finer grain control over their underlying resources. You can now use these new features to define the permissions your AWS IAM users (and applications) have to perform actions on specific or groups of Amazon EC2 and Amazon RDS resources.</p>

<p>You can apply user-defined tags to your EC2 and RDS resources to help organize resources according to whatever schema is most relevant for a particular organization – be it an application stack, an organization unit, a cost center, or any other schema that might be appropriate. These user-defined tags can already be used to generate detailed chargeback reports that provide a view into the costs associated with these resources.  And now these user-defined tags can also be used to create AWS IAM policies to define which users have permissions to use the resources that have certain tags associated with them.</p>

<p>For example, you can mandate that only Senior Database Administrators in your company can modify  “production” Amazon RDS DB instances. You do this by first tagging the relevant Amazon RDS DB instance resources as “production” instances, then creating an AWS IAM policy that permits the modify action on these “production” instances, and finally assigning the AWS IAM policy to your group of AWS IAM users who are Senior Database Administrators.</p>

<p>Additionally, you can set policies such as the following:</p>

<ul>
<li>Only certain users can terminate “production” EC2 or RDS instances</li>
<li>Only certain EBS volumes can be attached or detached from certain EC2 instances</li>
<li>Users can only stop or terminate EC2 instances that are tagged with their username</li>
<li>Only certain users can create larger RDS instances (e.g. M2.4Xlarge)</li>
<li>Only certain database engines, parameter groups and security groups can be used by users when they create RDS DB instances</li>
<li>Only certain users can create RDS instances that are Multi-AZ and PIOPs enabled</li>
</ul>


<p>Because AWS provides customers with fundamental infrastructure building blocks, there are a wide range of additional policy scenarios that you can support using tools like IAM, tags, and resource-level permission.  And our development teams are already hard at work on the next wave of features to extend our support for setting and managing resource-level permissions, so expect even more tools to help control your AWS resources soon.</p>
"))) ("Back-to-Basics Weekend Reading - Auctions and bidding: A guide for computer scientists" "<p><img src=\"/images/auckland.jpg\"/ width=\"650\"></p>
<p>I have just returned from the AWS Summits in New Zealand and Japan, which were both very well attended and, according to the feedback, very successful. While I was in New Zealand I had great discussion with the folks from <a href=\"http://www.trademe.co.nz/\">Trade Me</a>, the auction site which according to some counts for 70% of all NZ internet traffic. This resulted in some deep technical conversations later, over beer, with some colleagues and customers about the principles behinds different auction and bidding styles. I noticed that my basic knowledge there was rather rusty and I have decided to use this weekend to go a bit more in-depth in the various styles and techniques. An ideal paper for this is the survey by Parsons, Rodriquez-Aguilar and Klein, as it writing style brings economists and computer scientists together.</p>
<blockquote><p><em>There is a veritable menagerie of auctions — single dimensional, multi-dimensional, single sided, double sided, ﬁrst price, second price, English, Dutch, Japanese, sealed bid — and these have been extensively discussed and analysed in the economics literature. The main purpose of this paper is to survey this literature from a computer science perspective, primarily from the viewpoint of computer scientists who are interested in learning about auction theory, and to provide pointers into the economics literature for those who want a deeper technical understanding. In addition, since auctions are an increasingly important topic in computer science, we also look at work on auctions from the computer science literature. Overall, our aim is to identifying what both these bodies of work these tell us about creating electronic auctions.</em></p></blockquote>
<p><a href=\"http://wv.ly/19Tn3RZ\"><em>Auctions and bidding: A guide for computer scientists</em></a>, Simon Parsons, Juan A. Rodriguez-Aguilar and Mark Klein, ACM Computing Surveys (CSUR), Volume 43 Issue 2, January 2011</p>" "http://www.allthingsdistributed.com/2013/06/auctions-and-bidding.html" (20915 28960) old 20 nil nil ((title nil "Back-to-Basics Weekend Reading - Auctions and bidding: A guide for computer scientists") (link ((href . "http://www.allthingsdistributed.com/2013/06/auctions-and-bidding.html"))) (updated nil "2013-06-08T18:00:00Z") (id nil "http://www.allthingsdistributed.com/2013/06/auctions-and-bidding") (content ((type . "html")) "<p><img src=\"/images/auckland.jpg\"/ width=\"650\"></p>

<p>I have just returned from the AWS Summits in New Zealand and Japan, which were both very well attended and, according to the feedback, very successful. While I was in New Zealand I had great discussion with the folks from <a href=\"http://www.trademe.co.nz/\">Trade Me</a>, the auction site which according to some counts for 70% of all NZ internet traffic. This resulted in some deep technical conversations later, over beer, with some colleagues and customers about the principles behinds different auction and bidding styles. I noticed that my basic knowledge there was rather rusty and I have decided to use this weekend to go a bit more in-depth in the various styles and techniques. An ideal paper for this is the survey by Parsons, Rodriquez-Aguilar and Klein, as it writing style brings economists and computer scientists together.</p>

<blockquote><p><em>There is a veritable menagerie of auctions — single dimensional, multi-dimensional, single sided, double sided, ﬁrst price, second price, English, Dutch, Japanese, sealed bid — and these have been extensively discussed and analysed in the economics literature. The main purpose of this paper is to survey this literature from a computer science perspective, primarily from the viewpoint of computer scientists who are interested in learning about auction theory, and to provide pointers into the economics literature for those who want a deeper technical understanding. In addition, since auctions are an increasingly important topic in computer science, we also look at work on auctions from the computer science literature. Overall, our aim is to identifying what both these bodies of work these tell us about creating electronic auctions.</em></p></blockquote>

<p><a href=\"http://wv.ly/19Tn3RZ\"><em>Auctions and bidding: A guide for computer scientists</em></a>, Simon Parsons, Juan A. Rodriguez-Aguilar and Mark Klein, ACM Computing Surveys (CSUR), Volume 43 Issue 2, January 2011</p>
"))))